<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>
    Posts on 
    MLWhiz
    </title>
    <link>https://mlwhiz.com/post/</link>
    <description>Recent content in Posts 
    on MLWhiz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
    
    <lastBuildDate>Fri, 19 Apr 2019 00:00:00 +0000</lastBuildDate>
    
    
        <atom:link href="https://mlwhiz.com/post/atom.xml" rel="self" type="application/rss" />
    
    
    <item>
      <title>3 Awesome Visualization Techniques for every dataset</title>
      <link>https://mlwhiz.com/blog/2019/04/19/awesome_seaborn_visuals/</link>
      <pubDate>Fri, 19 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2019/04/19/awesome_seaborn_visuals/</guid>
      <description>

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/visualizations/kelly_Sikemma.jpeg&#34; style=&#34;height:80%;width:80%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Visualizations are awesome. &lt;strong&gt;However, a good visualization is annoyingly hard to make.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Moreover, it takes time and effort when it comes to present these visualizations to a bigger audience.&lt;/p&gt;

&lt;p&gt;We all know how to make &lt;a href=&#34;https://www.coursera.org/specializations/data-science-python?ranMID=40328&amp;amp;ranEAID=lVarvwc5BD0&amp;amp;ranSiteID=lVarvwc5BD0-SAQTYQNKSERwaOgd07RrHg&amp;amp;siteID=lVarvwc5BD0-SAQTYQNKSERwaOgd07RrHg&amp;amp;utm_content=3&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&amp;amp;ranMID=40328&amp;amp;ranEAID=je6NUbpObpQ&amp;amp;ranSiteID=je6NUbpObpQ-vcqjNx1ZulOAw6KkBwc5gg&amp;amp;siteID=je6NUbpObpQ-vcqjNx1ZulOAw6KkBwc5gg&amp;amp;utm_content=10&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=je6NUbpObpQ&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Bar-Plots, Scatter Plots, and Histograms&lt;/a&gt;, yet &lt;strong&gt;we don&amp;rsquo;t pay much attention to beautify them.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This hurts us - our credibility with peers and managers. You won&amp;rsquo;t feel it now, but it happens.&lt;/p&gt;

&lt;p&gt;Also, I find it essential to reuse my code. Every time I visit a new dataset do I need to start again? Some &lt;strong&gt;&lt;em&gt;reusable ideas of graphs that can help us to find information about the data FAST.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In this post, I am also going to talk about 3 cool visual tools:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Categorical Correlation with Graphs,&lt;/li&gt;
&lt;li&gt;Pairplots,&lt;/li&gt;
&lt;li&gt;Swarmplots and Graph Annotations using Seaborn.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;In short, this post is about useful and presentable graphs.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;I will be using data from &lt;a href=&#34;https://www.kaggle.com/karangadiya/fifa19&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;FIFA 19 complete player dataset&lt;/a&gt; on kaggle - Detailed attributes for every player registered in the latest edition of FIFA 19 database.&lt;/p&gt;

&lt;p&gt;Since the Dataset has many columns, we will only focus on a subset of categorical and continuous columns.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; sns
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;matplotlib inline
&lt;span style=&#34;color:#75715e&#34;&gt;# We dont Probably need the Gridlines. Do we? If yes comment this line&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set(style&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ticks&amp;#34;&lt;/span&gt;)
player_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;../input/data.csv&amp;#34;&lt;/span&gt;)
numcols &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [
 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Overall&amp;#39;&lt;/span&gt;,
 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Potential&amp;#39;&lt;/span&gt;,
&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Crossing&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Finishing&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ShortPassing&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Dribbling&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;LongPassing&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;BallControl&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Acceleration&amp;#39;&lt;/span&gt;,
       &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;SprintSpeed&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Agility&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Stamina&amp;#39;&lt;/span&gt;,
 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Value&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Wage&amp;#39;&lt;/span&gt;]
catcols &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Club&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Nationality&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Preferred Foot&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Position&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Body Type&amp;#39;&lt;/span&gt;]
&lt;span style=&#34;color:#75715e&#34;&gt;# Subset the columns&lt;/span&gt;
player_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; player_df[numcols&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; catcols]
&lt;span style=&#34;color:#75715e&#34;&gt;# Few rows of data&lt;/span&gt;
player_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;
    &lt;figure&gt;
      &lt;img src=&#34;https://mlwhiz.com/images/visualizations/football_dataset_head.png&#34;&gt;
      &lt;figcaption style=&#34;font-size: 12px;&#34;&gt;Player Data&lt;/figcaption&gt;
    &lt;/figure&gt;
&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;This is a nicely formatted data, yet we need to do &lt;strong&gt;some preprocessing to the Wage and Value columns&lt;/strong&gt;(as they are in Euro and contain strings) to make them numeric for our subsequent analysis.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;wage_split&lt;/span&gt;(x):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; int(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;K&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
player_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Wage&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; player_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Wage&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x : wage_split(x))
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;value_split&lt;/span&gt;(x):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;M&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; x:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; float(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;M&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:])
        &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;K&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; x:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; float(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;K&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:])&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
player_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Value&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; player_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Value&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x : value_split(x))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;hr /&gt;

&lt;h2 id=&#34;categorical-correlation-with-graphs&#34;&gt;Categorical Correlation with Graphs:&lt;/h2&gt;

&lt;p&gt;In Simple terms, Correlation is a measure of how two variables move together.&lt;/p&gt;

&lt;p&gt;For example, In the real world, &lt;em&gt;Income and Spend are positively correlated. If one increases the other also increases.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Academic Performance and Video Games Usage is negatively correlated. Increase in one predicts a decrease in another.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;So if our predictor variable is positively or negatively correlated with our target variable, it is valuable.&lt;/p&gt;

&lt;p&gt;I feel that Correlations among different variables are a pretty good thing to do when we try to understand our data.&lt;/p&gt;

&lt;p&gt;We can create a pretty good correlation plot using Seaborn easily.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;corr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; player_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;corr()
g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;heatmap(corr,  vmax&lt;span style=&#34;color:#f92672&#34;&gt;=.&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, center&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,
            square&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, linewidths&lt;span style=&#34;color:#f92672&#34;&gt;=.&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, cbar_kws&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;shrink&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;}, annot&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, fmt&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.2f&amp;#39;&lt;/span&gt;, cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;coolwarm&amp;#39;&lt;/span&gt;)
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;despine()
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_size_inches(&lt;span style=&#34;color:#ae81ff&#34;&gt;14&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)
    
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;
    &lt;figure&gt;
      &lt;img src=&#34;https://mlwhiz.com/images/visualizations/correlation_numerical.png&#34;&gt;
      &lt;figcaption style=&#34;font-size: 12px;&#34;&gt;Where did all the categorical variables go?&lt;/figcaption&gt;
    &lt;/figure&gt;
&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;But do you notice any problem?&lt;/p&gt;

&lt;p&gt;Yes, this graph only calculates Correlation between Numerical columns.
What if my target variable is &lt;code&gt;Club&lt;/code&gt; or &lt;code&gt;Position&lt;/code&gt;?&lt;/p&gt;

&lt;p&gt;I want to be able to get a correlation among three different cases, and we use the following metrics of correlation to calculate these:&lt;/p&gt;

&lt;h3 id=&#34;1-numerical-variables&#34;&gt;1. Numerical Variables&lt;/h3&gt;

&lt;p&gt;We already have this in the form of &lt;a href=&#34;https://en.wikipedia.org/wiki/Pearson_correlation_coefficient&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Pearson&amp;rsquo;s Correlation&lt;/a&gt; which is a measure of how two variables move together. This Ranges from [-1,1]&lt;/p&gt;

&lt;h3 id=&#34;2-categorical-variables&#34;&gt;2. Categorical Variables&lt;/h3&gt;

&lt;p&gt;We will use &lt;a href=&#34;https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Cramer&amp;rsquo;s V&lt;/a&gt; for categorical-categorical cases. It is the intercorrelation of two discrete variables and used with variables having two or more levels. It is a symmetrical measure as in the order of variable does not matter. Cramer(A,B) == Cramer(B,A).&lt;/p&gt;

&lt;p&gt;For Example: In our dataset, &lt;code&gt;Club&lt;/code&gt; and &lt;code&gt;Nationality&lt;/code&gt; must be somehow correlated.&lt;/p&gt;

&lt;p&gt;Let us check this using a stacked graph which is an excellent way to understand distribution between categorical vs. categorical variables. Note that we use a subset of data since there are a lot of nationalities and club in this data.&lt;/p&gt;

&lt;p&gt;We keep only the best teams(Kept FC Porto just for more diversity in the sample)and the most common nationalities.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/visualizations/stacked_club_nationality.png&#34; &#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Note that Club preference says quite a bit about Nationality: knowing the former helps a lot in predicting the latter.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We can see that if a player belongs to England, it is more probable that he plays in Chelsea or Manchester United and not in FC Barcelona or Bayern Munchen or Porto.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So there is some information present here. Cramer&amp;rsquo;s V captures the same information.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;If all clubs have the same proportion of players from every nationality, Cramer&amp;rsquo;s V is 0.&lt;/p&gt;

&lt;p&gt;If Every club prefers a single nationality Cramer&amp;rsquo;s V ==1, for example, all England player play in Manchester United, All Germans in Bayern Munchen and so on.&lt;/p&gt;

&lt;p&gt;In all other cases, it ranges from [0,1]&lt;/p&gt;

&lt;h3 id=&#34;3-numerical-and-categorical-variables&#34;&gt;3. Numerical and Categorical variables&lt;/h3&gt;

&lt;p&gt;We will use the &lt;a href=&#34;https://en.wikipedia.org/wiki/Correlation_ratio&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Correlation Ratio&lt;/a&gt; for categorical-continuous cases.&lt;/p&gt;

&lt;p&gt;Without getting into too much Maths, it is a measure of Dispersion.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Given a number can we find out which category it belongs to?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For Example:&lt;/p&gt;

&lt;p&gt;Suppose we have two columns from our dataset: &lt;code&gt;SprintSpeed&lt;/code&gt; and &lt;code&gt;Position&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;GK: 58(De Gea),52(T. Courtois), 58(M. Neuer), 43(G. Buffon)&lt;/li&gt;
&lt;li&gt;CB: 68(D. Godin), 59(V. Kompany), 73(S. Umtiti), 75(M. Benatia)&lt;/li&gt;
&lt;li&gt;ST: 91(C.Ronaldo), 94(G. Bale), 80(S.Aguero), 76(R. Lewandowski)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;As you can see these numbers are pretty predictive of the bucket they fall into and thus high Correlation Ratio.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;If I know the sprint speed is more than 85, I can definitely say this player plays at ST.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This ratio also ranges from [0,1]&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;The code to do this is taken from the dython package. I won&amp;rsquo;t write too much into code which you can anyway find in my &lt;a href=&#34;https://www.kaggle.com/mlwhiz/seaborn-visualizations-using-football-data&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Kaggle Kernel&lt;/a&gt;. The final result looks something like:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;player_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; player_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fillna(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
results &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; associations(player_df,nominal_columns&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;catcols,return_results&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;
    &lt;figure&gt;
      &lt;img src=&#34;https://mlwhiz.com/images/visualizations/correlation_plot_full.png&#34;&gt;
      &lt;figcaption style=&#34;font-size: 12px;&#34;&gt;Categorical vs. Categorical, Categorical vs. Numeric, Numeric vs. Numeric. Much more interesting&lt;/figcaption&gt;
    &lt;/figure&gt;
&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Isn&amp;rsquo;t it Beautiful?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We can understand so much about Football just by looking at this data. For Example:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The position of a player is highly correlated with dribbling ability. You won&amp;rsquo;t play Messi at the back. Right?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Value is more highly correlated with passing and ball control than dribbling. The rule is to pass the ball always. Neymar I am looking at you.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Club and Wage have high Correlation. To be expected.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Body Type and Preferred Foot is correlated highly. Does that mean if you are Lean, you are most likely left-footed? Doesn&amp;rsquo;t make much sense. One can investigate further.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Moreover, so much info we could find with this simple graph which was not visible in the typical correlation plot without Categorical Variables.&lt;/p&gt;

&lt;p&gt;I leave it here at that. One can look more into the chart and find more meaningful results, but the point is that this makes life so much easier to find patterns.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;pairplots&#34;&gt;Pairplots&lt;/h2&gt;

&lt;p&gt;While I talked a lot about correlation, it is a fickle metric.&lt;/p&gt;

&lt;p&gt;To understand what I mean let us see one example.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Anscombe&amp;rsquo;s quartet&lt;/strong&gt; comprises four datasets that have nearly identical Correlation of 1, yet have very different distributions and appear very different when graphed.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;
    &lt;figure&gt;
      &lt;img src=&#34;https://mlwhiz.com/images/visualizations/anscombe.png&#34;&gt;
      &lt;figcaption style=&#34;font-size: 12px;&#34;&gt;Anscombe Quartet - Correlations can be fickle.&lt;/figcaption&gt;
    &lt;/figure&gt;
&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Thus sometimes it becomes crucial to plot correlated data. And see the distributions individually.&lt;/p&gt;

&lt;p&gt;Now we have many columns in our dataset. Graphing them all would be so much effort.&lt;/p&gt;

&lt;p&gt;No, it is a single line of code.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;filtered_player_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; player_df[(player_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Club&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;isin([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;FC Barcelona&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Paris Saint-Germain&amp;#39;&lt;/span&gt;,
       &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Manchester United&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Manchester City&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Chelsea&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Real Madrid&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;FC Porto&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;FC Bayern München&amp;#39;&lt;/span&gt;])) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; 
                      (player_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Nationality&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;isin([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;England&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Brazil&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Argentina&amp;#39;&lt;/span&gt;,
       &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Brazil&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Italy&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Spain&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Germany&amp;#39;&lt;/span&gt;])) 
                     ]
&lt;span style=&#34;color:#75715e&#34;&gt;# Single line to create pairplot&lt;/span&gt;
g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pairplot(filtered_player_df[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Value&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;SprintSpeed&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Potential&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Wage&amp;#39;&lt;/span&gt;]])&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/visualizations/pairplot_normal.png&#34; &#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Pretty Good. We can see so much in this graph.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Wage and Value are highly correlated.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Most of the other values are correlated too. However, the trend of potential vs. value is unusual. We can see how the value increases exponentially as we reach a particular potential threshold. This information can be helpful in modeling. Can use some transformation on Potential to make it more correlated?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Caveat:&lt;/strong&gt; No categorical columns.&lt;/p&gt;

&lt;p&gt;Can we do better? We always can.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pairplot(filtered_player_df[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Value&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;SprintSpeed&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Potential&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Wage&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Club&amp;#39;&lt;/span&gt;]],hue &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Club&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/visualizations/pairplot_color.png&#34; &#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;So much more info. Just by adding the &lt;code&gt;hue&lt;/code&gt; parameter as a categorical variable &lt;code&gt;Club&lt;/code&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Porto&amp;rsquo;s Wage distribution is too much towards the lower side.&lt;/li&gt;
&lt;li&gt;I don&amp;rsquo;t see that steep distribution in value of Porto players. Porto&amp;rsquo;s players would always be looking out for an opportunity.&lt;/li&gt;
&lt;li&gt;See how a lot of pink points(Chelsea) form sort of a cluster on Potential vs. wage graph. Chelsea has a lot of high potential players with lower wages. Needs more attention.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I already know some of the points on the Wage/Value Subplot.&lt;/p&gt;

&lt;p&gt;The blue point for wage 500k is Messi. Also, the orange point having more value than Messi is Neymar.&lt;/p&gt;

&lt;p&gt;Although this hack still doesn&amp;rsquo;t solve the Categorical problem, I have something cool to look into categorical variables distribution. Though individually.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;swarmplots&#34;&gt;SwarmPlots&lt;/h2&gt;

&lt;p&gt;How to see the relationship between categorical and numerical data?&lt;/p&gt;

&lt;p&gt;Enter into picture Swarmplots, just like their name. &lt;em&gt;A swarm of points plotted for each category with a little dispersion on the y-axis to make them easier to see.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;They are my current favorite for plotting such relationships.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;swarmplot(y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Club&amp;#34;&lt;/span&gt;,
              x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Wage&amp;#39;&lt;/span&gt;, 
              data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; filtered_player_df,
              &lt;span style=&#34;color:#75715e&#34;&gt;# Decrease the size of the points to avoid crowding &lt;/span&gt;
              size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# remove the top and right line in graph&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;despine()
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_size_inches(&lt;span style=&#34;color:#ae81ff&#34;&gt;14&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;
    &lt;figure&gt;
      &lt;img src=&#34;https://mlwhiz.com/images/visualizations/club and wage.png&#34;&gt;
      &lt;figcaption style=&#34;font-size: 12px;&#34;&gt;Swarmplot...&lt;/figcaption&gt;
    &lt;/figure&gt;
&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Why don&amp;rsquo;t I use Boxplots? &lt;strong&gt;Where are the median values? Can I plot that?&lt;/strong&gt; Obviously. Overlay a bar plot on top, and we have a great looking graph.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;boxplot(y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Club&amp;#34;&lt;/span&gt;,
              x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Wage&amp;#39;&lt;/span&gt;, 
              data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; filtered_player_df, whis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inf)
g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;swarmplot(y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Club&amp;#34;&lt;/span&gt;,
              x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Wage&amp;#39;&lt;/span&gt;, 
              data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; filtered_player_df,
              &lt;span style=&#34;color:#75715e&#34;&gt;# Decrease the size of the points to avoid crowding &lt;/span&gt;
              size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,color &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;black&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# remove the top and right line in graph&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;despine()
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_size_inches(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;
    &lt;figure&gt;
      &lt;img src=&#34;https://mlwhiz.com/images/visualizations/swarn_box.png&#34;&gt;
      &lt;figcaption style=&#34;font-size: 12px;&#34;&gt;Swarmplot+Boxplot, Interesting&lt;/figcaption&gt;
    &lt;/figure&gt;
&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Pretty good. We can see the individual points on the graph, see some statistics and understand the wage difference categorically.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;The far right point is Messi. However, I should not have to tell you that in a text below the chart. Right?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This graph is going to go in a presentation. Your boss says. I want to write Messi on this graph. Comes into picture &lt;strong&gt;annotations.&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;max_wage &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; filtered_player_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Wage&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max()
max_wage_player &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; filtered_player_df[(player_df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Wage&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; max_wage)][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;boxplot(y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Club&amp;#34;&lt;/span&gt;,
              x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Wage&amp;#39;&lt;/span&gt;, 
              data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; filtered_player_df, whis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inf)
g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;swarmplot(y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Club&amp;#34;&lt;/span&gt;,
              x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Wage&amp;#39;&lt;/span&gt;, 
              data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; filtered_player_df,
              &lt;span style=&#34;color:#75715e&#34;&gt;# Decrease the size of the points to avoid crowding &lt;/span&gt;
              size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;black&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# remove the top and right line in graph&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;despine()
&lt;span style=&#34;color:#75715e&#34;&gt;# Annotate. xy for coordinate. max_wage is x and 0 is y. In this plot y ranges from 0 to 7 for each level&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# xytext for coordinates of where I want to put my text&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;annotate(s &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; max_wage_player,
             xy &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (max_wage,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;),
             xytext &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), 
             &lt;span style=&#34;color:#75715e&#34;&gt;# Shrink the arrow to avoid occlusion&lt;/span&gt;
             arrowprops &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;facecolor&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;width&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;shrink&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;0.03&lt;/span&gt;},
             backgroundcolor &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;white&amp;#39;&lt;/span&gt;)
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_size_inches(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;
    &lt;figure&gt;
      &lt;img src=&#34;https://mlwhiz.com/images/visualizations/annotated_box_swarn.png&#34;&gt;
      &lt;figcaption style=&#34;font-size: 12px;&#34;&gt;Annotated, Statistical Info and point swarm. To the presentation, I go.&lt;/figcaption&gt;
    &lt;/figure&gt;
&lt;/center&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;See Porto Down there. Competing with the giants with such a small wage budget.&lt;/li&gt;
&lt;li&gt;So many Highly paid players in Real and Barcelona.&lt;/li&gt;
&lt;li&gt;Manchester City has the highest median Wage.&lt;/li&gt;
&lt;li&gt;Manchester United and Chelsea believes in equality. Many players clustered in around the same wage scale.&lt;/li&gt;
&lt;li&gt;I am happy that while Neymar is more valued than Messi, Messi and Neymar have a huge Wage difference.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A semblance of normalcy in this crazy world.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;So to recap, in this post, we talked about calculating and reading correlations between different variable types, plotting correlations between numerical data and Plotting categorical data with Numerical data using Swarmplots. I love how we can overlay chart elements on top of each other in Seaborn.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Also if you want to learn more about Visualizations, I would like to call out an excellent course about &lt;a href=&#34;https://www.coursera.org/specializations/data-science-python?ranMID=40328&amp;amp;ranEAID=lVarvwc5BD0&amp;amp;ranSiteID=lVarvwc5BD0-SAQTYQNKSERwaOgd07RrHg&amp;amp;siteID=lVarvwc5BD0-SAQTYQNKSERwaOgd07RrHg&amp;amp;utm_content=3&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Data Visualization and applied plotting&lt;/a&gt; from the University of Michigan which is a part of a pretty good &lt;a href=&#34;https://www.coursera.org/specializations/data-science-python?ranMID=40328&amp;amp;ranEAID=lVarvwc5BD0&amp;amp;ranSiteID=lVarvwc5BD0-SAQTYQNKSERwaOgd07RrHg&amp;amp;siteID=lVarvwc5BD0-SAQTYQNKSERwaOgd07RrHg&amp;amp;utm_content=3&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Data Science Specialization with Python&lt;/a&gt; in itself. Do check it out&lt;/p&gt;

&lt;p&gt;If you liked this post, do look at my other &lt;a href=&#34;https://mlwhiz.com/blog/2015/09/13/seaborn_visualizations/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;post&lt;/a&gt; on Seaborn too where I have created some more straightforward reusable graphs.&lt;/p&gt;

&lt;p&gt;Code for this post in this &lt;a href=&#34;https://www.kaggle.com/mlwhiz/seaborn-visualizations-using-football-data&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;kaggle kernel&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;references&#34;&gt;References:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/the-search-for-categorical-correlation-a1cf7f1888c9&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;The Search for Categorical Correlation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://seaborn.pydata.org/generated/seaborn.swarmplot.html&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Seaborn Swarmplot Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://seaborn.pydata.org/generated/seaborn.pairplot.html&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Seaborn Pairplot Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Chatbots  aren&#39;t as difficult to make as You Think</title>
      <link>https://mlwhiz.com/blog/2019/04/15/chatbot/</link>
      <pubDate>Mon, 15 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2019/04/15/chatbot/</guid>
      <description>

&lt;p&gt;Chatbots are the in thing now. Every website must implement it. Every Data Scientist must know about them. Anytime we talk about AI; Chatbots must be discussed. But they look intimidating to someone very new to the field. We struggle with a lot of questions before we even begin to start working on them.
Are they hard to create? What technologies should I know before attempting to work on them? In the end, we end up discouraged reading through many posts on the internet and effectively accomplishing nothing.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/chatbot/dvader.jpeg&#34;  style=&#34;height:60%;width:60%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Let me assure you this is not going to be &lt;em&gt;&amp;ldquo;that kind of a post&amp;rdquo;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;I will try to distill some of the knowledge I acquired while working through a project in the &lt;a href=&#34;https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;amp;offerid=467035.11503135394&amp;amp;type=2&amp;amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Flanguage-processing&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Natural Language Processing&lt;/a&gt; course in the &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Advanced machine learning specialization&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So before I start, let me first say it for once that don&amp;rsquo;t be intimidated by the hype and the enigma surrounding Chatbots. They are pretty much using pretty simple NLP techniques which most of us already know. If you don&amp;rsquo;t, you are welcome to check out my &lt;a href=&#34;https://towardsdatascience.com/tagged/nlp-learning-series&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;NLP Learning Series&lt;/a&gt;, where I go through the problem of text classification in fair detail using &lt;a href=&#34;https://mlwhiz.com/blog/2019/02/08/deeplearning_nlp_conventional_methods/&#34;&gt;Conventional&lt;/a&gt;, &lt;a href=&#34;https://mlwhiz.com/blog/2019/03/09/deeplearning_architectures_text_classification/&#34;&gt;Deep Learning&lt;/a&gt; and &lt;a href=&#34;https://mlwhiz.com/blog/2019/03/30/transfer_learning_text_classification/&#34;&gt;Transfer Learning&lt;/a&gt; methods.&lt;/p&gt;

&lt;h2 id=&#34;a-very-brief-intro-to-chatbots&#34;&gt;A Very brief Intro to Chatbots&lt;/h2&gt;

&lt;p&gt;We can logically divide of Chatbots in the following two categories.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Database/FAQ based&lt;/strong&gt; - We have a database with some questions and answers, and we would like that a user can query that using Natural Language. This is the sort of Chatbots you find at most of the Banking websites for answering FAQs.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Chit-Chat Based&lt;/strong&gt; - Simulate dialogue with the user. These are the kind of chatbots that bring the cool in chatbots. We can use Seq-2-Seq models to create such bots.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;the-chatbot-we-will-be-creating&#34;&gt;The Chatbot we will be creating&lt;/h2&gt;

&lt;p&gt;We will be creating a &lt;strong&gt;dialogue chat bot&lt;/strong&gt;, which will be able to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Answer programming-related questions&lt;/strong&gt; (using StackOverflow dataset)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Chit-Chat&lt;/strong&gt; and simulate dialogue on all non-programming related questions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Once we will have it up and running our final chatbot should look like this.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/chatbot/telegram_final.png&#34;  style=&#34;height:60%;width:60%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Seems quite fun.&lt;/p&gt;

&lt;p&gt;We will be taking help of resources like Telegram and Chatterbot to build our Chatbot. So before we start, I think I should get you up and running with these two tools.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;1-telegram&#34;&gt;1. Telegram:&lt;/h2&gt;

&lt;p&gt;From the &lt;a href=&#34;https://telegram.org/faq#q-what-is-telegram-what-do-i-do-here&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;website&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Telegram is a messaging app with a focus on speed and security, it’s super-fast, simple and free. You can use Telegram on all your devices at the same time — your messages sync seamlessly across any number of your phones, tablets or computers.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For us, Telegram provides us with an easy way to create a Chatbot UI. It provides us with an access token which we will use to connect to the Telegram App backend and run our chatbot logic. Naturally, we need to have a window where we will write our questions to the chatbot, for us that is provided by Telegram. Also, telegram powers the chatbot by communicating with our chatbot logic. The above screenshot is taken from the telegram app only.&lt;/p&gt;

&lt;h3 id=&#34;set-up-telegram&#34;&gt;Set up Telegram:&lt;/h3&gt;

&lt;p&gt;Don&amp;rsquo;t worry if you don&amp;rsquo;t understand how it works yet; I will try to give step by step instructions as we go forward.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Step 1: &lt;a href=&#34;https://macos.telegram.org/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Download and Install&lt;/a&gt; Telegram App on your Laptop.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Step 2: Talk with BotFather by opening this &lt;a href=&#34;https://telegram.me/BotFather&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt; in Chrome and subsequently your Telegram App.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Step 3: The above steps will take you to a Chatbot called Botfather which can help you create a new bot. Inception Anyone? It will look something like this.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Set up a new bot using command &amp;ldquo;/newbot&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Create a name for Your bot.&lt;/li&gt;
&lt;li&gt;Create a username for your bot.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/chatbot/telegram_botfather.png&#34;  style=&#34;height:70%;width:70%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;Step 4: You will get an access token for the bot. Copy the Token at a safe place.&lt;/li&gt;
&lt;li&gt;Step 5: Click on the &amp;ldquo;t.me/MLWhizbot&amp;rdquo; link to open Chat with your chatbot in a new window.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Right now if you try to communicate with the chatbot, you won&amp;rsquo;t receive any answers. And that is how it should be.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/chatbot/telegram_unresponsive.png&#34;  style=&#34;height:20%;width:20%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;But that&amp;rsquo;s not at all fun. Is it? Let&amp;rsquo;s do some python magic to make it responsive.&lt;/p&gt;

&lt;h3 id=&#34;making-our-telegram-chatbot-responsive&#34;&gt;Making our Telegram Chatbot responsive&lt;/h3&gt;

&lt;p&gt;Create a file &lt;code&gt;main.py&lt;/code&gt; and put the following code in it. Don&amp;rsquo;t worry most of the code here is Boilerplate code to make our Chatbot communicate with Telegram using the Access token. We need to worry about implementing the class &lt;code&gt;SimpleDialogueManager&lt;/code&gt;. This class contains a function called &lt;code&gt;generate_answer&lt;/code&gt; which is where we will write our bot logic.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/usr/bin/env python3&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; requests
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; time
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; argparse
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; json
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; requests.compat &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; urljoin

&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;BotHandler&lt;/span&gt;(object):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        BotHandler is a class which implements all back-end of the bot.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        It has three main functions:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            &amp;#39;get_updates&amp;#39; — checks for new messages
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            &amp;#39;send_message&amp;#39; – posts new message to user
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            &amp;#39;get_answer&amp;#39; — computes the most relevant on a user&amp;#39;s question
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; __init__(self, token, dialogue_manager):
        
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;token &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; token
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;api_url &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://api.telegram.org/bot{}/&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(token)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dialogue_manager &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dialogue_manager

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_updates&lt;/span&gt;(self, offset&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, timeout&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;):
        params &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;timeout&amp;#34;&lt;/span&gt;: timeout, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;offset&amp;#34;&lt;/span&gt;: offset}
        raw_resp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; requests&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(urljoin(self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;api_url, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;getUpdates&amp;#34;&lt;/span&gt;), params)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
            resp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; raw_resp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;json()
        &lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; json&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decoder&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;JSONDecodeError &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; e:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Failed to parse response {}: {}.&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(raw_resp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;content, e))
            &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; []

        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;result&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; resp:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; []
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; resp[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;result&amp;#34;&lt;/span&gt;]

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;send_message&lt;/span&gt;(self, chat_id, text):
        params &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;chat_id&amp;#34;&lt;/span&gt;: chat_id, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;: text}
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; requests&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;post(urljoin(self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;api_url, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sendMessage&amp;#34;&lt;/span&gt;), params)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_answer&lt;/span&gt;(self, question):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; question &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/start&amp;#39;&lt;/span&gt;:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hi, I am your project bot. How can I help you today?&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dialogue_manager&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;generate_answer(question)


&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;is_unicode&lt;/span&gt;(text):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; len(text) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; len(text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;encode())


&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;SimpleDialogueManager&lt;/span&gt;(object):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    This is a simple dialogue manager to test the telegram bot.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    The main part of our bot will be written here.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;generate_answer&lt;/span&gt;(self, question): 
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hi&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; question:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hello, You&amp;#34;&lt;/span&gt; 
        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Don&amp;#39;t be rude. Say Hi first.&amp;#34;&lt;/span&gt;
        

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt;():
    &lt;span style=&#34;color:#75715e&#34;&gt;# Put your own Telegram Access token here...&lt;/span&gt;
    token &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;839585958:AAEfTDo2X6PgHb9IEdb62ueS4SmdpCkhtmc&amp;#39;&lt;/span&gt;
    simple_manager &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SimpleDialogueManager()
    bot &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BotHandler(token, simple_manager)
    &lt;span style=&#34;color:#75715e&#34;&gt;###############################################################&lt;/span&gt;

    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Ready to talk!&amp;#34;&lt;/span&gt;)
    offset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; True:
        updates &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; bot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_updates(offset&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;offset)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; update &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; updates:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;An update received.&amp;#34;&lt;/span&gt;)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;message&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; update:
                chat_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; update[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;message&amp;#34;&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;chat&amp;#34;&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;id&amp;#34;&lt;/span&gt;]
                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; update[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;message&amp;#34;&lt;/span&gt;]:
                    text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; update[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;message&amp;#34;&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;]
                    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; is_unicode(text):
                        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Update content: {}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(update))
                        bot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;send_message(chat_id, bot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_answer(update[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;message&amp;#34;&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;text&amp;#34;&lt;/span&gt;]))
                    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
                        bot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;send_message(chat_id, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hmm, you are sending some weird characters to me...&amp;#34;&lt;/span&gt;)
            offset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; max(offset, update[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;update_id&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
        time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sleep(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; __name__ &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;__main__&amp;#34;&lt;/span&gt;:
    main()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can run the file &lt;code&gt;main.py&lt;/code&gt; in the terminal window to make your bot responsive.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ python main.py&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/chatbot/telegram_naive.png&#34;  style=&#34;height:100%;width:100%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Nice. It is following simple logic. But the good thing is that our bot now does something.&lt;/p&gt;

&lt;p&gt;Also, take a look at the terminal window where we have run our &lt;code&gt;main.py&lt;/code&gt; File. Whenever a user asks a question, we get the sort of dictionary below containing Unique Chat ID, Chat Text, User Information, etc.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Update content: {&#39;update_id&#39;: 484689748, &#39;message&#39;: {&#39;message_id&#39;: 115, &#39;from&#39;: {&#39;id&#39;: 844474950, &#39;is_bot&#39;: False, &#39;first_name&#39;: &#39;Rahul&#39;, &#39;last_name&#39;: &#39;Agarwal&#39;, &#39;language_code&#39;: &#39;en&#39;}, &#39;chat&#39;: {&#39;id&#39;: 844474950, &#39;first_name&#39;: &#39;Rahul&#39;, &#39;last_name&#39;: &#39;Agarwal&#39;, &#39;type&#39;: &#39;private&#39;}, &#39;date&#39;: 1555266010, &#39;text&#39;: &#39;What is 2+2&#39;}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Until now whatever we had done was sort of setting up and engineering sort of work.&lt;/p&gt;

&lt;p&gt;Only if we can write some sound Data Science logic in the &lt;code&gt;generate_answer&lt;/code&gt; function in our &lt;code&gt;main.py&lt;/code&gt; we should have a decent chatbot.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;2-chatterbot&#34;&gt;2. ChatterBot&lt;/h2&gt;

&lt;p&gt;From the Documentation:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;ChatterBot is a Python library that makes it easy to generate automated responses to a user’s input. ChatterBot uses a selection of machine learning algorithms to produce different types of reactions. This makes it easy for developers to create chat bots and automate conversations with users.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Simply. It is a Blackbox system which can provide us with responses for Chitchat type questions for our Chatbot. And the best part about it is that it is pretty easy to integrate with our current flow. We could also have trained a SeqtoSeq model to do the same thing. Might be I will do it in a later post. I digress.&lt;/p&gt;

&lt;p&gt;So, install it with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ pip install chatterbot&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And change the &lt;code&gt;SimpleDialogueManager&lt;/code&gt; Class in main.py to the following. We can have a bot that can talk to the user and answer random queries.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;SimpleDialogueManager&lt;/span&gt;(object):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    This is a simple dialogue manager to test the telegram bot.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    The main part of our bot will be written here.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; __init__(self):
        &lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; chatterbot &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ChatBot
        &lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; chatterbot.trainers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ChatterBotCorpusTrainer
        chatbot &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ChatBot(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;MLWhizChatterbot&amp;#39;&lt;/span&gt;)
        trainer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ChatterBotCorpusTrainer(chatbot)
        trainer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;train(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;chatterbot.corpus.english&amp;#39;&lt;/span&gt;)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;chitchat_bot &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; chatbot

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;generate_answer&lt;/span&gt;(self, question): 
        response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;chitchat_bot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_response(question)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; response&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The code in &lt;code&gt;init&lt;/code&gt; instantiates a chatbot using chatterbot and trains it on the &lt;a href=&#34;https://github.com/gunthercox/chatterbot-corpus/tree/master/chatterbot_corpus/data/english&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;provided english corpus&lt;/a&gt; data. The data is pretty small, but you can always train it on your dataset too. Just see the &lt;a href=&#34;https://chatterbot.readthedocs.io/en/stable/training.html&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;documentation&lt;/a&gt;. We can then give our responses using the Chatterbot chatbot in the &lt;code&gt;generate_answer&lt;/code&gt; function.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/chatbot/telegram_chatterbot.png&#34;  style=&#34;height:80%;width:80%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Not too &amp;ldquo;ba a a a a a d&amp;rdquo; , I must say.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;creating-our-stackoverflow-chatbot&#34;&gt;Creating our StackOverFlow ChatBot&lt;/h2&gt;

&lt;p&gt;Ok, so finally we are at a stage where we can do something we love. Use Data Science to power our Application/Chatbot. Let us start with creating a rough architecture of what we are going to do next.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/chatbot/chatbot_architecture.png&#34;  style=&#34;height:80%;width:80%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;We will need to create two classifiers and save them as &lt;code&gt;.pkl&lt;/code&gt; files.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Intent-Classifier&lt;/strong&gt;: This classifier will predict if it a question is a Stack-Overflow question or not. If it is not a Stack-overflow question, we let Chatterbot handle it.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Programming-Language(Tag) Classifier&lt;/strong&gt;: This classifier will predict which language a question belongs to if the question is a Stack-Overflow question. We do this so that we can search for those language questions in our database only.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;To keep it simple we will create simple TFIDF models. We will need to save these TFIDF vectorizers.&lt;/p&gt;

&lt;p&gt;We will also need to store word vectors for every question for similarity calculations later.&lt;/p&gt;

&lt;p&gt;Let us go through the process step by step. You can get the full code in this &lt;a href=&#34;https://github.com/MLWhiz/chatbot/blob/master/Model%20Creation.ipynb&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;jupyter notebook&lt;/a&gt; in my &lt;a href=&#34;https://github.com/MLWhiz/chatbot&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;project repository&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;step-1-reading-and-visualizing-the-data&#34;&gt;Step 1. Reading and Visualizing the Data&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;dialogues &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data/dialogues.tsv&amp;#34;&lt;/span&gt;,sep&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
posts &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data/tagged_posts.tsv&amp;#34;&lt;/span&gt;,sep&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;dialogues&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: left;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;text&lt;/th&gt;
      &lt;th&gt;tag&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Okay -- you&#39;re gonna need to learn how to lie.&lt;/td&gt;
      &lt;td&gt;dialogue&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;I&#39;m kidding.  You know how sometimes you just ...&lt;/td&gt;
      &lt;td&gt;dialogue&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Like my fear of wearing pastels?&lt;/td&gt;
      &lt;td&gt;dialogue&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;I figured you&#39;d get to the good stuff eventually.&lt;/td&gt;
      &lt;td&gt;dialogue&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;Thank God!  If I had to hear one more story ab...&lt;/td&gt;
      &lt;td&gt;dialogue&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;posts&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;post_id&lt;/th&gt;
      &lt;th&gt;title&lt;/th&gt;
      &lt;th&gt;tag&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;Calculate age in C#&lt;/td&gt;
      &lt;td&gt;c#&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;Filling a DataSet or DataTable from a LINQ que...&lt;/td&gt;
      &lt;td&gt;c#&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;39&lt;/td&gt;
      &lt;td&gt;Reliable timer in a console application&lt;/td&gt;
      &lt;td&gt;c#&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;Best way to allow plugins for a PHP application&lt;/td&gt;
      &lt;td&gt;php&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;59&lt;/td&gt;
      &lt;td&gt;How do I get a distinct, ordered list of names...&lt;/td&gt;
      &lt;td&gt;c#&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Num Posts:&amp;#34;&lt;/span&gt;,len(posts))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Num Dialogues:&amp;#34;&lt;/span&gt;,len(dialogues))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Num Posts: 2171575
Num Dialogues: 218609
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;step-2-create-training-data-for-intent-classifier-chitchat-stackoverflow-question&#34;&gt;Step 2: Create training data for intent classifier - Chitchat/StackOverflow Question&lt;/h4&gt;

&lt;p&gt;We will be creating a TFIDF model with Logistic regression to do this. If you want to know about the TFIDF model you can read it here.&lt;/p&gt;

&lt;p&gt;We could also have used one of the Deep Learning models or transfer learning approaches to do this, but since the main objective of this post is to get a chatbot up and running and not worry too much about the accuracy we sort of work with the TFIDF based model only.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;texts  &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  list(dialogues[:&lt;span style=&#34;color:#ae81ff&#34;&gt;200000&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; list(posts[:&lt;span style=&#34;color:#ae81ff&#34;&gt;200000&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values)
labels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dialogue&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;200000&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;stackoverflow&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;200000&lt;/span&gt;
data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame({&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;:texts,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;target&amp;#39;&lt;/span&gt;:labels})

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;text_prepare&lt;/span&gt;(text):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Performs tokenization and simple preprocessing.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    
    replace_by_space_re &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;[/(){}\[\]\|@,;]&amp;#39;&lt;/span&gt;)
    bad_symbols_re &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;[^0-9a-z #+_]&amp;#39;&lt;/span&gt;)
    stopwords_set &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; set(stopwords&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;words(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;english&amp;#39;&lt;/span&gt;))

    text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lower()
    text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; replace_by_space_re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;, text)
    text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; bad_symbols_re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;, text)
    text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join([x &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split() &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; stopwords_set])

    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strip()

&lt;span style=&#34;color:#75715e&#34;&gt;# Doing some data cleaning&lt;/span&gt;
data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x : text_prepare(x))

X_train, X_test, y_train, y_test &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_test_split(data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;],data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;target&amp;#39;&lt;/span&gt;],test_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; , random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Train size = {}, test size = {}&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(len(X_train), len(X_test)))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Train size = 360000, test size = 40000
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;step-3-create-intent-classifier&#34;&gt;Step 3. Create Intent classifier&lt;/h4&gt;

&lt;p&gt;Here we Create a TFIDF Vectorizer to create features and also train a Logistic regression model to create the intent_classifier. Please note how we are saving TFIDF Vectorizer to &lt;code&gt;resources/tfidf.pkl&lt;/code&gt; and intent_classifier to &lt;code&gt;resources/intent_clf.pkl&lt;/code&gt;. We will need these files once we are going to write the &lt;code&gt;SimpleDialogueManager&lt;/code&gt; class for our final Chatbot.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# We will keep our models and vectorizers in this folder&lt;/span&gt;
&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt;mkdir resources

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tfidf_features&lt;/span&gt;(X_train, X_test, vectorizer_path):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Performs TF-IDF transformation and dumps the model.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    tfv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; TfidfVectorizer(dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32, min_df&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,  max_features&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, 
            strip_accents&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;unicode&amp;#39;&lt;/span&gt;, analyzer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;word&amp;#39;&lt;/span&gt;,token_pattern&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;\w{1,}&amp;#39;&lt;/span&gt;,
            ngram_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), use_idf&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,smooth_idf&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,sublinear_tf&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
            stop_words &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;english&amp;#39;&lt;/span&gt;)
    
    X_train &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfv&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_transform(X_train)
    X_test &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfv&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(X_test)
    
    pickle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dump(tfv,vectorizer_path)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; X_train, X_test

X_train_tfidf, X_test_tfidf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfidf_features(X_train, X_test, open(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;resources/tfidf.pkl&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;wb&amp;#39;&lt;/span&gt;))

intent_recognizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; LogisticRegression(C&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;,random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
intent_recognizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(X_train_tfidf,y_train)
pickle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dump(intent_recognizer, open(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;resources/intent_clf.pkl&amp;#34;&lt;/span&gt; , &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;wb&amp;#39;&lt;/span&gt;))

&lt;span style=&#34;color:#75715e&#34;&gt;# Check test accuracy.&lt;/span&gt;
y_test_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; intent_recognizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(X_test_tfidf)
test_accuracy &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; accuracy_score(y_test, y_test_pred)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Test accuracy = {}&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(test_accuracy))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Test accuracy = 0.989825
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The Intent Classifier has a pretty good test accuracy of 98%. TFIDF is not so bad.&lt;/p&gt;

&lt;h4 id=&#34;step-4-create-programming-language-classifier&#34;&gt;Step 4: Create Programming Language classifier&lt;/h4&gt;

&lt;p&gt;Let us first create the data for Programming Language classifier and then train a Logistic Regression model using TFIDF features. We save this tag Classifier at the location &lt;code&gt;resources/tag_clf.pkl&lt;/code&gt;. We do this step mostly because we don&amp;rsquo;t want to do similarity calculations over the whole database of questions but only on the subset of questions by the language tag.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# creating the data for Programming Language classifier &lt;/span&gt;
X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; posts[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;title&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values
y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; posts[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tag&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values

X_train, X_test, y_train, y_test &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_test_split(X, y, test_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Train size = {}, test size = {}&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(len(X_train), len(X_test)))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Train size = 1737260, test size = 434315
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;vectorizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pickle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load(open(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;resources/tfidf.pkl&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rb&amp;#39;&lt;/span&gt;))
X_train_tfidf, X_test_tfidf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; vectorizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(X_train), vectorizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(X_test)
tag_classifier &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; OneVsRestClassifier(LogisticRegression(C&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
tag_classifier&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(X_train_tfidf,y_train)
pickle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dump(tag_classifier, open(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;resources/tag_clf.pkl&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;wb&amp;#39;&lt;/span&gt;))

&lt;span style=&#34;color:#75715e&#34;&gt;# Check test accuracy.&lt;/span&gt;
y_test_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tag_classifier&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(X_test_tfidf)
test_accuracy &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; accuracy_score(y_test, y_test_pred)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Test accuracy = {}&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(test_accuracy))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Test accuracy = 0.8043816124241622
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Not Bad again.&lt;/p&gt;

&lt;h4 id=&#34;step-5-store-question-database-embeddings&#34;&gt;Step 5: Store Question database Embeddings&lt;/h4&gt;

&lt;p&gt;One can use &lt;a href=&#34;https://code.google.com/archive/p/word2vec/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;pre-trained word vectors&lt;/a&gt; from Google or get a better result by training their embeddings using their data. Since again accuracy and precision is not the primary goal of this post, we will use pretrained vectors.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Load Google&amp;#39;s pre-trained Word2Vec model.&lt;/span&gt;
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; gensim&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;models&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;KeyedVectors&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_word2vec_format(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;GoogleNews-vectors-negative300.bin&amp;#39;&lt;/span&gt;, binary&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True) &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We want to convert every question to an embedding and store them so that we don&amp;rsquo;t calculate the embeddings for the whole dataset every time. In essence, whenever the user asks a Stack Overflow question, we want to use some distance similarity measure to get the most similar question.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;question_to_vec&lt;/span&gt;(question, embeddings, dim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        question: a string
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        embeddings: dict where the key is a word and a value is its&amp;#39; embedding
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        dim: size of the representation
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        result: vector representation for the question
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    word_tokens &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; question&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;)
    question_len &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; len(word_tokens)
    question_mat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((question_len,dim), dtype &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
    
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; idx, word &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(word_tokens):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; word &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; embeddings:
            question_mat[idx,:] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings[word]
            
    &lt;span style=&#34;color:#75715e&#34;&gt;# remove zero-rows which stand for OOV words       &lt;/span&gt;
    question_mat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; question_mat[&lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;all(question_mat &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, axis &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)]
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Compute the mean of each word along the sentence&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; question_mat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
        vec &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(question_mat, axis &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;), dtype &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape((&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,dim))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
        vec &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,dim), dtype &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
        
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; vec

counts_by_tag &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; posts&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby(by&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tag&amp;#39;&lt;/span&gt;])[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;tag&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;count()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reset_index(name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;count&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sort_values([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;count&amp;#39;&lt;/span&gt;], ascending &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False)
counts_by_tag &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(zip(counts_by_tag[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tag&amp;#39;&lt;/span&gt;],counts_by_tag[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;count&amp;#39;&lt;/span&gt;]))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(counts_by_tag)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;[(&#39;c#&#39;, 394451), (&#39;java&#39;, 383456), (&#39;javascript&#39;, 375867), (&#39;php&#39;, 321752), (&#39;c_cpp&#39;, 281300), (&#39;python&#39;, 208607), (&#39;ruby&#39;, 99930), (&#39;r&#39;, 36359), (&#39;vb&#39;, 35044), (&#39;swift&#39;, 34809)]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We save the embeddings in a folder aptly named &lt;code&gt;resources/embeddings_folder&lt;/code&gt;. This folder will contain a .pkl file for every tag. For example one of the files will be &lt;code&gt;python.pkl&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;!&lt;/span&gt; mkdir resources&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;embeddings_folder

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; tag, count &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; counts_by_tag:
    tag_posts &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; posts[posts[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tag&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; tag]
    tag_post_ids &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tag_posts[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;post_id&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values
    tag_vectors &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((count, &lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;), dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, title &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(tag_posts[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;title&amp;#39;&lt;/span&gt;]):
        tag_vectors[i, :] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; question_to_vec(title, model, &lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;)
    &lt;span style=&#34;color:#75715e&#34;&gt;# Dump post ids and vectors to a file.&lt;/span&gt;
    filename &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;resources/embeddings_folder/&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tag &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.pkl&amp;#39;&lt;/span&gt;
    pickle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dump((tag_post_ids, tag_vectors), open(filename, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;wb&amp;#39;&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We are nearing the end now. We need to have a function to get most similar question&amp;rsquo;s &lt;em&gt;post id&lt;/em&gt; in the dataset given we know the programming Language of the question. Here it is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_similar_question&lt;/span&gt;(question,tag):
    &lt;span style=&#34;color:#75715e&#34;&gt;# get the path where all question embeddings are kept and load the post_ids and post_embeddings&lt;/span&gt;
    embeddings_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;resources/embeddings_folder/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tag &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;.pkl&amp;#34;&lt;/span&gt;
    post_ids, post_embeddings &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pickle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load(open(embeddings_path, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rb&amp;#39;&lt;/span&gt;))
    &lt;span style=&#34;color:#75715e&#34;&gt;# Get the embeddings for the question&lt;/span&gt;
    question_vec &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; question_to_vec(question, model, &lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;)
    &lt;span style=&#34;color:#75715e&#34;&gt;# find index of most similar post&lt;/span&gt;
    best_post_index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pairwise_distances_argmin(question_vec,
                                                post_embeddings)
    &lt;span style=&#34;color:#75715e&#34;&gt;# return best post id&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; post_ids[best_post_index]

get_similar_question(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;how to use list comprehension in python?&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;python&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;array([5947137])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;we can use this post ID and find this question at &lt;a href=&#34;https://stackoverflow.com/questions/5947137&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;https://stackoverflow.com/questions/5947137&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The question the similarity checker suggested has the actual text: &amp;ldquo;How can I use a list comprehension to extend a list in python? [duplicate]&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Not too bad. It could have been better if we train our embeddings or use &lt;a href=&#34;https://github.com/facebookresearch/StarSpace&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;starspace&lt;/a&gt; embeddings.&lt;/p&gt;

&lt;h2 id=&#34;assemble-the-puzzle-simpledialoguemanager-class&#34;&gt;Assemble the Puzzle - SimpleDialogueManager Class&lt;/h2&gt;

&lt;p&gt;Finally, we have reached the end of the whole exercise, and we have to fit all the pieces in the puzzle in our &lt;code&gt;SimpleDialogueManager&lt;/code&gt; Class. Here is the code for that. Go in the &lt;code&gt;main.py&lt;/code&gt; file again to paste this code and see if it works or not.&lt;/p&gt;

&lt;p&gt;Go through the comments to understand how the pieces are fitting together to build one wholesome logic.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; gensim
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pickle
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; re
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; nltk
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; nltk.corpus &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; stopwords
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.metrics.pairwise &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pairwise_distances_argmin

&lt;span style=&#34;color:#75715e&#34;&gt;# We will need this function to prepare text at prediction time&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;text_prepare&lt;/span&gt;(text):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Performs tokenization and simple preprocessing.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    
    replace_by_space_re &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;[/(){}\[\]\|@,;]&amp;#39;&lt;/span&gt;)
    bad_symbols_re &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;[^0-9a-z #+_]&amp;#39;&lt;/span&gt;)
    stopwords_set &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; set(stopwords&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;words(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;english&amp;#39;&lt;/span&gt;))

    text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lower()
    text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; replace_by_space_re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;, text)
    text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; bad_symbols_re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;, text)
    text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join([x &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split() &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; stopwords_set])

    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strip()

&lt;span style=&#34;color:#75715e&#34;&gt;# need this to convert questions asked by user to vectors&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;question_to_vec&lt;/span&gt;(question, embeddings, dim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        question: a string
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        embeddings: dict where the key is a word and a value is its&amp;#39; embedding
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        dim: size of the representation
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        result: vector representation for the question
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    word_tokens &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; question&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;)
    question_len &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; len(word_tokens)
    question_mat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((question_len,dim), dtype &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
    
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; idx, word &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(word_tokens):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; word &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; embeddings:
            question_mat[idx,:] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings[word]
            
    &lt;span style=&#34;color:#75715e&#34;&gt;# remove zero-rows which stand for OOV words       &lt;/span&gt;
    question_mat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; question_mat[&lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;all(question_mat &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, axis &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)]
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Compute the mean of each word along the sentence&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; question_mat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
        vec &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(question_mat, axis &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;), dtype &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape((&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,dim))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
        vec &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,dim), dtype &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
        
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; vec

&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;SimpleDialogueManager&lt;/span&gt;(object):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    This is a simple dialogue manager to test the telegram bot.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    The main part of our bot will be written here.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; __init__(self):

        &lt;span style=&#34;color:#75715e&#34;&gt;# Instantiate all the models and TFIDF Objects.&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Loading resources...&amp;#34;&lt;/span&gt;)
        &lt;span style=&#34;color:#75715e&#34;&gt;# Instantiate a Chatterbot for Chitchat type questions&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; chatterbot &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ChatBot
        &lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; chatterbot.trainers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ChatterBotCorpusTrainer
        chatbot &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ChatBot(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;MLWhizChatterbot&amp;#39;&lt;/span&gt;)
        trainer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ChatterBotCorpusTrainer(chatbot)
        trainer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;train(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;chatterbot.corpus.english&amp;#39;&lt;/span&gt;)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;chitchat_bot &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; chatbot
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Loading Word2vec model...&amp;#34;&lt;/span&gt;)
        &lt;span style=&#34;color:#75715e&#34;&gt;# Instantiate the Google&amp;#39;s pre-trained Word2Vec model.&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; gensim&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;models&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;KeyedVectors&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_word2vec_format(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;GoogleNews-vectors-negative300.bin&amp;#39;&lt;/span&gt;, binary&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True) 
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Loading Classifier objects...&amp;#34;&lt;/span&gt;)
        &lt;span style=&#34;color:#75715e&#34;&gt;# Load the intent classifier and tag classifier&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;intent_recognizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  pickle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load(open(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;resources/intent_clf.pkl&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rb&amp;#39;&lt;/span&gt;))
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tag_classifier &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  pickle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load(open(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;resources/tag_clf.pkl&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rb&amp;#39;&lt;/span&gt;))
        &lt;span style=&#34;color:#75715e&#34;&gt;# Load the TFIDF vectorizer object&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tfidf_vectorizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pickle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load(open(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;resources/tfidf.pkl&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rb&amp;#39;&lt;/span&gt;))
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Finished Loading Resources&amp;#34;&lt;/span&gt;)

    &lt;span style=&#34;color:#75715e&#34;&gt;# We created this function just above. We just need to have a function to get most similar question&amp;#39;s *post id* in the dataset given we know the programming Language of the question. Here it is:&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_similar_question&lt;/span&gt;(self,question,tag):
        &lt;span style=&#34;color:#75715e&#34;&gt;# get the path where all question embeddings are kept and load the post_ids and post_embeddings&lt;/span&gt;
        embeddings_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;resources/embeddings_folder/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; tag &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;.pkl&amp;#34;&lt;/span&gt;
        post_ids, post_embeddings &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pickle&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load(open(embeddings_path, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;rb&amp;#39;&lt;/span&gt;))
        &lt;span style=&#34;color:#75715e&#34;&gt;# Get the embeddings for the question&lt;/span&gt;
        question_vec &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; question_to_vec(question, self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;model, &lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;)
        &lt;span style=&#34;color:#75715e&#34;&gt;# find index of most similar post&lt;/span&gt;
        best_post_index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pairwise_distances_argmin(question_vec,
                                                    post_embeddings)
        &lt;span style=&#34;color:#75715e&#34;&gt;# return best post id&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; post_ids[best_post_index]

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;generate_answer&lt;/span&gt;(self, question): 
        prepared_question &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; text_prepare(question)
        features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tfidf_vectorizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform([prepared_question])
        &lt;span style=&#34;color:#75715e&#34;&gt;# find intent&lt;/span&gt;
        intent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;intent_recognizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(features)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
        &lt;span style=&#34;color:#75715e&#34;&gt;# Chit-chat part:   &lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; intent &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dialogue&amp;#39;&lt;/span&gt;:
            response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;chitchat_bot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_response(question)
        &lt;span style=&#34;color:#75715e&#34;&gt;# Stack Overflow Question&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
            &lt;span style=&#34;color:#75715e&#34;&gt;# find programming language&lt;/span&gt;
            tag &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tag_classifier&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(features)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
            &lt;span style=&#34;color:#75715e&#34;&gt;# find most similar question post id&lt;/span&gt;
            post_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_similar_question(question,tag)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
            &lt;span style=&#34;color:#75715e&#34;&gt;# respond with &lt;/span&gt;
            response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;I think its about &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;This thread might help you: https://stackoverflow.com/questions/&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; (tag, post_id)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; response&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here is the code for the whole &lt;a href=&#34;https://github.com/MLWhiz/chatbot/blob/master/main.py&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;main.py&lt;/code&gt;&lt;/a&gt; for you to use and see. Just run the whole &lt;code&gt;main.py&lt;/code&gt; using&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ python main.py&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And we will have our bot up and running.&lt;/p&gt;

&lt;p&gt;Again, here is the link to the github &lt;a href=&#34;https://github.com/MLWhiz/chatbot&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;repository&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;the-possibilities-are-really-endless&#34;&gt;The possibilities are really endless&lt;/h2&gt;

&lt;p&gt;This is just a small demo project of what you can do with the chatbots. You can do a whole lot more once you recognize that the backend is just python.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;One idea is to run a chatbot script on all the servers I have to run system commands straight from telegram. We can use &lt;code&gt;os.system&lt;/code&gt; to run any system command. Bye Bye SSH.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;You can &lt;strong&gt;make chatbots to do some daily tasks by using simple keyword-based intents&lt;/strong&gt;. It is just simple logic. Find out the weather, find out cricket scores or maybe newly released movies. Whatever floats your boat.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Or maybe try to integrate Telegram based Chatbot in your website. See &lt;a href=&#34;https://livechatbot.net/#&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;livechatbot&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Or maybe just try to have fun with it.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/chatbot/dilbert_chatbot.jpg&#34;  style=&#34;height:80%;width:80%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Here we learned how to create a simple chatbot. And it works well. We can improve a whole lot on this present chatbot by increasing classifier accuracy, handling edge cases, making it respond faster or maybe adding more logic to handle more use cases. But the fact remains the same. The AI in chatbots is just simple human logic and nothing magic.&lt;/p&gt;

&lt;p&gt;In this post, I closely followed one of the projects from this &lt;a href=&#34;https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;amp;offerid=467035.11503135394&amp;amp;type=2&amp;amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Flanguage-processing&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;course&lt;/a&gt; to create this chatbot. Do check out this course if you get confused, or tell me your problems in the comments I will certainly try to help.&lt;/p&gt;

&lt;p&gt;Follow me up at &lt;a href=&#34;https://medium.com/@rahul_agarwal&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Medium&lt;/a&gt; or Subscribe to my &lt;a href=&#34;https://mlwhiz.com&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;blog&lt;/a&gt; to be informed about my next posts.&lt;/p&gt;

&lt;p&gt;Till then Ciao!!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Why Sublime Text for Data Science is Hotter than Jennifer Lawrence?</title>
      <link>https://mlwhiz.com/blog/2019/03/31/sublime_ds_post/</link>
      <pubDate>Sun, 31 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2019/03/31/sublime_ds_post/</guid>
      <description>

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/sublime_ds/sublime_tool.jpeg&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Just Kidding, Nothing is hotter than Jennifer Lawrence. But as you are here, let&amp;rsquo;s proceed.&lt;/p&gt;

&lt;p&gt;For a practitioner in any field, they turn out as good as the tools they use. Data Scientists are no different. But sometimes we don&amp;rsquo;t even know which tools we need and also if we need them. We are not able to fathom if there could be a more natural way to solve the problem we face. We could learn about Data Science using awesome MOOCs like &lt;a href=&#34;https://www.coursera.org/learn/machine-learning?ranMID=40328&amp;amp;ranEAID=lVarvwc5BD0&amp;amp;ranSiteID=lVarvwc5BD0-IlsUicNUO2OWJZj6q7k7Hw&amp;amp;siteID=lVarvwc5BD0-IlsUicNUO2OWJZj6q7k7Hw&amp;amp;utm_content=3&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Machine Learning&lt;/a&gt; by Andrew Ng but no one teaches the spanky tools of the trade. This motivated me to write about the tools and skills that one is not taught in any course in my new series of short posts - &lt;strong&gt;Tools For Data Science&lt;/strong&gt;. As it is rightly said:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We shape our tools and afterward our tools shape us.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In this post, I will try to talk about the Sublime Text Editor in the context of Data Science.&lt;/p&gt;

&lt;p&gt;Sublime Text is such a lifesaver, and we as data scientists don&amp;rsquo;t even realize that we need it. We are generally so happy with our Jupyter Notebooks and R studio that we never try to use another editor.&lt;/p&gt;

&lt;p&gt;So, let me try to sway you a little bit from your Jupyter notebooks into integrating another editor in your workflow. I will try to provide some use cases below. On that note, these use cases are not at all exhaustive and are here just to demonstrate the functionality and Sublime power.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;1-create-a-dictionary-list-or-whatever&#34;&gt;1. Create A Dictionary/List or Whatever:&lt;/h2&gt;

&lt;p&gt;How many times does it happen that we want to &lt;strong&gt;&lt;em&gt;make a list or dictionary for our Python code from a list we got in an email text?&lt;/em&gt;&lt;/strong&gt; I bet numerous times. &lt;/p&gt;

&lt;p&gt;How do we do this? We haggle in Excel by loading that Text in Excel and then trying out concatenating operations. For those of us on a Mac, it is even more troublesome since Mac&amp;rsquo;s Excel is not as good as windows(to put it mildly)&lt;/p&gt;

&lt;p&gt;So, for example, if you had information about State Name and State Short Name and you had to create a dictionary for Python, you would end up doing something like this in Excel. Or maybe you will load the CSV in pandas and then play with it in Python itself.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/sublime_ds/previous_excel-min.gif&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Here is how you would do the same in Sublime.&lt;/em&gt; And see just how wonderful it looks. We ended up getting the Dictionary in one single line. It took me around 27 seconds to do. &lt;/p&gt;

&lt;p&gt;I still remember the first time I saw one of my developer friends doing this, and I was amazed. On that note, We should always learn from other domains&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/sublime_ds/now sublime-min.gif&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;So how I did this?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Here is a step by step idea. You might want to get some data in Sublime and try it out yourself. The command that you will be using most frequently is &lt;code&gt;Cmd+Shift+L&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Select all the text in the sublime window using &lt;code&gt;Cmd+A&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Cmd+Shift+L&lt;/code&gt; to get the cursor on all lines&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;Cmd&lt;/code&gt; and &lt;code&gt;Opt&lt;/code&gt; with arrow keys to move these cursors to required locations. &lt;code&gt;Cmd&lt;/code&gt; takes to beginning and end. &lt;code&gt;Opt&lt;/code&gt; takes you token by token&lt;/li&gt;
&lt;li&gt;Do your Magic and write.&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;Delete&lt;/code&gt; key to getting everything in one line&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;Esc&lt;/code&gt; to get out from Multiple cursor mode&lt;/li&gt;
&lt;li&gt;Enjoy!&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;2-select-selectively-and-look-good-while-doing-it&#34;&gt;2. Select Selectively and Look Good while doing it:&lt;/h2&gt;

&lt;p&gt;Another functionality in Sublime that I love. We all have used Replace functionality in many text editors. This functionality is &lt;code&gt;Find and Replace&lt;/code&gt; with a twist.&lt;/p&gt;

&lt;p&gt;So, without further ado, let me demonstrate it with an example. Let&amp;rsquo;s say we have a code snippet written in Python and we want to replace some word. We can very well do it with &lt;code&gt;Find and Replace&lt;/code&gt; Functionality. We will find and replace each word and would end up clicking a lot of times. Sublime makes it so much easier. And it looks impressive too. &lt;em&gt;You look like you know what you are doing, which will get a few brownie points in my book.&lt;/em&gt;&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/sublime_ds/sublime_mul-min.gif&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;So how I did this?&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Select the word you want to replace&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;Cmd+D&lt;/code&gt; multiple times to only select instances of the word you want to remove.&lt;/li&gt;
&lt;li&gt;When all words are selected, write the new word&lt;/li&gt;
&lt;li&gt;And that&amp;rsquo;s all&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/sublime_ds/thor_tools_2x.png&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;This concludes my post about one of the most efficient editors I have ever known. You can try to do a lot of things with Sublime but the above use cases are the ones which I find most useful. &lt;strong&gt;&lt;em&gt;These simple commands will make your work much more efficient and remove the manual drudgery which is sometimes a big part of our jobs.&lt;/em&gt;&lt;/strong&gt; Hope you end up using this in your Workflow. Trust me you will end up loving it.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Let me know if you liked this post. I will continue writing such Tips and Tricks in a series of posts. Also, do &lt;a href=&#34;https://medium.com/@rahul_agarwal&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;follow me on Medium&lt;/a&gt; to get notified about my future posts.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;PS1: All the things above will also work with Atom text editor using the exact same commands on Mac.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;PS2: For Window Users, Replace &lt;code&gt;Cmd&lt;/code&gt; by &lt;code&gt;Ctrl&lt;/code&gt; and &lt;code&gt;Opt&lt;/code&gt; with &lt;code&gt;Alt&lt;/code&gt; to get the same functionality.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NLP  Learning Series: Part 4 - Transfer Learning Intuition for Text Classification</title>
      <link>https://mlwhiz.com/blog/2019/03/30/transfer_learning_text_classification/</link>
      <pubDate>Sat, 30 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2019/03/30/transfer_learning_text_classification/</guid>
      <description>

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/nlp_tl/spiderman.jpeg&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;This post is the fourth post of the NLP Text classification series. To give you a recap, I started up with an NLP text classification competition on Kaggle called Quora Question insincerity challenge. So I thought to share the knowledge via a series of blog posts on text classification. The &lt;a href=&#34;https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/&#34;&gt;first post&lt;/a&gt; talked about the different &lt;strong&gt;preprocessing techniques that work with Deep learning models&lt;/strong&gt; and &lt;strong&gt;increasing embeddings coverage&lt;/strong&gt;. In the &lt;a href=&#34;https://mlwhiz.com/blog/2019/02/08/deeplearning_nlp_conventional_methods/&#34;&gt;second post&lt;/a&gt;, I talked through some &lt;strong&gt;basic conventional models&lt;/strong&gt; like TFIDF, Count Vectorizer, Hashing, etc. that have been used in text classification and tried to access their performance to create a baseline. In the &lt;a href=&#34;https://mlwhiz.com/blog/2019/03/09/deeplearning_architectures_text_classification/&#34;&gt;third post&lt;/a&gt;, I delved deeper into &lt;strong&gt;Deep learning models and the various architectures&lt;/strong&gt; we could use to solve the text Classification problem. In this post, I will try to use ULMFit model which is a transfer learning approach to this data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;As a side note&lt;/strong&gt;: if you want to know more about NLP, I would like to &lt;strong&gt;recommend this excellent course&lt;/strong&gt; on &lt;a href=&#34;https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;amp;offerid=467035.11503135394&amp;amp;type=2&amp;amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Flanguage-processing&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Natural Language Processing&lt;/a&gt; in the &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Advanced machine learning specialization&lt;/a&gt;. You can start for free with the 7-day Free Trial. This course covers a wide range of tasks in Natural Language Processing from basic to advanced: sentiment analysis, summarization, dialogue state tracking, to name a few. You can start for free with the 7-day Free Trial.&lt;/p&gt;

&lt;p&gt;Before introducing the notion of transfer learning to NLP applications, we will first need to understand a little bit about Language models.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;language-models-and-nlp-transfer-learning-intuition&#34;&gt;Language Models And NLP Transfer Learning Intuition:&lt;/h2&gt;

&lt;p&gt;In very basic terms the objective of the language model is to &lt;strong&gt;predict the next word given a stream of input words.&lt;/strong&gt; In the past, many different approaches have been used to solve this particular problem. Probabilistic models using Markov assumption is one example of this sort of models.&lt;/p&gt;

&lt;p&gt;$$ P(W_n) = P(W_n|W_{n-1}) $$&lt;/p&gt;

&lt;p&gt;In the recent era, people have been using &lt;em&gt;RNNs/LSTMs&lt;/em&gt; to create such language models. They take as input a word embedding and at each time state return the probability distribution of next word probability over the dictionary words. An example of this is shown below in which the below Neural Network uses multiple stacked layers of RNN cells to learn a language model to predict the next word.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/nlp_tl/language_model.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Now why do we need the concept of Language Modeling? Or How does predicting the next word tie with the current task of text classification?&lt;/em&gt; The intuition ties to the way that the neural network gets trained. The neural network that can predict the next word after being trained on a massive corpus like Wikipedia already has learned a lot of structure in a particular language. Can we use this knowledge in the weights of the network for our advantage? Yes, we can, and that is where the idea of Transfer Learning in NLP stems from. So to make this intuition more concrete, Let us think that our neural network is divided into two parts -&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Language Specific&lt;/strong&gt;: The lower part of the neural network is language specific. That is it learns the features of the language. This part could be used to transfer our knowledge from a language corpus to our current task&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Task Specific&lt;/strong&gt;: I will call the upper part of our network as task specific. The weights in these layers are trained so that it learns to predict the next word.&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/nlp_tl/language_model_2.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Now as it goes in a lot of transfer learning models for Image, we stack the Language Specific part with some dense and softmax layers(Our new task) and train on our new task to achieve what we want to do.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;ulmfit&#34;&gt;ULMFit:&lt;/h2&gt;

&lt;p&gt;Now the concept of Transfer learning in NLP is not entirely new and people already used Language models for transfer learning back in 2015-16 without good result. So what has changed now?&lt;/p&gt;

&lt;p&gt;The thing that has changed is that people like Jeremy Howard and Sebastian Ruder have done a lot of research on how to train these networks. And so we have achieved state of the art results on many text datasets with Transfer Learning approaches.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s follow up with the key research findings in the &lt;a href=&#34;https://arxiv.org/pdf/1801.06146.pdf&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;ULMFit paper&lt;/a&gt; written by them along with the code.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;change-in-the-way-transfer-learning-networks-are-trained&#34;&gt;Change in the way Transfer Learning networks are trained:&lt;/h2&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/nlp_tl/ulmfit_training.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Training a model as per ULMFiT we need to take these three steps:&lt;/p&gt;

&lt;p&gt;a) &lt;strong&gt;Create a Base Language Model:&lt;/strong&gt; Training the language model on a general-domain corpus that captures high-level natural language features&lt;br /&gt;
b) &lt;strong&gt;Finetune Base Language Model on Task Specific Data:&lt;/strong&gt; Fine-tuning the pre-trained language model on target task data&lt;br /&gt;
c) &lt;strong&gt;Finetune Base Language Model Layers + Task Specific Layers on Task Specific Data:&lt;/strong&gt; Fine-tuning the classifier on target task data&lt;/p&gt;

&lt;p&gt;So let us go through these three steps one by one along with the code that is provided to us with the FastAI library.&lt;/p&gt;

&lt;h4 id=&#34;a-create-a-base-language-model&#34;&gt;a) Create a Base Language Model:&lt;/h4&gt;

&lt;p&gt;This task might be the most time-consuming task. This model is analogous to resnet50 or Inception for the vision task. In the paper, they use the language model AWD-LSTM, a regular LSTM architecture trained with various tuned dropout hyperparameters. This model was trained on Wikitext-103 consisting of 28,595 preprocessed Wikipedia articles and 103 million words. We won&amp;rsquo;t perform this task ourselves and will use the fabulous FastAI library to use this model as below. The code below will take our data and preprocess it for usage in the AWD_LSTM model as well as load the model.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Language model data : We use test_df as validation for language model&lt;/span&gt;
data_lm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; TextLMDataBunch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_df(path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;,train_df&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_df ,valid_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_df)
learn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; language_model_learner(data_lm, AWD_LSTM, drop_mult&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It is also where we preprocess the data as per the required usage for the FastAI models. For example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(train_df)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/nlp_tl/train_df.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(data_lm)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;TextLMDataBunch;

Train: LabelList (1306122 items)
x: LMTextList
xxbos xxmaj how did xxmaj quebec nationalists see their province as a nation in the 1960s ?,xxbos xxmaj do you have an adopted dog , how would you encourage people to adopt and not shop ?,xxbos xxmaj why does velocity affect time ? xxmaj does velocity affect space geometry ?,xxbos xxmaj how did xxmaj otto von xxmaj guericke used the xxmaj magdeburg hemispheres ?,xxbos xxmaj can i convert montra xxunk d to a mountain bike by just changing the tyres ?
y: LMLabelList
,,,,
Path: .;

Valid: LabelList (375806 items)
x: LMTextList
xxbos xxmaj why do so many women become so rude and arrogant when they get just a little bit of wealth and power ?,xxbos xxmaj when should i apply for xxup rv college of engineering and xxup bms college of engineering ? xxmaj should i wait for the xxup comedk result or am i supposed to apply before the result ?,xxbos xxmaj what is it really like to be a nurse practitioner ?,xxbos xxmaj who are entrepreneurs ?,xxbos xxmaj is education really making good people nowadays ?
y: LMLabelList
,,,,
Path: .;

Test: None
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The tokenized prepared data is based on a lot of research from the FastAI developers. To make this post a little bit complete, I am sharing some of the tokens definition as well.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;xxunk&lt;/em&gt; is for an unknown word (one that isn&amp;rsquo;t present in the current vocabulary)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;xxpad&lt;/em&gt; is the token used for padding, if we need to regroup several texts of different lengths in a batch&lt;/li&gt;
&lt;li&gt;&lt;em&gt;xxbos&lt;/em&gt; represents the beginning of a text in your dataset&lt;/li&gt;
&lt;li&gt;&lt;em&gt;xxmaj&lt;/em&gt; is used to indicate the next word begins with a capital in the original text&lt;/li&gt;
&lt;li&gt;&lt;em&gt;xxup&lt;/em&gt; is used to indicate the next word is written in all caps in the original text&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;b-finetune-base-language-model-on-task-specific-data&#34;&gt;b) Finetune Base Language Model on Task Specific Data&lt;/h4&gt;

&lt;p&gt;This task is also pretty easy when we look at the code. The specific details of how we do the training is what holds the essence.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Learning with Discriminative fine tuning&lt;/span&gt;
learn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_one_cycle(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-2&lt;/span&gt;)
learn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unfreeze()
learn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_one_cycle(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-3&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Save encoder Object&lt;/span&gt;
learn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;save_encoder(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ft_enc&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The paper introduced two general concepts for this learning stage:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Discriminative fine-tuning:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Main Idea is: As different layers capture different types of information, they should be fine-tuned to different extents.
Instead of using the same learning rate for all layers of the model, discriminative fine-tuning allows us to tune each layer with different learning
rates. In the paper, the authors suggest first to finetune only the last layer, and then unfreeze all the layers with a learning rate lowered by a factor of 2.6.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Slanted triangular learning rates:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/nlp_tl/Stlr.png&#34;  height=&#34;200&#34; width=&#34;400&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;According to the authors: &lt;em&gt;&amp;ldquo;For adapting its parameters to task-specific features, we would like the model to quickly converge to a suitable region of the parameter space in the beginning of training and then refine its parameters&amp;rdquo;&lt;/em&gt;
The Main Idea is to use a high learning rate at the starting stage for increased learning and low learning rates to finetune at later stages in an epoch.&lt;/p&gt;

&lt;p&gt;After training our Language model on the Quora dataset, we should be able to see how our model performs on the Language Model task itself. FastAI library provides us with a simple function to do that.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# check how the language model performs&lt;/span&gt;
learn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;What should&amp;#34;&lt;/span&gt;, n_words&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;&#39;What should be the likelihood of a tourist visiting Mumbai for&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;c-finetune-base-language-model-layers-task-specific-layers-on-task-specific-data&#34;&gt;c) Finetune Base Language Model Layers + Task Specific Layers on Task Specific Data&lt;/h4&gt;

&lt;p&gt;This is the stage where task-specific learning takes place that is we add the classification layers and fine tune them.&lt;/p&gt;

&lt;p&gt;The authors augment the pretrained language model with two additional
linear blocks. Each block uses batch normalization (Ioffe and Szegedy, 2015) and dropout, with ReLU activations for the intermediate layer and a
softmax activation that outputs a probability distribution over target classes at the last layer. The params of these task-specific layers are the only ones that are learned from scratch.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#Creating Classification Data&lt;/span&gt;
data_clas &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; TextClasDataBunch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_df(path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;, train_df&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;train, valid_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;valid,  test_df&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;test_df, vocab&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;data_lm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;train_ds&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;vocab, bs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;,label_cols &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;target&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Creating Classifier Object&lt;/span&gt;
learn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; text_classifier_learner(data_clas, AWD_LSTM, drop_mult&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Add weights of finetuned Language model &lt;/span&gt;
learn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_encoder(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ft_enc&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Fitting Classifier Object&lt;/span&gt;
learn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_one_cycle(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-2&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Fitting Classifier Object after freezing all but last 2 layers&lt;/span&gt;
learn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;freeze_to(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
learn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_one_cycle(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, slice(&lt;span style=&#34;color:#ae81ff&#34;&gt;5e-3&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2.&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5e-3&lt;/span&gt;))
&lt;span style=&#34;color:#75715e&#34;&gt;# Fitting Classifier Object - discriminative learning&lt;/span&gt;
learn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unfreeze()
learn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_one_cycle(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, slice(&lt;span style=&#34;color:#ae81ff&#34;&gt;2e-3&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2e-3&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here also the Authors have derived a few novel methods:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Concat Pooling:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The authors use not only the concatenation of all the hidden state but also the Maxpool and Meanpool representation of all hidden states as input to the linear layers.&lt;/p&gt;

&lt;p&gt;$$ H = [h_1, &amp;hellip; , h_T ] $$&lt;/p&gt;

&lt;p&gt;$$ h_c = [h_T , maxpool(H), meanpool(H)] $$&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Gradual Unfreezing:&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Rather than fine-tuning all layers at once, which risks catastrophic forgetting(Forgetting everything we have learned so far from language models), the authors propose to gradually unfreeze the model starting from the last layer as this contains the least general knowledge. The Authors first unfreeze the last layer and fine-tune all unfrozen layers for one epoch. They then unfreeze the next lower frozen layer and repeat, until they finetune all layers until convergence at the last iteration. The function &lt;code&gt;slice(2e-3/100, 2e-3)&lt;/code&gt; means that we train every layer with different learning rates ranging from max to min value.&lt;/p&gt;

&lt;p&gt;One can get the predictions for the test data at once using:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;test_preds &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(learn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_preds(DatasetType&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Test, ordered&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])[:,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I am a big fan of Kaggle Kernels. One could not have imagined having all that compute for free. You can find a running version of the above code in this &lt;a href=&#34;https://www.kaggle.com/mlwhiz/ulmfit&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;kaggle kernel&lt;/a&gt;. Do try to experiment with it after forking and running the code. Also please upvote the kernel if you find it helpful.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;results&#34;&gt;Results:&lt;/h2&gt;

&lt;p&gt;Here are the final results of all the different approaches I have tried on the Kaggle Dataset. I ran a 5 fold Stratified CV.&lt;/p&gt;

&lt;h3 id=&#34;a-conventional-methods&#34;&gt;a. Conventional Methods:&lt;/h3&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/results_conv.png&#34;  style=&#34;height:40%;width:40%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h3 id=&#34;b-deep-learning-methods&#34;&gt;b. Deep Learning Methods:&lt;/h3&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/results_deep_learning.png&#34;  style=&#34;height:50%;width:50%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h3 id=&#34;c-transfer-learning-methods-ulmfit&#34;&gt;c. Transfer Learning Methods(ULMFIT):&lt;/h3&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/nlp_tl/results_ulm.png&#34;  style=&#34;height:30%;width:30%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;The results achieved were not very good compared to deep learning methods, but I still liked the idea of the transfer learning approach, and it was so easy to implement it using fastAI. Also running the code took a lot of time at 9 hours, compared to other methods which got over in 2 hours.&lt;/p&gt;

&lt;p&gt;Even if this approach didn&amp;rsquo;t work well for this dataset, it is a valid approach for other datasets, as the Authors of the paper have achieved pretty good results on different datasets — definitely a genuine method to try out.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PS:&lt;/strong&gt; Note that I didn&amp;rsquo;t work on tuning the above models, so these results are only cursory. You can try to squeeze more performance by performing hyperparams tuning &lt;a href=&#34;https://mlwhiz.com/blog/2017/12/28/hyperopt_tuning_ml_model/&#34;&gt;using hyperopt&lt;/a&gt; or just old fashioned Grid-search.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion:&lt;/h2&gt;

&lt;p&gt;Finally, this post concludes my NLP Learning series. It took a lot of time to write, but the effort was well worth it. I hope you found it helpful in your work. I will try to write some more on this topic when I get some time. Follow me up at &lt;a href=&#34;https://medium.com/@rahul_agarwal&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Medium&lt;/a&gt; or Subscribe to my blog to be informed about my next posts.&lt;/p&gt;

&lt;p&gt;Also if you want to &lt;a href=&#34;https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;amp;offerid=467035.11503135394&amp;amp;type=2&amp;amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Flanguage-processing&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;learn more about NLP&lt;/strong&gt; here&lt;/a&gt; is an excellent course. You can start for free with the 7-day Free Trial.&lt;/p&gt;

&lt;p&gt;Let me know if you think I can add something more to the post; I will try to incorporate it.&lt;/p&gt;

&lt;p&gt;Cheers!!!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NLP  Learning Series: Part 3 - Attention, CNN and what not for Text Classification</title>
      <link>https://mlwhiz.com/blog/2019/03/09/deeplearning_architectures_text_classification/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2019/03/09/deeplearning_architectures_text_classification/</guid>
      <description>

&lt;p&gt;This post is the third post of the NLP Text classification series. To give you a recap, I started up with an NLP text classification competition on Kaggle called Quora Question insincerity challenge. So I thought to share the knowledge via a series of blog posts on text classification. The &lt;a href=&#34;https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/&#34;&gt;first post&lt;/a&gt; talked about the different &lt;strong&gt;preprocessing techniques that work with Deep learning models&lt;/strong&gt; and &lt;strong&gt;increasing embeddings coverage&lt;/strong&gt;. In the &lt;a href=&#34;https://mlwhiz.com/blog/2019/02/08/deeplearning_nlp_conventional_methods/&#34;&gt;second post&lt;/a&gt;, I talked through some &lt;strong&gt;basic conventional models&lt;/strong&gt; like TFIDF, Count Vectorizer, Hashing, etc. that have been used in text classification and tried to access their performance to create a baseline. In this post, I delve deeper into &lt;strong&gt;Deep learning models and the various architectures&lt;/strong&gt; we could use to solve the text Classification problem. To make this post platform generic, I am going to code in both Keras and Pytorch. I will use various other models which we were not able to use in this competition like &lt;strong&gt;ULMFit transfer learning&lt;/strong&gt; approaches in the fourth post in the series.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;As a side note&lt;/strong&gt;: if you want to know more about NLP, I would like to &lt;strong&gt;recommend this excellent course&lt;/strong&gt; on &lt;a href=&#34;https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;amp;offerid=467035.11503135394&amp;amp;type=2&amp;amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Flanguage-processing&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Natural Language Processing&lt;/a&gt; in the &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Advanced machine learning specialization&lt;/a&gt;. You can start for free with the 7-day Free Trial. This course covers a wide range of tasks in Natural Language Processing from basic to advanced: sentiment analysis, summarization, dialogue state tracking, to name a few. You can start for free with the 7-day Free Trial.&lt;/p&gt;

&lt;p&gt;So let me try to go through some of the models which people are using to perform text classification and try to provide a brief intuition for them — also, some code in Keras and Pytorch. So you can try them out for yourself.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;1-textcnn&#34;&gt;1. TextCNN&lt;/h2&gt;

&lt;p&gt;The idea of using a CNN to classify text was first presented in the paper &lt;a href=&#34;https://www.aclweb.org/anthology/D14-1181&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Convolutional Neural Networks for Sentence Classification&lt;/a&gt; by Yoon Kim.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Representation:&lt;/strong&gt; The central intuition about this idea is to &lt;strong&gt;see our documents as images&lt;/strong&gt;. How? Let us say we have a sentence and we have maxlen = 70 and embedding size = 300. We can create a matrix of numbers with the shape 70x300 to represent this sentence. For images, we also have a matrix where individual elements are pixel values. Instead of image pixels, the input to the tasks is sentences or documents represented as a matrix. Each row of the matrix corresponds to one-word vector.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/text_convolution.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Convolution Idea:&lt;/strong&gt; While for an image we move our conv filter horizontally as well as vertically, for text we fix kernel size to filter_size x embed_size, i.e. (3,300) we are just going to move vertically down for the convolution taking look at three words at once since our filter size is 3 in this case. This idea seems right since our convolution filter is not splitting word embedding. It gets to look at the full embedding of each word. Also one can think of filter sizes as unigrams, bigrams, trigrams, etc. Since we are looking at a context window of 1,2,3, and 5 words respectively.&lt;/p&gt;

&lt;p&gt;Here is the text classification network coded in Pytorch:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; torch
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; torch.nn &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; nn
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; torch.nn.functional &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; F
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; torch.autograd &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Variable


&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;CNN_Text&lt;/span&gt;(nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Module):
    
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; __init__(self):
        super(CNN_Text, self)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__init__()
        filter_sizes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
        num_filters &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;36&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Embedding(max_features, embed_size)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Parameter(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(embedding_matrix, dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32))
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;weight&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;requires_grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convs1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ModuleList([nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Conv2d(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, num_filters, (K, embed_size)) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; K &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; filter_sizes])
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dropout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fc1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Linear(len(Ks)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;num_filters, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)


    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;forward&lt;/span&gt;(self, x):
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding(x)  
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unsqueeze(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)  
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [F&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;relu(conv(x))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; conv &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convs1] 
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [F&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max_pool1d(i, i&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;size(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; x]  
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cat(x, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dropout(x)  
        logit &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fc1(x)  
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; logit&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And for the Keras enthusiasts:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# https://www.kaggle.com/yekenot/2dcnn-textclassifier&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model_cnn&lt;/span&gt;(embedding_matrix):
    filter_sizes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
    num_filters &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;36&lt;/span&gt;

    inp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(maxlen,))
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Embedding(max_features, embed_size, weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[embedding_matrix])(inp)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Reshape((maxlen, embed_size, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))(x)

    maxpool_pool &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(filter_sizes)):
        conv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Conv2D(num_filters, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(filter_sizes[i], embed_size),
                                     kernel_initializer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;he_normal&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;)(x)
        maxpool_pool&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(MaxPool2D(pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(maxlen &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; filter_sizes[i] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))(conv))

    z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Concatenate(axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)(maxpool_pool)   
    z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Flatten()(z)
    z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dropout(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)(z)

    outp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sigmoid&amp;#34;&lt;/span&gt;)(z)

    model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inp, outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;outp)
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;binary_crossentropy&amp;#39;&lt;/span&gt;, optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
    
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I am a big fan of Kaggle Kernels. One could not have imagined having all that compute for free. You can find a running version of the above two code snippets in this &lt;a href=&#34;https://www.kaggle.com/mlwhiz/textcnn-pytorch-and-keras&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;kaggle kernel&lt;/a&gt;. Do try to experiment with it after forking and running the code. Also please upvote the kernel if you find it helpful.&lt;/p&gt;

&lt;p&gt;The Keras model and Pytorch model performed similarly with Pytorch model beating the keras model by a small margin. The Out-Of-Fold CV F1 score for the Pytorch model came out to be 0.6609 while for Keras model the same score came out to be 0.6559. I used the same preprocessing in both the models to be better able to compare the platforms.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;2-bidirectional-rnn-lstm-gru&#34;&gt;2. BiDirectional RNN(LSTM/GRU):&lt;/h2&gt;

&lt;p&gt;TextCNN works well for Text Classification. It takes care of words in close range. It can see &amp;ldquo;new york&amp;rdquo; together. However, it still can&amp;rsquo;t take care of all the context provided in a particular text sequence. It still does not learn the sequential structure of the data, where every word is dependent on the previous word. Or a word in the previous sentence.&lt;/p&gt;

&lt;p&gt;RNN help us with that. &lt;em&gt;They can remember previous information using hidden states and connect it to the current task.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Long Short Term Memory networks (LSTM) are a subclass of RNN, specialized in remembering information for an extended period. Moreover, the Bidirectional LSTM keeps the contextual information in both directions which is pretty useful in text classification task (But won&amp;rsquo;t work for a time series prediction task as we don&amp;rsquo;t have visibility into the future in this case).&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/birnn.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;For a most simplistic explanation of Bidirectional RNN, think of RNN cell as a black box taking as input a hidden state(a vector) and a word vector and giving out an output vector and the next hidden state. This box has some weights which are to be tuned using Backpropagation of the losses. Also, the same cell is applied to all the words so that the weights are shared across the words in the sentence. This phenomenon is called weight-sharing.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/singlernn.png&#34;  height=&#34;30%&#34; width=&#34;30%&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code&gt;        Hidden state, Word vector -&amp;gt;(RNN Cell) -&amp;gt; Output Vector , Next Hidden state
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For a sequence of length 4 like &lt;strong&gt;&amp;ldquo;you will never believe&amp;rdquo;&lt;/strong&gt;, The RNN cell gives 4 output vectors, which can be concatenated and then used as part of a dense feedforward architecture.&lt;/p&gt;

&lt;p&gt;In the Bidirectional RNN, the only change is that we read the text in the usual fashion as well in reverse. So we stack two RNNs in parallel, and hence we get 8 output vectors to append.&lt;/p&gt;

&lt;p&gt;Once we get the output vectors, we send them through a series of dense layers and finally a softmax layer to build a text classifier.&lt;/p&gt;

&lt;p&gt;In most cases, you need to understand how to stack some layers in a neural network to get the best results. We can try out multiple bidirectional GRU/LSTM layers in the network if it performs better.&lt;/p&gt;

&lt;p&gt;Due to the limitations of RNNs like not remembering long term dependencies, in practice, we almost always use LSTM/GRU to model long term dependencies. In such a case you can think of the RNN cell being replaced by an LSTM cell or a GRU cell in the above figure. An example model is provided below. You can use CuDNNGRU interchangeably with CuDNNLSTM when you build models. (CuDNNGRU/LSTM are just implementations of LSTM/GRU that are created to run faster on GPUs. In most cases always use them instead of the vanilla LSTM/GRU implementations)&lt;/p&gt;

&lt;p&gt;So here is some code in Pytorch for this network.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;BiLSTM&lt;/span&gt;(nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Module):
    
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; __init__(self):
        super(BiLSTM, self)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__init__()
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hidden_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;
        drp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Embedding(max_features, embed_size)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Parameter(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(embedding_matrix, dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32))
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;weight&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;requires_grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lstm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LSTM(embed_size, self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hidden_size, bidirectional&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, batch_first&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linear &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Linear(self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hidden_size&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; , &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;relu &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ReLU()
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dropout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(drp)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;out &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Linear(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)


    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;forward&lt;/span&gt;(self, x):
        h_embedding &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding(x)
        h_embedding &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unsqueeze(h_embedding, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
        
        h_lstm, _ &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lstm(h_embedding)
        avg_pool &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(h_lstm, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
        max_pool, _ &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max(h_lstm, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
        conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cat(( avg_pool, max_pool), &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
        conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;relu(self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linear(conc))
        conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dropout(conc)
        out &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;out(conc)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; out&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Also, here is the same code in Keras.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# BiDirectional LSTM&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model_lstm_du&lt;/span&gt;(embedding_matrix):
    inp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(maxlen,))
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Embedding(max_features, embed_size, weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[embedding_matrix])(inp)
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Here 64 is the size(dim) of the hidden state vector as well as the output vector. Keeping return_sequence we want the output for the entire sequence. So what is the dimension of output for this layer?
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        64*70(maxlen)*2(bidirection concat)
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    CuDNNLSTM is fast implementation of LSTM layer in Keras which only runs on GPU
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Bidirectional(CuDNNLSTM(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True))(x)
    avg_pool &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GlobalAveragePooling1D()(x)
    max_pool &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GlobalMaxPooling1D()(x)
    conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; concatenate([avg_pool, max_pool])
    conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;)(conc)
    conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dropout(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)(conc)
    outp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sigmoid&amp;#34;&lt;/span&gt;)(conc)
    model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inp, outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;outp)
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;binary_crossentropy&amp;#39;&lt;/span&gt;, optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can run this code in my &lt;a href=&#34;https://www.kaggle.com/mlwhiz/bilstm-pytorch-and-keras&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;BiLSTM with Pytorch and Keras kaggle kernel&lt;/a&gt; for this competition. Please do upvote the kernel if you find it helpful.&lt;/p&gt;

&lt;p&gt;In the BiLSTM case also, Pytorch model beats the keras model by a small margin. The Out-Of-Fold CV F1 score for the Pytorch model came out to be 0.6741 while for Keras model the same score came out to be 0.6727. This score is around a 1-2% increase from the TextCNN performance which is pretty good. Also, note that it is around 6-7% better than conventional methods.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;3-attention-models&#34;&gt;3. Attention Models&lt;/h2&gt;

&lt;p&gt;Dzmitry Bahdanau et al first presented attention in their paper &lt;a href=&#34;https://arxiv.org/abs/1409.0473&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Neural Machine Translation by Jointly Learning to Align and Translate&lt;/a&gt; but I find that the paper on &lt;a href=&#34;https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Hierarchical Attention Networks for Document Classification&lt;/a&gt; written jointly by CMU and Microsoft in 2016 is a much easier read and provides more intuition.&lt;/p&gt;

&lt;p&gt;So let us talk about the intuition first. In the past conventional methods like TFIDF/CountVectorizer etc. we used to find features from the text by doing a keyword extraction. Some word is more helpful in determining the category of a text than others. However, in this method we sort of lost the sequential structure of the text. With LSTM and deep learning methods, while we can take care of the sequence structure, we lose the ability to give higher weight to more important words.
&lt;strong&gt;Can we have the best of both worlds?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The answer is Yes. Actually, &lt;strong&gt;Attention is all you need&lt;/strong&gt;. In the author&amp;rsquo;s words:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Not all words contribute equally to the representation of the sentence meaning. Hence, we introduce attention mechanism to extract such words that are important to the meaning of the sentence and aggregate the representation of those informative words to form a sentence vector&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/birnn attention.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;In essence, we want to create scores for every word in the text, which is the attention similarity score for a word.&lt;/p&gt;

&lt;p&gt;To do this, we start with a weight matrix(W), a bias vector(b) and a context vector u. The optimization algorithm learns all of these weights. On this note I would like to highlight something I like a lot about neural networks - If you don&amp;rsquo;t know some params, let the network learn them. We only have to worry about creating architectures and params to tune.&lt;/p&gt;

&lt;p&gt;Then there are a series of mathematical operations. See the figure for more clarification. We can think of u1 as nonlinearity on RNN word output. After that v1 is a dot product of u1 with a context vector u raised to exponentiation. From an intuition viewpoint, the value of v1 will be high if u and u1 are similar. Since we want the sum of scores to be 1, we divide v by the sum of v’s to get the Final Scores,s&lt;/p&gt;

&lt;p&gt;These final scores are then multiplied by RNN output for words to weight them according to their importance. After which the outputs are summed and sent through dense layers and softmax for the task of text classification.&lt;/p&gt;

&lt;p&gt;Here is the code in Pytorch. &lt;strong&gt;Do try to read through the pytorch code for attention layer.&lt;/strong&gt; It just does what I have explained above.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Attention&lt;/span&gt;(nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Module):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; __init__(self, feature_dim, step_dim, bias&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;kwargs):
        super(Attention, self)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__init__(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;kwargs)
        
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;supports_masking &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; True

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bias &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; bias
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;feature_dim &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; feature_dim
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;step_dim &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; step_dim
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;features_dim &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
        
        weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros(feature_dim, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
        nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;kaiming_uniform_(weight)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Parameter(weight)
        
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; bias:
            self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Parameter(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros(step_dim))
        
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;forward&lt;/span&gt;(self, x, mask&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None):
        feature_dim &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;feature_dim 
        step_dim &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;step_dim

        eij &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mm(
            x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;contiguous()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;view(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, feature_dim), 
            self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;weight
        )&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;view(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, step_dim)
        
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bias:
            eij &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; eij &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b
            
        eij &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tanh(eij)
        a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(eij)
        
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; mask &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
            a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; mask

        a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(a, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, keepdim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1e-10&lt;/span&gt;)

        weighted_input &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unsqueeze(a, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(weighted_input, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Attention_Net&lt;/span&gt;(nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Module):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; __init__(self):
        super(Attention_Net, self)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__init__()
        drp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Embedding(max_features, embed_size)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Parameter(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(embedding_matrix, dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32))
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;weight&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;requires_grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding_dropout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout2d(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lstm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LSTM(embed_size, &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, bidirectional&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, batch_first&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lstm2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GRU(&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, bidirectional&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, batch_first&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;attention_layer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Attention(&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, maxlen)
        
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linear &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Linear(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; , &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;relu &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ReLU()
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;out &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Linear(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;forward&lt;/span&gt;(self, x):
        h_embedding &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding(x)
        h_embedding &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unsqueeze(h_embedding, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
        h_lstm, _ &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lstm(h_embedding)
        h_lstm, _ &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lstm2(h_lstm)
        h_lstm_atten &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;attention_layer(h_lstm)
        conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;relu(self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linear(h_lstm_atten))
        out &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;out(conc)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; out&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Same code for Keras.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dot_product&lt;/span&gt;(x, kernel):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Wrapper for dot product operation, in order to be compatible with both
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Theano and Tensorflow
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Args:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        x (): input
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        kernel (): weights
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Returns:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;backend() &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tensorflow&amp;#39;&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(x, K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(kernel)), axis&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(x, kernel)
    

&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;AttentionWithContext&lt;/span&gt;(Layer):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Attention operation, with a context/query vector, for temporal data.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Supports Masking.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;Hierarchical Attention Networks for Document Classification&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    by using a context vector to assist the attention
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    # Input shape
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        3D tensor with shape: `(samples, steps, features)`.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    # Output shape
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        2D tensor with shape: `(samples, features)`.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    How to use:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    The dimensions are inferred based on the output shape of the RNN.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Note: The layer has been tested with Keras 2.0.6
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Example:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        model.add(LSTM(64, return_sequences=True))
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        model.add(AttentionWithContext())
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        # next add a Dense layer (for classification/regression) or whatever...
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; __init__(self,
                 W_regularizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, u_regularizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, b_regularizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None,
                 W_constraint&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, u_constraint&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, b_constraint&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None,
                 bias&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;kwargs):

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;supports_masking &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; True
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; initializers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;glorot_uniform&amp;#39;&lt;/span&gt;)

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_regularizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; regularizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(W_regularizer)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;u_regularizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; regularizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(u_regularizer)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_regularizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; regularizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(b_regularizer)

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_constraint &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; constraints&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(W_constraint)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;u_constraint &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; constraints&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(u_constraint)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_constraint &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; constraints&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(b_constraint)

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bias &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; bias
        super(AttentionWithContext, self)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__init__(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;kwargs)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;build&lt;/span&gt;(self, input_shape):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;assert&lt;/span&gt; len(input_shape) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_weight((input_shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], input_shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],),
                                 initializer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init,
                                 name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{}_W&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name),
                                 regularizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_regularizer,
                                 constraint&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_constraint)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bias:
            self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_weight((input_shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],),
                                     initializer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;zero&amp;#39;&lt;/span&gt;,
                                     name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{}_b&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name),
                                     regularizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_regularizer,
                                     constraint&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_constraint)

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;u &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_weight((input_shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],),
                                 initializer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init,
                                 name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{}_u&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name),
                                 regularizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;u_regularizer,
                                 constraint&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;u_constraint)

        super(AttentionWithContext, self)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;build(input_shape)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;compute_mask&lt;/span&gt;(self, input, input_mask&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None):
        &lt;span style=&#34;color:#75715e&#34;&gt;# do not pass the mask to the next layers&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; None

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;call&lt;/span&gt;(self, x, mask&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None):
        uit &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dot_product(x, self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W)

        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bias:
            uit &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b

        uit &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tanh(uit)
        ait &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dot_product(uit, self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;u)

        a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(ait)

        &lt;span style=&#34;color:#75715e&#34;&gt;# apply mask after the exp. will be re-normalized next&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; mask &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
            &lt;span style=&#34;color:#75715e&#34;&gt;# Cast the mask to floatX to avoid float64 upcasting in theano&lt;/span&gt;
            a &lt;span style=&#34;color:#f92672&#34;&gt;*=&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(mask, K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;floatx())

        &lt;span style=&#34;color:#75715e&#34;&gt;# in some cases especially in the early stages of training the sum may be almost zero&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# and this results in NaN&amp;#39;s. A workaround is to add a very small positive number ε to the sum.&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())&lt;/span&gt;
        a &lt;span style=&#34;color:#f92672&#34;&gt;/=&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(a, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, keepdims&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;epsilon(), K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;floatx())

        a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(a)
        weighted_input &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; a
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(weighted_input, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;compute_output_shape&lt;/span&gt;(self, input_shape):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; input_shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], input_shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]


&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model_lstm_atten&lt;/span&gt;(embedding_matrix):
    inp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(maxlen,))
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Embedding(max_features, embed_size, weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[embedding_matrix], trainable&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)(inp)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Bidirectional(CuDNNLSTM(&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True))(x)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Bidirectional(CuDNNLSTM(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True))(x)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AttentionWithContext()(x)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;)(x)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sigmoid&amp;#34;&lt;/span&gt;)(x)
    model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inp, outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;x)
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;binary_crossentropy&amp;#39;&lt;/span&gt;, optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Again, my &lt;a href=&#34;https://www.kaggle.com/mlwhiz/attention-pytorch-and-keras&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Attention with Pytorch and Keras Kaggle kernel&lt;/a&gt; contains the working versions for this code. Please do upvote the kernel if you find it useful.&lt;/p&gt;

&lt;p&gt;This method performed well with Pytorch CV scores reaching around 0.6758 and Keras CV scores reaching around 0.678. &lt;strong&gt;This score is more than what we were able to achieve with BiLSTM and TextCNN.&lt;/strong&gt; However, please note that we didn&amp;rsquo;t work on tuning any of the given methods yet and so the scores might be different.&lt;/p&gt;

&lt;p&gt;With this, I leave you to experiment with new architectures and playing around with stacking multiple GRU/LSTM layers to improve your network performance. You can also look at including more techniques in these network like Bucketing, handmade features, etc. Some of the tips and new techniques are mentioned here on my blog post: &lt;a href=&#34;https://mlwhiz.com/blog/2019/02/19/siver_medal_kaggle_learnings/&#34;&gt;What my first Silver Medal taught me about Text Classification and Kaggle in general?&lt;/a&gt;. Also, here is another Kaggle kernel which is &lt;a href=&#34;https://www.kaggle.com/mlwhiz/multimodel-ensemble-clean-kernel?scriptVersionId=10279838&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;my silver-winning entry&lt;/a&gt; for this competition.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;

&lt;p&gt;Here are the final results of all the different approaches I have tried on the Kaggle Dataset. I ran a 5 fold Stratified CV.&lt;/p&gt;

&lt;h3 id=&#34;a-conventional-methods&#34;&gt;a. Conventional Methods:&lt;/h3&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/results_conv.png&#34;  style=&#34;height:40%;width:40%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h3 id=&#34;b-deep-learning-methods&#34;&gt;b. Deep Learning Methods:&lt;/h3&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/results_deep_learning.png&#34;  style=&#34;height:50%;width:50%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;PS:&lt;/strong&gt; Note that I didn&amp;rsquo;t work on tuning the above models, so these results are only cursory. You can try to squeeze more performance by performing hyperparams tuning &lt;a href=&#34;https://mlwhiz.com/blog/2017/12/28/hyperopt_tuning_ml_model/&#34;&gt;using hyperopt&lt;/a&gt; or just old fashioned Grid-search.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this post, I went through with the explanations of various deep learning architectures people are using for Text classification tasks. In the next post, we will delve further into the next new phenomenon in NLP space - Transfer Learning with BERT and ULMFit. Follow me up at &lt;a href=&#34;https://medium.com/@rahul_agarwal&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Medium&lt;/a&gt; or Subscribe to my blog to be informed about my next post.&lt;/p&gt;

&lt;p&gt;Also if you want to &lt;a href=&#34;https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;amp;offerid=467035.11503135394&amp;amp;type=2&amp;amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Flanguage-processing&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;learn more about NLP&lt;/strong&gt; here&lt;/a&gt; is an excellent course. You can start for free with the 7-day Free Trial.&lt;/p&gt;

&lt;p&gt;Let me know if you think I can add something more to the post; I will try to incorporate it.&lt;/p&gt;

&lt;p&gt;Cheers!!!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What my first Silver Medal taught me about Text Classification and Kaggle in general?</title>
      <link>https://mlwhiz.com/blog/2019/02/19/siver_medal_kaggle_learnings/</link>
      <pubDate>Tue, 19 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2019/02/19/siver_medal_kaggle_learnings/</guid>
      <description>

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/silver/leaderboard.png&#34;  style=&#34;height:90%;width:90%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Kaggle is an excellent place for learning. And I learned a lot of things from the recently concluded competition on &lt;strong&gt;Quora Insincere questions classification&lt;/strong&gt; in which I got a rank of &lt;strong&gt;&lt;code&gt;182/4037&lt;/code&gt;&lt;/strong&gt;. In this post, I will try to provide a summary of the things I tried. I will also try to summarize the ideas which I missed but were a part of other winning solutions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;As a side note&lt;/strong&gt;: if you want to know more about NLP, I would like to &lt;strong&gt;recommend this awesome course&lt;/strong&gt; on &lt;a href=&#34;https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;amp;offerid=467035.11503135394&amp;amp;type=2&amp;amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Flanguage-processing&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Natural Language Processing&lt;/a&gt; in the &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Advanced machine learning specialization&lt;/a&gt;. You can start for free with the 7-day Free Trial. This course covers a wide range of tasks in Natural Language Processing from basic to advanced: sentiment analysis, summarization, dialogue state tracking, to name a few. You can start for free with the 7-day Free Trial.&lt;/p&gt;

&lt;p&gt;So first a little bit of summary about the competition for the uninitiated. In this competition, we had to develop models that identify and flag insincere questions. &lt;strong&gt;&lt;em&gt;The challenge was not only a test for performance but also a test of efficient code writing skills.&lt;/em&gt;&lt;/strong&gt; As it was a kernel competition with limited outside data options, competitors were limited to use only the word embeddings provided by the competition organizers. That means we were not allowed to use State of the art models like BERT. We were also limited in the sense that all our models should run in a time of 2 hours. So say bye bye to stacking and monster ensembles though some solutions were able to do this by making their code ultra-efficient. More on this later.&lt;/p&gt;

&lt;h2 id=&#34;some-kaggle-learnings&#34;&gt;Some Kaggle Learnings:&lt;/h2&gt;

&lt;p&gt;There were a couple of &lt;strong&gt;learnings about kaggle as a whole&lt;/strong&gt; that I would like to share before jumping into my final solution:&lt;/p&gt;

&lt;h3 id=&#34;1-always-trust-your-cv&#34;&gt;1. Always trust your CV&lt;/h3&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/silver/CV_vs_LB.png&#34;  style=&#34;height:50%;width:50%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;One of the things that genuinely baffled a lot of people in this competition was that a good CV score did not necessarily translate well to a good LB score. The main reason for this was &lt;strong&gt;small test dataset&lt;/strong&gt;(only 65k rows) in the first stage(around 15% of total test data).&lt;/p&gt;

&lt;p&gt;A common theme on discussion forums was focussing on which submissions we should select as the final submission:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The one having the best local CV? or&lt;/li&gt;
&lt;li&gt;The one having the best LB?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And while it seems simple to say to trust your CV, common sense goes for a toss when you see that your LB score is going down or remaining constant whenever your Local CV score increases.&lt;/p&gt;

&lt;p&gt;Luckily I didn&amp;rsquo;t end up making the mistake of not trusting my CV score. Owing to a lot of excellent posts on Kaggle discussion board, &lt;strong&gt;&lt;em&gt;I selected a kernel with Public LB score of 0.697 and a Local CV of 0.701, which was around &amp;gt;1200 rank on Public LB as of the final submission. It achieved a score of 0.702 and ranked 182 on the private LB.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;While this seems like a straightforward choice post-facto, it was a hard decision to make at a time when you have at your disposal some public kernels having Public LB score &amp;gt;= 0.70&lt;/p&gt;

&lt;h3 id=&#34;2-use-the-code-from-public-kernels-but-check-for-errors&#34;&gt;2. Use the code from public kernels but check for errors&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaggle.com/bminixhofer/deterministic-neural-networks-using-pytorch&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;This&lt;/a&gt; Pytorch kernel by Benjamin Minixhofer is awesome. It made the base of many of my submissions for this competition. But this kernel had a mistake. It didn&amp;rsquo;t implement spatial dropout in the right way. You can find the correct implementation of spatial dropout in my post &lt;a href=&#34;https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/&#34;&gt;here&lt;/a&gt; or on my &lt;a href=&#34;https://www.kaggle.com/mlwhiz/third-place-model-for-toxic-spatial-dropout&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;kernel&lt;/a&gt;. Implementing spatial dropout in the right way gave a boost of around 0.004 to the local CV.&lt;/p&gt;

&lt;p&gt;Nonetheless, I learned pytorch using this kernel, and I am grateful to him for the same.&lt;/p&gt;

&lt;h3 id=&#34;3-don-t-trust-everything-that-goes-on-the-discussion-forums&#34;&gt;3. Don&amp;rsquo;t trust everything that goes on the discussion forums&lt;/h3&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/silver/read-what-the-smart-people-are-saying.png&#34;  style=&#34;height:90%;width:90%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;I will talk about two things here:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Seed tuning&lt;/strong&gt;: While in the middle of the competition, everyone was trying to get the best possible rank on the public LB. It is just human nature. A lot of discussions was around good seeds and bad seeds for neural network initialization. While it seems okay in the first look, the conversation went a stage further where &lt;strong&gt;people started tuning seeds in the kernel as a hyper param&lt;/strong&gt;. Some discussions even went on to say that it was a valid strategy. And that is where a large amount of overfitting to public LB started happening. The same submission would score 0.704 from 0.699 just by changing the seed. For a reference, that meant you could go from anywhere near 400-500 rank to top 50 only by changing seed in a public kernel. And that spelled disaster. Some people did that. They went up the public LB. Went crashing out at the private stage.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;CV score disclosure on discussion forums&lt;/strong&gt;: We always try to gauge our performance against other people. In a lot of discussions, people provided their CV scores and corresponding Public LB scores. The scores were all over the place and not comparable due to Different CV schemes, No of folds in CV, Metric reported, Overfitting or just plain Wrong implementation of Cross-Validation. But they ended up influencing a lot of starters and newcomers.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;4-on-that-note-be-active-on-discussion-forums-and-check-public-kernels-regularly&#34;&gt;4. On that note, be active on Discussion forums and check public kernels regularly&lt;/h3&gt;

&lt;p&gt;You can learn a lot just by being part of discussion forums and following public kernels. This competition had a lot of excellent public kernels on embeddings by &lt;a href=&#34;https://www.kaggle.com/sudalairajkumar/a-look-at-different-embeddings&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;SRK&lt;/a&gt;, Models by &lt;a href=&#34;https://www.kaggle.com/shujian/mix-of-nn-models-based-on-meta-embedding&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Shujian&lt;/a&gt;, and Preprocessing by &lt;a href=&#34;https://www.kaggle.com/theoviel/improve-your-score-with-text-preprocessing-v2&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Theo Viel&lt;/a&gt; which gave everyone a headstart. As the competition progressed, the discussions also evolved. There were discussions on speeding up the code, working approaches, F1 threshold finders, and other exciting topics which kept me occupied with new ideas and improvements.&lt;/p&gt;

&lt;p&gt;Even after the end, while reading up discussions on solutions overview, I learned a lot. And I would say it is very ** vital to check out the winning solutions.**&lt;/p&gt;

&lt;h3 id=&#34;5-share-a-lot&#34;&gt;5. Share a lot&lt;/h3&gt;

&lt;p&gt;Sharing is everything on Kaggle. People have shared their codes as well as their ideas while competing as well as after the competition ended. It is only together that we can go forward. I like blogging, so I am sharing the knowledge via a series of blog posts on text classification. The &lt;a href=&#34;https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/&#34;&gt;first post&lt;/a&gt; talked about the different &lt;strong&gt;preprocessing techniques that work with Deep learning models&lt;/strong&gt; and &lt;strong&gt;increasing embeddings coverage&lt;/strong&gt;. In the &lt;a href=&#34;https://mlwhiz.com/blog/2019/02/08/deeplearning_nlp_conventional_methods/&#34;&gt;second post&lt;/a&gt;, I talked through some &lt;strong&gt;basic conventional models&lt;/strong&gt; like TFIDF, Count Vectorizer, Hashing, etc. that have been used in text classification and tried to access their performance to create a baseline. In the third post, I will delve deeper into &lt;strong&gt;Deep learning models and the various architectures&lt;/strong&gt; we could use to solve the text Classification problem. To make this post platform generic I will try to write code in both Keras and Pytorch. We will try to use various other models which we were not able to use in this competition like &lt;strong&gt;ULMFit transfer learning&lt;/strong&gt; approaches in the fourth post in the series.&lt;/p&gt;

&lt;p&gt;It might take me a little time to write the whole series. Till then you can take a look at my other posts too: &lt;a href=&#34;https://mlwhiz.com/blog/2018/12/17/text_classification/&#34;&gt;What Kagglers are using for Text Classification&lt;/a&gt;, which talks about various deep learning models in use in NLP and &lt;a href=&#34;https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/&#34;&gt;how to switch from Keras to Pytorch&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;6-beware-of-trolls&#34;&gt;6. Beware of trolls :)&lt;/h3&gt;

&lt;p&gt;We were going along happily towards the end of the competition with two weeks left. Scores were increasing slowly. The top players were somewhat stagnant. &lt;strong&gt;&lt;em&gt;And then came Pavel and team with a Public LB score of 0.782.&lt;/em&gt;&lt;/strong&gt; The next group had an LB score of 0.713. Such a huge difference. I was so sure that there was some leakage in the data which nobody has caught yet except for Pavel. I spent nearly half a day to do EDA again.&lt;/p&gt;

&lt;p&gt;In the end, it turned out that what they did was &lt;a href=&#34;https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/80665&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;scraping&lt;/a&gt; — nicely played!&lt;/p&gt;

&lt;p&gt;They also have some pretty awesome ideas around including additional data, which could have worked but did not in this competition.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;my-final-solution&#34;&gt;My Final Solution:&lt;/h2&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/silver/lb2.png&#34;  style=&#34;height:90%;width:90%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;My main focus was on &lt;em&gt;meta-feature engineering&lt;/em&gt; and on &lt;em&gt;increasing embedding coverage and quality&lt;/em&gt;. That means I did not play much with various Neural Net architectures. Here are the things that I included in my final submission:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I noticed that Glove embeddings were doing good on the local CV but not on LB, while meta embeddings(mean of glove and paragram) were doing good on LB but not that good on the CV. I took a mixed approach so &lt;strong&gt;some of my models are trained with only glove embedding and some on meta embeddings&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Included four more features in embedding&lt;/strong&gt;. Thus my embedding was a 304-dimensional vector. The four new values corresponded to title case flag, uppercase flag, Textblob word polarity, textblob word subjectivity&lt;/li&gt;
&lt;li&gt;Found out &lt;strong&gt;NER tokens from the whole train and test data using spacy&lt;/strong&gt; and kept the tokens and the entities in a dict. I used this dict to create extra features like counts of &lt;code&gt;GPE&lt;/code&gt;, &lt;code&gt;PERSON&lt;/code&gt;, &lt;code&gt;ORG&lt;/code&gt;, &lt;code&gt;NORP&lt;/code&gt;, &lt;code&gt;WORK_OF_ART&lt;/code&gt;.Added some value and were highly correlated with the target.&lt;/li&gt;
&lt;li&gt;Other features that I used include &lt;code&gt;total_length&lt;/code&gt;,&lt;code&gt;capitals&lt;/code&gt;,&lt;code&gt;words_vs_unique&lt;/code&gt; as well as some engineered features like &lt;code&gt;sum_feat&lt;/code&gt;(sum of expletives), &lt;code&gt;question_start_with_why&lt;/code&gt;, &lt;code&gt;question_start_with_how_or_what&lt;/code&gt;, &lt;code&gt;question_start_with_do_or_are&lt;/code&gt;. Might not have added much value but still kept them.&lt;/li&gt;
&lt;li&gt;My final solution consisted of a &lt;strong&gt;stacked ensemble for four models&lt;/strong&gt;. I stacked the four models using Logistic regression(with positive weights and 0 intercept) and gave the weights as a list in the final kernel.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can find the kernel for my final submission &lt;a href=&#34;https://www.kaggle.com/mlwhiz/multimodel-ensemble-clean-kernel?scriptVersionId=10279838&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;tips-and-tricks-used-in-other-solutions&#34;&gt;Tips and Tricks used in other solutions:&lt;/h2&gt;

&lt;h3 id=&#34;1-increasing-embeddings-coverage&#34;&gt;1. Increasing Embeddings Coverage:&lt;/h3&gt;

&lt;p&gt;In the third place solution &lt;a href=&#34;https://www.kaggle.com/wowfattie/3rd-place&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;kernel&lt;/a&gt;, wowfattie uses stemming, lemmatization, capitalize, lower, uppercase, as well as embedding of the nearest word using a spell checker to get embeddings for all words in his vocab. Such a great idea. &lt;strong&gt;I liked this solution the best as it can do what I was trying to do and finished at a pretty good place.&lt;/strong&gt; Also, the code is very clean.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; nltk.stem &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; PorterStemmer
ps &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; PorterStemmer()
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; nltk.stem.lancaster &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; LancasterStemmer
lc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; LancasterStemmer()
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; nltk.stem &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; SnowballStemmer
sb &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SnowballStemmer(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;english&amp;#34;&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;load_glove&lt;/span&gt;(word_dict, lemma_dict):
    EMBEDDING_FILE &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;../input/embeddings/glove.840B.300d/glove.840B.300d.txt&amp;#39;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_coefs&lt;/span&gt;(word,&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;arr): &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; word, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;asarray(arr, dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;)
    embeddings_index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dict(get_coefs(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;o&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;)) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; o &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; open(EMBEDDING_FILE))
    embed_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;
    nb_words &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; len(word_dict)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    embedding_matrix &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((nb_words, embed_size), dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)
    unknown_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((embed_size,), dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(unknown_vector[:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; key &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; tqdm(word_dict):
        word &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; key
        embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(word)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
            embedding_matrix[word_dict[key]] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embedding_vector
            &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
        word &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; key&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lower()
        embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(word)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
            embedding_matrix[word_dict[key]] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embedding_vector
            &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
        word &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; key&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;upper()
        embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(word)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
            embedding_matrix[word_dict[key]] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embedding_vector
            &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
        word &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; key&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;capitalize()
        embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(word)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
            embedding_matrix[word_dict[key]] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embedding_vector
            &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
        word &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ps&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stem(key)
        embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(word)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
            embedding_matrix[word_dict[key]] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embedding_vector
            &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
        word &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stem(key)
        embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(word)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
            embedding_matrix[word_dict[key]] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embedding_vector
            &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
        word &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stem(key)
        embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(word)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
            embedding_matrix[word_dict[key]] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embedding_vector
            &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
        word &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lemma_dict[key]
        embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(word)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
            embedding_matrix[word_dict[key]] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embedding_vector
            &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(key) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
            word &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; correction(key)
            embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(word)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
                embedding_matrix[word_dict[key]] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embedding_vector
                &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
        embedding_matrix[word_dict[key]] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; unknown_vector                    
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; embedding_matrix, nb_words &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&#34;2-checkpoint-ensembling&#34;&gt;2. Checkpoint Ensembling:&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Get a lot of models at no cost&lt;/strong&gt;. Most of the winning solutions have some version of checkpoint ensembling. For the third place solution, the predictions are a weighted average of predictions after the 4th epoch and predictions after the 5th epoch. I got this idea but forgot to implement it in my ensemble based kernel submission.&lt;/p&gt;

&lt;h3 id=&#34;3-meta-embeddings&#34;&gt;3. Meta Embeddings:&lt;/h3&gt;

&lt;p&gt;A lot of winning solutions ended up using &lt;strong&gt;weighted meta embeddings&lt;/strong&gt; where they provided a higher weight to the Glove embedding. Some solutions also used &lt;strong&gt;concatenated embeddings&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&#34;4-model-architecture&#34;&gt;4. Model Architecture:&lt;/h3&gt;

&lt;p&gt;One surprising thing I saw people doing was to use a &lt;strong&gt;1Dconv layer just after the Bidirectional layer&lt;/strong&gt;. For example, This is the &lt;a href=&#34;https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/80568&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;architecture&lt;/a&gt; used by the team that placed first in the competition.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/silver/arch_1_place.png&#34;  style=&#34;height:50%;width:50%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h3 id=&#34;5-bucketing-variable-sequence-length-and-increased-hidden-units&#34;&gt;5. Bucketing/Variable Sequence Length and increased hidden units:&lt;/h3&gt;

&lt;p&gt;Another thing I noticed is the increased number of hidden units as compared to many public kernels. Most of the public kernels used a hidden unit size of 60 due to time constraints. I used 80 units at the cost of training one less network. A lot of high scoring kernels were able to use a higher number of hidden units owing to variable sequence length idea or bucketing. From the 1st place kernel discussion:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We do not pad sequences to the same length based on the whole data, but just on a batch level. That means we conduct &lt;strong&gt;padding and truncation on the data generator level for each batch separately&lt;/strong&gt;, so that length of the sentences in a batch can vary in size. Additionally, we further improved this by not truncating based on the length of the longest sequence in the batch but based on the 95% percentile of lengths within the sequence. This improved runtime heavily and kept accuracy quite robust on single model level, and improved it by being able to average more models.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Also from 7th place &lt;a href=&#34;https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/80561&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;discussion&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Bucketing is to make a minibatch from instances that have similar lengths to alleviate the cost of padding. This makes the training speed more than &lt;strong&gt;3x faster, and thus I can run 9 epochs for each split of 5-fold.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Thus the use of this technique also allowed some competitors to fit many more epochs in less time and run more models at the same time. Pretty Neat!&lt;/p&gt;

&lt;h3 id=&#34;6-for-those-winners-who-didn-t-use-bucketing-maxlen-72-was-too-large&#34;&gt;6. For those winners who didn&amp;rsquo;t use bucketing, Maxlen = 72 was too large:&lt;/h3&gt;

&lt;p&gt;Most of us saw a distribution of question length and took the length that covered maximum questions fully as the maxlen parameter. I never tried to tune it, but it seems like it could have been tuned. &lt;strong&gt;One of the tricks was to use maxlen ranging from 35 to 60.&lt;/strong&gt; This made the kernels run a lot faster.&lt;/p&gt;

&lt;h3 id=&#34;7-time-taking-models-complex-architectures-like-capsule-were-mostly-not-used&#34;&gt;7. Time taking models/complex architectures like Capsule were mostly not used:&lt;/h3&gt;

&lt;p&gt;Most of the winning solutions didn&amp;rsquo;t use capsule networks as they took a lot of time to train.&lt;/p&gt;

&lt;h3 id=&#34;8-backprop-errors-on-embeddings-weights-in-last-few-epochs&#34;&gt;8. Backprop errors on embeddings weights in last few epochs:&lt;/h3&gt;

&lt;p&gt;Another thing I saw was in the &lt;a href=&#34;https://www.kaggle.com/kentaronakanishi/18th-place-solution&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;18th place kernel&lt;/a&gt; which uses a single model&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; epoch &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;:
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embeddings&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;weight&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;requires_grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; True&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;hr /&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion:&lt;/h2&gt;

&lt;p&gt;It was a good and long 2-month competition, and I learned a lot about Text and NLP during this time. I want to emphasize here is that &lt;strong&gt;I ended up trying a lot of things that didn&amp;rsquo;t work before reaching my final solution&lt;/strong&gt;. It was a little frustrating at times, but in the end, I was happy that I ended up with the best data science practices. Would also like to thank Kaggle master Kazanova who along with some of his friends released a &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-BShznKdc3CUauhfsM7_8xw&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;“How to win a data science competition”&lt;/a&gt; Coursera course. I learned a lot from this course.&lt;/p&gt;

&lt;p&gt;Let me know in the comments if you think something is missing/wrong or if I could add more tips/tricks for this competition.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NLP  Learning Series: Part 2 - Conventional Methods for Text Classification</title>
      <link>https://mlwhiz.com/blog/2019/02/08/deeplearning_nlp_conventional_methods/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2019/02/08/deeplearning_nlp_conventional_methods/</guid>
      <description>

&lt;p&gt;This is the second post of the NLP Text classification series. To give you a recap, recently I started up with an NLP text classification competition on Kaggle called Quora Question insincerity challenge. And I thought to share the knowledge via a series of blog posts on text classification. The &lt;a href=&#34;https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/&#34;&gt;first post&lt;/a&gt; talked about the various &lt;strong&gt;preprocessing techniques that work with Deep learning models&lt;/strong&gt; and &lt;strong&gt;increasing embeddings coverage&lt;/strong&gt;. In this post, I will try to take you through some &lt;strong&gt;basic conventional models&lt;/strong&gt; like TFIDF, Count Vectorizer, Hashing etc. that have been used in text classification and try to access their performance to create a baseline. We will delve deeper into &lt;strong&gt;Deep learning models&lt;/strong&gt; in the third post which will focus on different architectures for solving the text classification problem. We will try to use various other models which we were not able to use in this competition like &lt;strong&gt;ULMFit transfer learning&lt;/strong&gt; approaches in the fourth post in the series.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;As a side note&lt;/strong&gt;: if you want to know more about NLP, I would like to &lt;strong&gt;recommend this awesome course&lt;/strong&gt; on &lt;a href=&#34;https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;amp;offerid=467035.11503135394&amp;amp;type=2&amp;amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Flanguage-processing&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Natural Language Processing&lt;/a&gt; in the &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Advanced machine learning specialization&lt;/a&gt;. You can start for free with the 7-day Free Trial. This course covers a wide range of tasks in Natural Language Processing from basic to advanced: sentiment analysis, summarization, dialogue state tracking, to name a few. You can start for free with the 7-day Free Trial.&lt;/p&gt;

&lt;p&gt;It might take me a little time to write the whole series. Till then you can take a look at my other posts too: &lt;a href=&#34;https://mlwhiz.com/blog/2018/12/17/text_classification/&#34;&gt;What Kagglers are using for Text Classification&lt;/a&gt;, which talks about various deep learning models in use in NLP and &lt;a href=&#34;https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/&#34;&gt;how to switch from Keras to Pytorch&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So again we start with the first step: Preprocessing.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;basic-preprocessing-techniques-for-text-data-continued&#34;&gt;Basic Preprocessing Techniques for text data(Continued)&lt;/h2&gt;

&lt;p&gt;So in the last post, we talked about various preprocessing methods for text for deep learning purpose. Most of the preprocessing for conventional methods remains the same. &lt;strong&gt;We will still remove special characters, punctuations, and contractions&lt;/strong&gt;. But We also may want to do stemming/lemmatization when it comes to conventional methods. Let us talk about them.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;For grammatical reasons, documents are going to use different forms of a word, such as organize, organizes, and organizing. Additionally, there are families of derivationally related words with similar meanings, such as democracy, democratic, and democratization.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Since we are going to create features for words in the feature creation step, it makes sense to reduce words to a common denominator so that &amp;lsquo;organize&amp;rsquo;,&amp;lsquo;organizes&amp;rsquo; and &amp;lsquo;organizing&amp;rsquo; could be referred to by a single word &amp;lsquo;organize&amp;rsquo;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;a-stemming&#34;&gt;a) Stemming&lt;/h3&gt;

&lt;p&gt;Stemming is the process of converting words to their base forms using crude Heuristic rules. For example, one rule could be to remove &amp;rsquo;s&amp;rsquo; from the end of any word, so that &amp;lsquo;cats&amp;rsquo; becomes &amp;lsquo;cat&amp;rsquo;. or another rule could be to replace &amp;lsquo;ies&amp;rsquo; with &amp;lsquo;i&amp;rsquo; so that &amp;lsquo;ponies becomes &amp;lsquo;poni&amp;rsquo;. One of the main point to note here is that when we stem the word we might get a nonsense word like &amp;lsquo;poni&amp;rsquo;. But it will still work for our use case as we count the number of occurrences of a particular word and not focus on the meanings of these words in conventional methods. It doesn&amp;rsquo;t work with deep learning for precisely the same reason.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/text_stemming.png&#34;  style=&#34;height:90%;width:90%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;We can do this pretty simply by using this function in python.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; nltk.stem &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt;  SnowballStemmer
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; nltk.tokenize.toktok &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ToktokTokenizer
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;stem_text&lt;/span&gt;(text):
    tokenizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ToktokTokenizer()
    stemmer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SnowballStemmer(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;english&amp;#39;&lt;/span&gt;)
    tokens &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tokenize(text)
    tokens &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [token&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strip() &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; token &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; tokens]
    tokens &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [stemmer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stem(token) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; token &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; tokens]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join(tokens)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;hr /&gt;

&lt;h3 id=&#34;b-lemmatization&#34;&gt;b) Lemmatization&lt;/h3&gt;

&lt;p&gt;Lemmatization is very similar to stemming but it aims to remove endings only if the base form is present in a dictionary.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; nltk.stem &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; WordNetLemmatizer
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; nltk.tokenize.toktok &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ToktokTokenizer
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lemma_text&lt;/span&gt;(text):
    tokenizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ToktokTokenizer()
    tokens &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tokenize(text)
    tokens &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [token&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strip() &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; token &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; tokens]
    tokens &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [wordnet_lemmatizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lemmatize(token) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; token &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; tokens]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join(tokens)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once we are done with processing a text, our text will necessarily go through these following steps.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clean_sentence&lt;/span&gt;(x):
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lower()
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; clean_text(x)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; clean_numbers(x)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; replace_typical_misspell(x)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; remove_stopwords(x)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; replace_contractions(x)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lemma_text(x)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#39;&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;hr /&gt;

&lt;h2 id=&#34;text-representation&#34;&gt;Text Representation&lt;/h2&gt;

&lt;p&gt;In Conventional Machine learning methods, we ought to create features for a text. There are a lot of representations that are present to achieve this. Let us talk about them one by one.&lt;/p&gt;

&lt;h3 id=&#34;a-bag-of-words-countvectorizer-features&#34;&gt;a) Bag of Words - Countvectorizer Features&lt;/h3&gt;

&lt;p&gt;Suppose we have a series of sentences(documents)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [
     &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;This is good&amp;#39;&lt;/span&gt;,
     &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;This is bad&amp;#39;&lt;/span&gt;,
     &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;This is awesome&amp;#39;&lt;/span&gt;
     ]  &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/countvectorizer.png&#34;  style=&#34;height:90%;width:90%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Bag of words will create a dictionary of the most common words in all the sentences. For the example above the dictionary would look like:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;word_index
{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;this&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;is&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;good&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bad&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;awesome&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And then encode the sentences using the above dict.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;This &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; good &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
This &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; bad &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
This &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; awesome &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We could do this pretty simply in Python by using the CountVectorizer class from Python. Don&amp;rsquo;t worry much about the heavy name, it just does what I explained above. It has a lot of parameters most significant of which are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ngram_range:&lt;/strong&gt; I specify in the code (1,3). This means that unigrams, bigrams, and trigrams will be taken into account while creating features.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;min_df:&lt;/strong&gt; Minimum no of time an ngram should appear in a corpus to be used as a feature.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;cnt_vectorizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; CountVectorizer(dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32,
            strip_accents&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;unicode&amp;#39;&lt;/span&gt;, analyzer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;word&amp;#39;&lt;/span&gt;,token_pattern&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;\w{1,}&amp;#39;&lt;/span&gt;,
            ngram_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;),min_df&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)


&lt;span style=&#34;color:#75715e&#34;&gt;# we fit count vectorizer to get ngrams from both train and test data.&lt;/span&gt;
cnt_vectorizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(list(train_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cleaned_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; list(test_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cleaned_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values))

xtrain_cntv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  cnt_vectorizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(train_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cleaned_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values) 
xtest_cntv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cnt_vectorizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(test_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cleaned_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We could then use these features with any machine learning classification model like Logistic Regression, Naive Bayes, SVM or LightGBM as we would like.
For example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Fitting a simple Logistic Regression on CV Feats&lt;/span&gt;
clf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; LogisticRegression(C&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;)
clf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(xtrain_cntv,y_train)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kaggle.com/mlwhiz/conventional-methods-for-quora-classification/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Here&lt;/a&gt; is a link to a kernel where I tried these features on the Quora Dataset. If you like it please don&amp;rsquo;t forget to upvote.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;b-tfidf-features&#34;&gt;b) TFIDF Features&lt;/h3&gt;

&lt;p&gt;TFIDF is a simple technique to find features from sentences. While in Count features we take count of all the words/ngrams present in a document, with TFIDF we take features only for the significant words. How do we do that? If you think of a document in a corpus, we will consider two things about any word in that document:&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/tfidf.png&#34;  style=&#34;height:90%;width:90%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Term Frequency:&lt;/strong&gt; How important is the word in the document?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$$TF(word\ in\ a\ document) = \dfrac{No\ of\ occurances\ of\ that\ word\ in\ document}{No\ of\ words\ in\ document}$$&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Inverse Document Frequency:&lt;/strong&gt; How important the term is in the whole corpus?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$$IDF(word\ in\ a\ corpus) = -log(ratio\ of\ documents\ that\ include\ the\ word)$$&lt;/p&gt;

&lt;p&gt;TFIDF then is just multiplication of these two scores.&lt;/p&gt;

&lt;p&gt;Intuitively, One can understand that a word is important if it occurs many times in a document. But that creates a problem. Words like &amp;ldquo;a&amp;rdquo;, &amp;ldquo;the&amp;rdquo; occur many times in sentence. Their TF score will always be high. We solve that by using Inverse Document frequency, which is high if the word is rare, and low if the word is common across the corpus.&lt;/p&gt;

&lt;p&gt;In essence, we want to find important words in a document which are also not very common.&lt;/p&gt;

&lt;p&gt;We could do this pretty simply in Python by using the TFIDFVectorizer class from Python. It has a lot of parameters most significant of which are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ngram_range:&lt;/strong&gt; I specify in the code (1,3). This means that unigrams, bigrams, and trigrams will be taken into account while creating features.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;min_df:&lt;/strong&gt; Minimum no of time an ngram should appear in a corpus to be used as a feature.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Always start with these features. They work (almost) everytime!&lt;/span&gt;
tfv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; TfidfVectorizer(dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32, min_df&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,  max_features&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, 
            strip_accents&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;unicode&amp;#39;&lt;/span&gt;, analyzer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;word&amp;#39;&lt;/span&gt;,token_pattern&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;\w{1,}&amp;#39;&lt;/span&gt;,
            ngram_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), use_idf&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,smooth_idf&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,sublinear_tf&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
            stop_words &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;english&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Fitting TF-IDF to both training and test sets (semi-supervised learning)&lt;/span&gt;
tfv&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(list(train_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cleaned_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; list(test_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cleaned_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values))
xtrain_tfv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  tfv&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(train_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cleaned_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values) 
xvalid_tfv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tfv&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(test_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cleaned_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Again, we could use these features with any machine learning classification model like Logistic Regression, Naive Bayes, SVM or LightGBM as we would like. &lt;a href=&#34;https://www.kaggle.com/mlwhiz/conventional-methods-for-quora-classification/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Here&lt;/a&gt; is a link to a kernel where I tried these features on the Quora Dataset. If you like it please don&amp;rsquo;t forget to upvote.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;c-hashing-features&#34;&gt;c) Hashing Features&lt;/h3&gt;

&lt;p&gt;Normally there will be a lot of ngrams in a document corpus. The number of features that our TFIDFVectorizer generated was in excess of 2,00,000 features. This might lead to a problem on very large datasets as we have to hold a very large vocabulary dictionary in memory. One way to counter this is to use the Hash Trick.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/hashfeats.png&#34;  style=&#34;height:90%;width:90%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;One can think of hashing as a single function which maps any ngram to a number range for example between 0 to 1024. Now we don&amp;rsquo;t have to store our ngrams in a dictionary. We can just use the function to get the index of any word, rather than getting the index from a dictionary.&lt;/p&gt;

&lt;p&gt;Since there can be more than 1024 ngrams, different ngrams might map to the same number, and this is called collision. The larger the range we provide our Hashing function, the less is the chance of collisions.&lt;/p&gt;

&lt;p&gt;We could do this pretty simply in Python by using the HashingVectorizer class from Python. It has a lot of parameters most significant of which are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ngram_range:&lt;/strong&gt; I specify in the code (1,3). This means that unigrams, bigrams, and trigrams will be taken into account while creating features.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;n_features:&lt;/strong&gt; No of features you want to consider. The range I gave above.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Always start with these features. They work (almost) everytime!&lt;/span&gt;
hv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; HashingVectorizer(dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32,
            strip_accents&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;unicode&amp;#39;&lt;/span&gt;, analyzer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;word&amp;#39;&lt;/span&gt;,
            ngram_range&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;),n_features&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,non_negative&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
&lt;span style=&#34;color:#75715e&#34;&gt;# Fitting Hash Vectorizer to both training and test sets (semi-supervised learning)&lt;/span&gt;
hv&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(list(train_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cleaned_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; list(test_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cleaned_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values))
xtrain_hv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  hv&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(train_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cleaned_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values) 
xvalid_hv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; hv&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(test_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cleaned_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values)
y_train &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;target&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kaggle.com/mlwhiz/conventional-methods-for-quora-classification/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Here&lt;/a&gt; is a link to a kernel where I tried these features on the Quora Dataset. If you like it please don&amp;rsquo;t forget to upvote.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;d-word2vec-features&#34;&gt;d) Word2vec Features&lt;/h3&gt;

&lt;p&gt;We already talked a little about word2vec in the previous post. We can use the word to vec features to create sentence level feats also. We want to create a &lt;code&gt;d&lt;/code&gt; dimensional vector for sentence. For doing this, we will simply average the word embedding of all the words in a sentence.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/word2vec_feats.png&#34;  style=&#34;height:90%;width:90%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;We can do this in Python using the following functions.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# load the GloVe vectors in a dictionary:&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;load_glove_index&lt;/span&gt;():
    EMBEDDING_FILE &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;../input/embeddings/glove.840B.300d/glove.840B.300d.txt&amp;#39;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_coefs&lt;/span&gt;(word,&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;arr): &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; word, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;asarray(arr, dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;)[:&lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;]
    embeddings_index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dict(get_coefs(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;o&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;)) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; o &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; open(EMBEDDING_FILE))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; embeddings_index

embeddings_index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; load_glove_index()

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Found &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; word vectors.&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; len(embeddings_index))

&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; nltk.corpus &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; stopwords
stop_words &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; stopwords&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;words(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;english&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sent2vec&lt;/span&gt;(s):
    words &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; str(s)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lower()
    words &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; word_tokenize(words)
    words &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [w &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; w &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; words &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; w &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; stop_words]
    words &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [w &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; w &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; words &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;isalpha()]
    M &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; w &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; words:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
            M&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(embeddings_index[w])
        &lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt;:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
    M &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(M)
    v &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; M&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; type(v) &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ndarray:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros(&lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; v &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt((v &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum())

&lt;span style=&#34;color:#75715e&#34;&gt;# create glove features&lt;/span&gt;
xtrain_glove &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([sent2vec(x) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; tqdm(train_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cleaned_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values)])
xtest_glove &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([sent2vec(x) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; tqdm(test_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cleaned_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values)])&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kaggle.com/mlwhiz/conventional-methods-for-quora-classification/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Here&lt;/a&gt; is a link to a kernel where I tried these features on the Quora Dataset. If you like it please don&amp;rsquo;t forget to upvote.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;

&lt;p&gt;Here are the results of different approaches on the Kaggle Dataset. I ran a 5 fold Stratified CV.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/results_conv.png&#34;  style=&#34;height:40%;width:40%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kaggle.com/mlwhiz/conventional-methods-for-quora-classification/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Here&lt;/a&gt; is the code. If you like it please don&amp;rsquo;t forget to upvote.
Also note that I didn&amp;rsquo;t work on tuning the models, so these results are only cursory. You can try to squeeze more performance by performing hyperparams tuning &lt;a href=&#34;https://mlwhiz.com/blog/2017/12/28/hyperopt_tuning_ml_model/&#34;&gt;using hyperopt&lt;/a&gt; or just old fashioned Grid-search and the performance of models may change after that substantially.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;While Deep Learning works a lot better for NLP classification task, it still makes sense to have an understanding of how these problems were solved in the past, so that we can appreciate the nature of the problem. I have tried to provide a perspective on the conventional methods and one should experiment with them too to create baselines before moving to Deep Learning methods. If you want to &lt;strong&gt;learn more about NLP&lt;/strong&gt; &lt;a href=&#34;https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;amp;offerid=467035.11503135394&amp;amp;type=2&amp;amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Flanguage-processing&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; is an awesome course. You can start for free with the 7-day Free Trial. If you think I can add something to the flow, do mention it in the comments.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;endnotes-and-references&#34;&gt;Endnotes and References&lt;/h2&gt;

&lt;p&gt;This post is a result of an effort of a lot of excellent Kagglers and I will try to reference them in this section. If I leave out someone, do understand that it was not my intention to do so.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Approaching (Almost) Any NLP Problem on Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;How to: Preprocessing when using embeddings&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
</description>
    </item>
    
    <item>
      <title>NLP  Learning Series: Part 1 - Text Preprocessing Methods for Deep Learning</title>
      <link>https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/</link>
      <pubDate>Thu, 17 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/</guid>
      <description>

&lt;p&gt;Recently, I started up with an NLP competition on Kaggle called Quora Question insincerity challenge. It is an NLP Challenge on text classification and as the problem has become more clear after working through the competition as well as by going through the invaluable kernels put up by the kaggle experts, I thought of sharing the knowledge.&lt;/p&gt;

&lt;p&gt;Since we have a large amount of material to cover, I am splitting this post into a series of posts. The first post i.e. this one will be based on &lt;strong&gt;preprocessing techniques that work with Deep learning models&lt;/strong&gt; and we will also talk about &lt;strong&gt;increasing embeddings coverage&lt;/strong&gt;. In the &lt;a href=&#34;https://mlwhiz.com/blog/2019/02/08/deeplearning_nlp_conventional_methods/&#34;&gt;second post&lt;/a&gt;, I will try to take you through some &lt;strong&gt;basic conventional models&lt;/strong&gt; like TFIDF, Count Vectorizer, Hashing etc. that have been used in text classification and try to access their performance to create a baseline. We will delve deeper into &lt;strong&gt;Deep learning models&lt;/strong&gt; in the third post which will focus on different architectures for solving the text classification problem. We will try to use various other models which we were not able to use in this competition like &lt;strong&gt;ULMFit transfer learning&lt;/strong&gt; approaches in the fourth post in the series.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;As a side note&lt;/strong&gt;: if you want to know more about NLP, I would like to recommend this awesome course on &lt;a href=&#34;https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;amp;offerid=467035.11503135394&amp;amp;type=2&amp;amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Flanguage-processing&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Natural Language Processing&lt;/a&gt; in the &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Advanced machine learning specialization&lt;/a&gt;. You can start for free with the 7-day Free Trial. This course covers a wide range of tasks in Natural Language Processing from basic to advanced: sentiment analysis, summarization, dialogue state tracking, to name a few. You can start for free with the 7-day Free Trial.&lt;/p&gt;

&lt;p&gt;It might take me a little time to write the whole series. Till then you can take a look at my other posts: &lt;a href=&#34;https://mlwhiz.com/blog/2018/12/17/text_classification/&#34;&gt;What Kagglers are using for Text Classification&lt;/a&gt;, which talks about various deep learning models in use in NLP and &lt;a href=&#34;https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/&#34;&gt;how to switch from Keras to Pytorch&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So first let me start with explaining a little more about the text classification problem. &lt;strong&gt;Text classification&lt;/strong&gt; is a common task in natural language processing, which transforms a sequence of a text of indefinite length into a category of text. How could you use that?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;To find the sentiment of a review.&lt;/li&gt;
&lt;li&gt;Find toxic comments on a platform like Facebook&lt;/li&gt;
&lt;li&gt;Find Insincere questions on Quora. A current ongoing competition on kaggle&lt;/li&gt;
&lt;li&gt;Find fake reviews on websites&lt;/li&gt;
&lt;li&gt;Will a text advert get clicked or not?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now each of these problems has something in common. From a Machine Learning perspective, these are essentially the same problem with just the target labels changing and nothing else. With that said, the addition of business knowledge can help make these models more robust and that is what we want to incorporate while preprocessing the data for test classification. While the preprocessing pipeline I am focussing on in this post is mainly centered around Deep Learning but most of it will also be applicable to conventional machine learning models too.&lt;/p&gt;

&lt;p&gt;But let me first go through the flow of a deep learning pipeline for text data before going through all the steps to get a higher level perspective about the whole process.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/text_processing_flow_1.png&#34;  style=&#34;height:90%;width:90%&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;We normally start with cleaning up the text data and performing basic EDA. Here we try to improve our data quality by cleaning up the data. We also try to improve the quality of our word2vec embeddings by removing OOV(Out-of-Vocabulary) words. These first two steps normally don&amp;rsquo;t have much order between them and I generally go back and forth between these two steps. Next, we create a representation for text that could be fed into a deep learning model. We then start with creating our models and training them. Finally, we evaluate the models using appropriate metrics and get approval from respective shareholders to deploy our models. Don&amp;rsquo;t worry if these terms don&amp;rsquo;t make much sense now. I will try to explain them through the course of this article.&lt;/p&gt;

&lt;p&gt;Here at this junction, let us take a little detour to talk a little about word embeddings. We will have to think about them while preprocessing data for our Deep Learning models.&lt;/p&gt;

&lt;h2 id=&#34;a-primer-on-word2vec-embeddings&#34;&gt;A Primer on word2vec embeddings:&lt;/h2&gt;

&lt;p&gt;We need to have a way to represent words in a vocab. One way to do that could be to use One hot encoding of word vectors but that is not really a good choice. One of the major reasons is that the one-hot word vectors cannot accurately express the similarity between different words, such as the cosine similarity.&lt;/p&gt;

&lt;p&gt;$$\frac{\boldsymbol{x}^\top \boldsymbol{y}}{|\boldsymbol{x}| |\boldsymbol{y}|} \in [-1, 1].$$&lt;/p&gt;

&lt;p&gt;Given the structure of one hot encoded vectors, the similarity is always going to come as 0 between different words. Another reason is that as the size of vocabulary increases these one hot encoded vectors become very large.&lt;/p&gt;

&lt;p&gt;Word2Vec overcomes the above difficulties by providing us with a fixed length vector representation of words and by capturing the similarity and analogy relationships between different words.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/word2vec.png&#34; style=&#34;height:80%;width:80%&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Word2vec vectors of words are learned in such a way that they allow us to learn different analogies. It enables us to do algebraic manipulations on words which were not possible before. For example: What is king - man + woman? It comes out to be Queen.&lt;/p&gt;

&lt;p&gt;Word2Vec vectors also help us to find out the similarity between words. If we try to find similar words to &amp;ldquo;good&amp;rdquo;, we will find awesome, great etc. It is this property of word2vec that makes it invaluable for text classification. Now our deep learning network understands that &amp;ldquo;good&amp;rdquo; and &amp;ldquo;great&amp;rdquo; are essentially words with similar meaning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Thus in very simple terms, word2vec creates vectors for words. Thus we have a &lt;code&gt;d&lt;/code&gt; dimensional vector for every word(common bigrams too) in a dictionary.&lt;/strong&gt; We normally use pretrained word vectors which are provided to us by others after training on large corpora of texts like Wikipedia, twitter etc. The most commonly used pretrained word vectors are Glove and Fasttext with 300-dimensional word vectors. We are going to use Glove in this post.&lt;/p&gt;

&lt;h2 id=&#34;basic-preprocessing-techniques-for-text-data&#34;&gt;Basic Preprocessing Techniques for text data:&lt;/h2&gt;

&lt;p&gt;In most of the cases, we observe that text data is not entirely clean. Data coming from different sources have different characteristics and that makes Text Preprocessing as one of the most important steps in the classification pipeline. For example, Text data from Twitter is totally different from text data on Quora, or some news/blogging platform, and thus would need to be treated differently. Helpfully, the techniques I am going to talk about in this post are generic enough for any kind of data you might encounter in the jungles of NLP.&lt;/p&gt;

&lt;h4 id=&#34;a-cleaning-special-characters-and-removing-punctuations&#34;&gt;a) Cleaning Special Characters and Removing Punctuations:&lt;/h4&gt;

&lt;p&gt;Our preprocessing pipeline depends a lot on the word2vec embeddings we are going to use for our classification task. &lt;em&gt;In principle our preprocessing should match the preprocessing that was used before training the word embedding&lt;/em&gt;. Since most of the embeddings don&amp;rsquo;t provide vector values for punctuations and other special chars, the first thing you want to do is to get rid of is the special characters in your text data. These are some of the special chars that were there in the Quora Question data and we use &lt;code&gt;replace&lt;/code&gt; function to get rid of these special chars.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Some preprocesssing that will be common to all the text classification methods you will see. &lt;/span&gt;

puncts &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;,&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#34;&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;:&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;)&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;(&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;!&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;?&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;|&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;;&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#39;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;$&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;amp;&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;[&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;]&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;gt;&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;%&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;=&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;#&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;*&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;•&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;~&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;@&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;£&amp;#39;&lt;/span&gt;, 
 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;·&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;_&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;}&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;©&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;^&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;®&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;`&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;lt;&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;→&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;°&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;€&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;™&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;›&amp;#39;&lt;/span&gt;,  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;♥&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;←&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;×&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;§&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;″&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;′&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Â&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;█&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;½&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;à&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;…&amp;#39;&lt;/span&gt;, 
 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;“&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;★&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;”&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;–&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;●&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;â&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;►&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;−&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;¢&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;²&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;¬&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;░&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;¶&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;↑&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;±&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;¿&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;▾&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;═&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;¦&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;║&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;―&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;¥&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;▓&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;—&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;‹&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;─&amp;#39;&lt;/span&gt;, 
 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;▒&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;：&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;¼&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;⊕&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;▼&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;▪&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;†&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;■&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;’&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;▀&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;¨&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;▄&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;♫&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;☆&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;é&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;¯&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;♦&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;¤&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;▲&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;è&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;¸&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;¾&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Ã&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;⋅&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;‘&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;∞&amp;#39;&lt;/span&gt;, 
 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;∙&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;）&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;↓&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;、&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;│&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;（&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;»&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;，&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;♪&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;╩&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;╚&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;³&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;・&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;╦&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;╣&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;╔&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;╗&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;▬&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;❤&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ï&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Ø&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;¹&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;≤&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;‡&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;√&amp;#39;&lt;/span&gt;, ]

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clean_text&lt;/span&gt;(x):
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; str(x)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; punct &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; puncts:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; punct &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; x:
            x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(punct, f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; {punct} &amp;#39;&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This could also have been done with the help of a simple regex. But I normally like the above way of doing things as it helps to understand the sort of characters we are removing from our data.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clean_text&lt;/span&gt;(x):
    pattern &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;[^a-zA-z0-9\s]&amp;#39;&lt;/span&gt;
    text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(pattern, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;, x)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&#34;b-cleaning-numbers&#34;&gt;b) Cleaning Numbers:&lt;/h4&gt;

&lt;p&gt;Why do we want to replace numbers with &lt;code&gt;#&lt;/code&gt;s? Because most embeddings have preprocessed their text like this.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Small Python Trick:&lt;/strong&gt; We use an &lt;code&gt;if&lt;/code&gt; statement in the code below to check beforehand if a number exists in a text. It is as an &lt;code&gt;if&lt;/code&gt; is always fast than a &lt;code&gt;re.sub&lt;/code&gt; command and most of our text doesn&amp;rsquo;t contain numbers.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clean_numbers&lt;/span&gt;(x):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; bool(re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;search(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;\d&amp;#39;&lt;/span&gt;, x)):
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;[0-9]{5,}&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;#####&amp;#39;&lt;/span&gt;, x)
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;[0-9]{4}&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;####&amp;#39;&lt;/span&gt;, x)
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;[0-9]{3}&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;###&amp;#39;&lt;/span&gt;, x)
        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;[0-9]{2}&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;##&amp;#39;&lt;/span&gt;, x)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&#34;c-removing-misspells&#34;&gt;c) Removing Misspells:&lt;/h4&gt;

&lt;p&gt;It always helps to find out misspells in the data. As those word embeddings are not present in the word2vec, we should replace words with their correct spellings to get better embedding coverage. The following code artifact is an adaptation of Peter Norvig&amp;rsquo;s spell checker. It uses word2vec ordering of words to approximate word probabilities. As Google word2vec apparently orders words in decreasing order of frequency in the training corpus. You can use this to find out some misspelled words in the data you have.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# This comes from CPMP script in the Quora questions similarity challenge. &lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; re
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; collections &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Counter
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; gensim
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; heapq
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; operator &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; itemgetter
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; multiprocessing &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Pool

model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; gensim&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;models&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;KeyedVectors&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_word2vec_format(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;../input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin&amp;#39;&lt;/span&gt;, 
                                                        binary&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
words &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;index2word

w_rank &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i,word &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(words):
    w_rank[word] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i

WORDS &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; w_rank

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;words&lt;/span&gt;(text): &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;findall(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;\w+&amp;#39;&lt;/span&gt;, text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lower())

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;P&lt;/span&gt;(word): 
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Probability of `word`.&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# use inverse of rank as proxy&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# returns 0 if the word isn&amp;#39;t in the dictionary&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; WORDS&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(word, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;correction&lt;/span&gt;(word): 
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Most probable spelling correction for word.&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; max(candidates(word), key&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;P)

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;candidates&lt;/span&gt;(word): 
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Generate possible spelling corrections for word.&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; (known([word]) &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; known(edits1(word)) &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; known(edits2(word)) &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; [word])

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;known&lt;/span&gt;(words): 
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;The subset of `words` that appear in the dictionary of WORDS.&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; set(w &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; w &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; words &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; w &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; WORDS)

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;edits1&lt;/span&gt;(word):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;All edits that are one edit away from `word`.&amp;#34;&lt;/span&gt;
    letters    &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;abcdefghijklmnopqrstuvwxyz&amp;#39;&lt;/span&gt;
    splits     &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [(word[:i], word[i:])    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(word) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)]
    deletes    &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [L &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; R[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:]               &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; L, R &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; splits &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; R]
    transposes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [L &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; R[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; R[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; R[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;:] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; L, R &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; splits &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(R)&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
    replaces   &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [L &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; R[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:]           &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; L, R &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; splits &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; R &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; letters]
    inserts    &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [L &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; R               &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; L, R &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; splits &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; letters]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; set(deletes &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; transposes &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; replaces &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; inserts)

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;edits2&lt;/span&gt;(word): 
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;All edits that are two edits away from `word`.&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; (e2 &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; e1 &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; edits1(word) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; e2 &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; edits1(e1))

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;build_vocab&lt;/span&gt;(texts):
    sentences &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; texts&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split())&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values
    vocab &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; sentence &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sentences:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; word &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sentence:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
                vocab[word] &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
            &lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;KeyError&lt;/span&gt;:
                vocab[word] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; vocab

vocab &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; build_vocab(train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;question_text)

top_90k_words &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dict(heapq&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nlargest(&lt;span style=&#34;color:#ae81ff&#34;&gt;90000&lt;/span&gt;, vocab&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;items(), key&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;itemgetter(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)))

pool &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Pool(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)
corrected_words &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pool&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(correction,list(top_90k_words&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keys()))

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; word,corrected_word &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(top_90k_words,corrected_words):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; word&lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt;corrected_word:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(word,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;:&amp;#34;&lt;/span&gt;,corrected_word)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once we are through with finding misspelled data, the next thing remains to replace them using a misspell mapping and regex functions.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;mispell_dict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;colour&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;color&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;centre&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;center&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;favourite&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;favorite&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;travelling&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;traveling&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;counselling&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;counseling&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;theatre&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;theater&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cancelled&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;canceled&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;labour&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;labor&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;organisation&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;organization&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;wwii&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;world war 2&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;citicise&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;criticize&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;youtu &amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;youtube &amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Qoura&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Quora&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sallary&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;salary&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Whta&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;What&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;narcisist&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;narcissist&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;howdo&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;how do&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;whatare&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;what are&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;howcan&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;how can&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;howmuch&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;how much&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;howmany&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;how many&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;whydo&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;why do&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;doI&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;do I&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;theBest&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;the best&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;howdoes&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;how does&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mastrubation&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;masturbation&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mastrubate&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;masturbate&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;mastrubating&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;masturbating&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pennis&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;penis&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Etherium&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Ethereum&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;narcissit&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;narcissist&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bigdata&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;big data&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2k17&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2017&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2k18&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2018&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;qouta&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;quota&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;exboyfriend&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ex boyfriend&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;airhostess&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;air hostess&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;whst&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;what&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;watsapp&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;whatsapp&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;demonitisation&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;demonetization&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;demonitization&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;demonetization&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;demonetisation&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;demonetization&amp;#39;&lt;/span&gt;}

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_get_mispell&lt;/span&gt;(mispell_dict):
    mispell_re &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;)&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;|&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join(mispell_dict&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keys()))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; mispell_dict, mispell_re

mispellings, mispellings_re &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; _get_mispell(mispell_dict)
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;replace_typical_misspell&lt;/span&gt;(text):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;replace&lt;/span&gt;(match):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; mispellings[match&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;group(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; mispellings_re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(replace, text)

&lt;span style=&#34;color:#75715e&#34;&gt;# Usage&lt;/span&gt;
replace_typical_misspell(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Whta is demonitisation&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&#34;d-removing-contractions&#34;&gt;d) Removing Contractions:&lt;/h4&gt;

&lt;p&gt;Contractions are words that we write with an apostrophe. Examples of contractions are words like &amp;ldquo;ain&amp;rsquo;t&amp;rdquo; or &amp;ldquo;aren&amp;rsquo;t&amp;rdquo;. Since we want to standardize our text, it makes sense to expand these contractions. Below we have done this using a contraction mapping and regex functions.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;contraction_dict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ain&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;is not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;aren&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;are not&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;can&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;cannot&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#39;cause&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;because&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;could&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;could have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;couldn&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;could not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;didn&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;did not&amp;#34;&lt;/span&gt;,  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;doesn&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;does not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;don&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;do not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;hadn&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;had not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;hasn&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;has not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;haven&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;have not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;he&amp;#39;d&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;he would&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;he&amp;#39;ll&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;he will&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;he&amp;#39;s&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;he is&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;how&amp;#39;d&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;how did&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;how&amp;#39;d&amp;#39;y&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;how do you&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;how&amp;#39;ll&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;how will&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;how&amp;#39;s&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;how is&amp;#34;&lt;/span&gt;,  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;I&amp;#39;d&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;I would&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;I&amp;#39;d&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;I would have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;I&amp;#39;ll&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;I will&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;I&amp;#39;ll&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;I will have&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;I&amp;#39;m&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;I am&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;I&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;I have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;i&amp;#39;d&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;i would&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;i&amp;#39;d&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;i would have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;i&amp;#39;ll&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;i will&amp;#34;&lt;/span&gt;,  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;i&amp;#39;ll&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;i will have&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;i&amp;#39;m&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;i am&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;i&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;i have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;isn&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;is not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;it&amp;#39;d&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;it would&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;it&amp;#39;d&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;it would have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;it&amp;#39;ll&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;it will&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;it&amp;#39;ll&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;it will have&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;it&amp;#39;s&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;it is&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;let&amp;#39;s&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;let us&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ma&amp;#39;am&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;madam&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;mayn&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;may not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;might&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;might have&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;mightn&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;might not&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;mightn&amp;#39;t&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;might not have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;must&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;must have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;mustn&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;must not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;mustn&amp;#39;t&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;must not have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;needn&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;need not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;needn&amp;#39;t&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;need not have&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;o&amp;#39;clock&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;of the clock&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;oughtn&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ought not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;oughtn&amp;#39;t&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ought not have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;shan&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;shall not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sha&amp;#39;n&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;shall not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;shan&amp;#39;t&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;shall not have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;she&amp;#39;d&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;she would&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;she&amp;#39;d&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;she would have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;she&amp;#39;ll&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;she will&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;she&amp;#39;ll&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;she will have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;she&amp;#39;s&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;she is&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;should&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;should have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;shouldn&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;should not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;shouldn&amp;#39;t&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;should not have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;so&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;so have&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;so&amp;#39;s&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;so as&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;this&amp;#39;s&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;this is&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;that&amp;#39;d&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;that would&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;that&amp;#39;d&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;that would have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;that&amp;#39;s&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;that is&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;there&amp;#39;d&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;there would&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;there&amp;#39;d&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;there would have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;there&amp;#39;s&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;there is&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;here&amp;#39;s&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;here is&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;they&amp;#39;d&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;they would&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;they&amp;#39;d&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;they would have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;they&amp;#39;ll&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;they will&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;they&amp;#39;ll&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;they will have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;they&amp;#39;re&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;they are&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;they&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;they have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;to&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;to have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;wasn&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;was not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;we&amp;#39;d&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;we would&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;we&amp;#39;d&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;we would have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;we&amp;#39;ll&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;we will&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;we&amp;#39;ll&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;we will have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;we&amp;#39;re&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;we are&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;we&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;we have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;weren&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;were not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;what&amp;#39;ll&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;what will&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;what&amp;#39;ll&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;what will have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;what&amp;#39;re&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;what are&amp;#34;&lt;/span&gt;,  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;what&amp;#39;s&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;what is&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;what&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;what have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;when&amp;#39;s&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;when is&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;when&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;when have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;where&amp;#39;d&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;where did&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;where&amp;#39;s&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;where is&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;where&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;where have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;who&amp;#39;ll&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;who will&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;who&amp;#39;ll&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;who will have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;who&amp;#39;s&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;who is&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;who&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;who have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;why&amp;#39;s&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;why is&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;why&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;why have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;will&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;will have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;won&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;will not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;won&amp;#39;t&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;will not have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;would&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;would have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;wouldn&amp;#39;t&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;would not&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;wouldn&amp;#39;t&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;would not have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;y&amp;#39;all&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;you all&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;y&amp;#39;all&amp;#39;d&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;you all would&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;y&amp;#39;all&amp;#39;d&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;you all would have&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;y&amp;#39;all&amp;#39;re&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;you all are&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;y&amp;#39;all&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;you all have&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;you&amp;#39;d&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;you would&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;you&amp;#39;d&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;you would have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;you&amp;#39;ll&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;you will&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;you&amp;#39;ll&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;you will have&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;you&amp;#39;re&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;you are&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;you&amp;#39;ve&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;you have&amp;#34;&lt;/span&gt;}

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;_get_contractions&lt;/span&gt;(contraction_dict):
    contraction_re &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;)&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;|&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join(contraction_dict&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keys()))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; contraction_dict, contraction_re

contractions, contractions_re &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; _get_contractions(contraction_dict)

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;replace_contractions&lt;/span&gt;(text):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;replace&lt;/span&gt;(match):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; contractions[match&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;group(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; contractions_re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sub(replace, text)

&lt;span style=&#34;color:#75715e&#34;&gt;# Usage&lt;/span&gt;
replace_contractions(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;this&amp;#39;s a text with contraction&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Apart from the above techniques, there are other preprocessing techniques of text like Stemming, Lemmatization and Stopword Removal. Since these techniques are not used along with Deep Learning NLP models, we won&amp;rsquo;t talk about them.&lt;/p&gt;

&lt;h2 id=&#34;representation-sequence-creation&#34;&gt;Representation: Sequence Creation&lt;/h2&gt;

&lt;p&gt;One of the things that have made Deep Learning the goto choice for NLP is the fact that we don&amp;rsquo;t really have to hand-engineer features from the text data. The deep learning algorithms take as input a sequence of text to learn the structure of text just like a human does. Since Machine cannot understand words they expect their data in numerical form. So we would like to represent out text data as a series of numbers. To understand how this is done we need to understand a little about the Keras Tokenizer function. One can use any other tokenizer also but keras tokenizer seems like a good choice for me.&lt;/p&gt;

&lt;h4 id=&#34;a-tokenizer&#34;&gt;a) Tokenizer:&lt;/h4&gt;

&lt;p&gt;In simple words, a tokenizer is a utility function to split a sentence into words.
&lt;code&gt;keras.preprocessing.text.Tokenizer&lt;/code&gt; tokenizes(splits) the texts into tokens(words) while keeping only the most occurring words in the text corpus.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#Signature:&lt;/span&gt;
Tokenizer(num_words&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;!&amp;#34;#$%&amp;amp;()*+,-./:;&amp;lt;=&amp;gt;?@[&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\\&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;]^_`{|}~&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;, 
lower&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;, char_level&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False, oov_token&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, document_count&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;kwargs)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The num_words parameter keeps a prespecified number of words in the text only. This is helpful as we don&amp;rsquo;t want our models to get a lot of noise by considering words that occur very infrequently. In real-world data, most of the words we leave using num_words param are normally misspells. The tokenizer also filters some non-wanted tokens by default and converts the text into lowercase.&lt;/p&gt;

&lt;p&gt;The tokenizer once fitted to the data also keeps an index of words(dictionary of words which we can use to assign a unique number to a word) which can be accessed by tokenizer.word_index. The words in the indexed dictionary are ranked in order of frequencies.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/tokenizer_working.png&#34; style=&#34;height:80%;width:80%&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;So the whole code to use tokenizer is as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras.preprocessing.text &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Tokenizer
&lt;span style=&#34;color:#75715e&#34;&gt;## Tokenize the sentences&lt;/span&gt;
tokenizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Tokenizer(num_words&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;max_features)
tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_on_texts(list(train_X)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;list(test_X))
train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;texts_to_sequences(train_X)
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;texts_to_sequences(test_X)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;where &lt;code&gt;train_X&lt;/code&gt; and &lt;code&gt;test_X&lt;/code&gt; are lists of documents in the corpus.&lt;/p&gt;

&lt;h4 id=&#34;b-pad-sequence&#34;&gt;b) Pad Sequence:&lt;/h4&gt;

&lt;p&gt;Normally our model expects that each sequence(each training example) will be of the same length(same number of words/tokens). We can control this using the &lt;code&gt;maxlen&lt;/code&gt; parameter.&lt;/p&gt;

&lt;p&gt;For example:
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/pad_seq.png&#34; style=&#34;height:40%;width:40%&#34; &gt;&lt;/center&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;train_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pad_sequences(train_X, maxlen&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;maxlen)
test_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pad_sequences(test_X, maxlen&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;maxlen)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now our train data contains a list of list of numbers. Each list has the same length. And we also have the &lt;code&gt;word_index&lt;/code&gt; which is a dictionary of most occuring words in the text corpus.&lt;/p&gt;

&lt;h2 id=&#34;embedding-enrichment&#34;&gt;Embedding Enrichment:&lt;/h2&gt;

&lt;p&gt;As I said I will be using GLoVE Word2Vec embeddings to explain the enrichment. GLoVE pretrained vectors are trained on the Wikipedia corpus. (You can &lt;a href=&#34;https://nlp.stanford.edu/projects/glove/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;download them here&lt;/a&gt;). That means some of the words that might be present in your data might not be present in the embeddings. How could we deal with that? Let&amp;rsquo;s first load the Glove Embeddings first.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;load_glove_index&lt;/span&gt;():
    EMBEDDING_FILE &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;../input/embeddings/glove.840B.300d/glove.840B.300d.txt&amp;#39;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_coefs&lt;/span&gt;(word,&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;arr): &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; word, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;asarray(arr, dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;)[:&lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;]
    embeddings_index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dict(get_coefs(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;o&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;)) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; o &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; open(EMBEDDING_FILE))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; embeddings_index

glove_embedding_index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; load_glove_index()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Be sure to put the path of the folder where you download these GLoVE vectors. What does this &lt;code&gt;glove_embedding_index&lt;/code&gt; contain? It is just a dictionary in which the key is the word and the value is the word vector, a &lt;code&gt;np.array&lt;/code&gt; of length 300. The length of this dictionary is somewhere around a billion. Since we only want the embeddings of words that are in our &lt;code&gt;word_index&lt;/code&gt;, we will create a matrix which just contains required embeddings.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/embedding_matrix_creation.png&#34; style=&#34;height:100%;width:100%&#34; &gt;&lt;/center&gt;
&lt;/div&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;create_glove&lt;/span&gt;(word_index,embeddings_index):
    emb_mean,emb_std &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.005838499&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.48782197&lt;/span&gt;
    all_embs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stack(embeddings_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values())
    embed_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; all_embs&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
    nb_words &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; min(max_features, len(word_index))
    embedding_matrix &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;normal(emb_mean, emb_std, (nb_words, embed_size))
    count_found &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nb_words
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; word, i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; tqdm(word_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;items()):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; max_features: &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
        embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(word)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None: 
            embedding_matrix[i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  embedding_vector
        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
                count_found&lt;span style=&#34;color:#f92672&#34;&gt;-=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Got embedding for &amp;#34;&lt;/span&gt;,count_found,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; words.&amp;#34;&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; embedding_matrix&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The above code works fine but is there a way that we can use the preprocessing in GLoVE to our advantage? Yes. When preprocessing was done for glove, the creators didn&amp;rsquo;t convert the words to lowercase. That means that it contains multiple variations of a word like &amp;lsquo;USA&amp;rsquo;, &amp;lsquo;usa&amp;rsquo; and &amp;lsquo;Usa&amp;rsquo;. That also means that in some cases while a word like &amp;lsquo;Word&amp;rsquo; is present, its analog in lowercase i.e. &amp;lsquo;word&amp;rsquo; is not present. We can get through this situation by using the below code.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;create_glove&lt;/span&gt;(word_index,embeddings_index):
    emb_mean,emb_std &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.005838499&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.48782197&lt;/span&gt;
    all_embs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stack(embeddings_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values())
    embed_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; all_embs&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
    nb_words &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; min(max_features, len(word_index))
    embedding_matrix &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;normal(emb_mean, emb_std, (nb_words, embed_size))

    count_found &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nb_words
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; word, i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; tqdm(word_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;items()):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; max_features: &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
        embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(word)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None: 
            embedding_matrix[i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  embedding_vector
        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; word&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;islower():
                &lt;span style=&#34;color:#75715e&#34;&gt;# try to get the embedding of word in titlecase if lowercase is not present&lt;/span&gt;
                embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(word&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;capitalize())
                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None: 
                    embedding_matrix[i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embedding_vector
                &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
                    count_found&lt;span style=&#34;color:#f92672&#34;&gt;-=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
            &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
                count_found&lt;span style=&#34;color:#f92672&#34;&gt;-=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Got embedding for &amp;#34;&lt;/span&gt;,count_found,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; words.&amp;#34;&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; embedding_matrix&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The above was just an example of how we can use our knowledge of an embedding to get better coverage. Sometimes depending on the problem, one might also derive value by adding extra information to the embeddings using some domain knowledge and NLP skills. For example, we can add external knowledge to the embeddings themselves by adding polarity and subjectivity of a word from the TextBlob package in Python.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; textblob &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; TextBlob
word_sent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; TextBlob(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;good&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sentiment
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(word_sent&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;polarity,word_sent&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subjectivity)
&lt;span style=&#34;color:#75715e&#34;&gt;# 0.7 0.6&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We can get the polarity and subjectivity of any word using TextBlob. Pretty neat. So let us try to add this extra information to our embeddings.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;create_glove&lt;/span&gt;(word_index,embeddings_index):
    emb_mean,emb_std &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.005838499&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.48782197&lt;/span&gt;
    all_embs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stack(embeddings_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values())
    embed_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; all_embs&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
    nb_words &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; min(max_features, len(word_index))
    embedding_matrix &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;normal(emb_mean, emb_std, (nb_words, embed_size&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))
    
    count_found &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nb_words
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; word, i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; tqdm(word_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;items()):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; max_features: &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
        embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(word)
        word_sent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; TextBlob(word)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sentiment
        &lt;span style=&#34;color:#75715e&#34;&gt;# Extra information we are passing to our embeddings&lt;/span&gt;
        extra_embed &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [word_sent&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;polarity,word_sent&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subjectivity]
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None: 
            embedding_matrix[i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(embedding_vector,extra_embed)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; word&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;islower():
                embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings_index&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(word&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;capitalize())
                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; embedding_vector &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None: 
                    embedding_matrix[i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(embedding_vector,extra_embed)
                &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
                    embedding_matrix[i,&lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;:] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; extra_embed
                    count_found&lt;span style=&#34;color:#f92672&#34;&gt;-=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
            &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
                embedding_matrix[i,&lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;:] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; extra_embed
                count_found&lt;span style=&#34;color:#f92672&#34;&gt;-=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Got embedding for &amp;#34;&lt;/span&gt;,count_found,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; words.&amp;#34;&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; embedding_matrix&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Engineering embeddings is an essential part of getting better performance from the Deep learning models at a later stage. Generally, I revisit this part of code multiple times during the stage of a project while trying to improve my models even further. You can show up a lot of creativity here to improve coverage over your &lt;code&gt;word_index&lt;/code&gt; and to include extra features in your embedding.&lt;/p&gt;

&lt;h2 id=&#34;more-engineered-features&#34;&gt;More Engineered Features&lt;/h2&gt;

&lt;p&gt;&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/example_nlp_network.png&#34; style=&#34;height:100%;width:100%&#34; &gt;&lt;/center&gt;
&lt;/div&gt;
One can always add sentence specific features like sentence length, number of unique words etc. as another input layer to give extra information to the Deep Neural Network. For example: I created these extra features as part of a feature engineering pipeline for Quora Insincerity Classification Challenge.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;add_features&lt;/span&gt;(df):
    df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;question_text&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;question_text&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;progress_apply(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x:str(x))
    df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;lower_question_text&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;question_text&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lower())
    df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;total_length&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;question_text&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;progress_apply(len)
    df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;capitals&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;question_text&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;progress_apply(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; comment: sum(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; c &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; comment &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; c&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;isupper()))
    df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;caps_vs_length&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;progress_apply(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; row: float(row[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;capitals&amp;#39;&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;float(row[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;total_length&amp;#39;&lt;/span&gt;]),
                                axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;num_words&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;question_text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;str&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;count(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;\S+&amp;#39;&lt;/span&gt;)
    df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;num_unique_words&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;question_text&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;progress_apply(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; comment: len(set(w &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; w &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; comment&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split())))
    df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;words_vs_unique&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;num_unique_words&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;num_words&amp;#39;&lt;/span&gt;] 
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; df&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion:&lt;/h2&gt;

&lt;p&gt;NLP is still a very interesting problem in Deep Learning space and thus I would encourage you to do a lot of experimentation to see what works and what doesn&amp;rsquo;t. I have tried to provide a wholesome perspective of the preprocessing steps for a Deep Learning Neural network for any NLP problem. But that doesn&amp;rsquo;t mean it is definitive. If you want to learn more about NLP &lt;a href=&#34;https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;amp;offerid=467035.11503135394&amp;amp;type=2&amp;amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Flanguage-processing&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; is an awesome course. You can start for free with the 7-day Free Trial. If you think we can add something to the flow, do mention it in the comments.&lt;/p&gt;

&lt;h2 id=&#34;endnotes-and-references&#34;&gt;Endnotes and References&lt;/h2&gt;

&lt;p&gt;This post is a result of an effort of a lot of excellent Kagglers and I will try to reference them in this section. If I leave out someone, do understand that it was not my intention to do so.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;How to: Preprocessing when using embeddings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Improve your Score with some Text Preprocessing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Pytorch baseline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/hengzheng/pytorch-starter&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Pytorch starter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A Layman guide to moving from Keras to Pytorch</title>
      <link>https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/</link>
      <pubDate>Sun, 06 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/</guid>
      <description>

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/artificial-neural-network.png&#34;  height=&#34;350&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Recently I started up with a competition on kaggle on text classification, and as a part of the competition, I had to somehow move to Pytorch to get deterministic results. Now I have always worked with Keras in the past and it has given me pretty good results, but somehow I got to know that the &lt;strong&gt;CuDNNGRU/CuDNNLSTM layers in keras are not deterministic&lt;/strong&gt;, even after setting the seeds. So Pytorch did come to rescue. And am  I  glad that I moved.&lt;/p&gt;

&lt;p&gt;As a &lt;strong&gt;side note&lt;/strong&gt;: if you want to know more about &lt;strong&gt;NLP&lt;/strong&gt;, I would like to recommend this awesome course on &lt;strong&gt;&lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Natural Language Processing&lt;/a&gt;&lt;/strong&gt; in the &lt;strong&gt;&lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Advanced machine learning specialization&lt;/a&gt;&lt;/strong&gt;. You can start for free with the 7-day Free Trial. This course covers a wide range of tasks in Natural Language Processing from basic to advanced: Sentiment Analysis, summarization, dialogue state tracking, to name a few.&lt;/p&gt;

&lt;p&gt;Also take a look at my other post: &lt;a href=&#34;https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/&#34;&gt;Text Preprocessing Methods for Deep Learning&lt;/a&gt;, which talks about different preprocessing techniques you can use for your NLP task and &lt;a href=&#34;https://mlwhiz.com/blog/2018/12/17/text_classification/&#34;&gt;What Kagglers are using for Text Classification&lt;/a&gt;, which talks about various deep learning models in use in NLP.&lt;/p&gt;

&lt;p&gt;Ok back to the task at hand. &lt;em&gt;While Keras is great to start with deep learning, with time you are going to resent some of its limitations.&lt;/em&gt; I sort of thought about moving to Tensorflow. It seemed like a good transition as TF is the backend of Keras. But was it hard? With the whole &lt;code&gt;session.run&lt;/code&gt; commands and tensorflow sessions, I was sort of confused. It was not Pythonic at all.&lt;/p&gt;

&lt;p&gt;Pytorch helps in that since it seems like the &lt;strong&gt;python way to do things&lt;/strong&gt;. You have things under your control and you are not losing anything on the performance front. In the words of Andrej Karpathy:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;en&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;I&amp;#39;ve been using PyTorch a few months now and I&amp;#39;ve never felt better. I have more energy. My skin is clearer. My eye sight has improved.&lt;/p&gt;&amp;mdash; Andrej Karpathy (@karpathy) &lt;a href=&#34;https://twitter.com/karpathy/status/868178954032513024?ref_src=twsrc%5Etfw&#34;&gt;May 26, 2017&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;So without further ado let me translate Keras to Pytorch for you.&lt;/p&gt;

&lt;h2 id=&#34;the-classy-way-to-write-your-network&#34;&gt;The Classy way to write your network?&lt;/h2&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/structured.jpeg&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Ok, let us create an example network in keras first which we will try to port into Pytorch. Here I would like to give a piece of advice too. When you try to move from Keras to Pytorch &lt;strong&gt;take any network you have and try porting it to Pytorch&lt;/strong&gt;. It will make you understand Pytorch in a much better way. Here I am trying to write one of the networks that gave pretty good results in the Quora Insincere questions classification challenge for me. This model has all the bells and whistles which at least any Text Classification deep learning network could contain with its GRU, LSTM and embedding layers and also a meta input layer. And thus would serve as a good example. Also if you want to read up more on how the BiLSTM/GRU and Attention model work do visit my post &lt;a href=&#34;https://mlwhiz.com/blog/2018/12/17/text_classification/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_model&lt;/span&gt;(features,clipvalue&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt;,num_filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;40&lt;/span&gt;,dropout&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;,embed_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;501&lt;/span&gt;):
    features_input &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],))
    inp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(maxlen, ))
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 1: Word2Vec Embeddings.&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Embedding(max_features, embed_size, weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[embedding_matrix], trainable&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)(inp)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 2: SpatialDropout1D(0.1)&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SpatialDropout1D(dropout)(x)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 3: Bidirectional CuDNNLSTM&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Bidirectional(LSTM(num_filters, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True))(x)

    &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 4: Bidirectional CuDNNGRU&lt;/span&gt;
    x, x_h, x_c &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Bidirectional(GRU(num_filters, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, return_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; True))(x)  
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 5: some pooling operations&lt;/span&gt;
    avg_pool &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GlobalAveragePooling1D()(x)
    max_pool &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GlobalMaxPooling1D()(x)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 6: A concatenation of the last state, maximum pool, average pool and &lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# additional features&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; concatenate([avg_pool, x_h, max_pool,features_input])
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 7: A dense layer&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;)(x)

    &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 8: A dropout layer&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dropout(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)(x)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 9: Output dense layer with one output for our Binary Classification problem.&lt;/span&gt;
    outp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sigmoid&amp;#34;&lt;/span&gt;)(x)

    &lt;span style=&#34;color:#75715e&#34;&gt;# Some keras model creation and compiling&lt;/span&gt;
    model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[inp,features_input], outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;outp)
    adam &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;adam(clipvalue&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;clipvalue)
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;binary_crossentropy&amp;#39;&lt;/span&gt;,
                  optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;adam,
                  metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So a model in pytorch is defined as a class(therefore a little more classy) which inherits from &lt;code&gt;nn.module&lt;/code&gt; . Every class necessarily contains an &lt;code&gt;__init__&lt;/code&gt; procedure block and a block for the &lt;code&gt;forward&lt;/code&gt; pass.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;In the &lt;code&gt;__init__&lt;/code&gt; part the user defines all the layers the network is going to have but doesn&amp;rsquo;t yet define how those layers would be connected to each other&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;In the forward pass block, the user defines how data flows from one layer to another inside the network.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;why-is-this-classy&#34;&gt;Why is this Classy?&lt;/h4&gt;

&lt;p&gt;Obviously classy because of Classes. Duh! But jokes apart, I found it beneficial due to a couple of reasons:&lt;/p&gt;

&lt;p&gt;1) It gives you a &lt;strong&gt;lot of control&lt;/strong&gt; on how your network is built.&lt;/p&gt;

&lt;p&gt;2) You understand a lot about the network when you are building it since you have to specify input and output dimensions. So ** fewer chances of error**. (Although this one is really up to the skill level)&lt;/p&gt;

&lt;p&gt;3) &lt;strong&gt;Easy to debug&lt;/strong&gt; networks. Any time you find any problem with the network just use something like &lt;code&gt;print(&amp;quot;avg_pool&amp;quot;, avg_pool.size())&lt;/code&gt; in the forward pass to check the sizes of the layer and you will debug the network easily&lt;/p&gt;

&lt;p&gt;4) You can &lt;strong&gt;return multiple outputs&lt;/strong&gt; from the forward layer. This is pretty helpful in the Encoder-Decoder architecture where you can return both the encoder and decoder output. Or in the case of autoencoder where you can return the output of the model and the hidden layer embedding for the data.&lt;/p&gt;

&lt;p&gt;5) &lt;strong&gt;Pytorch tensors work in a very similar manner to numpy arrays&lt;/strong&gt;. For example, I could have used Pytorch Maxpool function to write the maxpool layer but &lt;code&gt;max_pool, _ = torch.max(h_gru, 1)&lt;/code&gt; will also work.&lt;/p&gt;

&lt;p&gt;6) You can set up &lt;strong&gt;different layers with different initialization schemes&lt;/strong&gt;. Something you won&amp;rsquo;t be able to do in Keras. For example, in the below network I have changed the initialization scheme of my LSTM layer. The LSTM layer has different initializations for biases, input layer weights, and hidden layer weights.&lt;/p&gt;

&lt;p&gt;7) Wait until you see the &lt;strong&gt;training loop in Pytorch&lt;/strong&gt; You will be amazed at the sort of &lt;strong&gt;control&lt;/strong&gt; it provides.&lt;/p&gt;

&lt;p&gt;Now the same model in Pytorch will look like something like this. Do go through the code comments to understand more on how to port.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Alex_NeuralNet_Meta&lt;/span&gt;(nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Module):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; __init__(self,hidden_size,lin_size, embedding_matrix&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;embedding_matrix):
        super(Alex_NeuralNet_Meta, self)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__init__()

        &lt;span style=&#34;color:#75715e&#34;&gt;# Initialize some parameters for your model&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hidden_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; hidden_size
        drp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;

        &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 1: Word2Vec Embeddings.&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Embedding(max_features, embed_size)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Parameter(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(embedding_matrix, dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32))
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;weight&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;requires_grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False

        &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 2: Dropout1D(0.1)&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding_dropout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout2d(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)

        &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 3: Bidirectional CuDNNLSTM&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lstm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LSTM(embed_size, hidden_size, bidirectional&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, batch_first&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)

        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; name, param &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lstm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;named_parameters():
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bias&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; name:
                 nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;constant_(param, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;weight_ih&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; name:
                 nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;kaiming_normal_(param)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;weight_hh&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; name:
                 nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;orthogonal_(param)

        &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 4: Bidirectional CuDNNGRU&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gru &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GRU(hidden_size&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, hidden_size, bidirectional&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, batch_first&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)

        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; name, param &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gru&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;named_parameters():
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bias&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; name:
                 nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;constant_(param, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;weight_ih&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; name:
                 nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;kaiming_normal_(param)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;weight_hh&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; name:
                 nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;orthogonal_(param)

        &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 7: A dense layer&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linear &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Linear(hidden_size&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], lin_size)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;relu &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ReLU()
        
        &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 8: A dropout layer &lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dropout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(drp)

        &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 9: Output dense layer with one output for our Binary Classification problem.&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;out &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Linear(lin_size, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;forward&lt;/span&gt;(self, x):
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        here x[0] represents the first element of the input that is going to be passed. 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        We are going to pass a tuple where first one contains the sequences(x[0])
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        and the second one is a additional feature vector(x[1])
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        h_embedding &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding(x[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
        &lt;span style=&#34;color:#75715e&#34;&gt;# Based on comment by Ivank to integrate spatial dropout. &lt;/span&gt;
        embeddings &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; h_embedding&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unsqueeze(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)    &lt;span style=&#34;color:#75715e&#34;&gt;# (N, T, 1, K)&lt;/span&gt;
        embeddings &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;permute(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# (N, K, 1, T)&lt;/span&gt;
        embeddings &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding_dropout(embeddings)  &lt;span style=&#34;color:#75715e&#34;&gt;# (N, K, 1, T), some features are masked&lt;/span&gt;
        embeddings &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;permute(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# (N, T, 1, K)&lt;/span&gt;
        h_embedding &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# (N, T, K)&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;#h_embedding = torch.squeeze(self.embedding_dropout(torch.unsqueeze(h_embedding, 0)))&lt;/span&gt;
        
        &lt;span style=&#34;color:#75715e&#34;&gt;#print(&amp;#34;emb&amp;#34;, h_embedding.size())&lt;/span&gt;
        h_lstm, _ &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lstm(h_embedding)
        &lt;span style=&#34;color:#75715e&#34;&gt;#print(&amp;#34;lst&amp;#34;,h_lstm.size())&lt;/span&gt;
        h_gru, hh_gru &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gru(h_lstm)
        hh_gru &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; hh_gru&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;view(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hidden_size )
        &lt;span style=&#34;color:#75715e&#34;&gt;#print(&amp;#34;gru&amp;#34;, h_gru.size())&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;#print(&amp;#34;h_gru&amp;#34;, hh_gru.size())&lt;/span&gt;

        &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 5: is defined dynamically as an operation on tensors.&lt;/span&gt;
        avg_pool &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(h_gru, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
        max_pool, _ &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max(h_gru, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
        &lt;span style=&#34;color:#75715e&#34;&gt;#print(&amp;#34;avg_pool&amp;#34;, avg_pool.size())&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;#print(&amp;#34;max_pool&amp;#34;, max_pool.size())&lt;/span&gt;
        
        &lt;span style=&#34;color:#75715e&#34;&gt;# the extra features you want to give to the model&lt;/span&gt;
        f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cuda()
        &lt;span style=&#34;color:#75715e&#34;&gt;#print(&amp;#34;f&amp;#34;, f.size())&lt;/span&gt;

        &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 6: A concatenation of the last state, maximum pool, average pool and &lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# additional features&lt;/span&gt;
        conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cat(( hh_gru, avg_pool, max_pool,f), &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
        &lt;span style=&#34;color:#75715e&#34;&gt;#print(&amp;#34;conc&amp;#34;, conc.size())&lt;/span&gt;

        &lt;span style=&#34;color:#75715e&#34;&gt;# passing conc through linear and relu ops&lt;/span&gt;
        conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;relu(self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linear(conc))
        conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dropout(conc)
        out &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;out(conc)
        &lt;span style=&#34;color:#75715e&#34;&gt;# return the final output&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; out&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Hope you are still there with me. One thing I would like to emphasize here is that you need to code something up in Pytorch to really understand how it works. And know that once you do that you would be glad that you put in the effort. On to the next section.&lt;/p&gt;

&lt;h2 id=&#34;tailored-or-readymade-the-best-fit-with-a-highly-customizable-training-loop&#34;&gt;Tailored or Readymade: The Best Fit with a highly customizable Training Loop&lt;/h2&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/sewing-machine.jpg&#34;  height=&#34;300&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;In the above section I wrote that you will be amazed once you saw the training loop. That was an exaggeration. On the first try you will be a little baffled/confused. But as soon as you read through the loop more than once it will make a lot of intuituve sense. Once again read up the comments and the code to gain a better understanding.&lt;/p&gt;

&lt;p&gt;This training loop does k-fold cross-validation on your training data and outputs Out-of-fold train_preds and test_preds averaged over the runs on the test data. I apologize if the flow looks something straight out of a kaggle competition, but if you understand this you would be able to create a training loop for your own workflow. And that is the beauty of Pytorch.&lt;/p&gt;

&lt;p&gt;So a brief summary of this loop are as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Create stratified splits using train data&lt;/li&gt;
&lt;li&gt;Loop through the splits.

&lt;ul&gt;
&lt;li&gt;Convert your train and CV data to tensor and load your data to the GPU using the
&lt;code&gt;X_train_fold = torch.tensor(x_train[train_idx.astype(int)], dtype=torch.long).cuda()&lt;/code&gt; command&lt;/li&gt;
&lt;li&gt;Load the model onto the GPU using the &lt;code&gt;model.cuda()&lt;/code&gt; command&lt;/li&gt;
&lt;li&gt;Define Loss function, Scheduler and Optimizer&lt;/li&gt;
&lt;li&gt;create &lt;code&gt;train_loader&lt;/code&gt;    and     valid_loader` to iterate through batches.&lt;/li&gt;
&lt;li&gt;Start running epochs. In each epoch

&lt;ul&gt;
&lt;li&gt;Set the model mode to train using &lt;code&gt;model.train()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Go through the batches in &lt;code&gt;train_loader&lt;/code&gt; and run the forward pass&lt;/li&gt;
&lt;li&gt;Run a scheduler step to change the learning rate&lt;/li&gt;
&lt;li&gt;Compute loss&lt;/li&gt;
&lt;li&gt;Set the existing gradients in the optimizer to zero&lt;/li&gt;
&lt;li&gt;Backpropagate the losses through the network&lt;/li&gt;
&lt;li&gt;Clip the gradients&lt;/li&gt;
&lt;li&gt;Take an optimizer step to change the weights in the whole network&lt;/li&gt;
&lt;li&gt;Set the model mode to eval using &lt;code&gt;model.eval()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Get predictions for the validation data using &lt;code&gt;valid_loader&lt;/code&gt; and store in variable &lt;code&gt;valid_preds_fold&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Calculate Loss and print&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;After all epochs are done. Predict the test data and store the predictions. These predictions will be averaged at the end of the split loop to get the final &lt;code&gt;test_preds&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Get Out-of-fold(OOF) predictions for train set using &lt;code&gt;train_preds[valid_idx] = valid_preds_fold&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;These OOF predictions can then be used to calculate the Local CV score for your model.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pytorch_model_run_cv&lt;/span&gt;(x_train,y_train,features,x_test, model_obj, feats &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False,clip &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; True):
    seed_everything()
    avg_losses_f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    avg_val_losses_f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    &lt;span style=&#34;color:#75715e&#34;&gt;# matrix for the out-of-fold predictions&lt;/span&gt;
    train_preds &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((len(x_train)))
    &lt;span style=&#34;color:#75715e&#34;&gt;# matrix for the predictions on the test set&lt;/span&gt;
    test_preds &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((len(x_test)))
    splits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(StratifiedKFold(n_splits&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;n_splits, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;SEED)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(x_train, y_train))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, (train_idx, valid_idx) &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(splits):
        seed_everything(i&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;i)
        x_train &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(x_train)
        y_train &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(y_train)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; feats:
            features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(features)
        x_train_fold &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(x_train[train_idx&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(int)], dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;long)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cuda()
        y_train_fold &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(y_train[train_idx&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(int), np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis], dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cuda()
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; feats:
            kfold_X_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; features[train_idx&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(int)]
            kfold_X_valid_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; features[valid_idx&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(int)]
        x_val_fold &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(x_train[valid_idx&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(int)], dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;long)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cuda()
        y_val_fold &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(y_train[valid_idx&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(int), np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis], dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cuda()
        
        model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; copy&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;deepcopy(model_obj)

        model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cuda()

        loss_fn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;BCEWithLogitsLoss(reduction&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sum&amp;#39;&lt;/span&gt;)

        step_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;
        base_lr, max_lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.001&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.003&lt;/span&gt;   
        optimizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optim&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(filter(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; p: p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;requires_grad, model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parameters()), 
                                 lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;max_lr)
        
        &lt;span style=&#34;color:#75715e&#34;&gt;################################################################################################&lt;/span&gt;
        scheduler &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; CyclicLR(optimizer, base_lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;base_lr, max_lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;max_lr,
                   step_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;step_size, mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;exp_range&amp;#39;&lt;/span&gt;,
                   gamma&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.99994&lt;/span&gt;)
        &lt;span style=&#34;color:#75715e&#34;&gt;###############################################################################################&lt;/span&gt;

        train &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MyDataset(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;TensorDataset(x_train_fold, y_train_fold))
        valid &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MyDataset(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;TensorDataset(x_val_fold, y_val_fold))
        
        train_loader &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataLoader(train, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;batch_size, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
        valid_loader &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataLoader(valid, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;batch_size, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)

        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Fold {i + 1}&amp;#39;&lt;/span&gt;)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; epoch &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(n_epochs):
            start_time &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()
            model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;train()

            avg_loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.&lt;/span&gt;  
            &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, (x_batch, y_batch, index) &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(train_loader):
                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; feats:       
                    f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; kfold_X_features[index]
                    y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model([x_batch,f])
                &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
                    y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(x_batch)

                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; scheduler:
                    scheduler&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;batch_step()

                &lt;span style=&#34;color:#75715e&#34;&gt;# Compute and print loss.&lt;/span&gt;
                loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; loss_fn(y_pred, y_batch)
                optimizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zero_grad()
                loss&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;backward()
                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; clip:
                    nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip_grad_norm_(model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parameters(),&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
                optimizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;step()
                avg_loss &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; loss&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item() &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; len(train_loader)
                
            model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eval()
            
            valid_preds_fold &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((x_val_fold&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;size(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)))
            test_preds_fold &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((len(x_test)))
            
            avg_val_loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.&lt;/span&gt;
            &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, (x_batch, y_batch,index) &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(valid_loader):
                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; feats:
                    f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; kfold_X_valid_features[index]            
                    y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model([x_batch,f])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;detach()
                &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
                    y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(x_batch)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;detach()
                
                avg_val_loss &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; loss_fn(y_pred, y_batch)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item() &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; len(valid_loader)
                valid_preds_fold[index] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sigmoid(y_pred&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
            
            elapsed_time &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time() &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; start_time 
            &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch {}/{} &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; loss={:.4f} &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; val_loss={:.4f} &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; time={:.2f}s&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(
                epoch &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, n_epochs, avg_loss, avg_val_loss, elapsed_time))
        avg_losses_f&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(avg_loss)
        avg_val_losses_f&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(avg_val_loss) 
        &lt;span style=&#34;color:#75715e&#34;&gt;# predict all samples in the test set batch per batch&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, (x_batch,) &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(test_loader):
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; feats:
                f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_features[i &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; batch_size:(i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; batch_size]
                y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model([x_batch,f])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;detach()
            &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
                y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(x_batch)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;detach()

            test_preds_fold[i &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; batch_size:(i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; batch_size] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sigmoid(y_pred&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
            
        train_preds[valid_idx] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_preds_fold
        test_preds &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; test_preds_fold &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; len(splits)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;All &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; loss={:.4f} &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; val_loss={:.4f} &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; &amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;average(avg_losses_f),np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;average(avg_val_losses_f)))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; train_preds, test_preds&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&#34;but-why-why-so-much-code&#34;&gt;But Why? Why so much code?&lt;/h4&gt;

&lt;p&gt;Okay. I get it. That was probably a handful. What you could have done with a simple&lt;code&gt;.fit&lt;/code&gt; in keras, takes a lot of code to accomplish in Pytorch. But understand that you get a lot of power too. Some use cases for you to understand:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;While in Keras you have prespecified schedulers like &lt;code&gt;ReduceLROnPlateau&lt;/code&gt; (and it is a task to write them), in Pytorch you can experiment like crazy. &lt;strong&gt;If you know how to write Python you are going to get along just fine&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Want to change the structure of your model between the epochs. Yeah you can do it. Changing the input size for convolution networks on the fly.&lt;/li&gt;
&lt;li&gt;And much more. It is only your imagination that will stop you.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;wanna-run-it-yourself&#34;&gt;Wanna Run it Yourself?&lt;/h2&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/tools.jpg&#34; alt=&#34;You have all the tools it seems&#34; height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;So another small confession here. The code above will not run as is as there are some code artifacts which I have not shown here. I did this in favor of making the post more readable. Like you see the &lt;code&gt;seed_everything&lt;/code&gt;, &lt;code&gt;MyDataset&lt;/code&gt; and &lt;code&gt;CyclicLR&lt;/code&gt; (From Jeremy Howard Course) functions and classes in the code above which are not really included with Pytorch. But fret not my friend. I have tried to write a &lt;a href=&#34;https://www.kaggle.com/mlwhiz/third-place-model-for-toxic-comments-in-pytorch/edit&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Kaggle Kernel&lt;/a&gt; with the whole running code. You can see the code here and include it in your projects.&lt;/p&gt;

&lt;p&gt;If you liked this post, &lt;strong&gt;please don&amp;rsquo;t forget to upvote the &lt;a href=&#34;https://www.kaggle.com/mlwhiz/third-place-model-for-toxic-comments-in-pytorch/edit&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Kernel&lt;/a&gt; too.&lt;/strong&gt; I will be obliged.&lt;/p&gt;

&lt;h2 id=&#34;endnotes-and-references&#34;&gt;Endnotes and References&lt;/h2&gt;

&lt;p&gt;This post is a result of an effort of a lot of excellent Kagglers and I will try to reference them in this section. If I leave out someone, do understand that it was not my intention to do so.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52644&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Discussion on 3rd Place winner model in Toxic comment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/larryfreeman/toxic-comments-code-for-alexander-s-9872-model&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;3rd Place model in Keras by Larry Freeman&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/spirosrap/bilstm-attention-kfold-clr-extra-features-capsule&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Pytorch starter Capsule model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;How to: Preprocessing when using embeddings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Improve your Score with some Text Preprocessing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Pytorch baseline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/hengzheng/pytorch-starter&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Pytorch starter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What Kagglers are using for Text Classification</title>
      <link>https://mlwhiz.com/blog/2018/12/17/text_classification/</link>
      <pubDate>Mon, 17 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2018/12/17/text_classification/</guid>
      <description>

&lt;p&gt;With the problem of Image Classification is more or less solved by Deep learning, &lt;em&gt;Text Classification is the next new developing theme in deep learning&lt;/em&gt;. For those who don&amp;rsquo;t know, Text classification is a common task in natural language processing, which transforms a sequence
of text of indefinite length into a category of text. How could you use that?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;To find sentiment of a review.&lt;/li&gt;
&lt;li&gt;Find toxic comments in a platform like Facebook&lt;/li&gt;
&lt;li&gt;Find Insincere questions on Quora. A current ongoing competition on kaggle&lt;/li&gt;
&lt;li&gt;Find fake reviews on websites&lt;/li&gt;
&lt;li&gt;Will a text advert get clicked or not&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And much more. The whole internet is filled with text and to categorise that information algorithmically will only give us incremental benefits to say the least in the field of AI.&lt;/p&gt;

&lt;p&gt;Here I am going to use the data from Quora&amp;rsquo;s Insincere questions to talk about the different models that people are building and sharing to perform this task. Obviously these standalone models are not going to put you on the top of the leaderboard, yet I hope that this ensuing discussion would be helpful for people who want to learn more about text classification. This is going to be a long post in that regard.&lt;/p&gt;

&lt;p&gt;As a side note: if you want to know more about NLP, I would like to recommend this awesome course on &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Natural Language Processing&lt;/a&gt; in the &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Advanced machine learning specialization&lt;/a&gt;. You can start for free with the 7-day Free Trial. This course covers a wide range of tasks in Natural Language Processing from basic to advanced: sentiment analysis, summarization, dialogue state tracking, to name a few.&lt;/p&gt;

&lt;p&gt;Also take a look at my other post: &lt;a href=&#34;https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/&#34;&gt;Text Preprocessing Methods for Deep Learning&lt;/a&gt;, which talks about different preprocessing techniques you can use for your NLP task and &lt;a href=&#34;https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/&#34;&gt;how to switch from Keras to Pytorch&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So let me try to go through some of the models which people are using to perform text classification and try to provide a brief intuition for them.&lt;/p&gt;

&lt;h2 id=&#34;1-textcnn&#34;&gt;1. TextCNN:&lt;/h2&gt;

&lt;p&gt;The idea of using a CNN to classify text was first presented in the paper &lt;a href=&#34;https://www.aclweb.org/anthology/D14-1181&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Convolutional Neural Networks for Sentence Classification&lt;/a&gt; by Yoon Kim. Instead of image pixels, the input to the tasks are sentences or documents represented as a matrix. Each row of the matrix corresponds to one word vector. That is, each row is word-vector that represents a word. Thus a sequence of max length 70 gives us a image of 70(max sequence length)x300(embedding size)&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/text_convolution.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Now for some intuition. While for a image we move our conv filter horizontally also since here we have fixed our kernel size to filter_size x embed_size i.e. (3,300) we are just going to move down for the convolution taking look at three words at once since our filter size is 3 in this case.Also one can think of filter sizes as unigrams, bigrams, trigrams etc. Since we are looking at a context window of 1,2,3, and 5 words respectively. Here is the text classification network coded in Keras:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# https://www.kaggle.com/yekenot/2dcnn-textclassifier&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model_cnn&lt;/span&gt;(embedding_matrix):
    filter_sizes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
    num_filters &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;36&lt;/span&gt;

    inp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(maxlen,))
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Embedding(max_features, embed_size, weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[embedding_matrix])(inp)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Reshape((maxlen, embed_size, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))(x)

    maxpool_pool &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(filter_sizes)):
        conv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Conv2D(num_filters, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(filter_sizes[i], embed_size),
                                     kernel_initializer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;he_normal&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elu&amp;#39;&lt;/span&gt;)(x)
        maxpool_pool&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(MaxPool2D(pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(maxlen &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; filter_sizes[i] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))(conv))

    z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Concatenate(axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)(maxpool_pool)   
    z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Flatten()(z)
    z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dropout(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)(z)

    outp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sigmoid&amp;#34;&lt;/span&gt;)(z)

    model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inp, outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;outp)
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;binary_crossentropy&amp;#39;&lt;/span&gt;, optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
    
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I have written a simplified and well commented code to run this network(taking input from a lot of other kernels) on a &lt;a href=&#34;https://www.kaggle.com/mlwhiz/learning-text-classification-textcnn&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;kaggle kernel&lt;/a&gt; for this competition. Do take a look there to learn the preprocessing steps, and the word to vec embeddings usage in this model. You will learn something. Please do upvote the kernel if you find it helpful. This kernel scored around 0.661 on the public leaderboard.&lt;/p&gt;

&lt;h2 id=&#34;2-bidirectional-rnn-lstm-gru&#34;&gt;2. BiDirectional RNN(LSTM/GRU):&lt;/h2&gt;

&lt;p&gt;TextCNN takes care of a lot of things. For example it takes care of words in close range. It is able to see &amp;ldquo;new york&amp;rdquo; together. But it still can&amp;rsquo;t take care of all the context provided in a particular text sequence. It still does not learn the seem to learn the sequential structure of the data, where every word is dependednt on the previous word. Or a word in the previous sentence.&lt;/p&gt;

&lt;p&gt;RNN help us with that. &lt;em&gt;They are able to remember previous information using hidden states and connect it to the current task.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Long Short Term Memory networks (LSTM) are a subclass of RNN, specialized in remembering information for a long period of time. More over the Bidirectional LSTM keeps the contextual information in both directions which is pretty useful in text classification task (But won&amp;rsquo;t work for a time sweries prediction task).&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/birnn.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;For a most simplistic explanation of Bidirectional RNN, think of RNN cell as taking as input a hidden state(a vector) and the word vector and giving out an output vector and the next hidden state.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        Hidden state, Word vector -&amp;gt;(RNN Cell) -&amp;gt; Output Vector , Next Hidden state
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For a sequence of length 4 like &amp;lsquo;you will never believe&amp;rsquo;, The RNN cell will give 4 output vectors. Which can be concatenated and then used as part of a dense feedforward architecture.&lt;/p&gt;

&lt;p&gt;In the Bidirectional RNN the only change is that we read the text in the normal fashion as well in reverse. So we stack two RNNs in parallel and hence we get 8 output vectors to append.&lt;/p&gt;

&lt;p&gt;Once we get the output vectors we send them through a series of dense layers and finally a softmax layer to build a text classifier.&lt;/p&gt;

&lt;p&gt;Due to the limitations of RNNs like not remembering long term dependencies, in practice we almost always use LSTM/GRU to model long term dependencies. In such a case you can just think of the RNN cell being replaced by a LSTM cell or a GRU cell in the above figure. An example model is provided below. You can use CuDNNGRU interchangably with CuDNNLSTM, when you build models.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# BiDirectional LSTM&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model_lstm_du&lt;/span&gt;(embedding_matrix):
    inp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(maxlen,))
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Embedding(max_features, embed_size, weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[embedding_matrix])(inp)
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Here 64 is the size(dim) of the hidden state vector as well as the output vector. Keeping return_sequence we want the output for the entire sequence. So what is the dimension of output for this layer?
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        64*70(maxlen)*2(bidirection concat)
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    CuDNNLSTM is fast implementation of LSTM layer in Keras which only runs on GPU
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Bidirectional(CuDNNLSTM(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True))(x)
    avg_pool &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GlobalAveragePooling1D()(x)
    max_pool &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GlobalMaxPooling1D()(x)
    conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; concatenate([avg_pool, max_pool])
    conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;)(conc)
    conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dropout(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)(conc)
    outp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sigmoid&amp;#34;&lt;/span&gt;)(conc)
    model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inp, outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;outp)
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;binary_crossentropy&amp;#39;&lt;/span&gt;, optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I have written a simplified and well commented code to run this network(taking input from a lot of other kernels) on a &lt;a href=&#34;https://www.kaggle.com/mlwhiz/learning-text-classification-bidirectionalrnn&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;kaggle kernel&lt;/a&gt; for this competition. Do take a look there to learn the preprocessing steps, and the word to vec embeddings usage in this model. You will learn something. Please do upvote the kernel if you find it helpful. This kernel scored around 0.671 on the public leaderboard.&lt;/p&gt;

&lt;h2 id=&#34;3-attention-models&#34;&gt;3. Attention Models&lt;/h2&gt;

&lt;p&gt;The concept of Attention is relatively new as it comes from &lt;a href=&#34;https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Hierarchical Attention Networks for Document Classification&lt;/a&gt; paper written jointly by CMU and Microsoft guys in 2016.&lt;/p&gt;

&lt;p&gt;So in the past we used to find features from text by doing a keyword extraction. Some word are more helpful in determining the category of a text than others. But in this method we sort of lost the sequential structure of text. With LSTM and deep learning methods while we are able to take case of the sequence structure we lose the ability to give higher weightage to more important words.
Can we have the best of both worlds?&lt;/p&gt;

&lt;p&gt;And that is attention for you. In the author&amp;rsquo;s words:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Not all words contribute equally to the representation of the sentence meaning. Hence, we introduce attention mechanism to extract
such words that are important to the meaning of the sentence and aggregate the representation of those informative words to form a sentence vector&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/birnn attention.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;In essense we want to create scores for every word in the text, which are the attention similarity score for a word.&lt;/p&gt;

&lt;p&gt;To do this we start with a weight matrix(W), a bias vector(b) and a context vector u. All of them will be learned by the optimmization algorithm.&lt;/p&gt;

&lt;p&gt;Then there are a series of mathematical operations. See the figure for more clarification. We can think of u1 as non linearity on RNN word output. After that v1 is a dot product of u1 with a context vector u raised to an exponentiation. From an intuition viewpoint, the value of v1 will be high if u and u1 are similar. Since we want the sum of scores to be 1, we divide v by the sum of v’s to get the Final Scores,s&lt;/p&gt;

&lt;p&gt;These final scores are then multiplied by RNN output for words to weight them according to their importance. After which the outputs are summed and sent through dense layers and softmax for the task of text classification.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dot_product&lt;/span&gt;(x, kernel):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Wrapper for dot product operation, in order to be compatible with both
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Theano and Tensorflow
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Args:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        x (): input
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        kernel (): weights
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Returns:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;backend() &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tensorflow&amp;#39;&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(x, K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(kernel)), axis&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(x, kernel)
    

&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;AttentionWithContext&lt;/span&gt;(Layer):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Attention operation, with a context/query vector, for temporal data.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Supports Masking.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;Hierarchical Attention Networks for Document Classification&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    by using a context vector to assist the attention
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    # Input shape
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        3D tensor with shape: `(samples, steps, features)`.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    # Output shape
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        2D tensor with shape: `(samples, features)`.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    How to use:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    The dimensions are inferred based on the output shape of the RNN.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Note: The layer has been tested with Keras 2.0.6
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Example:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        model.add(LSTM(64, return_sequences=True))
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        model.add(AttentionWithContext())
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        # next add a Dense layer (for classification/regression) or whatever...
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; __init__(self,
                 W_regularizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, u_regularizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, b_regularizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None,
                 W_constraint&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, u_constraint&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, b_constraint&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None,
                 bias&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;kwargs):

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;supports_masking &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; True
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; initializers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;glorot_uniform&amp;#39;&lt;/span&gt;)

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_regularizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; regularizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(W_regularizer)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;u_regularizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; regularizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(u_regularizer)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_regularizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; regularizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(b_regularizer)

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_constraint &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; constraints&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(W_constraint)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;u_constraint &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; constraints&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(u_constraint)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_constraint &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; constraints&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(b_constraint)

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bias &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; bias
        super(AttentionWithContext, self)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__init__(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;kwargs)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;build&lt;/span&gt;(self, input_shape):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;assert&lt;/span&gt; len(input_shape) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_weight((input_shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], input_shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],),
                                 initializer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init,
                                 name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{}_W&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name),
                                 regularizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_regularizer,
                                 constraint&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_constraint)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bias:
            self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_weight((input_shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],),
                                     initializer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;zero&amp;#39;&lt;/span&gt;,
                                     name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{}_b&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name),
                                     regularizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_regularizer,
                                     constraint&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_constraint)

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;u &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_weight((input_shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],),
                                 initializer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init,
                                 name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{}_u&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name),
                                 regularizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;u_regularizer,
                                 constraint&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;u_constraint)

        super(AttentionWithContext, self)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;build(input_shape)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;compute_mask&lt;/span&gt;(self, input, input_mask&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None):
        &lt;span style=&#34;color:#75715e&#34;&gt;# do not pass the mask to the next layers&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; None

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;call&lt;/span&gt;(self, x, mask&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None):
        uit &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dot_product(x, self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W)

        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bias:
            uit &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b

        uit &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tanh(uit)
        ait &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dot_product(uit, self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;u)

        a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(ait)

        &lt;span style=&#34;color:#75715e&#34;&gt;# apply mask after the exp. will be re-normalized next&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; mask &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
            &lt;span style=&#34;color:#75715e&#34;&gt;# Cast the mask to floatX to avoid float64 upcasting in theano&lt;/span&gt;
            a &lt;span style=&#34;color:#f92672&#34;&gt;*=&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(mask, K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;floatx())

        &lt;span style=&#34;color:#75715e&#34;&gt;# in some cases especially in the early stages of training the sum may be almost zero&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# and this results in NaN&amp;#39;s. A workaround is to add a very small positive number ε to the sum.&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())&lt;/span&gt;
        a &lt;span style=&#34;color:#f92672&#34;&gt;/=&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(a, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, keepdims&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;epsilon(), K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;floatx())

        a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(a)
        weighted_input &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; a
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(weighted_input, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;compute_output_shape&lt;/span&gt;(self, input_shape):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; input_shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], input_shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]


&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model_lstm_atten&lt;/span&gt;(embedding_matrix):
    inp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(maxlen,))
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Embedding(max_features, embed_size, weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[embedding_matrix], trainable&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)(inp)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Bidirectional(CuDNNLSTM(&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True))(x)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Bidirectional(CuDNNLSTM(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True))(x)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AttentionWithContext()(x)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;)(x)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sigmoid&amp;#34;&lt;/span&gt;)(x)
    model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inp, outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;x)
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;binary_crossentropy&amp;#39;&lt;/span&gt;, optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I have written a simplified and well commented code to run this network(taking input from a lot of other kernels) on a &lt;a href=&#34;https://www.kaggle.com/mlwhiz/learning-text-classification-attention&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;kaggle kernel&lt;/a&gt; for this competition. Do take a look there to learn the preprocessing steps, and the word to vec embeddings usage in this model. You will learn something. Please do upvote the kernel if you find it helpful. This kernel scored around 0.682 on the public leaderboard.&lt;/p&gt;

&lt;p&gt;Hope that Helps! Do checkout the kernels for all the networks and see the comments too. I will try to write a part 2 of this post where I would like to talk about capsule networks and more techniques as they get used in this competition.&lt;/p&gt;

&lt;p&gt;Here are the kernel links again: &lt;a href=&#34;https://www.kaggle.com/mlwhiz/learning-text-classification-textcnn&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;TextCNN&lt;/a&gt;,&lt;a href=&#34;https://www.kaggle.com/mlwhiz/learning-text-classification-bidirectionalrnn&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;BiLSTM/GRU&lt;/a&gt;,&lt;a href=&#34;https://www.kaggle.com/mlwhiz/learning-text-classification-attention&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Attention&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Do upvote the kenels if you find them helpful.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;CNN for NLP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.diveintodeeplearning.org/d2l-en.pdf&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;https://en.diveintodeeplearning.org/d2l-en.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gist.github.com/cbaziotis/7ef97ccf71cbc14366835198c09809d2&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;https://gist.github.com/cbaziotis/7ef97ccf71cbc14366835198c09809d2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://univagora.ro/jour/index.php/ijccc/article/view/3142&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;http://univagora.ro/jour/index.php/ijccc/article/view/3142&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/shujian/fork-of-mix-of-nn-models&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Shujian&amp;rsquo;s kernel on Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>To all Data Scientists - The one Graph Algorithm you need to know</title>
      <link>https://mlwhiz.com/blog/2018/12/07/connected_components/</link>
      <pubDate>Fri, 07 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2018/12/07/connected_components/</guid>
      <description>

&lt;p&gt;Graphs provide us with a very useful data structure. They can help us to find structure within our data. With the advent of Machine learning and big data we need to get as much information as possible about our data. Learning a little bit of graph theory can certainly help us with that.&lt;/p&gt;

&lt;p&gt;Here is a &lt;a href=&#34;https://www.coursera.org/learn/big-data-graph-analytics?ranMID=40328&amp;amp;ranEAID=lVarvwc5BD0&amp;amp;ranSiteID=lVarvwc5BD0-uD3tAFL0mCUdzcfwDd6FTQ&amp;amp;siteID=lVarvwc5BD0-uD3tAFL0mCUdzcfwDd6FTQ&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Graph Analytics for Big Data course on Coursera by UCSanDiego&lt;/a&gt; which I highly recommend to learn the basics of graph theory. You can start for free with the 7-day Free Trial.&lt;/p&gt;

&lt;p&gt;One of the algorithms I am going to focus in the current post is called &lt;strong&gt;Connected Components&lt;/strong&gt;. Why it is important. We all know clustering.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You can think of Connected Components in very layman&amp;rsquo;s terms as sort of a hard clustering algorithm which finds clusters/islands in related/connected data. As a concrete example: Say you have data about roads joining any two cities in the world. And you need to find out all the continents in the world and which city they contain.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;How will you achieve that? Come on give some thought.&lt;/p&gt;

&lt;p&gt;To put a &lt;strong&gt;Retail Perspective&lt;/strong&gt;: Lets say, we have a lot of customers using a lot of accounts. One way in which we can use the Connected components algorithm is to find out distinct families in our dataset. We can assume edges(roads) between CustomerIDs based on same credit card usage, or same address or same mobile number etc. Once we have those connections, we can then run the connected component algorithm on the same to create individual clusters to which we can then assign a family ID. We can use these family IDs to provide personalized recommendations based on a family needs. We can also use this family ID to fuel our classification algorithms by creating grouped features based on family.&lt;/p&gt;

&lt;p&gt;In &lt;strong&gt;Finance Perspective&lt;/strong&gt;: Another use case would be to capture fraud using these family IDs. If an account has done fraud in past, it is highly probable that the connected accounts are also susceptible to fraud.&lt;/p&gt;

&lt;p&gt;So enough of use cases. Lets start with a simple graph class written in Python to start up our exploits with code.&lt;/p&gt;

&lt;p&gt;This post will revolve more around code from here onwards.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34; A Python Class
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;A simple Python graph class, demonstrating the essential 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;facts and functionalities of graphs.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Taken from https://www.python-course.eu/graphs_python.php
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Changed the implementation a little bit to include weighted edges
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Graph&lt;/span&gt;(object):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; __init__(self, graph_dict&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None):
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34; initializes a graph object 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            If no dictionary or None is given, 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            an empty dictionary will be used
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; graph_dict &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; None:
            graph_dict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__graph_dict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; graph_dict

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vertices&lt;/span&gt;(self):
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34; returns the vertices of a graph &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; list(self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__graph_dict&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keys())

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;edges&lt;/span&gt;(self):
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34; returns the edges of a graph &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__generate_edges()

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;add_vertex&lt;/span&gt;(self, vertex):
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34; If the vertex &amp;#34;vertex&amp;#34; is not in 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            self.__graph_dict, a key &amp;#34;vertex&amp;#34; with an empty
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            dict as a value is added to the dictionary. 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            Otherwise nothing has to be done. 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; vertex &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__graph_dict:
            self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__graph_dict[vertex] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;add_edge&lt;/span&gt;(self, edge,weight&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34; assumes that edge is of type set, tuple or list
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
        edge &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; set(edge)
        (vertex1, vertex2) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tuple(edge)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; vertex1 &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__graph_dict:
            self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__graph_dict[vertex1][vertex2] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; weight
        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
            self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__graph_dict[vertex1] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {vertex2:weight}

        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; vertex2 &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__graph_dict:
            self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__graph_dict[vertex2][vertex1] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; weight
        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
            self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__graph_dict[vertex2] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {vertex1:weight}
        

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;__generate_edges&lt;/span&gt;(self):
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34; A static method generating the edges of the 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            graph &amp;#34;graph&amp;#34;. Edges are represented as sets 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            with one (a loop back to the vertex) or two 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            vertices 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
        edges &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; vertex &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__graph_dict:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; neighbour,weight &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__graph_dict[vertex]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iteritems():
                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (neighbour, vertex, weight) &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; edges:
                    edges&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append([vertex, neighbour, weight])
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; edges

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; __str__(self):
        res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;vertices: &amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; k &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__graph_dict:
            res &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; str(k) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;
        res &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;edges: &amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; edge &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__generate_edges():
            res &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; str(edge) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; res
    
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;adj_mat&lt;/span&gt;(self):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__graph_dict&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can certainly play with our new graph class.Here we try to build some graphs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; { &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;a&amp;#34;&lt;/span&gt; : {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;},
      &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;b&amp;#34;&lt;/span&gt; : {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;c&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;},
      &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;c&amp;#34;&lt;/span&gt; : {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;b&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;e&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;}
    }
graph &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Graph(g)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Vertices of graph:&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;vertices())
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Edges of graph:&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;edges())
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Add vertex:&amp;#34;&lt;/span&gt;)
graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_vertex(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;z&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Vertices of graph:&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;vertices()) 
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Add an edge:&amp;#34;&lt;/span&gt;)
graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_edge({&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;a&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;z&amp;#34;&lt;/span&gt;})    
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Vertices of graph:&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;vertices())
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Edges of graph:&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;edges())
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Adding an edge {&amp;#34;x&amp;#34;,&amp;#34;y&amp;#34;} with new vertices:&amp;#39;&lt;/span&gt;)
graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_edge({&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;x&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;y&amp;#34;&lt;/span&gt;})
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Vertices of graph:&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;vertices())
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Edges of graph:&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;edges())&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-family:courier new,monospace; background-color:#f6c6529c; color:#000000&#34;&gt;Vertices of graph:
[&#39;a&#39;, &#39;c&#39;, &#39;b&#39;]
Edges of graph:
[[&#39;a&#39;, &#39;d&#39;, 2], [&#39;c&#39;, &#39;b&#39;, 5], [&#39;c&#39;, &#39;e&#39;, 5], [&#39;c&#39;, &#39;d&#39;, 3], [&#39;b&#39;, &#39;c&#39;, 2]]
Add vertex:
Vertices of graph:
[&#39;a&#39;, &#39;c&#39;, &#39;b&#39;, &#39;z&#39;]
Add an edge:
Vertices of graph:
[&#39;a&#39;, &#39;c&#39;, &#39;b&#39;, &#39;z&#39;]
Edges of graph:
[[&#39;a&#39;, &#39;z&#39;, 1], [&#39;a&#39;, &#39;d&#39;, 2], [&#39;c&#39;, &#39;b&#39;, 5], [&#39;c&#39;, &#39;e&#39;, 5], [&#39;c&#39;, &#39;d&#39;, 3], [&#39;b&#39;, &#39;c&#39;, 2], [&#39;z&#39;, &#39;a&#39;, 1]]
Adding an edge {&#34;x&#34;,&#34;y&#34;} with new vertices:
Vertices of graph:
[&#39;a&#39;, &#39;c&#39;, &#39;b&#39;, &#39;y&#39;, &#39;x&#39;, &#39;z&#39;]
Edges of graph:
[[&#39;a&#39;, &#39;z&#39;, 1], [&#39;a&#39;, &#39;d&#39;, 2], [&#39;c&#39;, &#39;b&#39;, 5], [&#39;c&#39;, &#39;e&#39;, 5], [&#39;c&#39;, &#39;d&#39;, 3], [&#39;b&#39;, &#39;c&#39;, 2], [&#39;y&#39;, &#39;x&#39;, 1], [&#39;x&#39;, &#39;y&#39;, 1], [&#39;z&#39;, &#39;a&#39;, 1]]
&lt;/pre&gt;

&lt;p&gt;Lets do something interesting now.&lt;/p&gt;

&lt;p&gt;We will use the above graph class for our understanding purpose. There are many Modules in python which we can use to do whatever I am going to do next,but to understand the methods we will write everything from scratch.
Lets start with an example graph which we can use for our purpose.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/MapGermanyGraph.svg/1200px-MapGermanyGraph.svg.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Frankfurt&amp;#39;&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Mannheim&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;85&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Wurzburg&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;217&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Kassel&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;173&lt;/span&gt;},
     &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Mannheim&amp;#39;&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Frankfurt&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;85&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Karlsruhe&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;},
     &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Karlsruhe&amp;#39;&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Augsburg&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;250&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Mannheim&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;80&lt;/span&gt;},
     &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Augsburg&amp;#39;&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Karlsruhe&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;250&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Munchen&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;84&lt;/span&gt;},
     &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Wurzburg&amp;#39;&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Erfurt&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;186&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Numberg&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;103&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Frankfurt&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;217&lt;/span&gt;},
     &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Erfurt&amp;#39;&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Wurzburg&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;186&lt;/span&gt;},
     &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Numberg&amp;#39;&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Wurzburg&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;103&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Stuttgart&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;183&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Munchen&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;167&lt;/span&gt;},
     &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Munchen&amp;#39;&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Numberg&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;167&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Augsburg&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;84&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Kassel&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;502&lt;/span&gt;},
     &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Kassel&amp;#39;&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Frankfurt&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;173&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Munchen&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;502&lt;/span&gt;},
     &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Stuttgart&amp;#39;&lt;/span&gt;: {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Numberg&amp;#39;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;183&lt;/span&gt;}
     }
graph &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Graph(g)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Vertices of graph:&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;vertices())
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Edges of graph:&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;edges())&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-family:courier new,monospace; background-color:#f6c6529c; color:#000000&#34;&gt;
Vertices of graph:
[&#39;Mannheim&#39;, &#39;Erfurt&#39;, &#39;Munchen&#39;, &#39;Numberg&#39;, &#39;Stuttgart&#39;, &#39;Augsburg&#39;, &#39;Kassel&#39;, &#39;Frankfurt&#39;, &#39;Wurzburg&#39;, &#39;Karlsruhe&#39;]
Edges of graph:
[[&#39;Mannheim&#39;, &#39;Frankfurt&#39;, 85], [&#39;Mannheim&#39;, &#39;Karlsruhe&#39;, 80], [&#39;Erfurt&#39;, &#39;Wurzburg&#39;, 186], [&#39;Munchen&#39;, &#39;Numberg&#39;, 167], [&#39;Munchen&#39;, &#39;Augsburg&#39;, 84], [&#39;Munchen&#39;, &#39;Kassel&#39;, 502], [&#39;Numberg&#39;, &#39;Stuttgart&#39;, 183], [&#39;Numberg&#39;, &#39;Wurzburg&#39;, 103], [&#39;Numberg&#39;, &#39;Munchen&#39;, 167], [&#39;Stuttgart&#39;, &#39;Numberg&#39;, 183], [&#39;Augsburg&#39;, &#39;Munchen&#39;, 84], [&#39;Augsburg&#39;, &#39;Karlsruhe&#39;, 250], [&#39;Kassel&#39;, &#39;Munchen&#39;, 502], [&#39;Kassel&#39;, &#39;Frankfurt&#39;, 173], [&#39;Frankfurt&#39;, &#39;Mannheim&#39;, 85], [&#39;Frankfurt&#39;, &#39;Wurzburg&#39;, 217], [&#39;Frankfurt&#39;, &#39;Kassel&#39;, 173], [&#39;Wurzburg&#39;, &#39;Numberg&#39;, 103], [&#39;Wurzburg&#39;, &#39;Erfurt&#39;, 186], [&#39;Wurzburg&#39;, &#39;Frankfurt&#39;, 217], [&#39;Karlsruhe&#39;, &#39;Mannheim&#39;, 80], [&#39;Karlsruhe&#39;, &#39;Augsburg&#39;, 250]]
&lt;/pre&gt;

&lt;p&gt;Lets say we are given a graph with the cities of Germany and respective distance between them. &lt;strong&gt;You want to find out how to go from Frankfurt (The starting node) to Munchen&lt;/strong&gt;. There might be many ways in which you can traverse the graph but you need to find how many cities you will need to visit on a minimum to go from frankfurt to Munchen)
This problem is analogous to finding out distance between nodes in an unweighted graph.&lt;/p&gt;

&lt;p&gt;The algorithm that we use here is called as &lt;strong&gt;Breadth First Search&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;min_num_edges_between_nodes&lt;/span&gt;(graph,start_node):
    distance &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    shortest_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    queue &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [start_node] &lt;span style=&#34;color:#75715e&#34;&gt;#FIFO&lt;/span&gt;
    levels &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
    levels[start_node] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; 
    shortest_paths &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
    shortest_paths[start_node] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;:&amp;#34;&lt;/span&gt;
    visited &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [start_node]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; len(queue)&lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
        start &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; queue&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pop(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
        neighbours &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; graph[start]
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; neighbour,_ &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; neighbours&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iteritems():
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; neighbour &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; visited:
                queue&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(neighbour)
                visited&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(neighbour)
                levels[neighbour] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; levels[start]&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
                shortest_paths[neighbour] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; shortest_paths[start] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;-&amp;gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; start
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; levels, shortest_paths&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;What we do in the above piece of code is create a queue and traverse it based on levels.
We start with Frankfurt as starting node.
We loop through its neighbouring cities(Menheim, Wurzburg and Kassel) and push them into the queue.
We keep track of what level they are at and also the path through which we reached them.
Since we are popping a first element of a queue we are sure we will visit cities in the order of their level.&lt;/p&gt;

&lt;p&gt;Checkout this good &lt;a href=&#34;https://medium.com/basecs/breaking-down-breadth-first-search-cebe696709d9&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;post&lt;/a&gt; about BFS to understand more about queues and BFS.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;min_num_edges_between_nodes(g,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Frankfurt&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-family:courier new,monospace; background-color:#f6c6529c; color:#000000&#34;&gt;
  ({&#39;Augsburg&#39;: 3,
  &#39;Erfurt&#39;: 2,
  &#39;Frankfurt&#39;: 0,
  &#39;Karlsruhe&#39;: 2,
  &#39;Kassel&#39;: 1,
  &#39;Mannheim&#39;: 1,
  &#39;Munchen&#39;: 2,
  &#39;Numberg&#39;: 2,
  &#39;Stuttgart&#39;: 3,
  &#39;Wurzburg&#39;: 1},
 {&#39;Augsburg&#39;: &#39;:-&gt;Frankfurt-&gt;Mannheim-&gt;Karlsruhe&#39;,
  &#39;Erfurt&#39;: &#39;:-&gt;Frankfurt-&gt;Wurzburg&#39;,
  &#39;Frankfurt&#39;: &#39;:&#39;,
  &#39;Karlsruhe&#39;: &#39;:-&gt;Frankfurt-&gt;Mannheim&#39;,
  &#39;Kassel&#39;: &#39;:-&gt;Frankfurt&#39;,
  &#39;Mannheim&#39;: &#39;:-&gt;Frankfurt&#39;,
  &#39;Munchen&#39;: &#39;:-&gt;Frankfurt-&gt;Kassel&#39;,
  &#39;Numberg&#39;: &#39;:-&gt;Frankfurt-&gt;Wurzburg&#39;,
  &#39;Stuttgart&#39;: &#39;:-&gt;Frankfurt-&gt;Wurzburg-&gt;Numberg&#39;,
  &#39;Wurzburg&#39;: &#39;:-&gt;Frankfurt&#39;})
&lt;/pre&gt;

&lt;p&gt;I did this example to show how  BFS algorithm works.
We can extend this algorithm to find out connected components in an unconnected graph.
Lets say we need to find groups of unconnected vertices in the graph.&lt;/p&gt;

&lt;p&gt;For example: the below graph has 3 unconnected sub-graphs. Can we find what nodes belong to a particular subgraph?&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/8/85/Pseudoforest.svg&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#We add another countries in the loop &lt;/span&gt;
graph &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Graph(g)
graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_edge((&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Mumbai&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Delhi&amp;#34;&lt;/span&gt;),&lt;span style=&#34;color:#ae81ff&#34;&gt;400&lt;/span&gt;)
graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_edge((&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Delhi&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Kolkata&amp;#34;&lt;/span&gt;),&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;)
graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_edge((&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Kolkata&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Bangalore&amp;#34;&lt;/span&gt;),&lt;span style=&#34;color:#ae81ff&#34;&gt;600&lt;/span&gt;)
graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_edge((&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;TX&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;NY&amp;#34;&lt;/span&gt;),&lt;span style=&#34;color:#ae81ff&#34;&gt;1200&lt;/span&gt;)
graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_edge((&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ALB&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;NY&amp;#34;&lt;/span&gt;),&lt;span style=&#34;color:#ae81ff&#34;&gt;800&lt;/span&gt;)

g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;adj_mat()

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;bfs_connected_components&lt;/span&gt;(graph):
    connected_components &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    nodes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; graph&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keys()

    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; len(nodes)&lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
        start_node &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nodes&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pop()
        queue &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [start_node] &lt;span style=&#34;color:#75715e&#34;&gt;#FIFO&lt;/span&gt;
        visited &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [start_node]
        &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; len(queue)&lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
            start &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; queue[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
            queue&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;remove(start)
            neighbours &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; graph[start]
            &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; neighbour,_ &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; neighbours&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iteritems():
                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; neighbour &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; visited:
                    queue&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(neighbour)
                    visited&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(neighbour)
                    nodes&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;remove(neighbour)
        connected_components&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(visited)
        
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; connected_components

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; bfs_connected_components(g)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The above code is similar to the previous BFS code. We keep all the vertices of the graph in the nodes list. We take a node from the nodes list and start BFS on it. as we visit a node we remove that node from the nodes list. Whenever the BFS completes we start again with another node in the nodes list until the nodes list is empty.&lt;/p&gt;

&lt;pre style=&#34;font-family:courier new,monospace; background-color:#f6c6529c; color:#000000&#34;&gt;[[&#39;Kassel&#39;,
  &#39;Munchen&#39;,
  &#39;Frankfurt&#39;,
  &#39;Numberg&#39;,
  &#39;Augsburg&#39;,
  &#39;Mannheim&#39;,
  &#39;Wurzburg&#39;,
  &#39;Stuttgart&#39;,
  &#39;Karlsruhe&#39;,
  &#39;Erfurt&#39;],
 [&#39;Bangalore&#39;, &#39;Kolkata&#39;, &#39;Delhi&#39;, &#39;Mumbai&#39;],
 [&#39;NY&#39;, &#39;ALB&#39;, &#39;TX&#39;]]
&lt;/pre&gt;

&lt;p&gt;As you can see we are able to find distinct components in our data. Just by using Edges and Vertices. This algorithm could be run on different data to satisfy any use case I presented above.&lt;/p&gt;

&lt;p&gt;But Normally using Connected Components for a retail case will involve a lot of data and you will need to scale this algorithm.&lt;/p&gt;

&lt;h2 id=&#34;connected-components-in-pyspark&#34;&gt;Connected Components in PySpark&lt;/h2&gt;

&lt;p&gt;Below is an implementation from this paper on &lt;a href=&#34;https://ai.google/research/pubs/pub43122&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Connected Components in
MapReduce and Beyond&lt;/a&gt; from Google Research. Read the PPT to understand the implementation better.
Some ready to use code for you.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;create_edges&lt;/span&gt;(line):
    a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [int(x) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; line&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;)]
    edges_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[]

    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(a)&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; ,len(a)):
            edges_list&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append((a[i],a[j]))
            edges_list&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append((a[j],a[i]))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; edges_list

&lt;span style=&#34;color:#75715e&#34;&gt;# adj_list.txt is a txt file containing adjacency list of the graph.&lt;/span&gt;
adjacency_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;textFile(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;adj_list.txt&amp;#34;&lt;/span&gt;)

edges_rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; adjacency_list&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatMap(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; line : create_edges(line))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distinct()

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;largeStarInit&lt;/span&gt;(record):
    a, b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; record
    &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; (a,b)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; (b,a)

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;largeStar&lt;/span&gt;(record):
    a, b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; record
    t_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(b)
    t_list&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(a)
    list_min &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; min(t_list)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; b:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; x:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; (x,list_min)

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;smallStarInit&lt;/span&gt;(record):
    a, b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; record
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; b&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt;a:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; (a,b)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; (b,a)

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;smallStar&lt;/span&gt;(record):
    a, b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; record
    t_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(b)
    t_list&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(a)
    list_min &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; min(t_list)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; t_list:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt;list_min:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; (x,list_min)

&lt;span style=&#34;color:#75715e&#34;&gt;#Handle case for single nodes&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;single_vertex&lt;/span&gt;(line):
    a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [int(x) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; line&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;)]
    edges_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(a)&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
        edges_list&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append((a[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],a[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; edges_list

iteration_num &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; 
&lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; iteration_num&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;iter&amp;#34;&lt;/span&gt;, iteration_num
        large_star_rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; edges_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupByKey()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatMap(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x : largeStar(x))
        small_star_rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; large_star_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatMap(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x : smallStarInit(x))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupByKey()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatMap(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x : smallStar(x))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distinct()
        iteration_num &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
        
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;iter&amp;#34;&lt;/span&gt;, iteration_num
        large_star_rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; small_star_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatMap(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: largeStarInit(x))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupByKey()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatMap(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x : largeStar(x))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distinct()
        small_star_rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; large_star_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatMap(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x : smallStarInit(x))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupByKey()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatMap(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x : smallStar(x))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distinct()
        iteration_num &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;#check Convergence&lt;/span&gt;

    changes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (large_star_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subtract(small_star_rdd)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;union(small_star_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subtract(large_star_rdd)))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;collect()
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(changes) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; :
        &lt;span style=&#34;color:#66d9ef&#34;&gt;break&lt;/span&gt;

single_vertex_rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; adjacency_list&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatMap(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; line : single_vertex(line))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distinct()

answer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; single_vertex_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;collect() &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; large_star_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;collect()

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; answer[:&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;or-use-graphframes-in-pyspark&#34;&gt;Or Use GraphFrames in PySpark&lt;/h2&gt;

&lt;p&gt;To Install graphframes:&lt;/p&gt;

&lt;p&gt;I ran on command line: pyspark &amp;ndash;packages graphframes:graphframes:0.5.0-spark2.1-s_2.11 which opened up my notebook and installed graphframes after i try to import in my notebook.&lt;/p&gt;

&lt;p&gt;The string to be formatted as : graphframes:(latest version)-spark(your spark version)-s_(your scala version).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Checkout&lt;/em&gt; &lt;a href=&#34;http://go.databricks.com/hubfs/notebooks/3-GraphFrames-User-Guide-python.html&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;this guide on how to use GraphFrames&lt;/a&gt; for more information.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; graphframes &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vertices&lt;/span&gt;(line):
    vert &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [int(x) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; line&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;)]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; vert

vertices &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; adjacency_list&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatMap(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: vertices(x))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distinct()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;collect()
vertices &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sqlContext&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;createDataFrame([[x] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; vertices], [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;id&amp;#34;&lt;/span&gt;])

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;create_edges&lt;/span&gt;(line):
    a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [int(x) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; line&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;)]
    edges_list&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(a)&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:
        edges_list&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append((a[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],a[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(a)&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; ,len(a)):
            edges_list&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append((a[i],a[j]))
            edges_list&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append((a[j],a[i]))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; edges_list

edges &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; adjacency_list&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatMap(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: create_edges(x))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distinct()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;collect()
edges &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sqlContext&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;createDataFrame(edges, [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;src&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;dst&amp;#34;&lt;/span&gt;])

g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GraphFrame(vertices, edges)
sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;setCheckpointDir(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;.&amp;#34;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# graphframes uses the same paper we referenced apparently&lt;/span&gt;
cc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;connectedComponents()
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; cc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The GraphFrames library implements the CC algorithm as well as a variety of other graph algorithms.&lt;/p&gt;

&lt;p&gt;The above post was a lot of code but hope it was helpful. It took me a lot of time to implement the algorithm so wanted to make it easy for the folks.&lt;/p&gt;

&lt;p&gt;If you want to read up more on Graph Algorithms here is an &lt;a href=&#34;https://www.coursera.org/learn/big-data-graph-analytics?ranMID=40328&amp;amp;ranEAID=lVarvwc5BD0&amp;amp;ranSiteID=lVarvwc5BD0-uD3tAFL0mCUdzcfwDd6FTQ&amp;amp;siteID=lVarvwc5BD0-uD3tAFL0mCUdzcfwDd6FTQ&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Graph Analytics for Big Data course on Coursera by UCSanDiego&lt;/a&gt; which I highly recommend to learn the basics of graph theory.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.python-course.eu/graphs_python.php&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Graphs in Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/basecs/a-gentle-introduction-to-graph-theory-77969829ead8&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;A Gentle Intoduction to Graph Theory Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/learn/big-data-graph-analytics?ranMID=40328&amp;amp;ranEAID=lVarvwc5BD0&amp;amp;ranSiteID=lVarvwc5BD0-uD3tAFL0mCUdzcfwDd6FTQ&amp;amp;siteID=lVarvwc5BD0-uD3tAFL0mCUdzcfwDd6FTQ&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Graph Analytics for Big Data course on Coursera by UCSanDiego&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Object Detection: An End to End Theoretical Perspective</title>
      <link>https://mlwhiz.com/blog/2018/09/22/object_detection/</link>
      <pubDate>Sat, 22 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2018/09/22/object_detection/</guid>
      <description>

&lt;p&gt;We all know about the image classification problem. Given an image can you find out the class the image belongs to? We can solve any new image classification problem with ConvNets and &lt;a href=&#34;https://medium.com/@14prakash/transfer-learning-using-keras-d804b2e04ef8&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Transfer Learning&lt;/a&gt; using pre-trained nets.
&lt;br&gt;
&lt;div style=&#34;color:black; background-color: #E9DAEE;&#34;&gt;
ConvNet as fixed feature extractor. Take a ConvNet pretrained on ImageNet, remove the last fully-connected layer (this layer&amp;rsquo;s outputs are the 1000 class scores for a different task like ImageNet), then treat the rest of the ConvNet as a fixed feature extractor for the new dataset. In an AlexNet, this would compute a 4096-D vector for every image that contains the activations of the hidden layer immediately before the classifier. We call these features CNN codes. It is important for performance that these codes are ReLUd (i.e. thresholded at zero) if they were also thresholded during the training of the ConvNet on ImageNet (as is usually the case). Once you extract the 4096-D codes for all images, train a linear classifier (e.g. Linear SVM or Softmax classifier) for the new dataset.
&lt;/div&gt;
&lt;br&gt;&lt;/p&gt;

&lt;p&gt;As a side note: if you want to know more about convnets and Transfer Learning I would like to recommend this awesome course on &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Deep Learning in Computer Vision&lt;/a&gt; in the &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Advanced machine learning specialization&lt;/a&gt;. You can start for free with the 7-day Free Trial. This course talks about various CNN architetures and covers a wide variety of problems in the image domain including detection and segmentation.&lt;/p&gt;

&lt;p&gt;But there are a lot many interesting problems in the Image domain. The one which we are going to focus on today is the Segmentation, Localization and Detection problem.
So what are these problems?&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/id1.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;So these problems are divided into 4 major buckets. In the next few lines I would try to explain each of these problems concisely before we take a deeper dive:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Semantic Segmentation: Given an image, can we classify each pixel as belonging to a particular class?&lt;/li&gt;
&lt;li&gt;Classification+Localization: We were able to classify an image as a cat. Great. Can we also get the location of the said cat in that image by drawing a bounding box around the cat? Here we assume that there is a fixed number(commonly 1) in the image.&lt;/li&gt;
&lt;li&gt;Object Detection: A More general case of the Classification+Localization problem. In a real-world setting, we don&amp;rsquo;t know how many objects are in the image beforehand. So can we detect all the objects in the image and draw bounding boxes around them?&lt;/li&gt;
&lt;li&gt;Instance Segmentation: Can we create masks for each individual object in the image? It is different from semantic segmentation. How? If you look in the 4th image on the top, we won&amp;rsquo;t be able to distinguish between the two dogs using semantic segmentation procedure as it would sort of merge both the dogs together.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In this post, we will focus mainly on Object Detection.&lt;/p&gt;

&lt;h2 id=&#34;classification-localization&#34;&gt;Classification+Localization&lt;/h2&gt;

&lt;p&gt;So lets first try to understand how we can solve the problem when we have a single object in the image. The Classification+Localization case. Pretty neatly said in the CS231n notes:&lt;/p&gt;

&lt;div style=&#34;color:black; background-color: #E9DAEE;&#34;&gt;
Treat localization as a regression problem!
&lt;/div&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/id2.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Input Data:&lt;/strong&gt; Lets first talk about what sort of data such sort of model expects. Normally in an image classification setting we used to have data in the form (X,y) where X is the image and y used to be the class labels.
In the Classification+Localization setting we will have data normally in the form (X,y), where X is still the image and y is a array containing (class_label, x,y,w,h) where,&lt;/p&gt;

&lt;p&gt;x = bounding box top left corner x-coordinate&lt;/p&gt;

&lt;p&gt;y = bounding box top left corner y-coordinate&lt;/p&gt;

&lt;p&gt;w = width of bounding box in pixel&lt;/p&gt;

&lt;p&gt;h = height of bounding box in pixel&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Model:&lt;/strong&gt; So in this setting we create a multi-output model which takes an image as the input and has (n_labels + 4) output nodes. n_labels nodes for each of the output class and 4 nodes that give the predictions for (x,y,w,h).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Loss:&lt;/strong&gt; In such a setting setting up the loss is pretty important. Normally the loss is a weighted sum of the Softmax Loss(from the Classification Problem) and the regression L2 loss(from the bounding box coordinates).&lt;/p&gt;

&lt;p&gt;$$Loss = alpha*SoftmaxLoss + (1-alpha)*L2Loss$$&lt;/p&gt;

&lt;p&gt;Since these two losses would be on a different scale, the alpha hyper-parameter needs to be tuned.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;There is one thing I would like to note here. We are trying to do object localization task but we still have our convnets in place here. We are just adding one more output layer to also predict the coordinates of the bounding box and tweaking our loss function. And here in lies the essence of the whole Deep Learning framework - Stack layers on top of each other, reuse components to create better models, and create architectures to solve your own problem. And that is what we are going to see a lot going forward.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;object-detection&#34;&gt;Object Detection&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;So how does this idea of localization using regression get mapped to Object Detection?&lt;/em&gt; It doesn&amp;rsquo;t. We don&amp;rsquo;t have a fixed number of objects. So we can&amp;rsquo;t have 4 outputs denoting, the bounding box coordinates.&lt;/p&gt;

&lt;p&gt;One naive idea could be to apply a CNN to many different crops of the image, CNN classifies each crop as object class or background class. This is intractable. There could be a lot of such crops that you can create.&lt;/p&gt;

&lt;h3 id=&#34;region-proposals&#34;&gt;Region Proposals:&lt;/h3&gt;

&lt;p&gt;If just there was a method(Normally called Region Proposal Network)which could find some cropped regions for us automatically, we could just run our convnet on those regions and be done with object detection. And that is what selective search (Uijlings et al, &amp;ldquo;&lt;a href=&#34;https://medium.com/r/?url=http%3A%2F%2Fwww.huppelen.nl%2Fpublications%2FselectiveSearchDraft.pdf&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Selective Search for Object Recognition&lt;/a&gt;&amp;rdquo;, IJCV 2013) provided for RCNN.&lt;/p&gt;

&lt;p&gt;So what are Region Proposals:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Find &lt;em&gt;&amp;ldquo;blobby&amp;rdquo;&lt;/em&gt; image regions that are likely to contain objects&lt;/li&gt;
&lt;li&gt;Relatively fast to run; e.g. Selective Search gives 2000 region proposals in a few seconds on CPU&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;How the region proposals are being made?&lt;/p&gt;

&lt;h3 id=&#34;selective-search-for-object-recognition&#34;&gt;Selective Search for Object Recognition:&lt;/h3&gt;

&lt;p&gt;So this paper starts with a set of some initial regions using &lt;a href=&#34;P. F. Felzenszwalb and D. P. Huttenlocher. [Efficient GraphBased Image Segmentation](https://medium.com/r/?url=http%3A%2F%2Fpeople.cs.uchicago.edu%2F~pff%2Fpapers%2Fseg-ijcv.pdf). IJCV, 59:167–181, 2004. 1, 3, 4, 5, 7&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;13&lt;/a&gt;
&lt;br&gt;
&lt;div style=&#34;color:black; background-color: #E9DAEE;&#34;&gt;
Graph-based image segmentation techniques generally represent the problem in terms of a graph G = (V, E) where each node v ∈ V corresponds to a pixel in the image, and the edges in E connect certain pairs of neighboring pixels. A weight is associated with each edge based on some property of the pixels that it connects, such as their image intensities. Depending on the method, there may or may not be an edge connecting each pair of vertices.
&lt;/div&gt;
&lt;br&gt;
In this paper they take an approach:
&lt;br&gt;
&lt;div style=&#34;color:black; background-color: #E9DAEE;&#34;&gt;
Each edge (vi , vj )∈ E has a corresponding weight w((vi , vj )), which is a non-negative measure of the dissimilarity between neighboring elements vi and vj . In the case of image segmentation, the elements in V are pixels and the weight of an edge is some measure of the dissimilarity between the two pixels connected by that edge (e.g., the difference in intensity, color, motion, location or some other local attribute). In the graph-based approach, a segmentation S is a partition of V into components such that each component (or region) C ∈ S corresponds to a connected component in a graph.
&lt;/div&gt;
&lt;br&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/id3.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;As you can see if we create bounding boxes around these masks we will be losing a lot of regions. We want to have the whole baseball player in a single bounding box/frame. We need to somehow group these initial regions.
For that the authors of &lt;a href=&#34;https://medium.com/r/?url=http%3A%2F%2Fwww.huppelen.nl%2Fpublications%2FselectiveSearchDraft.pdf&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Selective Search for Object Recognition&lt;/a&gt; apply the Hierarchical Grouping algorithm to these initial regions. In this algorithm they merge most similar regions together based on different notions of similarity based on colour, texture, size and fill.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/id5.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/id6.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h2 id=&#34;rcnn&#34;&gt;RCNN&lt;/h2&gt;

&lt;p&gt;The above selective search is the region proposal they used in RCNN paper. But what is RCNN and how does it use region proposals?&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/id7.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;div style=&#34;color:black; background-color: #E9DAEE;&#34;&gt;
Object detection system overview. Our system
(1) takes an input image, (2) extracts around 2000 bottom-up region proposals, (3) computes features for each proposal using a large convolutional neural network (CNN), and then (4) classifies each region using class-specific linear SVM.
&lt;/div&gt;
&lt;br&gt;
Along with this, the authors have also used a class specific bounding box regressor, that takes:
Input : (Px,Py,Ph,Pw) - the location of the proposed region.
Target: (Gx,Gy,Gh,Gw) - Ground truth labels for the region.
The goal is to learn a transformation that maps the proposed region(P) to the Ground truth box(G)

### Training RCNN

What is the input to an RCNN?
So we have got an image, Region Proposals from the RPN strategy and the ground truths of the labels (labels, ground truth boxes)
Next we treat all region proposals with ≥ 0.5 IoU(Intersection over union) overlap with a ground-truth box as positive training example for that box&#39;s class and the rest as negative. We train class specific SVM&#39;s

So every region proposal becomes a training example. and the convnet gives a feature vector for that region proposal. We can then train our n-SVMs using the class specific data.

### Test Time RCNN

At test time we predict detection boxes using class specific SVMs. We will be getting a lot of overlapping detection boxes at the time of testing. Non-maximum suppression is an integral part of the object detection pipeline. First, it sorts all detection boxes on the basis of their scores. The detection box M with the maximum score is selected and all other detection boxes with a significant overlap (using a pre-defined threshold) with M are suppressed. This process is recursively applied on the remaining boxes

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/id8.jpeg&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h3 id=&#34;problems-with-rcnn&#34;&gt;Problems with RCNN:&lt;/h3&gt;

&lt;p&gt;Training is slow.
Inference (detection) is slow. 47s / image with VGG16 - Since the Convnet needs to be run many times.&lt;/p&gt;

&lt;p&gt;Need for speed. Hence comes in picture by the same authors:&lt;/p&gt;

&lt;h2 id=&#34;fast-rcnn&#34;&gt;Fast RCNN&lt;/h2&gt;

&lt;div style=&#34;color:black; background-color: #E9DAEE;&#34;&gt;
So the next idea from the same authors: Why not create convolution map of input image and then just select the regions from that convolutional map? Do we really need to run so many convnets? What we can do is run just a single convnet and then apply region proposal crops on the features calculated by the convnet and use a simple SVM to classify those crops.
&lt;/div&gt;
&lt;br&gt;
Something like:

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/id9.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;div style=&#34;color:black; background-color: #E9DAEE;&#34;&gt;
From Paper: Fig. illustrates the Fast R-CNN architecture. A Fast R-CNN network takes as input an entire image and a set of object proposals. The network first processes the whole image with several convolutional (conv) and max pooling layers to produce a conv feature map. Then, for each object proposal a region of interest (RoI) pooling layer extracts a fixed-length feature vector from the feature map. Each feature vector is fed into a sequence of fully connected (fc) layers that finally branch into two sibling output layers: one that produces softmax probability estimates over K object classes plus a catch-all &#34;background&#34; class and another layer that outputs four real-valued numbers for each of the K object classes. Each set of 4 values encodes refined bounding-box positions for one of the K classes.
&lt;/div&gt;
&lt;br&gt;
This idea depends a little upon the architecture of the model that get used too. Do we take the 4096 bottleneck layer from VGG16?
So the architecture that the authors have proposed is:

&lt;div style=&#34;color:black; background-color: #E9DAEE;&#34;&gt;
We experiment with three pre-trained ImageNet [4] networks, each with five max pooling layers and between five and thirteen conv layers (see Section 4.1 for network details). When a pre-trained network initializes a Fast R-CNN network, it undergoes three transformations. First, the last max pooling layer is replaced by a RoI pooling layer that is configured by setting H and W to be compatible with the net&#39;s first fully connected layer (e.g., H = W = 7 for VGG16). Second, the network&#39;s last fully connected layer and softmax (which were trained for 1000-way ImageNet classification) are replaced with the two sibling layers described earlier (a fully connected layer and softmax over K + 1 categories and category-specific bounding-box regressors). Third, the network is modified to take two data inputs: a list of images and a list of RoIs in those images.
&lt;/div&gt;
&lt;br&gt;
This obviously is a little confusing and &#34;hairy&#34;, let us break this down. But for that, we need to see the VGG16 architecture.

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/id10.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;The last pooling layer is 7x7x512. This is the layer the network authors intend to replace by the ROI pooling layers. This pooling layer has got as input the location of the region proposal(xmin_roi,ymin_roi,h_roi,w_roi) and the previous feature map(14x14x512).&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/id11.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Now the location of ROI coordinates are in the units of the input image i.e. 224x224 pixels. But the layer on which we have to apply the ROI pooling operation is 14x14x512. As we are using VGG we will transform image (224 x 224 x 3) into (14 x 14 x 512) - height and width is divided by 16. we can map ROIs coordinates onto the feature map just by dividing them by 16.&lt;/p&gt;

&lt;div style=&#34;color:black; background-color: #E9DAEE;&#34;&gt;
In its depth, the convolutional feature map has encoded all the information for the image while maintaining the location of the &#34;things&#34; it has encoded relative to the original image. For example, if there was a red square on the top left of the image and the convolutional layers activate for it, then the information for that red square would still be on the top left of the convolutional feature map.
&lt;/div&gt;
&lt;br&gt;
How the ROI pooling is done?

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/id12.gif&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;In the above image our region proposal is (0,3,5,7) and we divide that area into 4 regions since we want to have a ROI pooling layer of 2x2.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/r/?url=https%3A%2F%2Fstackoverflow.com%2Fquestions%2F48163961%2Fhow-do-you-do-roi-pooling-on-areas-smaller-than-the-target-size&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;How do you do ROI-Pooling on Areas smaller than the target size?&lt;/a&gt; if region proposal size is 5x5 and ROI pooling layer of size 7x7. If this happens, we resize to 35x35 just by copying 7 times each cell and then max-pooling back to 7x7.&lt;/p&gt;

&lt;p&gt;After replacing the pooling layer, the authors also replaced the 1000 layer imagenet classification layer by a fully connected layer and softmax over K + 1 categories(+1 for Background) and category-specific bounding-box regressors.&lt;/p&gt;

&lt;h3 id=&#34;training-fast-rcnn&#34;&gt;Training Fast-RCNN&lt;/h3&gt;

&lt;p&gt;What is the input to an Fast- RCNN?&lt;/p&gt;

&lt;p&gt;Pretty much similar: So we have got an image, Region Proposals from the RPN strategy and the ground truths of the labels (labels, ground truth boxes)&lt;/p&gt;

&lt;p&gt;Next we treat all region proposals with ≥ 0.5 IoU(Intersection over union) overlap with a ground-truth box as positive training example for that box&amp;rsquo;s class and the rest as negative. This time we have a dense layer on top, and we use multi task loss.&lt;/p&gt;

&lt;p&gt;So every ROI becomes a training example. The main difference is that there is concept of multi-task loss:&lt;/p&gt;

&lt;p&gt;A Fast R-CNN network has two sibling output layers. The first outputs a discrete probability distribution (per RoI), p = (p0, . . . , pK), over K + 1 categories. As usual, p is computed by a softmax over the K+1 outputs of a fully connected layer. The second sibling layer outputs bounding-box regression offsets, t= (tx , ty , tw, th), for each of the K object classes. Each training RoI is labeled with a ground-truth class u and a ground-truth bounding-box regression target v. We use a multi-task loss L on each labeled RoI to jointly train for classification and bounding-box regression&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/id13.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Where Lcls is the softmax classification loss and Lloc is the regression loss. u=0 is for BG class and hence we add to loss only when we have a boundary box for any of the other class. Further:&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/id14.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h3 id=&#34;problem&#34;&gt;Problem:&lt;/h3&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/id15.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h2 id=&#34;faster-rcnn&#34;&gt;Faster-RCNN&lt;/h2&gt;

&lt;p&gt;The next question that got asked was : Can the network itself do region proposals?&lt;/p&gt;

&lt;div style=&#34;color:black; background-color: #E9DAEE;&#34;&gt;
The intuition is that: With FastRCNN we&#39;re already computing an Activation Map in the CNN, why not run the Activation Map through a few more layers to find the interesting regions, and then finish off the forward pass by predicting the classes + bbox coordinates?
&lt;/div&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/id16.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h3 id=&#34;how-does-the-region-proposal-network-work&#34;&gt;How does the Region Proposal Network work?&lt;/h3&gt;

&lt;p&gt;One of the main idea in the paper is the idea of Anchors. Anchors are fixed bounding boxes that are placed throughout the image with different sizes and ratios that are going to be used for reference when first predicting object locations.&lt;/p&gt;

&lt;p&gt;So first of all we define anchor centers on the image.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/id17.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;The anchor centers are separated by 16 px in case of VGG16 network as the final convolution layer of (14x14x512) subsamples the image by a factor of 16(&lt;sup&gt;224&lt;/sup&gt;&amp;frasl;&lt;sub&gt;14&lt;/sub&gt;).
This is how anchors look like:&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/id18.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;So we start with some predefined regions we think our objects could be with Anchors.&lt;/li&gt;
&lt;li&gt;Our RPN Classifies which regions have the object and the offset of the object bounding box. 1 if IOU for anchor with bounding box&amp;gt;0.5 0 otherwise.&lt;/li&gt;
&lt;li&gt;Non-Maximum suppression to reduce region proposals&lt;/li&gt;
&lt;li&gt;Fast RCNN detection network on top of proposals&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;faster-rcnn-loss&#34;&gt;Faster-RCNN Loss:&lt;/h3&gt;

&lt;hr /&gt;

&lt;p&gt;The whole network is then jointly trained with 4 losses:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;RPN classify object / not object&lt;/li&gt;
&lt;li&gt;RPN regress box coordinates offset&lt;/li&gt;
&lt;li&gt;Final classification score (object classes)&lt;/li&gt;
&lt;li&gt;Final box coordinates offset&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;results&#34;&gt;Results:&lt;/h2&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/id19.jpeg&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Disclaimer:&lt;/strong&gt; &lt;em&gt;This is my own understanding of these papers with inputs from many blogs and slides on the internet. Let me know if you find something wrong with my understanding. I will be sure to correct myself and post.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References:&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://cs231n.github.io/transfer-learning/#tf&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Transfer Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture11.pdf&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;CS231 Object detection Lecture Slides&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://people.cs.uchicago.edu/~pff/papers/seg-ijcv.pdf&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Efficient Graph-Based Image Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1311.2524.pdf&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Rich feature hierarchies for accurate object detection and semantic segmentation(RCNN Paper)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/r/?url=http%3A%2F%2Fwww.huppelen.nl%2Fpublications%2FselectiveSearchDraft.pdf&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Selective Search for Object Recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://deepsense.ai/region-of-interest-pooling-explained/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;ROI Pooling Explanation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/fasterrcnn-explained-part-1-with-code-599c16568cff&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Faster RCNN Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/48163961/how-do-you-do-roi-pooling-on-areas-smaller-than-the-target-size&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;StackOverflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/@smallfishbigsea/faster-r-cnn-explained-864d4fb7e3f8&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Faster RCNN Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tryolabs.com/blog/2018/01/18/faster-r-cnn-down-the-rabbit-hole-of-modern-object-detection/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Faster RCNN Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/r/?url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.01497.pdf&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.slideshare.net/WenjingChen7/deep-learning-for-object-detection&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;https://www.slideshare.net/WenjingChen7/deep-learning-for-object-detection&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Hyperopt - A bayesian Parameter Tuning Framework</title>
      <link>https://mlwhiz.com/blog/2017/12/28/hyperopt_tuning_ml_model/</link>
      <pubDate>Thu, 28 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2017/12/28/hyperopt_tuning_ml_model/</guid>
      <description>

&lt;p&gt;Recently I was working on a in-class competition from the &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-BShznKdc3CUauhfsM7_8xw&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;How to win a data science competition&amp;rdquo;&lt;/a&gt; Coursera course. You can start for free with the 7-day Free Trial. Learned a lot of new things from that about using &lt;a href=&#34;https://mlwhiz.com/blog/2017/12/26/how_to_win_a_data_science_competition/&#34;&gt;XGBoost for time series prediction&lt;/a&gt; tasks.&lt;/p&gt;

&lt;p&gt;The one thing that I tried out in this competition was the Hyperopt package - A bayesian Parameter Tuning Framework. And I was literally amazed. Left the machine with hyperopt in the night. And in the morning I had my results. It was really awesome and I did avoid a lot of hit and trial.&lt;/p&gt;

&lt;h2 id=&#34;what-really-is-hyperopt&#34;&gt;What really is Hyperopt?&lt;/h2&gt;

&lt;p&gt;From the site:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hyperopt is a Python library for serial and parallel optimization over awkward search spaces, which may include real-valued, discrete, and conditional dimensions.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;What the above means is that it is a optimizer that could minimize/maximize the loss function/accuracy(or whatever metric) for you.&lt;/p&gt;

&lt;p&gt;All of us are fairly known to cross-grid search or random-grid search. Hyperopt takes as an input a space of hyperparams in which it will search, and moves according to the result of past trials.&lt;/p&gt;

&lt;p&gt;To know more about how it does this, take a look at this &lt;a href=&#34;https://conference.scipy.org/proceedings/scipy2013/pdfs/bergstra_hyperopt.pdf&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt; by J Bergstra.
Here is the &lt;a href=&#34;https://github.com/hyperopt/hyperopt/wiki/FMin&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;documentation&lt;/a&gt; from github.&lt;/p&gt;

&lt;h2 id=&#34;how&#34;&gt;How?&lt;/h2&gt;

&lt;p&gt;Let me just put the code first. This is how I define the objective function. The objective function takes space(the hyperparam space) as the input and returns the loss(The thing you want to minimize.Or negative of the thing you want to maximize)&lt;/p&gt;

&lt;p&gt;(X,y) and (Xcv,ycv) are the train and cross validation dataframes respectively.&lt;/p&gt;

&lt;p&gt;We have defined a hyperparam space by using the variable &lt;code&gt;space&lt;/code&gt; which is actually just a dictionary. We could choose different distributions for different parameter values.&lt;/p&gt;

&lt;p&gt;We use the &lt;code&gt;fmin&lt;/code&gt; function from the hyperopt package to minimize our &lt;code&gt;fn&lt;/code&gt; through the &lt;code&gt;space&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.metrics &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; mean_squared_error
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; xgboost &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; xgb
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; hyperopt &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; hp, fmin, tpe, STATUS_OK, Trials
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;objective&lt;/span&gt;(space):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(space)
    clf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; xgb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;XGBRegressor(n_estimators &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;,colsample_bytree&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;space[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;colsample_bytree&amp;#39;&lt;/span&gt;],
                           learning_rate &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,
                            max_depth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(space[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;max_depth&amp;#39;&lt;/span&gt;]),
                            min_child_weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; space[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;min_child_weight&amp;#39;&lt;/span&gt;],
                            subsample &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; space[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;subsample&amp;#39;&lt;/span&gt;],
                           gamma &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; space[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gamma&amp;#39;&lt;/span&gt;],
                           reg_lambda &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; space[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;reg_lambda&amp;#39;&lt;/span&gt;],)

    eval_set  &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [( X, y), ( Xcv, ycv)]

    clf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(X, y,
            eval_set&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;eval_set, eval_metric&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rmse&amp;#34;&lt;/span&gt;,
            early_stopping_rounds&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;,verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)

    pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; clf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(Xcv)
    mse_scr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; mean_squared_error(ycv, pred)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SCORE:&amp;#34;&lt;/span&gt;, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(mse_scr)
    &lt;span style=&#34;color:#75715e&#34;&gt;#change the metric if you like&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;:mse_scr, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;status&amp;#39;&lt;/span&gt;: STATUS_OK }


space &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;max_depth&amp;#39;&lt;/span&gt;: hp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;quniform(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;x_max_depth&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;min_child_weight&amp;#39;&lt;/span&gt;: hp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;quniform (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;x_min_child&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;subsample&amp;#39;&lt;/span&gt;: hp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;x_subsample&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gamma&amp;#39;&lt;/span&gt; : hp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;x_gamma&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;),
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;colsample_bytree&amp;#39;&lt;/span&gt; : hp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;x_colsample_bytree&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;reg_lambda&amp;#39;&lt;/span&gt; : hp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;x_reg_lambda&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    }


trials &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Trials()
best &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fmin(fn&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;objective,
            space&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;space,
            algo&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tpe&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;suggest,
            max_evals&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;,
            trials&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;trials)

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; best&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;finally&#34;&gt;Finally:&lt;/h2&gt;

&lt;p&gt;Running the above gives us pretty good hyperparams for our learning algorithm.
In fact I bagged up the results from multiple hyperparam settings and it gave me the best score on the LB.
If you like this and would like to get more information about such things, subscribe to the mailing list on the right hand side.
Also I would definitely recommend this &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-BShznKdc3CUauhfsM7_8xw&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;course&lt;/a&gt; about winning Kaggle competitions by Kazanova, Kaggle rank 3 . Do take a look.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using XGBoost for time series prediction tasks</title>
      <link>https://mlwhiz.com/blog/2017/12/26/win_a_data_science_competition/</link>
      <pubDate>Tue, 26 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2017/12/26/win_a_data_science_competition/</guid>
      <description>

&lt;p&gt;Recently Kaggle master Kazanova along with some of his friends released a &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-BShznKdc3CUauhfsM7_8xw&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;How to win a data science competition&amp;rdquo;&lt;/a&gt; Coursera course. You can start for free with the 7-day Free Trial. The Course involved a final project which itself was a time series prediction problem. Here I will describe how I got a top 10 position as of writing this article.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/lboard.png&#34;  height=&#34;800&#34; width=&#34;600&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h2 id=&#34;description-of-the-problem&#34;&gt;Description of the Problem:&lt;/h2&gt;

&lt;p&gt;In this competition we were given a challenging time-series dataset consisting of daily sales data, kindly provided by one of the largest Russian software firms - 1C Company.&lt;/p&gt;

&lt;p&gt;We were asked you to predict total sales for every product and store in the next month.&lt;/p&gt;

&lt;p&gt;The evaluation metric was RMSE where True target values are clipped into [0,20] range. This target range will be a lot important in understanding the submissions that I will prepare.&lt;/p&gt;

&lt;p&gt;The main thing that I noticed was that the data preparation aspect of this competition was by far the most important thing. I creted a variety of features. Here are the steps I took and the features I created.&lt;/p&gt;

&lt;h2 id=&#34;1-created-a-dataframe-of-all-date-block-num-store-and-item-combinations&#34;&gt;1. Created a dataframe of all Date_block_num, Store and  Item combinations:&lt;/h2&gt;

&lt;p&gt;This is important because in the months we don&amp;rsquo;t have a data for an item store combination, the machine learning algorithm needs to be specifically told that the sales is zero.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; itertools &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; product
&lt;span style=&#34;color:#75715e&#34;&gt;# Create &amp;#34;grid&amp;#34; with columns&lt;/span&gt;
index_cols &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;shop_id&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_id&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;]

&lt;span style=&#34;color:#75715e&#34;&gt;# For every month we create a grid from all shops/items combinations from that month&lt;/span&gt;
grid &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; block_num &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sales[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unique():
    cur_shops &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[sales[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; block_num, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;shop_id&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unique()
    cur_items &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[sales[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; block_num, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_id&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unique()
    grid&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(list(product(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;[cur_shops, cur_items, [block_num]])),dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;int32&amp;#39;&lt;/span&gt;))
grid &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;vstack(grid), columns &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; index_cols,dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;2-cleaned-up-a-little-of-sales-data-after-some-basic-eda&#34;&gt;2. Cleaned up a little of sales data after some basic EDA:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;sales &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales[sales&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item_price&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100000&lt;/span&gt;]
sales &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales[sales&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item_cnt_day&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;3-created-mean-encodings&#34;&gt;3. Created Mean Encodings:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;sales_m &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;shop_id&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_id&amp;#39;&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;agg({&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_cnt_day&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sum&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_price&amp;#39;&lt;/span&gt;: np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean})&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reset_index()
sales_m &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;merge(grid,sales_m,on&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;shop_id&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_id&amp;#39;&lt;/span&gt;],how&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;left&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fillna(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# adding the category id too&lt;/span&gt;
sales_m &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;merge(sales_m,items,on&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_id&amp;#39;&lt;/span&gt;],how&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;left&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; type_id &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_id&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;shop_id&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_category_id&amp;#39;&lt;/span&gt;]:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; column_id,aggregator,aggtype &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; [(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_price&amp;#39;&lt;/span&gt;,np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;avg&amp;#39;&lt;/span&gt;),(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_cnt_day&amp;#39;&lt;/span&gt;,np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sum&amp;#39;&lt;/span&gt;),(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_cnt_day&amp;#39;&lt;/span&gt;,np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;avg&amp;#39;&lt;/span&gt;)]:

        mean_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby([type_id,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;aggregate(aggregator)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reset_index()[[column_id,type_id,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;]]
        mean_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [type_id&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;_&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;aggtype&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;_&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;column_id,type_id,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;]

        sales_m &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;merge(sales_m,mean_df,on&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;,type_id],how&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;left&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;These above lines add the following 9 features :&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;lsquo;item_id_avg_item_price&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_id_sum_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_id_avg_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;shop_id_avg_item_price&amp;rsquo;,&lt;/li&gt;
&lt;li&gt;&amp;lsquo;shop_id_sum_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;shop_id_avg_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_category_id_avg_item_price&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_category_id_sum_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_category_id_avg_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;4-create-lag-features&#34;&gt;4. Create Lag Features:&lt;/h2&gt;

&lt;p&gt;Next we create lag features with diferent lag periods on the following features:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;lsquo;item_id_avg_item_price&amp;rsquo;,&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_id_sum_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_id_avg_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;shop_id_avg_item_price&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;shop_id_sum_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;shop_id_avg_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_category_id_avg_item_price&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_category_id_sum_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_category_id_avg_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;lag_variables  &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(sales_m&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns[&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;:])&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_cnt_day&amp;#39;&lt;/span&gt;]
lags &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; ,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; ,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; ,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;]
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; lag &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; lags:
    sales_new_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales_m&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;copy()
    sales_new_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;date_block_num&lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt;lag
    sales_new_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales_new_df[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;shop_id&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_id&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;lag_variables]
    sales_new_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;shop_id&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_id&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; [lag_feat&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;_lag_&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;str(lag) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; lag_feat &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; lag_variables]
    sales_means &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;merge(sales_means, sales_new_df,on&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;shop_id&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_id&amp;#39;&lt;/span&gt;] ,how&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;left&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;5-fill-na-with-zeros&#34;&gt;5. Fill NA with zeros:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; feat &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sales_means&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_cnt&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; feat:
        sales_means[feat]&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sales_means[feat]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fillna(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_price&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; feat:
        sales_means[feat]&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sales_means[feat]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fillna(sales_means[feat]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;median())&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;6-drop-the-columns-that-we-are-not-going-to-use-in-training&#34;&gt;6. Drop the columns that we are not going to use in training:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;cols_to_drop &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lag_variables[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_name&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_price&amp;#39;&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;7-take-a-recent-bit-of-data-only&#34;&gt;7. Take a recent bit of data only:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;sales_means &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales_means[sales_means[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;8-split-in-train-and-cv&#34;&gt;8. Split in train and CV :&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;X_train &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales_means[sales_means[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;33&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(cols_to_drop, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
X_cv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  sales_means[sales_means[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;33&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(cols_to_drop, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;9-the-magic-sauce&#34;&gt;9. THE MAGIC SAUCE:&lt;/h2&gt;

&lt;p&gt;In the start I told that the clipping aspect of [0,20] will be important.
In the next few lines I clipped the days to range[0,40]. You might ask me why 40. An intuitive answer is if I had clipped to range [0,20] there would be very few tree nodes that could give 20 as an answer. While if I increase it to 40 having a 20 becomes much more easier. Please note that We will clip our predictions in the [0,20] range in the end.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clip&lt;/span&gt;(x):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;40&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;40&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x
train[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_cnt_day&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: clip(x[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_cnt_day&amp;#39;&lt;/span&gt;]),axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
cv[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_cnt_day&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: clip(x[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_cnt_day&amp;#39;&lt;/span&gt;]),axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;10-modelling&#34;&gt;10: Modelling:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Created a XGBoost model to get the most important features(Top 42 features)&lt;/li&gt;
&lt;li&gt;Use hyperopt to tune xgboost&lt;/li&gt;
&lt;li&gt;Used top 10 models from tuned XGBoosts to generate predictions.&lt;/li&gt;
&lt;li&gt;clipped the predictions to [0,20] range&lt;/li&gt;
&lt;li&gt;Final solution was the average of these 10 predictions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Learned a lot of new things from this &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-BShznKdc3CUauhfsM7_8xw&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;awesome course&lt;/a&gt;. Most recommended.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Good Feature Building Techniques - Tricks for Kaggle -  My Kaggle Code Repository</title>
      <link>https://mlwhiz.com/blog/2017/09/14/kaggle_tricks/</link>
      <pubDate>Thu, 14 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2017/09/14/kaggle_tricks/</guid>
      <description>

&lt;p&gt;Often times it happens that we fall short of creativity. And creativity is one of the basic ingredients of what we do. Creating features needs creativity. So here is the list of ideas I gather in day to day life, where people have used creativity to get great results on Kaggle leaderboards.&lt;/p&gt;

&lt;p&gt;Take a look at the &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;How to Win a Data Science Competition: Learn from Top Kagglers&lt;/a&gt; course in the &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Advanced machine learning specialization&lt;/a&gt; by Kazanova(Number 3 Kaggler at the time of writing). You can start for free with the 7-day Free Trial.&lt;/p&gt;

&lt;p&gt;This post is inspired by a &lt;a href=&#34;https://www.kaggle.com/gaborfodor/from-eda-to-the-top-lb-0-368&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Kernel&lt;/a&gt; on Kaggle written by Beluga, one of the top Kagglers, for a knowledge based &lt;a href=&#34;https://www.kaggle.com/c/nyc-taxi-trip-duration&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;competition&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Some of the techniques/tricks I am sharing have been taken directly from that kernel so you could take a look yourself.
Otherwise stay here and read on.&lt;/p&gt;

&lt;h2 id=&#34;1-don-t-try-predicting-the-future-when-you-don-t-have-to&#34;&gt;1. Don&amp;rsquo;t try predicting the future when you don&amp;rsquo;t have to:&lt;/h2&gt;

&lt;p&gt;If both training/test comes from the same timeline, we can get really crafty with features. Although this is a case with Kaggle only, we can use this to our advantage. For example: In the Taxi Trip duration challenge the test data is randomly sampled from the train data. In this case we can use the target variable averaged over different categorical variable as a feature. Like in this case Beluga actually used the averaged the target variable over different weekdays. He then mapped the same averaged value as a variable by mapping it to test data too.&lt;/p&gt;

&lt;h2 id=&#34;2-logloss-clipping-technique&#34;&gt;2. logloss clipping Technique:&lt;/h2&gt;

&lt;p&gt;Something that I learned in the Neural Network course by Jeremy Howard. Its based on a very simple Idea. Logloss penalises a lot if we are very confident and wrong. So in case of Classification problems where we have to predict probabilities, it would be much better to clip our probabilities between 0.05-0.95 so that we are never very sure about our prediction.&lt;/p&gt;

&lt;h2 id=&#34;3-kaggle-submission-in-gzip-format&#34;&gt;3. kaggle submission in gzip format:&lt;/h2&gt;

&lt;p&gt;A small piece of code that will help you save countless hours of uploading. Enjoy.
df.to_csv(&amp;lsquo;submission.csv.gz&amp;rsquo;, index=False, compression=&amp;lsquo;gzip&amp;rsquo;)&lt;/p&gt;

&lt;h2 id=&#34;4-how-best-to-use-latitude-and-longitude-features-part-1&#34;&gt;4. How best to use Latitude and Longitude features - Part 1:&lt;/h2&gt;

&lt;p&gt;One of the best things that I liked about the Beluga Kernel is how he used the Lat/Lon Data. So in the example we had pickup Lat/Lon and Dropoff Lat/Lon. We created features like:&lt;/p&gt;

&lt;h4 id=&#34;a-haversine-distance-between-the-two-lat-lons&#34;&gt;A. Haversine Distance Between the Two Lat/Lons:&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;haversine_array&lt;/span&gt;(lat1, lng1, lat2, lng2):
    lat1, lng1, lat2, lng2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; map(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;radians, (lat1, lng1, lat2, lng2))
    AVG_EARTH_RADIUS &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6371&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# in km&lt;/span&gt;
    lat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lat2 &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; lat1
    lng &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lng2 &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; lng1
    d &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(lat &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos(lat1) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos(lat2) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(lng &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
    h &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; AVG_EARTH_RADIUS &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arcsin(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(d))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; h&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&#34;b-manhattan-distance-between-the-two-lat-lons&#34;&gt;B. Manhattan Distance Between the two Lat/Lons:&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dummy_manhattan_distance&lt;/span&gt;(lat1, lng1, lat2, lng2):
    a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; haversine_array(lat1, lng1, lat1, lng2)
    b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; haversine_array(lat1, lng1, lat2, lng1)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&#34;c-bearing-between-the-two-lat-lons&#34;&gt;C. Bearing Between the two Lat/Lons:&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;bearing_array&lt;/span&gt;(lat1, lng1, lat2, lng2):
    AVG_EARTH_RADIUS &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6371&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# in km&lt;/span&gt;
    lng_delta_rad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;radians(lng2 &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; lng1)
    lat1, lng1, lat2, lng2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; map(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;radians, (lat1, lng1, lat2, lng2))
    y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(lng_delta_rad) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos(lat2)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos(lat1) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(lat2) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(lat1) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos(lat2) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos(lng_delta_rad)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;degrees(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arctan2(y, x))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&#34;d-center-latitude-and-longitude-between-pickup-and-dropoff&#34;&gt;D. Center Latitude and Longitude between Pickup and Dropoff:&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[:, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;center_latitude&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (train[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_latitude&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; train[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_latitude&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[:, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;center_longitude&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (train[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_longitude&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; train[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_longitude&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;5-how-best-to-use-latitude-and-longitude-features-part-2&#34;&gt;5. How best to use Latitude and Longitude features - Part 2:&lt;/h2&gt;

&lt;p&gt;The Second way he used the Lat/Lon Feats was to create clusters for Pickup and Dropoff Lat/Lons. The way it worked was it created sort of Boroughs in the data by design.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.cluster &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; MiniBatchKMeans
coords &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;vstack((train[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_longitude&amp;#39;&lt;/span&gt;]]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values,
                    train[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_longitude&amp;#39;&lt;/span&gt;]]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values,
                    test[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_longitude&amp;#39;&lt;/span&gt;]]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values,
                    test[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_longitude&amp;#39;&lt;/span&gt;]]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values))

sample_ind &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;permutation(len(coords))[:&lt;span style=&#34;color:#ae81ff&#34;&gt;500000&lt;/span&gt;]
kmeans &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MiniBatchKMeans(n_clusters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10000&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(coords[sample_ind])

train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[:, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_cluster&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; kmeans&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(train[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_longitude&amp;#39;&lt;/span&gt;]])
train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[:, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_cluster&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; kmeans&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(train[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_longitude&amp;#39;&lt;/span&gt;]])
test&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[:, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_cluster&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; kmeans&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(test[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_longitude&amp;#39;&lt;/span&gt;]])
test&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[:, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_cluster&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; kmeans&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(test[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_longitude&amp;#39;&lt;/span&gt;]])&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;He then used these Clusters to create features like counting no of trips going out and coming in on a particular day.&lt;/p&gt;

&lt;h2 id=&#34;6-how-best-to-use-latitude-and-longitude-features-part-3&#34;&gt;6. How best to use Latitude and Longitude features - Part 3&lt;/h2&gt;

&lt;p&gt;He used PCA to transform longitude and latitude coordinates. In this case it is not about dimension reduction since he transformed 2D-&amp;gt; 2D. The rotation could help for decision tree splits, and it did actually.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;pca &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; PCA()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(coords)
train[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_pca0&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pca&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(train[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_longitude&amp;#39;&lt;/span&gt;]])[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
train[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_pca1&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pca&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(train[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_longitude&amp;#39;&lt;/span&gt;]])[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
train[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_pca0&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pca&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(train[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_longitude&amp;#39;&lt;/span&gt;]])[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
train[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_pca1&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pca&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(train[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_longitude&amp;#39;&lt;/span&gt;]])[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
test[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_pca0&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pca&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(test[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_longitude&amp;#39;&lt;/span&gt;]])[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
test[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_pca1&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pca&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(test[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_longitude&amp;#39;&lt;/span&gt;]])[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
test[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_pca0&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pca&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(test[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_longitude&amp;#39;&lt;/span&gt;]])[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
test[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_pca1&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pca&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(test[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_longitude&amp;#39;&lt;/span&gt;]])[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;7-lets-not-forget-the-normal-things-you-can-do-with-your-features&#34;&gt;7. Lets not forget the Normal Things you can do with your features:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Scaling by Max-Min&lt;/li&gt;
&lt;li&gt;Normalization using Standard Deviation&lt;/li&gt;
&lt;li&gt;Log based feature/Target: use log based features or log based target function.&lt;/li&gt;
&lt;li&gt;One Hot Encoding&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;8-creating-intuitive-additional-features&#34;&gt;8. Creating Intuitive Additional Features:&lt;/h2&gt;

&lt;p&gt;A) Date time Features: Time based Features like &amp;ldquo;Evening&amp;rdquo;, &amp;ldquo;Noon&amp;rdquo;, &amp;ldquo;Night&amp;rdquo;, &amp;ldquo;Purchases_last_month&amp;rdquo;, &amp;ldquo;Purchases_last_week&amp;rdquo; etc.&lt;/p&gt;

&lt;p&gt;B) Thought Features: Suppose you have shopping cart data and you want to categorize TripType (See Walmart Recruiting: Trip Type Classification on &lt;a href=&#34;https://www.kaggle.com/c/walmart-recruiting-trip-type-classification/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Kaggle&lt;/a&gt; for some background).&lt;/p&gt;

&lt;p&gt;You could think of creating a feature like &amp;ldquo;Stylish&amp;rdquo; where you create this variable by adding together number of items that belong to category Men&amp;rsquo;s Fashion, Women&amp;rsquo;s Fashion, Teens Fashion.&lt;/p&gt;

&lt;p&gt;You could create a feature like &amp;ldquo;Rare&amp;rdquo; which is created by tagging some items as rare, based on the data we have and then counting the number of those rare items in the shopping cart. Such features might work or might not work. From what I have observed they normally provide a lot of value.&lt;/p&gt;

&lt;p&gt;I feel this is the way that Target&amp;rsquo;s &amp;ldquo;Pregnant Teen model&amp;rdquo; was made. They would have had a variable in which they kept all the items that a pregnant teen could buy and put it into a classification algorithm.&lt;/p&gt;

&lt;h2 id=&#34;9-the-not-so-normal-things-which-people-do&#34;&gt;9 . The not so Normal Things which people do:&lt;/h2&gt;

&lt;p&gt;These features are highly unintuitive and should not be created where the machine learning model needs to be interpretable.&lt;/p&gt;

&lt;p&gt;A) Interaction Features: If you have features A and B create features A*B, A+B, A/B, A-B. This explodes the feature space. If you have 10 features and you are creating two variable interactions you will be adding 10C2 * 4  features = 180 features to your model. And most of us have a lot more than 10 features.&lt;/p&gt;

&lt;p&gt;B) Bucket Feature Using Hashing: Suppose you have a lot of features. In the order of Thousands but you don&amp;rsquo;t want to use all the thousand features because of the training times of algorithms involved. People bucket their features using some hashing algorithm to achieve this.Mostly done for text classification tasks.
For example:
If we have 6 features A,B,C,D,E,F.
And the row of data is:
A:1,B:1,C:1,D:0,E:1,F:0
I may decide to use a hashing function so that these 6 features correspond to 3 buckets and create the data using this feature hashing vector.
After processing my data might look like:
Bucket1:2,Bucket2:2,Bucket3:0
Which happened because A and B fell in bucket1, C and E fell in bucket2 and D and F fell in bucket 3. I summed up the observations here, but you could substitute addition with any math function you like.
Now i would use Bucket1,Bucket2,Bucket3 as my variables for machine learning.&lt;/p&gt;

&lt;p&gt;Will try to keep on expanding. Wait for more&amp;hellip;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The story of every distribution - Discrete Distributions</title>
      <link>https://mlwhiz.com/blog/2017/09/14/discrete_distributions/</link>
      <pubDate>Thu, 14 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2017/09/14/discrete_distributions/</guid>
      <description>

&lt;p&gt;Distributions play an important role in the life of every Statistician. I coming from a non-statistic background am not so well versed in these and keep forgetting about the properties of these famous distributions. That is why I chose to write my own understanding in an intuitive way to keep a track.
One of the most helpful way to learn more about these is the &lt;a href=&#34;https://projects.iq.harvard.edu/stat110/home&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;STAT110&lt;/a&gt; course by Joe Blitzstein and his &lt;a href=&#34;http://amzn.to/2xAsYzE&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;book&lt;/a&gt;. You can check out this &lt;a href=&#34;https://www.coursera.org/specializations/statistics?siteID=lVarvwc5BD0-1nQtJg8.ENATqSUIufAaaw&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Coursera&lt;/a&gt; course too. Hope it could be useful to someone else too. So here goes:&lt;/p&gt;

&lt;h2 id=&#34;1-bernoulli-distribution&#34;&gt;1. Bernoulli Distribution:&lt;/h2&gt;

&lt;p&gt;Perhaps the most simple discrete distribution of all.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Story:&lt;/strong&gt; A Coin is tossed with probability p of heads.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF of Bernoulli Distribution is given by:&lt;/strong&gt;&lt;/p&gt;

&lt;div&gt;$$P(X=k) = \begin{cases}1-p &amp; k = 0\\p &amp; k = 1\end{cases}$$&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;CDF of Bernoulli Distribution is given by:&lt;/strong&gt;&lt;/p&gt;

&lt;div&gt;$$P(X \leq k) = \begin{cases}0 &amp; k \lt 0\\1-p &amp; 0 \leq k \lt 1 \\1 &amp; k \geq 1\end{cases}$$&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Expected Value:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$E[X] = \sum kP(X=k)$$
$$E[X] = 0*P(X=0)+1*P(X=1) = p$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$Var[X] = E[X^2] - E[X]^2$$
Now we find,
$$E[X]^2 = p^2$$
and
$$E[X^2] = \sum k^2P(X=k)$$
$$E[X^2] =  0^2P(X=0) + 1^2P(X=1) = p $$
Thus,
$$Var[X] = p(1-p)$$&lt;/p&gt;

&lt;h2 id=&#34;2-binomial-distribution&#34;&gt;2. Binomial Distribution:&lt;/h2&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/maxresdefault.jpg&#34;  height=&#34;400&#34; width=&#34;500&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;One of the most basic distribution in the Statistician toolkit. The parameters of this distribution is n(number of trials) and p(probability of success).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Story:&lt;/strong&gt;
Probability of getting exactly k successes in n trials&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF of binomial Distribution is given by:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$P(X=k) = \left(\begin{array}{c}n\ k\end{array}\right) p^{k}(1-p)^{n-k}$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;CDF of binomial Distribution is given by:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$ P(X\leq k) = \sum_{i=0}^k  \left(\begin{array}{c}n\ i\end{array}\right)  p^i(1-p)^{n-i} $$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Expected Value:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$E[X] = \sum kP(X=k)$$
$$E[X] = \sum_{k=0}^n k \left(\begin{array}{c}n\ k\end{array}\right) * p^{k}(1-p)^{n-k} = np $$&lt;/p&gt;

&lt;p&gt;A better way to solve this:&lt;/p&gt;

&lt;div&gt;$$ X = I_{1} + I_{2} + ....+ I_{n-1}+ I_{n} $$&lt;/div&gt;

&lt;p&gt;X is the sum on n Indicator Bernoulli random variables.&lt;/p&gt;

&lt;p&gt;Thus,&lt;/p&gt;

&lt;div&gt;
$$E[X] = E[I_{1} + I_{2} + ....+ I_{n-1}+ I_{n}]$$&lt;/div&gt;

&lt;div&gt;$$E[X] = E[I_{1}] + E[I_{2}] + ....+ E[I_{n-1}]+ E[I_{n}]$$&lt;/div&gt;

&lt;div&gt;$$E[X] = \underbrace{p + p + ....+ p + p}_{n} = np$$&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Variance:&lt;/strong&gt;&lt;/p&gt;

&lt;div&gt;$$ X = I_{1} + I_{2} + ....+ I_{n-1}+ I_{n} $$&lt;/div&gt;
X is the sum on n Indicator Bernoulli random variables.
&lt;div&gt;$$Var[X] = Var[I_{1} + I_{2} + ....+ I_{n-1}+ I_{n}]$$&lt;/div&gt;
&lt;div&gt;$$Var[X] = Var[I_{1}] + Var[I_{2}] + ....+ Var[I_{n-1}]+ Var[I_{n}]$$&lt;/div&gt;
&lt;div&gt;$$Var[X] = \underbrace{p(1-p) + p(1-p) + ....+ p(1-p) + p(1-p)}_{n} = np(1-p)$$&lt;/div&gt;

&lt;h2 id=&#34;3-geometric-distribution&#34;&gt;3. Geometric Distribution:&lt;/h2&gt;

&lt;p&gt;The parameters of this distribution is p(probability of success).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Story:&lt;/strong&gt;
The number of failures before the first success(Heads) when a coin with probability p is tossed&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF of Geometric Distribution is given by:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$P(X=k) = (1-p)^kp$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;CDF of Geometric Distribution is given by:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$ P(X\leq k) = \sum_{i=0}^k (1-p)^{i}p$$
$$ P(X\leq k) = p(1+q+q^2&amp;hellip;+q^k)= p(1-q^k)/(1-q) = 1-(1-p)^k $$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Expected Value:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$E[X] = \sum kP(X=k)$$
$$E[X] = \sum_{k=0}^{inf} k (1-p)^kp$$
$$E[X] = qp +2q^2p +3q^3p +4q^4p &amp;hellip;. $$
$$E[X] = qp(1+2q+3q^2+4q^3+&amp;hellip;.)$$
$$E[X] = qp/(1-q)^2 = q/p $$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$Var[X] = E[X^2] - E[X]^2$$
Now we find,
$$E[X]^2 = q^2/p^2$$
and
$$E[X^2] = \sum_0^k k^2q^kp= qp + 4q^2p + 9q^3p +16q^4p &amp;hellip; = qp(1+4q+9q^2+16q^3&amp;hellip;.)$$
$$E[X^2] = qp^{-2}(1+q)$$&lt;/p&gt;

&lt;p&gt;Thus,
$$Var[X] =q/p^2$$&lt;/p&gt;

&lt;p&gt;Check Math appendix at bottom of this post for Geometric Series Proofs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Q. A doctor is seeking an anti-depressant for a newly diagnosed patient. Suppose that, of the available anti-depressant drugs, the probability that any particular drug will be effective for a particular patient is p=0.6. What is the probability that the first drug found to be effective for this patient is the first drug tried, the second drug tried, and so on? What is the expected number of drugs that will be tried to find one that is effective?&lt;/p&gt;

&lt;p&gt;A. Expected number of drugs that will be tried to find one that is effective = q/p = .4/.6 =.67&lt;/p&gt;

&lt;h2 id=&#34;4-negative-binomial-distribution&#34;&gt;4. Negative Binomial Distribution:&lt;/h2&gt;

&lt;p&gt;The parameters of this distribution is p(probability of success) and r(number of success).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Story:&lt;/strong&gt;
The &lt;strong&gt;number of failures&lt;/strong&gt; of independent Bernoulli(p) trials before the rth success.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF of Negative Binomial Distribution is given by:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;r successes , k failures , last attempt needs to be a success:
$$P(X=k) = \left(\begin{array}{c}k+r-1\ k\end{array}\right) p^r(1-p)^k$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Expected Value:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The negative binomial RV could be stated as the sum of r Geometric RVs
$$X = X^1+X^2&amp;hellip;. X^{r-1} +X^r$$
Thus,
$$E[X] = E[X^1]+E[X^2]&amp;hellip;. E[X^{r-1}] +E[X^r]$$&lt;/p&gt;

&lt;p&gt;$$E[X] = rq/p$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The negative binomial RV could be stated as the sum of r independent Geometric RVs
$$X = X^1+X^2&amp;hellip;. X^{r-1} +X^r$$
Thus,
$$Var[X] = Var[X^1]+Var[X^2]&amp;hellip;. Var[X^{r-1}] +Var[X^r]$$&lt;/p&gt;

&lt;p&gt;$$E[X] = rq/p^2$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Q. Pat is required to sell candy bars to raise money for the 6th grade field trip. There are thirty houses in the neighborhood, and Pat is not supposed to return home until five candy bars have been sold. So the child goes door to door, selling candy bars. At each house, there is a 0.4 probability of selling one candy bar and a 0.6 probability of selling nothing.
What&amp;rsquo;s the probability of selling the last candy bar at the nth house?&lt;/p&gt;

&lt;p&gt;A. r = 5 ; k = n - r&lt;/p&gt;

&lt;p&gt;Probability of selling the last candy bar at the nth house =
$$P(X=k) = \left(\begin{array}{c}k+r-1\ k\end{array}\right) p^r(1-p)^k$$
$$P(X=k) = \left(\begin{array}{c}n-1\ n-5\end{array}\right) .4^5(.6)^{n-5}$$&lt;/p&gt;

&lt;h2 id=&#34;5-poisson-distribution&#34;&gt;5. Poisson Distribution:&lt;/h2&gt;

&lt;p&gt;The parameters of this distribution is $\lambda$ the rate parameter.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Motivation:&lt;/strong&gt;
There is as such no story to this distribution but only motivation for using this distribution. The Poisson distribution is often used for applications where we count the successes of a large number of trials where the per-trial success rate is small. For example, the Poisson distribution is a good starting point for counting the number of people who email you over the course of an hour.The number of chocolate chips in a chocolate chip cookie is another good candidate for a Poisson distribution, or the number of earthquakes in a year in some particular region&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF of Poisson Distribution is given by:&lt;/strong&gt;
$$ P(X=k) = \frac{e^{-\lambda}\lambda^k} {k!}$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Expected Value:&lt;/strong&gt;&lt;/p&gt;

&lt;div&gt;$$E[X] = \sum kP(X=k)$$&lt;/div&gt;

&lt;div&gt;$$ E[X] = \sum_{k=0}^{inf} k \frac{e^{-\lambda}\lambda^k} {k!}$$&lt;/div&gt;
&lt;div&gt;$$ E[X] = \lambda e^{-\lambda}\sum_{k=0}^{inf}  \frac{\lambda^{k-1}} {(k-1)!}$$&lt;/div&gt;
&lt;div&gt;$$ E[X] = \lambda e^{-\lambda} e^{\lambda} = \lambda $$&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Variance:&lt;/strong&gt;&lt;/p&gt;

&lt;div&gt;$$Var[X] = E[X^2] - E[X]^2$$&lt;/div&gt;

&lt;p&gt;Now we find,
&lt;div&gt;$$E[X]^2 = \lambda + \lambda^2$$&lt;/div&gt;
Thus,
$$Var[X] = \lambda$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Q. If electricity power failures occur according to a Poisson distribution with an average of 3 failures every twenty weeks, calculate the probability that there will not be more than one failure during a particular week?&lt;/p&gt;

&lt;p&gt;A. Probability = P(X=0)+P(X=1) =&lt;/p&gt;

&lt;div&gt;$$e^{-3/20} + e^{-3/20}3/20 = 23/20*e^{-3/20} $$&lt;/div&gt;

&lt;p&gt;Probability of selling the last candy bar at the nth house =
$$P(X=k) = \left(\begin{array}{c}k+r-1\ k\end{array}\right) p^r(1-p)^k$$
$$P(X=k) = \left(\begin{array}{c}n-1\ n-5\end{array}\right) .4^5(.6)^{n-5}$$&lt;/p&gt;

&lt;h2 id=&#34;math-appendix&#34;&gt;Math Appendix:&lt;/h2&gt;

&lt;p&gt;Some Math (For Geometric Distribution) :&lt;/p&gt;

&lt;p&gt;$$a+ar+ar^2+ar^3+⋯=a/(1−r)=a(1−r)^{−1}$$
Taking the derivatives of both sides, the first derivative with respect to r must be:
$$a+2ar+3ar^2+4ar^3⋯=a(1−r)^{−2}$$
Multiplying above with r:
$$ar+2ar^2+3ar^3+4ar^4⋯=ar(1−r)^{−2}$$
Taking the derivatives of both sides, the first derivative with respect to r must be:
$$a+4ar+9ar^2+16ar^3⋯=a(1−r)^{-3}(1+r)$$&lt;/p&gt;

&lt;h2 id=&#34;bonus-python-graphs-and-functions&#34;&gt;Bonus - Python Graphs and Functions:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Useful Function to create graph&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;chart_creator&lt;/span&gt;(x,y,title):
    &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt  &lt;span style=&#34;color:#75715e&#34;&gt;#sets up plotting under plt&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; sns           &lt;span style=&#34;color:#75715e&#34;&gt;#sets up styles and gives us more plotting options&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd             &lt;span style=&#34;color:#75715e&#34;&gt;#lets us handle data as dataframes&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;matplotlib inline
    &lt;span style=&#34;color:#75715e&#34;&gt;# Create a list of 100 Normal RVs&lt;/span&gt;
    data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(zip(x,y))
    data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;x&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;y&amp;#39;&lt;/span&gt;]
    &lt;span style=&#34;color:#75715e&#34;&gt;# We dont Probably need the Gridlines. Do we? If yes comment this line&lt;/span&gt;
    sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set(style&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ticks&amp;#34;&lt;/span&gt;)

    &lt;span style=&#34;color:#75715e&#34;&gt;# Here we create a matplotlib axes object. The extra parameters we use&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#34;ci&amp;#34; to remove confidence interval&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#34;marker&amp;#34; to have a x as marker.&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#34;scatter_kws&amp;#34; to provide style info for the points.[s for size]&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#34;line_kws&amp;#34; to provide style info for the line.[lw for line width]&lt;/span&gt;

    g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;regplot(x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;x&amp;#39;&lt;/span&gt;, y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;y&amp;#39;&lt;/span&gt;, data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;data, ci &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False,
        scatter_kws&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;color&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;darkred&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;alpha&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;s&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;90&lt;/span&gt;},
        line_kws&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;color&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;g&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;alpha&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;lw&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;},marker&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;x&amp;#34;&lt;/span&gt;)

    &lt;span style=&#34;color:#75715e&#34;&gt;# remove the top and right line in graph&lt;/span&gt;
    sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;despine()

    &lt;span style=&#34;color:#75715e&#34;&gt;# Set the size of the graph from here&lt;/span&gt;
    g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_size_inches(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;)
    &lt;span style=&#34;color:#75715e&#34;&gt;# Set the Title of the graph from here&lt;/span&gt;
    g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axes&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_title(title, fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;34&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
    &lt;span style=&#34;color:#75715e&#34;&gt;# Set the xlabel of the graph from here&lt;/span&gt;
    g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;k&amp;#34;&lt;/span&gt;,size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;67&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
    &lt;span style=&#34;color:#75715e&#34;&gt;# Set the ylabel of the graph from here&lt;/span&gt;
    g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;pmf&amp;#34;&lt;/span&gt;,size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;67&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
    &lt;span style=&#34;color:#75715e&#34;&gt;# Set the ticklabel size and color of the graph from here&lt;/span&gt;
    g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tick_params(labelsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;14&lt;/span&gt;,labelcolor&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;black&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And here I will generate the PMFs of the discrete distributions we just discussed above using Pythons built in functions. For more details on the upper function, please see my previous post - &lt;a href=&#34;http://mlwhiz.com/blog/2015/09/13/seaborn_visualizations/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Create basic graph visualizations with SeaBorn&lt;/a&gt;. Also take a look at the &lt;a href=&#34;https://docs.scipy.org/doc/scipy/reference/stats.html&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;documentation&lt;/a&gt; guide for the below functions&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Binomial :&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; scipy.stats &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; binom
n&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;
p&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;
k &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,n)
pmf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; binom&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pmf(k, n, p)
chart_creator(k,pmf,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Binomial PMF&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/output_12_0.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Geometric :&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; scipy.stats &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; geom
n&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;
p&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;
k &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,n)
&lt;span style=&#34;color:#75715e&#34;&gt;# -1 here is the location parameter for generating the PMF we want.&lt;/span&gt;
pmf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; geom&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pmf(k, p,&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
chart_creator(k,pmf,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Geometric PMF&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/output_13_0.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Negative Binomial :&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; scipy.stats &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; nbinom
r&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# number of successes&lt;/span&gt;
p&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# probability of Success&lt;/span&gt;
k &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;# number of failures&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# -1 here is the location parameter for generating the PMF we want.&lt;/span&gt;
pmf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nbinom&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pmf(k, r, p)
chart_creator(k,pmf,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Nbinom PMF&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/output_14_0.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#Poisson&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; scipy.stats &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; poisson
lamb &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# Rate&lt;/span&gt;
k &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;)
pmf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; poisson&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pmf(k, lamb)
chart_creator(k,pmf,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Poisson PMF&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/output_15_0.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h2 id=&#34;references&#34;&gt;References:&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://amzn.to/2xAsYzE&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Introduction to Probability by Joe Blitzstein&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Negative_binomial_distribution&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Next thing I want to come up with is a same sort of post for continuous distributions too. Keep checking for the same. Till then Ciao.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Today I Learned This Part 2: Pretrained Neural Networks What are they?</title>
      <link>https://mlwhiz.com/blog/2017/04/17/deep_learning_pretrained_models/</link>
      <pubDate>Mon, 17 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2017/04/17/deep_learning_pretrained_models/</guid>
      <description>

&lt;p&gt;Deeplearning is the buzz word right now. I was working on the &lt;a href=&#34;http://www.fast.ai/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;course&lt;/a&gt; for deep learning by Jeremy Howard and one thing I noticed were pretrained deep Neural Networks. In the first lesson he used the pretrained NN to predict on the &lt;a href=&#34;https://www.kaggle.com/c/dogs-vs-cats&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Dogs vs Cats&lt;/a&gt; competition on Kaggle to achieve very good results.&lt;/p&gt;

&lt;h2 id=&#34;what-are-pretrained-neural-networks&#34;&gt;What are pretrained Neural Networks?&lt;/h2&gt;

&lt;p&gt;So let me tell you about the background a little bit. There is a challenge that happens every year in the visual recognition community - The Imagenet Challenge. The task there is to classify the images in 1000 categories using Image training data. People train big convolutional deep learning models for this challenge.&lt;/p&gt;

&lt;p&gt;Now what does training a neural model actually mean? It just means that they learn the weights for a NN. What if we can get the weights they learn? We can use those weights to load them into our own NN model and predict on the test dataset. Right?&lt;/p&gt;

&lt;p&gt;But actually we can go further than that. We can add an extra layer on top of the NN they have prepared to classify our own dataset.&lt;/p&gt;

&lt;p&gt;In a way you can think of the intermediate features created by the Pretrained neural networks to be the features for the next layer.&lt;/p&gt;

&lt;h2 id=&#34;why-it-works&#34;&gt;Why it works?&lt;/h2&gt;

&lt;p&gt;We are essentially doing the image classification task only. We need to find out edges, shapes, intensities and other features from the images that are given to us. The pretrained model is already pretty good at finding these sort of features. Forget neural nets, if we plug these features into a machine learning algorithm we should be good.&lt;/p&gt;

&lt;p&gt;What we actually do here is replace the last layer of the neural network with a new prediction/output layer and train while keeping the weights for all the layers before the second last layer constant.&lt;/p&gt;

&lt;h2 id=&#34;code&#34;&gt;Code:&lt;/h2&gt;

&lt;p&gt;I assume that you understand Keras a little. If not you can look at the docs.
Let us get into coding now. First of all we will create the architecture of the neural network the VGG Team created in 2014. Then we will load the weights.&lt;/p&gt;

&lt;p&gt;Import some stuff&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; numpy.random &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random, permutation
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; scipy &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; misc, ndimage
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; scipy.ndimage.interpolation &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; zoom
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; keras
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; backend &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; K
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras.utils.data_utils &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; get_file
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras.models &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Sequential, Model
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras.layers.core &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Flatten, Dense, Dropout, Lambda
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras.layers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Input
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras.layers.convolutional &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Convolution2D, MaxPooling2D, ZeroPadding2D
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras.optimizers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; SGD, RMSprop, Adam
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras.preprocessing &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; image&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;VGG has just one type of convolutional block, and one type of fully connected (&amp;lsquo;dense&amp;rsquo;) block. We start by defining the building blocks of our Deep learning model.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ConvBlock&lt;/span&gt;(layers, model, filters):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(layers):
        model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(ZeroPadding2D((&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)))
        model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Convolution2D(filters, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(MaxPooling2D((&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;), strides&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)))

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;FCBlock&lt;/span&gt;(model):
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;4096&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Dropout(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;script src=&#34;//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e&#34;&gt;&lt;/script&gt;

&lt;p&gt;Now the input of the VGG Model was images. When the VGG model was trained in 2014, the creators subtracted the average of each of the three (R,G,B) channels first, so that the data for each channel had a mean of zero. Furthermore, their software that expected the channels to be in B,G,R order, whereas Python by default uses R,G,B. We need to preprocess our data to make these two changes, so that it is compatible with the VGG model. We also add some helper functions.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#Mean of each channel as provided by VGG researchers&lt;/span&gt;
vgg_mean &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#ae81ff&#34;&gt;123.68&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;116.779&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;103.939&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape((&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vgg_preprocess&lt;/span&gt;(x):
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; vgg_mean     &lt;span style=&#34;color:#75715e&#34;&gt;# subtract mean&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x[:, ::&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]    &lt;span style=&#34;color:#75715e&#34;&gt;# reverse axis bgr-&amp;gt;rgb&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;VGG_16&lt;/span&gt;():
    model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Sequential()
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Lambda(vgg_preprocess, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;)))
    ConvBlock(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, model, &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;)
    ConvBlock(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, model, &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;)
    ConvBlock(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, model, &lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;)
    ConvBlock(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, model, &lt;span style=&#34;color:#ae81ff&#34;&gt;512&lt;/span&gt;)
    ConvBlock(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, model, &lt;span style=&#34;color:#ae81ff&#34;&gt;512&lt;/span&gt;)
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Flatten())
    FCBlock(model)
    FCBlock(model)
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model


&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;finetune&lt;/span&gt;(model, num_classes):
    &lt;span style=&#34;color:#75715e&#34;&gt;# Drop last layer&lt;/span&gt;
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pop()
    &lt;span style=&#34;color:#75715e&#34;&gt;# Make all layers untrainable. i.e fix all weights&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; layer &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers: layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False
    &lt;span style=&#34;color:#75715e&#34;&gt;# Add a new layer which is the new output layer&lt;/span&gt;
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Dense(num_classes, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;))
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;Adam(lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.001&lt;/span&gt;),
                loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;categorical_crossentropy&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model


&lt;span style=&#34;color:#75715e&#34;&gt;# A way to generate batches of images&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_batches&lt;/span&gt;(path, dirname, gen&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ImageDataGenerator(), shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True,
                batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, class_mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;categorical&amp;#39;&lt;/span&gt;):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; gen&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flow_from_directory(path&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;dirname, target_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;224&lt;/span&gt;),
                class_mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;class_mode, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;shuffle, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;batch_size)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The hard part is done now. Just create a VGG object and load the weights.We will need to load pretrained weights into the model too. You can download the &amp;ldquo;VGG16_weights.h5&amp;rdquo; file &lt;a href=&#34;https://drive.google.com/file/d/0Bz7KyqmuGsilT0J5dmRCM0ROVHc/view&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; VGG_16()
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_weights(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;VGG16_weights.h5&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Since our dogs vs cat dataset is binary classification model&lt;/span&gt;
ftmodel &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; finetune(model,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; ftmodel&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/keras_net.png&#34;  height=&#34;400&#34; width=&#34;500&#34; &gt;&lt;/center&gt;
&lt;/div&gt;
Showing a little bit of output here. This is how the last layers of our Neural net look after training. Now we have got a architecture which we got to train. Here we are only training to get the last layer weights. As you can see from the trainable params.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;dogscats/&amp;#34;&lt;/span&gt;
batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# Iterators to get our images from our datasets. The datasets are folders named train and valid. Both folder contain two directories &amp;#39;dogs&amp;#39; and &amp;#39;cats&amp;#39;. In each directory the corresponding images are kept.&lt;/span&gt;

batches &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_batches(path,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;train&amp;#39;&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;batch_size)
val_batches &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_batches(path,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;valid&amp;#39;&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;batch_size)

&lt;span style=&#34;color:#75715e&#34;&gt;# Now run for some epochs till the validation loss stops decreasing.&lt;/span&gt;
no_of_epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; epoch &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(no_of_epochs):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Running epoch: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%d&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; epoch
    ftmodel&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit_generator(batches, samples_per_epoch&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;batches&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nb_sample, nb_epoch&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
                validation_data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;val_batches, nb_val_samples&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;val_batches&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nb_sample)
    latest_weights_filename &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ft&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%d&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;.h5&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; epoch
    ftmodel&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;save_weights(latest_weights_filename)

&lt;span style=&#34;color:#75715e&#34;&gt;#Create Predictions on test set. The test images should be in the folder dogscats/test/test_images/ , which is a single directory containing all images.&lt;/span&gt;

test_batches &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_batches(path, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;batch_size, class_mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None)

preds &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ftmodel&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict_generator(test_batches, test_batches&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nb_sample)

isdog &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; preds[:,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
image_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; batches&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;filenames
final_submission &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stack([ids,isdog], axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And we are done!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Maths Beats Intuition probably every damn time</title>
      <link>https://mlwhiz.com/blog/2017/04/16/maths_beats_intuition/</link>
      <pubDate>Sun, 16 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2017/04/16/maths_beats_intuition/</guid>
      <description>

&lt;p&gt;Newton once said that &lt;strong&gt;&amp;ldquo;God does not play dice with the universe&amp;rdquo;&lt;/strong&gt;. But actually he does. Everything happening around us could be explained in terms of probabilities. We repeatedly watch things around us happen due to chances, yet we never learn. We always get dumbfounded by the playfulness of nature.&lt;/p&gt;

&lt;p&gt;One of such ways intuition plays with us is with the Birthday problem.&lt;/p&gt;

&lt;h2 id=&#34;problem-statement&#34;&gt;Problem Statement:&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;In a room full of N people, what is the probability that 2 or more people share the same birthday(Assumption: 365 days in year)?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;By the &lt;a href=&#34;https://en.wikipedia.org/wiki/Pigeonhole_principle&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;pigeonhole principle&lt;/a&gt;, the probability reaches 100% when the number of people reaches 366 (since there are only 365 possible birthdays).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;However, the paradox is that 99.9% probability is reached with just 70 people, and 50% probability is reached with just 23 people.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;mathematical-proof&#34;&gt;Mathematical Proof:&lt;/h2&gt;

&lt;p&gt;Sometimes a good strategy when trying to find out probability of an event is to look at the probability of the complement event.Here it is easier to find the probability of the complement event.
We just need to count the number of cases in which no person has the same birthday.(Sampling without replacement)
Since there are k ways in which birthdays can be chosen with replacement.&lt;/p&gt;

&lt;p&gt;$P(birthday Match) = 1 - \dfrac{(365).364&amp;hellip;(365−k+1)}{365^k}$&lt;/p&gt;

&lt;h2 id=&#34;simulation&#34;&gt;Simulation:&lt;/h2&gt;

&lt;p&gt;Lets try to build around this result some more by trying to simulate this result:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;matplotlib inline
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt  &lt;span style=&#34;color:#75715e&#34;&gt;#sets up plotting under plt&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; sns           &lt;span style=&#34;color:#75715e&#34;&gt;#sets up styles and gives us more plotting options&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd             &lt;span style=&#34;color:#75715e&#34;&gt;#lets us handle data as dataframes&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sim_bithday_problem&lt;/span&gt;(num_people_room, trials &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;This function takes as input the number of people in the room.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Runs 1000 trials by default and returns
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    (number of times same brthday found)/(no of trials)
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    same_birthdays_found &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(trials):
        &lt;span style=&#34;color:#75715e&#34;&gt;# randomly sample from the birthday space which could be any of a number from 1 to 365&lt;/span&gt;
        birthdays &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randint(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;365&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_people_room)]
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(birthdays) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; len(set(birthdays))&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
            same_birthdays_found&lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; same_birthdays_found&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;float(trials)

num_people &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;)
probs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [sim_bithday_problem(i) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; num_people]
data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame()
data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;num_peeps&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; num_people
data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;probs&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; probs
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set(style&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ticks&amp;#34;&lt;/span&gt;)

g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;regplot(x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;num_peeps&amp;#34;&lt;/span&gt;, y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;probs&amp;#34;&lt;/span&gt;, data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;data, ci &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False,
    scatter_kws&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;color&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;darkred&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;alpha&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;s&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;90&lt;/span&gt;},
    marker&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;x&amp;#34;&lt;/span&gt;,fit_reg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)

sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;despine()
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_size_inches(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axes&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;As the Number of people in room reaches 23 the probability reaches ~0.5&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;At more than 50 people the probability is reaching 1&amp;#39;&lt;/span&gt;, fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;g&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;# of people in room&amp;#34;&lt;/span&gt;,size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Probability&amp;#34;&lt;/span&gt;,size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tick_params(labelsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;14&lt;/span&gt;,labelcolor&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;black&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/bithdayproblem.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;We can see from the &lt;a href=&#34;https://mlwhiz.com/blog/2015/09/13/seaborn_visualizations/&#34;&gt;graph&lt;/a&gt; that as the Number of people in room reaches 23 the probability reaches ~ 0.5. So we have proved this fact Mathematically as well as with simulation.&lt;/p&gt;

&lt;h2 id=&#34;intuition&#34;&gt;Intuition:&lt;/h2&gt;

&lt;p&gt;To understand it we need to think of this problem in terms of pairs. There are ${{23}\choose{2}} = 253$ pairs of people in the room when only 23 people are present. Now with that big number you should not find the probability of 0.5 too much. In the case of 70 people we are looking at ${{70}\choose{2}} = 2450$ pairs.&lt;/p&gt;

&lt;p&gt;So thats it for now. To learn more about this go to &lt;a href=&#34;https://en.wikipedia.org/wiki/Birthday_problem&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Wikipedia&lt;/a&gt; which has an awesome page on this topic.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References:&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://amzn.to/2nIUkxq&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Introduction to Probability by Joseph K. Blitzstein&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Birthday_problem&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Birthday Problem on Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Today I Learned This Part I: What are word2vec Embeddings?</title>
      <link>https://mlwhiz.com/blog/2017/04/09/word_vec_embeddings_examples_understanding/</link>
      <pubDate>Sun, 09 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2017/04/09/word_vec_embeddings_examples_understanding/</guid>
      <description>

&lt;p&gt;Recently Quora put out a &lt;a href=&#34;https://www.kaggle.com/c/quora-question-pairs&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Question similarity&lt;/a&gt; competition on Kaggle. This is the first time I was attempting an NLP problem so a lot to learn. The one thing that blew my mind away was the word2vec embeddings.&lt;/p&gt;

&lt;p&gt;Till now whenever I heard the term word2vec I visualized it as a way to create a bag of words vector for a sentence.&lt;/p&gt;

&lt;p&gt;For those who don&amp;rsquo;t know &lt;em&gt;bag of words&lt;/em&gt;:
If we have a series of sentences(documents)&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;This is good       - [1,1,1,0,0]&lt;/li&gt;
&lt;li&gt;This is bad        - [1,1,0,1,0]&lt;/li&gt;
&lt;li&gt;This is awesome    - [1,1,0,0,1]&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Bag of words would encode it using &lt;em&gt;0:This 1:is 2:good 3:bad 4:awesome&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;But it is much more powerful than that.&lt;/p&gt;

&lt;p&gt;What word2vec does is that it creates vectors for words.
What I mean by that is that we have a 300 dimensional vector for every word(common bigrams too) in a dictionary.&lt;/p&gt;

&lt;h2 id=&#34;how-does-that-help&#34;&gt;How does that help?&lt;/h2&gt;

&lt;p&gt;We can use this for multiple scenarios but the most common are:&lt;/p&gt;

&lt;p&gt;A. &lt;em&gt;Using word2vec embeddings we can find out similarity between words&lt;/em&gt;.
Assume you have to answer if these two statements signify the same thing:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;President greets press in Chicago&lt;/li&gt;
&lt;li&gt;Obama speaks to media in Illinois.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If we do a sentence similarity metric or a bag of words approach to compare these two sentences we will get a pretty low score.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/word2vecembed.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;But with a word encoding we can say that&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;President is similar to Obama&lt;/li&gt;
&lt;li&gt;greets is similar to speaks&lt;/li&gt;
&lt;li&gt;press is similar to media&lt;/li&gt;
&lt;li&gt;Chicago is similar to Illinois&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;B. &lt;em&gt;Encode Sentences&lt;/em&gt;: I read a &lt;a href=&#34;https://www.linkedin.com/pulse/duplicate-quora-question-abhishek-thakur&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;post&lt;/a&gt; from Abhishek Thakur a prominent kaggler.(Must Read). What he did was he used these word embeddings to create a 300 dimensional vector for every sentence.&lt;/p&gt;

&lt;p&gt;His Approach: Lets say the sentence is &amp;ldquo;What is this&amp;rdquo;
And lets say the embedding for every word is given in 4 dimension(normally 300 dimensional encoding is given)&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;what : [.25 ,.25 ,.25 ,.25]&lt;/li&gt;
&lt;li&gt;is   : [  1 ,  0 ,  0 ,  0]&lt;/li&gt;
&lt;li&gt;this : [ .5 ,  0 ,  0 , .5]&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Then the vector for the sentence is normalized elementwise addition of the vectors. i.e.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Elementwise addition : [.25+1+0.5, 0.25+0+0 , 0.25+0+0, .25+0+.5] = [1.75, .25, .25, .75]
divided by
math.sqrt(1.25^2 + .25^2 + .25^2 + .75^2) = 1.5
gives:[1.16, .17, .17, 0.5]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Thus I can convert any sentence to a vector  of a fixed dimension(decided by the embedding). To find similarity between two sentences I can use a variety of distance/similarity metrics.&lt;/p&gt;

&lt;p&gt;C. Also It enables us to do algebraic manipulations on words which was not possible before. For example: What is king - man + woman ?&lt;/p&gt;

&lt;p&gt;Guess what it comes out to be : &lt;em&gt;Queen&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;application-coding&#34;&gt;Application/Coding:&lt;/h2&gt;

&lt;p&gt;Now lets get down to the coding part as we know a little bit of fundamentals.&lt;/p&gt;

&lt;p&gt;First of all we download a custom word embedding from Google. There are many other embeddings too.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;wget https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The above file is pretty big. Might take some time. Then moving on to coding.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; gensim.models &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; word2vec
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; gensim&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;models&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;KeyedVectors&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_word2vec_format(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;data/GoogleNews-vectors-negative300.bin.gz&amp;#39;&lt;/span&gt;, binary&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&#34;1-starting-simple-lets-find-out-similar-words-want-to-find-similar-words-to-python&#34;&gt;1. Starting simple, lets find out similar words. Want to find similar words to python?&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;most_similar(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;python&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;font-size:80%;color:black;font-family: helvetica;line-height:18px;margin-top:8px;margin-left:20px&#34;&gt;
[(u&#39;pythons&#39;, 0.6688377261161804),&lt;br&gt;
 (u&#39;Burmese_python&#39;, 0.6680364608764648),&lt;br&gt;
 (u&#39;snake&#39;, 0.6606293320655823),&lt;br&gt;
 (u&#39;crocodile&#39;, 0.6591362953186035),&lt;br&gt;
 (u&#39;boa_constrictor&#39;, 0.6443519592285156),&lt;br&gt;
 (u&#39;alligator&#39;, 0.6421656608581543),&lt;br&gt;
 (u&#39;reptile&#39;, 0.6387745141983032),&lt;br&gt;
 (u&#39;albino_python&#39;, 0.6158879995346069),&lt;br&gt;
 (u&#39;croc&#39;, 0.6083582639694214),&lt;br&gt;
 (u&#39;lizard&#39;, 0.601341724395752)]&lt;br&gt;
 &lt;/div&gt;

&lt;h3 id=&#34;2-now-we-can-use-this-model-to-find-the-solution-to-the-equation&#34;&gt;2. Now we can use this model to find the solution to the equation:&lt;/h3&gt;

&lt;p&gt;What is king - man + woman?&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;most_similar(positive &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;king&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;woman&amp;#39;&lt;/span&gt;],negative &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;man&amp;#39;&lt;/span&gt;])&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;font-size:80%;color:black;font-family: helvetica;line-height:18px;margin-top:8px;margin-left:20px&#34;&gt;
[(u&#39;queen&#39;, 0.7118192315101624),&lt;br&gt;
 (u&#39;monarch&#39;, 0.6189674139022827),&lt;br&gt;
 (u&#39;princess&#39;, 0.5902431011199951),&lt;br&gt;
 (u&#39;crown_prince&#39;, 0.5499460697174072),&lt;br&gt;
 (u&#39;prince&#39;, 0.5377321839332581),&lt;br&gt;
 (u&#39;kings&#39;, 0.5236844420433044),&lt;br&gt;
 (u&#39;Queen_Consort&#39;, 0.5235946178436279),&lt;br&gt;
 (u&#39;queens&#39;, 0.5181134343147278),&lt;br&gt;
 (u&#39;sultan&#39;, 0.5098593235015869),&lt;br&gt;
 (u&#39;monarchy&#39;, 0.5087412595748901)]&lt;br&gt;
&lt;/div&gt;

&lt;p&gt;You can do plenty of freaky/cool things using this:&lt;/p&gt;

&lt;h3 id=&#34;3-lets-say-you-wanted-a-girl-and-had-a-girl-name-like-emma-in-mind-but-you-got-a-boy-so-what-is-the-male-version-for-emma&#34;&gt;3. Lets say you wanted a girl and had a girl name like emma in mind but you got a boy. So what is the male version for emma?&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;most_similar(positive &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;emma&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;he&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;male&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mr&amp;#39;&lt;/span&gt;],negative &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;she&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mrs&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;female&amp;#39;&lt;/span&gt;])&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;font-size:80%;color:black;font-family: helvetica;line-height:18px;margin-top:8px;margin-left:20px&#34;&gt;
[(u&#39;sanchez&#39;, 0.4920658469200134),&lt;br&gt;
 (u&#39;kenny&#39;, 0.48300960659980774),&lt;br&gt;
 (u&#39;alves&#39;, 0.4684845209121704),&lt;br&gt;
 (u&#39;gareth&#39;, 0.4530612826347351),&lt;br&gt;
 (u&#39;bellamy&#39;, 0.44884198904037476),&lt;br&gt;
 (u&#39;gibbs&#39;, 0.445194810628891),&lt;br&gt;
 (u&#39;dos_santos&#39;, 0.44508373737335205),&lt;br&gt;
 (u&#39;gasol&#39;, 0.44387346506118774),&lt;br&gt;
 (u&#39;silva&#39;, 0.4424275755882263),&lt;br&gt;
 (u&#39;shaun&#39;, 0.44144102931022644)]&lt;br&gt;&lt;br&gt;
&lt;/div&gt;

&lt;h3 id=&#34;4-find-which-word-doesn-t-belong-to-a-list-https-github-com-dhammack-word2vecexample-blob-master-main-py&#34;&gt;4. Find which word doesn&amp;rsquo;t belong to a &lt;a href=&#34;https://github.com/dhammack/Word2VecExample/blob/master/main.py&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;list&lt;/a&gt;?&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;doesnt_match(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;math shopping reading science&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I think staple doesn&amp;rsquo;t belong in this list!&lt;/p&gt;

&lt;h2 id=&#34;other-cool-things&#34;&gt;Other Cool Things&lt;/h2&gt;

&lt;h3 id=&#34;1-recommendations&#34;&gt;1. Recommendations:&lt;/h3&gt;

&lt;div style=&#34;margin-top: 4px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/recommendationpaper.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;In this &lt;a href=&#34;https://arxiv.org/abs/1603.04259&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt;, the authors have shown that itembased CF can be cast in the same framework of word embedding.&lt;/p&gt;

&lt;h3 id=&#34;2-some-other-examples-http-byterot-blogspot-in-2015-06-five-crazy-abstractions-my-deep-learning-word2doc-model-just-did-nlp-gensim-html-that-people-have-seen-after-using-their-own-embeddings&#34;&gt;2. Some other &lt;a href=&#34;http://byterot.blogspot.in/2015/06/five-crazy-abstractions-my-deep-learning-word2doc-model-just-did-NLP-gensim.html&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;examples&lt;/a&gt; that people have seen after using their own embeddings:&lt;/h3&gt;

&lt;p&gt;Library - Books = Hall&lt;br&gt;
Obama + Russia - USA = Putin&lt;br&gt;
Iraq - Violence = Jordan&lt;br&gt;
President - Power = Prime Minister (Not in India Though)&lt;br&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-seeing-the-above-i-started-playing-with-it-a-little&#34;&gt;3.Seeing the above I started playing with it a little.&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Is this model sexist?&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;most_similar(positive &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;donald_trump&amp;#34;&lt;/span&gt;],negative &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;brain&amp;#39;&lt;/span&gt;])&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;font-size:80%;color:black;font-family: helvetica;line-height:18px;margin-top:8px;margin-left:20px&#34;&gt;
[(u&#39;novak&#39;, 0.40405112504959106),&lt;br&gt;
 (u&#39;ozzie&#39;, 0.39440611004829407),&lt;br&gt;
 (u&#39;democrate&#39;, 0.39187556505203247),&lt;br&gt;
 (u&#39;clinton&#39;, 0.390536367893219),&lt;br&gt;
 (u&#39;hillary_clinton&#39;, 0.3862358033657074),&lt;br&gt;
 (u&#39;bnp&#39;, 0.38295692205429077),&lt;br&gt;
 (u&#39;klaar&#39;, 0.38228923082351685),&lt;br&gt;
 (u&#39;geithner&#39;, 0.380607008934021),&lt;br&gt;
 (u&#39;bafana_bafana&#39;, 0.3801495432853699),&lt;br&gt;
 (u&#39;whitman&#39;, 0.3790769875049591)]&lt;br&gt;
&lt;/div&gt;

&lt;p&gt;Whatever it is doing it surely feels like magic. Next time I will try to write more on how it works once I understand it fully.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Top Data Science Resources on the Internet right now</title>
      <link>https://mlwhiz.com/blog/2017/03/26/top_data_science_resources_on_the_internet_right_now/</link>
      <pubDate>Sun, 26 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2017/03/26/top_data_science_resources_on_the_internet_right_now/</guid>
      <description>

&lt;p&gt;I have been looking to create this list for a while now. There are many people on quora who ask me how I started in the data science field. And so I wanted to create this reference.&lt;/p&gt;

&lt;p&gt;To be frank, when I first started learning it all looked very utopian and out of the world. The Andrew Ng course felt like black magic. And it still doesn&amp;rsquo;t cease to amaze me. After all, we are predicting the future. Take the case of Nate Silver - What else can you call his success if not Black Magic?&lt;/p&gt;

&lt;p&gt;But it is not magic. And this is a way an aspiring guy could take to become a &lt;b&gt;&lt;u&gt;self-trained data scientist&lt;/u&gt;&lt;/b&gt;. Follow in order. I have tried to include everything that comes to my mind. So here goes:&lt;/p&gt;

&lt;h2 id=&#34;1-stat-110-introduction-to-probability-joe-blitzstein-harvard-university-http-projects-iq-harvard-edu-stat110-youtube&#34;&gt;1. &lt;a href=&#34;http://projects.iq.harvard.edu/stat110/youtube&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Stat 110: Introduction to Probability: Joe Blitzstein - Harvard University&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;The one stat course you gotta take&lt;/em&gt;. If not for the content then for Prof. Blitzstein sense of humor. I took this course to enhance my understanding of probability distributions and statistics, but this course taught me a lot more than that. Apart from Learning to think conditionally, this also taught me how to explain difficult concepts with a story.&lt;/p&gt;

&lt;p&gt;This was a Hard Class but most definitely fun. The focus was not only on getting Mathematical proofs but also on understanding the intuition behind them and how intuition can help in deriving them more easily. Sometimes the same proof was done in different ways to facilitate learning of a concept.&lt;/p&gt;

&lt;p&gt;One of the things I liked most about this course is the focus on concrete examples while explaining abstract concepts. The inclusion of ** Gambler’s Ruin Problem, Matching Problem, Birthday Problem, Monty Hall, Simpsons Paradox, St. Petersberg Paradox ** etc. made this course much much more exciting than a normal Statistics Course.&lt;/p&gt;

&lt;p&gt;It will help you understand Discrete (Bernoulli, Binomial, Hypergeometric, Geometric, Negative Binomial, FS, Poisson) and Continuous (Uniform, Normal, expo, Beta, Gamma) Distributions and the stories behind them. Something that I was always afraid of.&lt;/p&gt;

&lt;p&gt;He got a textbook out based on this course which is clearly a great text:&lt;/p&gt;

&lt;div style=&#34;margin-left:1em ; text-align: center;&#34;&gt;
&lt;a href=&#34;https://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science-ebook/dp/B00MMOJ19I/ref=as_li_ss_il?ie=UTF8&amp;linkCode=li3&amp;tag=mlwhizcon-20&amp;linkId=7254baef925507e0d8dfd07cca2f519d&#34; target=&#34;_blank&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=B00MMOJ19I&amp;Format=_SL250_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li3&amp;o=1&amp;a=B00MMOJ19I&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;
&lt;/div&gt;

&lt;h2 id=&#34;2-data-science-cs109-http-cs109-github-io-2015&#34;&gt;2. &lt;a href=&#34;http://cs109.github.io/2015/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Data Science CS109&lt;/a&gt;: -&lt;/h2&gt;

&lt;p&gt;Again by Professor Blitzstein. Again an awesome course. &lt;em&gt;Watch it after Stat110 as you will be able to understand everything much better with a thorough grinding in Stat110 concepts&lt;/em&gt;. You will learn about &lt;em&gt;Python Libraries&lt;/em&gt; like &lt;strong&gt;Numpy,Pandas&lt;/strong&gt; for data science, along with a thorough intuitive grinding for various Machine learning Algorithms. Course description from Website:&lt;/p&gt;

&lt;div style=&#34;color:black; background-color: #E9DAEE;&#34;&gt;
Learning from data in order to gain useful predictions and insights. This course introduces methods for five key facets of an investigation: data wrangling, cleaning, and sampling to get a suitable data set; data management to be able to access big data quickly and reliably; exploratory data analysis to generate hypotheses and intuition; prediction based on statistical methods such as regression and classification; and communication of results through visualization, stories, and interpretable summaries.
&lt;/div&gt;

&lt;h2 id=&#34;3-cs229-andrew-ng-https-click-linksynergy-com-fs-bin-click-id-lvarvwc5bd0-offerid-495576-248-type-3-subid-0&#34;&gt;3. &lt;a href=&#34;https://click.linksynergy.com/fs-bin/click?id=lVarvwc5BD0&amp;amp;offerid=495576.248&amp;amp;type=3&amp;amp;subid=0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;CS229: Andrew Ng&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;After doing these two above courses you will gain the status of what I would like to call a &lt;strong&gt;&amp;ldquo;Beginner&amp;rdquo;&lt;/strong&gt;. Congrats!!!. &lt;em&gt;You know stuff, you know how to implement stuff&lt;/em&gt;. Yet you do not fully understand all the math and grind that goes behind all this.&lt;/p&gt;

&lt;p&gt;Here comes the Game Changer machine learning course. Contains the maths behind many of the Machine Learning algorithms.  I will put this course as the &lt;em&gt;one course you gotta take&lt;/em&gt; as this course motivated me into getting in this field and Andrew Ng is a great instructor. Also this was the first course that I took.&lt;/p&gt;

&lt;p&gt;Also recently Andrew Ng Released a new Book. You can get the Draft chapters by subcribing on his website &lt;a href=&#34;http://www.mlyearning.org/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You are done with the three musketeers of the trade. You know Python, you understand Statistics and you have gotten the taste of the math behind ML approaches. Now it is time for the new kid on the block. D&amp;rsquo;artagnan. This kid has skills. While the three musketeers are masters in their trade, this guy brings qualities that adds a new freshness to our data science journey. Here comes Big Data for you.&lt;/p&gt;

&lt;h2 id=&#34;4-intro-to-hadoop-mapreduce-udacity-https-www-udacity-com-course-intro-to-hadoop-and-mapreduce-ud617&#34;&gt;4. &lt;a href=&#34;https://www.udacity.com/course/intro-to-hadoop-and-mapreduce--ud617&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Intro to Hadoop &amp;amp; Mapreduce - Udacity&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Let us first focus on the literal elephant in the room - Hadoop.&lt;/em&gt; Short and Easy Course. Taught the Fundamentals of Hadoop streaming with Python. Taken by Cloudera on Udacity. I am doing much more advanced stuff with python and Mapreduce now but this is one of the courses that laid the foundation there.&lt;/p&gt;

&lt;p&gt;Once  you are done through this course you would have gained quite a basic understanding of concepts and you would have installed a Hadoop VM in your own machine. You would also have solved the Basic Wordcount Problem.
Read this amazing Blog Post from Michael Noll: &lt;a href=&#34;http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Writing An Hadoop MapReduce Program In Python - Michael G. Noll&lt;/a&gt;.  Just read the basic mapreduce codes. Don&amp;rsquo;t use Iterators and Generators yet. This has been a starting point for many of us Hadoop developers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Now try to solve these two problems from the CS109 Harvard course from 2013:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A.&lt;/strong&gt; First, grab the file word_list.txt from &lt;a href=&#34;https://raw.github.com/cs109/content/master/labs/lab8/word_list.txt&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.  This contains a list of six-letter words. To keep things simple, all of  the words consist of lower-case letters only.Write a mapreduce job that  finds all anagrams in word_list.txt.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;B.&lt;/strong&gt; For the next problem, download the file &lt;a href=&#34;https://raw.github.com/cs109/content/master/labs/lab8/baseball_friends.csv&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;baseball_friends.csv&lt;/a&gt;. Each row of this csv file contains the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A person&amp;rsquo;s name&lt;/li&gt;
&lt;li&gt;The team that person is rooting for &amp;ndash; either &amp;ldquo;Cardinals&amp;rdquo; or &amp;ldquo;Red Sox&amp;rdquo;&lt;/li&gt;
&lt;li&gt;A list of that person&amp;rsquo;s friends, which could have arbitrary length&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;For  example:&lt;/em&gt; The first line tells us that Aaden is a Red Sox friend and he  has 65  friends, who are all listed here. For this problem, it&amp;rsquo;s safe to  assume  that all of the names are unique and that the friendship  structure is  symmetric (i.e. if Alannah shows up in Aaden&amp;rsquo;s friends list, then Aaden will show up in Alannah&amp;rsquo;s friends list).
Write  an mr job that lists each person&amp;rsquo;s name, their favorite  team, the  number of Red Sox fans they are friends with, and the number  of  Cardinals fans they are friends with.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Try to do this yourself.&lt;/strong&gt; Don&amp;rsquo;t use the mrjob (pronounced Mr. Job) way that  they use in the CS109 2013 class. Use the proper Hadoop Streaming way as taught in the Udacity class as it is much more customizable in the long run.&lt;/p&gt;

&lt;p&gt;If you are done with these, you can safely call yourself as someone who could &lt;strong&gt;&amp;ldquo;think in Mapreduce&amp;rdquo;&lt;/strong&gt; as how people like to call it.Try to do groupby, filter and joins using Hadoop. You can read up some good tricks from my blog:&lt;br&gt;
&lt;a href=&#34;https://mlwhiz.com/blog/2015/05/09/hadoop_mapreduce_streaming_tricks_and_techniques/&#34;&gt;Hadoop Mapreduce Streaming Tricks and Techniques&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If you are someone who likes learning from a book you can get:
&lt;div style=&#34;margin-left:1em ; text-align: center;&#34;&gt;
&lt;a href=&#34;https://www.amazon.com/Hadoop-Definitive-Storage-Analysis-Internet/dp/1491901632/ref=as_li_ss_il?s=books&amp;ie=UTF8&amp;qid=1490543345&amp;sr=1-1&amp;keywords=hadoop+python&amp;linkCode=li2&amp;tag=mlwhizcon-20&amp;linkId=e0a6c64497866b874326afa08a069654&#34; target=&#34;_blank&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1491901632&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li2&amp;o=1&amp;a=1491901632&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;h2 id=&#34;5-spark-in-memory-big-data-tool&#34;&gt;5. Spark - In memory Big Data tool.&lt;/h2&gt;

&lt;p&gt;Now  comes the next part of your learning process. This should be undertaken after a little bit of experience with Hadoop. Spark will provide you with the speed and tools that Hadoop couldn&amp;rsquo;t.&lt;/p&gt;

&lt;p&gt;Now Spark is used for data preparation as well as Machine learning purposes. I would encourage you to take a look at the series of courses on edX provided by Berkeley instructors. This course delivers on what it says. It teaches Spark. Total beginners will have difficulty following the course as the course progresses very fast. That said anyone with a decent understanding of how big data works will be OK.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.edx.org/xseries/data-science-engineering-apacher-sparktm&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Data Science and Engineering with Apache® Spark™&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have written a little bit about Basic data processing with Spark here. Take a look:
&lt;a href=&#34;https://mlwhiz.com/blog/2015/09/07/spark_basics_explained/&#34;&gt;Learning Spark using Python: Basics and Applications&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Also take a look at some of the projects I did as part of course at &lt;a href=&#34;http://www.github.com/MLWhiz/Spark_Projects/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;github&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If you would like a book to read:
&lt;div style=&#34;margin-left:1em ; text-align: center;&#34;&gt;
&lt;a href=&#34;https://www.amazon.com/Advanced-Analytics-Spark-Patterns-Learning/dp/1491912766/ref=as_li_ss_il?s=books&amp;ie=UTF8&amp;qid=1490543902&amp;sr=1-1&amp;keywords=spark+python&amp;linkCode=li2&amp;tag=mlwhizcon-20&amp;linkId=85591cf408de278e23e8570b7e9c284b&#34; target=&#34;_blank&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1491912766&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li2&amp;o=1&amp;a=1491912766&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;If you don&amp;rsquo;t go through the courses, &lt;strong&gt;try solving the same two problems above that you solved by Hadoop using Spark too&lt;/strong&gt;. Otherwise the problem sets in the courses are more than enough.&lt;/p&gt;

&lt;h2 id=&#34;6-understand-linux-shell&#34;&gt;6. Understand Linux Shell:&lt;/h2&gt;

&lt;p&gt;Shell is a big friend for data scientists. It allows you to do simple data related tasks in the terminal itself. I couldn&amp;rsquo;t emphasize how much time shell saves for me everyday.&lt;/p&gt;

&lt;p&gt;Read these tutorials by me for doing that:&lt;br&gt;
&lt;a href=&#34;https://mlwhiz.com/blog/2015/10/09/shell_basics_for_data_science/&#34;&gt;Shell Basics every Data Scientist Should know -Part I&lt;/a&gt;
&lt;a href=&#34;https://mlwhiz.com/blog/2015/10/11/shell_basics_for_data_science_2/&#34;&gt;Shell Basics every Data Scientist Should know - Part II(AWK)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If you would like a course you can go for &lt;a href=&#34;https://www.edx.org/course/introduction-linux-linuxfoundationx-lfs101x-1#!&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;this course on edX&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you want a book, go for:&lt;/p&gt;

&lt;div style=&#34;margin-left:1em ; text-align: center;&#34;&gt;
&lt;a href=&#34;https://www.amazon.com/Linux-Command-Line-Complete-Introduction/dp/1593273894/ref=as_li_ss_il?s=books&amp;ie=UTF8&amp;qid=1490544715&amp;sr=1-1&amp;keywords=the+linux+command+line&amp;linkCode=li2&amp;tag=mlwhizcon-20&amp;linkId=9f155a16f16c7ae34e682e0e0312ee8f&#34; target=&#34;_blank&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1593273894&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li2&amp;o=1&amp;a=1593273894&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Congrats you are an &amp;ldquo;Hacker&amp;rdquo; now.&lt;/strong&gt; You have got all the main tools in your belt to be a data scientist. On to more advanced topics. From here it depends on you what you want to learn. You may want to take a totally different approach than what I took going from here. There is no particular order. &lt;strong&gt;&amp;ldquo;All Roads lead to Rome&amp;rdquo;&lt;/strong&gt; as long as you are running.&lt;/p&gt;

&lt;h2 id=&#34;7-learn-statistical-inference-and-bayesian-statistics-https-click-linksynergy-com-fs-bin-click-id-lvarvwc5bd0-offerid-467035-204-type-3-subid-0&#34;&gt;7. &lt;a href=&#34;https://click.linksynergy.com/fs-bin/click?id=lVarvwc5BD0&amp;amp;offerid=467035.204&amp;amp;type=3&amp;amp;subid=0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Learn Statistical Inference and Bayesian Statistics&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;I took the previous version of the specialization which was a single course taught by Mine Çetinkaya-Rundel. She is a great instrucor and explains the fundamentals of Statistical inference nicely. A must take course. You will learn about hypothesis testing, confidence intervals, and statistical inference methods for numerical and categorical data.
You can also use these books:&lt;/p&gt;

&lt;div style=&#34;margin-left:1em ; text-align: center;&#34;&gt;
&lt;a href=&#34;https://www.amazon.com/dp/1943450056/ref=as_li_ss_il?m=A3EEBE82C3HYRD&amp;linkCode=li2&amp;tag=mlwhizcon-20&amp;linkId=cfd246ebddfde379bc01dcb2c467c199&#34; target=&#34;_blank&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1943450056&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li2&amp;o=1&amp;a=1943450056&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;
&lt;/t&gt;&lt;/t&gt;
&lt;a href=&#34;https://www.amazon.com/Probability-Statistics-4th-Morris-DeGroot/dp/0321500466/ref=as_li_ss_il?ie=UTF8&amp;qid=1490547535&amp;sr=8-1&amp;keywords=degroot+statistics&amp;linkCode=li2&amp;tag=mlwhizcon-20&amp;linkId=fc106a3b8c56be8baf34793816762ec8&#34; target=&#34;_blank&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=0321500466&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li2&amp;o=1&amp;a=0321500466&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;
&lt;/div&gt;

&lt;h2 id=&#34;8-deep-learning&#34;&gt;8. Deep Learning&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.fast.ai/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Intro&lt;/a&gt; - Making neural nets uncool again. An awesome Deep learning class from Kaggle Master Jeremy Howard. Entertaining and enlightening at the same time.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://cs231n.github.io/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Advanced&lt;/a&gt; - A series of notes from the Stanford CS class CS231n: Convolutional Neural Networks for Visual Recognition.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://neuralnetworksanddeeplearning.com/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Bonus&lt;/a&gt; - A free online book by Michael Nielsen.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://amzn.to/2npItnM&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Advanced Math Book&lt;/a&gt; - A math intensive book by Yoshua Bengio &amp;amp; Ian Goodfellow&lt;/p&gt;

&lt;h2 id=&#34;9-algorithms-graph-algorithms-recommendation-systems-pagerank-and-more-https-www-youtube-com-watch-v-xoa5v9ao7s0-list-pllsst5z-dsk9jdlct8t62vtzwyw9lnepv&#34;&gt;9. &lt;a href=&#34;https://www.youtube.com/watch?v=xoA5v9AO7S0&amp;amp;list=PLLssT5z_DsK9JDLcT8T62VtzwyW9LNepV&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Algorithms, Graph Algorithms, Recommendation Systems, Pagerank and More&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;This course used to be there on Coursera but now only video links on youtube available.
You can learn from this book too:
&lt;div style=&#34;margin-left:1em ; text-align: center;&#34;&gt;
&lt;a href=&#34;https://www.amazon.com/Mining-Massive-Datasets-Jure-Leskovec/dp/1107077230/ref=as_li_ss_il?ie=UTF8&amp;linkCode=li2&amp;tag=mlwhizcon-20&amp;linkId=ba893a022640a279d427fd0c5ea44c1a&#34; target=&#34;_blank&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1107077230&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li2&amp;o=1&amp;a=1107077230&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;Apart from that if you want to learn about Python and the basic intricacies of the language you can take the &lt;strong&gt;&lt;a href=&#34;https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;amp;offerid=495576.1921197134&amp;amp;type=2&amp;amp;murl=https%3A%2F%2Fwww.coursera.org%2Fspecializations%2Fcomputer-fundamentals&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Computer Science Mini Specialization from RICE university&lt;/a&gt;&lt;/strong&gt; too. This is a series of 6 short but good courses. I worked on these courses as Data science will require you to do a lot of programming. And the best way to learn programming is by doing programming. The lectures are good but the problems and assignments are awesome. If you work on this you will learn Object Oriented Programming,Graph algorithms and games in Python. Pretty cool stuff.&lt;/p&gt;

&lt;h2 id=&#34;10-advanced-maths&#34;&gt;10. Advanced Maths:&lt;/h2&gt;

&lt;p&gt;Couldn&amp;rsquo;t write enough of the importance of Math. But here are a few awesome resources that you can go for.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Linear Algebra By Gilbert Strang&lt;/a&gt; - A Great Class by a great Teacher. I Would definitely recommend this class to anyone who wants to learn LA.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://ocw.mit.edu/courses/mathematics/18-02sc-multivariable-calculus-fall-2010/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Multivariate Calculus - MIT OCW&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://lagunita.stanford.edu/courses/Engineering/CVX101/Winter2014/about&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Convex Optimization&lt;/a&gt; - a MOOC on optimization from Stanford, by Steven Boyd, an authority on the subject.&lt;/p&gt;

&lt;p&gt;The Machine learning field is evolving and new advancements are made every day. That&amp;rsquo;s why I didn&amp;rsquo;t put a third tier. The maximum I can call myself is a &amp;ldquo;Hacker&amp;rdquo; and my learning continues. Hope you do the same.&lt;/p&gt;

&lt;p&gt;Hope you like this list. Please provide your inputs in comments on more learning resources as you see fit.&lt;/p&gt;

&lt;p&gt;Till then. Ciao!!!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Basics Of Linear Regression</title>
      <link>https://mlwhiz.com/blog/2017/03/23/basics_of_linear_regression/</link>
      <pubDate>Thu, 23 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2017/03/23/basics_of_linear_regression/</guid>
      <description>

&lt;p&gt;Today we will look into the basics of linear regression. Here we go :&lt;/p&gt;

&lt;h2 id=&#34;contents&#34;&gt;Contents&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Simple Linear Regression (SLR)&lt;/li&gt;
&lt;li&gt;Multiple Linear Regression (MLR)&lt;/li&gt;
&lt;li&gt;Assumptions&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;1-simple-linear-regression&#34;&gt;1. Simple Linear Regression&lt;/h2&gt;

&lt;p&gt;Regression is the process of building a relationship between a dependent variable and set of independent variables. Linear Regression restricts this relationship to be linear in terms of coefficients. In SLR, we consider only one independent variable.&lt;/p&gt;

&lt;h3 id=&#34;example-the-waist-circumference-adipose-tissue-data&#34;&gt;Example: The Waist Circumference – Adipose Tissue data&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Studies have shown that individuals with excess Adipose tissue (AT) in the abdominal region have a higher risk of cardio-vascular diseases&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Computed Tomography, commonly called the CT Scan is the only technique that allows for the precise and reliable measurement of the AT (at any site in the body)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The problems with using the CT scan are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Many physicians do not have access to this technology&lt;/li&gt;
&lt;li&gt;Irradiation of the patient (suppresses the immune system)&lt;/li&gt;
&lt;li&gt;Expensive&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Is there a simpler yet reasonably accurate way to predict the AT area? i.e.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Easily available&lt;/li&gt;
&lt;li&gt;Risk free&lt;/li&gt;
&lt;li&gt;Inexpensive&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A group of researchers  conducted a study with the aim of predicting abdominal AT area using simple anthropometric measurements i.e. measurements on the human body&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The Waist Circumference – Adipose Tissue data is a part of this study wherein the aim is to study how well waist circumference(WC) predicts the AT area&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Setting working directory&lt;/span&gt;
filepath &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/Users/nkaveti/Documents/Work_Material/Statistics Learning/&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;setwd&lt;/span&gt;(filepath)

&lt;span style=&#34;color:#75715e&#34;&gt;# Reading data&lt;/span&gt;
Waist_AT &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; read.csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;adipose_tissue.csv&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Number of rows: &amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(Waist_AT), &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\n&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;head&lt;/span&gt;(Waist_AT)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Number of rows:  109
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;&lt;th scope=col&gt;Waist&lt;/th&gt;&lt;th scope=col&gt;AT&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;&lt;td&gt;74.75&lt;/td&gt;&lt;td&gt;25.72&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;72.60&lt;/td&gt;&lt;td&gt;25.89&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;81.80&lt;/td&gt;&lt;td&gt;42.60&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;83.95&lt;/td&gt;&lt;td&gt;42.80&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;74.65&lt;/td&gt;&lt;td&gt;29.84&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;71.85&lt;/td&gt;&lt;td&gt;21.68&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Let&amp;rsquo;s start with a scatter plot of &lt;strong&gt;Waist&lt;/strong&gt; Vs &lt;strong&gt;AT&lt;/strong&gt;, to understand the relationship between these two variables.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;plot(AT &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; Waist, data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Waist_AT)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/output_6_0.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Any observations from above plot?&lt;/p&gt;

&lt;p&gt;Now the objective is to find a linear relation between &lt;code&gt;Waist&lt;/code&gt; and &lt;code&gt;AT&lt;/code&gt;. In otherwords, finding the amount of change in &lt;code&gt;AT&lt;/code&gt; per one unit change (increment/decrement) in &lt;code&gt;Waist&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;In SLR, it is equivalent to finding an optimal straight line equation such that the sum of squares of differences between straight line and the points will be minimum. This method of estimation is called as &lt;a href=&#34;https://en.wikipedia.org/wiki/Ordinary_least_squares&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Ordiany Least Squares (OLS)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;$$AT  = \beta_0 + \beta_1 \ Waist + \epsilon$$&lt;/p&gt;

&lt;div&gt;$$Min_{\beta_0 , \beta_1} \ \ \epsilon^\intercal \epsilon \implies Min_{\beta_0 , \beta_1} \ \ (AT  - \beta_0 - \beta_1 \ Waist)^\intercal (AT  - \beta_0 - \beta_1 \ Waist)$$&lt;/div&gt;

&lt;p&gt;Where, $\beta_1$ represents the amount of change in &lt;code&gt;AT&lt;/code&gt; per one unit change in &lt;code&gt;Waist&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Now our problem becomes an unconstrained optimization problem. We can find optimal values for $\beta_0$ and $\beta_1$ using basic calculus.&lt;/p&gt;

&lt;p&gt;Lets re-write above regression equation in matrix form&lt;/p&gt;

&lt;p&gt;$$ AT = X \beta + \epsilon$$&lt;/p&gt;

&lt;p&gt;Where, $ X = [1 \ \ Waist]$ 1 is a vector of ones and $\beta = (\beta_0, \ \beta_1)$&lt;/p&gt;

&lt;p&gt;$$
\begin{equation}
\begin{split}
\epsilon^\intercal \epsilon &amp;amp; = {(AT - X \beta)}^\intercal {(AT - X \beta)} &lt;br /&gt;
&amp;amp; = AT^\intercal AT - AT^\intercal X \beta - {(X \beta)}^\intercal AT + {(X \beta)}^\intercal (X \beta)
\end{split}
\end{equation}
$$&lt;/p&gt;

&lt;p&gt;Now differentiate this w.r.t to $\beta$ and equate it to zero. Then we have,
$$\hat{\beta} = (X^\intercal X)^{-1} X^\intercal AT $$&lt;/p&gt;

&lt;p&gt;Now we can find the fitted values of model by substituting $\hat{\beta}$ in above regression equation
$$\hat{AT} = X \hat{\beta}=X(X^\intercal X)^{-1} X^\intercal AT$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; We are arriving to above equation through an assumption&lt;a href=&#34;#Assumptions&#34;&gt;$^1$&lt;/a&gt; of $E(\epsilon)=0$. What happens if this assumption violates?&lt;/p&gt;

&lt;p&gt;Let, $X(X^\intercal X)^{-1} X^\intercal = H$
$$\hat{AT} = H \ AT$$&lt;/p&gt;

&lt;p&gt;We call H as an hat matrix, because it transforms $AT$ into $\hat{AT}$ :D&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Lets compute the hat matrix&lt;/span&gt;
X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;cbind&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, Waist_AT&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;Waist)
temp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;solve&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;t&lt;/span&gt;(X) &lt;span style=&#34;color:#f92672&#34;&gt;%*%&lt;/span&gt; X) &lt;span style=&#34;color:#f92672&#34;&gt;%*%&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;t&lt;/span&gt;(X)
betahat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; temp &lt;span style=&#34;color:#f92672&#34;&gt;%*%&lt;/span&gt; Waist_AT&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;AT &lt;span style=&#34;color:#75715e&#34;&gt;# Estimated coefficients&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Let&amp;#39;s compare the computed values with lm() output: \n \n&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Computed Coefficients: \n \n&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;data.frame&lt;/span&gt;(Intercept &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; betahat[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], Waist &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; betahat[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]))
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;======================================================================= \n&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;#cat(&amp;#34;Optimal value for beta_0 is: &amp;#34;, betahat[1], &amp;#34;and for beta_1 is: &amp;#34;, betahat[2], &amp;#34;\n \n&amp;#34;)&lt;/span&gt;
fit_lm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lm(AT &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; Waist, data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Waist_AT)
&lt;span style=&#34;color:#75715e&#34;&gt;#cat(&amp;#34;Compare our computed estimates with lm() estimates&amp;#34;, &amp;#34;\n&amp;#34;)&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(fit_lm)
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;======================================================================= \n \n&amp;#34;&lt;/span&gt;)
H &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;%*%&lt;/span&gt; temp &lt;span style=&#34;color:#75715e&#34;&gt;# Computing hat matrix&lt;/span&gt;
AThat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; H &lt;span style=&#34;color:#f92672&#34;&gt;%*%&lt;/span&gt; Waist_AT&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;AT &lt;span style=&#34;color:#75715e&#34;&gt;# Computing predicted values&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Therefore, there is a&amp;#34;&lt;/span&gt;, betahat[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;increment in AT per one unit change in Waist \n&amp;#34;&lt;/span&gt; )&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Let&#39;s compare the computed values with lm() output:

Computed Coefficients:

  Intercept    Waist
1 -215.9815 3.458859
=======================================================================

Call:
lm(formula = AT ~ Waist, data = Waist_AT)

Coefficients:
(Intercept)        Waist
   -215.981        3.459

=======================================================================

Therefore, there is a 3.458859 increment in AT per one unit change in Waist
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;what-s-next&#34;&gt;What&amp;rsquo;s next?&lt;/h2&gt;

&lt;p&gt;We succesfully computed estimates for regression coefficients and fitted values.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;We are working on only one sample, how can we generalise these results to population?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;How to measure model&amp;rsquo;s performance quantitatively?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;**  We are working on only one sample, how can we generalise these results to population? **&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s focus on question 1. Our regression coefficients are computed using only one sample and these values will change, if we change the sample. But how much they vary? We need to estimate the variation for each beta coefficient to check whether the corresponding regressor is consistently explaining the same behaviour even if we change the sample.&lt;/p&gt;

&lt;p&gt;Now the big problem is collecting multiple samples to check the above hypothesis. Hence, we use distributions to check statistical significance of regressors.&lt;/p&gt;

&lt;p&gt;For our example, we need to test below two hypotheses.&lt;/p&gt;

&lt;p&gt;$$ Null \ Hypothesis: \beta_{0} = 0 $$&lt;/p&gt;

&lt;p&gt;$$ Alternative \ Hypothesis: \beta_{0} \neq 0$$&lt;/p&gt;

&lt;p&gt;$$ Null \ Hypothesis: \beta_{1} = 0 $$&lt;/p&gt;

&lt;p&gt;$$ Alternative \ Hypothesis: \beta_{1} \neq 0$$&lt;/p&gt;

&lt;p&gt;Test Statistic for these hypotheses is,&lt;/p&gt;

&lt;p&gt;$$t = \frac{\hat{\beta&lt;em&gt;{i}}}{\sqrt{Var(\hat{\beta&lt;/em&gt;{i}})}}$$&lt;/p&gt;

&lt;p&gt;Test statistic &lt;code&gt;t&lt;/code&gt; follows &lt;code&gt;t-distribution&lt;/code&gt;, assuming&lt;a href=&#34;#Assumptions&#34;&gt;$^2$&lt;/a&gt; dependent variable follows &lt;code&gt;normal distribution&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Suggestion:&lt;/strong&gt; If your not aware of &lt;a href=&#34;https://en.wikipedia.org/wiki/Statistical_hypothesis_testing&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;testing of hypothesis&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/Probability_distribution&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;probability distributions&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/P-value&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;p-values&lt;/a&gt; please browse through the Google.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s recall that,  $\hat{\beta} = (X^\intercal X)^{-1} X^\intercal AT$&lt;/p&gt;

&lt;p&gt;$$\begin{equation}
\begin{split}
Var(\hat{\beta}) &amp;amp; = Var((X^\intercal X)^{-1} X^\intercal AT) &lt;br /&gt;
 &amp;amp; = (X^\intercal X)^{-1} X^\intercal \ Var(AT) \ X(X^\intercal X)^{-1} &lt;br /&gt;
 &amp;amp; = (X^\intercal X)^{-1} X^\intercal \ X(X^\intercal X)^{-1} \ \sigma^2 &lt;br /&gt;
 &amp;amp; = (X^\intercal X)^{-1} \sigma^2
\end{split}
\end{equation}
$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; In the above calculations we assumed&lt;a href=&#34;#Assumptions&#34;&gt;$^3$&lt;/a&gt; $Var(AT) = \sigma^2$ (Constant). Where, $\sigma^2$ is variation in population AT.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Suggestion:&lt;/strong&gt; Try solving $(X^\intercal X)^{-1}$ with $X = [1, \  x]$ where $x = (x_1, x_2, x_3 &amp;hellip; x_n)$. You will get the following expression.&lt;/p&gt;

&lt;div&gt;$$
\
Var(\hat{\beta}) =
\frac{1}{n \sum x_i^2 - (\sum x_i)^2}
\begin{bmatrix}
    \sum_{i=1}^n x_i^2 &amp; -\sum x_i \\
    -\sum x_i &amp; n
\end{bmatrix}
\sigma^2
\
$$&lt;/div&gt;

&lt;p&gt;Diagonal elements of above matrix are varinaces of $\beta_0$ and $\beta_1$ respectively. Off-diagonal element is covariance between $\beta_0$ and $\beta_1$.&lt;/p&gt;

&lt;p&gt;Hence,&lt;/p&gt;

&lt;div&gt;
$$Var(\hat{\beta_0}) = \frac{\sigma^2 \sum_{i = 1}^n x_i^2}{n \sum_{i = 1}^n (x_i - \bar{x})^2}$$
&lt;/div&gt;

&lt;div&gt;
$$Var(\hat{\beta_1}) = \frac{\sigma^2}{\sum_{i = 1}^n (x_i - \bar{x})^2}$$
&lt;/div&gt;

&lt;p&gt;One important observation from $Var(\hat{\beta})$ expressions is, $Var(x)$ is inversely proportional to $Var(\hat{\beta})$. That is, we will get more consistent estimators if there is high variation in corresponding predictors.&lt;/p&gt;

&lt;p&gt;Recall that, $\sigma^2$ in above expression is the population variance, not the sample. Hence, we need to estimate this using the sample that we have.&lt;/p&gt;

&lt;p&gt;$$\hat{\sigma^2} = \frac{1}{n-2} \sum_{i = 1}^n e_i^2$$&lt;/p&gt;

&lt;p&gt;Where, $e_i = AT_i - \hat{AT}_i$&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Let&amp;#39;s compute variances of beta hat and test statistic &amp;#39;t&amp;#39;&lt;/span&gt;
sigmasq &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;length&lt;/span&gt;(AThat[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)]))&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;sum&lt;/span&gt;((AThat &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; Waist_AT&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;AT)&lt;span style=&#34;color:#f92672&#34;&gt;^&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
VarBeta0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (sigmasq &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sum&lt;/span&gt;(Waist_AT&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;Waist&lt;span style=&#34;color:#f92672&#34;&gt;^&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;length&lt;/span&gt;(AThat) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sum&lt;/span&gt;((Waist_AT&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;Waist &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;mean&lt;/span&gt;(Waist_AT&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;Waist))&lt;span style=&#34;color:#f92672&#34;&gt;^&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))
VarBeta1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sigmasq&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;sum&lt;/span&gt;((Waist_AT&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;Waist &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;mean&lt;/span&gt;(Waist_AT&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;Waist))&lt;span style=&#34;color:#f92672&#34;&gt;^&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Let&amp;#39;s compare the computed values with lm() output: \n \n&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;======================================================================= \n&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Computed Coefficients: \n \n&amp;#34;&lt;/span&gt;)
res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;data.frame&lt;/span&gt;(Estimate &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; betahat, Std.Error &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;sqrt&lt;/span&gt;(VarBeta0), &lt;span style=&#34;color:#66d9ef&#34;&gt;sqrt&lt;/span&gt;(VarBeta1)), t_value &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(betahat[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;sqrt&lt;/span&gt;(VarBeta0), betahat[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;sqrt&lt;/span&gt;(VarBeta1)))
&lt;span style=&#34;color:#66d9ef&#34;&gt;row.names&lt;/span&gt;(res) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;(Intercept)&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Waist&amp;#34;&lt;/span&gt;)
res&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;p_value &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;pt(&lt;span style=&#34;color:#66d9ef&#34;&gt;abs&lt;/span&gt;(res&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;t_value), &lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(Waist_AT)&lt;span style=&#34;color:#ae81ff&#34;&gt;-1&lt;/span&gt;, lower.tail &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;FALSE&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(res)
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;=======================================================================&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;summary&lt;/span&gt;(fit_lm)
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;=======================================================================&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Let&#39;s compare the computed values with lm() output:

=======================================================================
Computed Coefficients:

               Estimate  Std.Error   t_value      p_value
(Intercept) -215.981488 21.7962708 -9.909103 7.507198e-17
Waist          3.458859  0.2346521 14.740376 1.297124e-27
=======================================================================



Call:
lm(formula = AT ~ Waist, data = Waist_AT)

Residuals:
     Min       1Q   Median       3Q      Max
-107.288  -19.143   -2.939   16.376   90.342

Coefficients:
             Estimate Std. Error t value Pr(&amp;gt;|t|)
(Intercept) -215.9815    21.7963  -9.909   &amp;lt;2e-16 ***
Waist          3.4589     0.2347  14.740   &amp;lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 33.06 on 107 degrees of freedom
Multiple R-squared:   0.67, Adjusted R-squared:  0.667
F-statistic: 217.3 on 1 and 107 DF,  p-value: &amp;lt; 2.2e-16



=======================================================================
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Residual standard error = $\sqrt{sigmasq}$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How to measure model&amp;rsquo;s performance quantitatively?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s focus on question 2 (How to measure model&amp;rsquo;s performance quantitatively?). Recall that, our objective of building model is to explain the variation in &lt;code&gt;AT&lt;/code&gt; using the variation in &lt;code&gt;Waist&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Total variation in AT is, $\sum_{i=1}^n (AT - mean(AT))^2$ this can be splitted into two parts as follows:&lt;/p&gt;

&lt;div&gt;
$$
\begin{equation}
\begin{split}
\sum_{i=1}^n (AT_i - \bar{AT})^2 &amp; = \sum_{i=1}^n (AT  - \hat{AT_i} + \hat{AT_i} - \bar{AT})^2 \\
&amp; = \sum_{i = 1}^n (\hat{AT_i} - \bar{AT})^2 + \sum_{i=1}^n (AT_i - \hat{AT_i})^2
\end{split}
\end{equation}
$$
&lt;/div&gt;

&lt;p&gt;Where, $\sum_{i=1}^n (AT_i - \bar{AT})^2$ is the total variation in AT, $\sum_{i = 1}^n (\hat{AT_i} - \bar{AT})^2$ is the explained variation in AT, this is also called as &lt;strong&gt;Regression Sum of Squares&lt;/strong&gt; and $\sum_{i=1}^n (AT_i - \hat{AT_i})^2$ is the unexplained variation in AT, this is also called as &lt;strong&gt;Error Sum of Squares&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We can measure our model using the proportion of total variation explained by independent variable(s). That is, $\frac{Regression \  Sum \ of \ Squares}{Total \ Sum \ of \ Squares}$&lt;/p&gt;

&lt;p&gt;The above measure is called as Multiple R-squared:&lt;/p&gt;

&lt;div&gt;
$$Multiple \ R-squared = \frac{\sum_{i = 1}^n (\hat{AT_i} - \bar{AT})^2}{\sum_{i=1}^n (AT_i - \bar{AT})^2}$$
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Interesting facts:&lt;/strong&gt; Multiple R-squared value in SLR is equals to $r^2$ and (1 - Multiple R-squared) is equals to the variance in residuals.&lt;/p&gt;

&lt;p&gt;Where, r is &lt;a href=&#34;https://en.wikipedia.org/wiki/Pearson_correlation_coefficient&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;pearson&amp;rsquo;s correlation coefficient&lt;/a&gt; between dependent and independent variable.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Let&amp;#39;s compute Multiple R-squared measure for our example&lt;/span&gt;
SSR &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sum&lt;/span&gt;((AThat &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;mean&lt;/span&gt;(Waist_AT&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;AT))&lt;span style=&#34;color:#f92672&#34;&gt;^&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
SST &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sum&lt;/span&gt;((Waist_AT&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;AT &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;mean&lt;/span&gt;(Waist_AT&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;AT))&lt;span style=&#34;color:#f92672&#34;&gt;^&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
MulRSq &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SSR&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;SST
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Compute Multiple R-squared: &amp;#34;&lt;/span&gt;, MulRSq, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\n \n&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Note that computed R squared value is matching with lm() Multiple R-squared value in above output \n \n&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;======================================================================= \n \n&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Compute Multiple R-squared:  0.6700369

Note that computed R squared value is matching with lm() Multiple R-squared value in above output

=======================================================================
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;What happens to the Multiple R-squared value when you add an irrelevant variable to the model?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In the below model, I am generating a random sample of uniform numbers between 1 to 100 and considering this as one of indepedent variable.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;set.seed&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1234&lt;/span&gt;)
fit_lm2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lm(AT &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; Waist &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; runif(&lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(Waist_AT), &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;), data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Waist_AT)
&lt;span style=&#34;color:#66d9ef&#34;&gt;summary&lt;/span&gt;(fit_lm2)
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;======================================================================= \n \n&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Call:
lm(formula = AT ~ Waist + runif(nrow(Waist_AT), 1, 100), data = Waist_AT)

Residuals:
    Min      1Q  Median      3Q     Max
-106.06  -17.53   -3.63   13.70   91.36

Coefficients:
                               Estimate Std. Error t value Pr(&amp;gt;|t|)
(Intercept)                   -226.2894    23.4350  -9.656 3.33e-16 ***
Waist                            3.5060     0.2376  14.757  &amp;lt; 2e-16 ***
runif(nrow(Waist_AT), 1, 100)    0.1397     0.1181   1.183    0.239
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 33 on 106 degrees of freedom
Multiple R-squared:  0.6743,  Adjusted R-squared:  0.6682
F-statistic: 109.7 on 2 and 106 DF,  p-value: &amp;lt; 2.2e-16



=======================================================================
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Multiple R-squared value increases irrespective of quality of explanation, which is incorrect. We should penalize our model performance if the quality of explanation is poor, that is why we need to adjust our R-squared value.&lt;/p&gt;

&lt;p&gt;To penalize the explained part of AT, we inflate the unexplained part of AT with $\frac{Total \ degrees \ of \ freedom}{Error \ degrees \ of \ freedom}$. That is,&lt;/p&gt;

&lt;p&gt;$$Adjusted \ R-squared = 1 - (1 - R^2) \frac{n-1}{n-p-1}$$&lt;/p&gt;

&lt;p&gt;Where, n = Total number of observations; p = Total number of predictors (excluding intercept)&lt;/p&gt;

&lt;p&gt;Adding a new independent variable will increase $\frac{n-1}{n-p-1}$ and $R^2$. If the amount of increment in $R^2$ is less than the amount of increment in $\frac{n-1}{n-p-1}$ than it will decrease the Adjusted R-squared value.&lt;/p&gt;

&lt;p&gt;In &lt;code&gt;fit_lm2&lt;/code&gt; model Adjusted R-squared decreases when we add randomly generated variable into the model.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Let&amp;#39;s compute adjusted R-squared  for our example&lt;/span&gt;
TDF &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(Waist_AT[&lt;span style=&#34;color:#ae81ff&#34;&gt;-1&lt;/span&gt;, ]) &lt;span style=&#34;color:#75715e&#34;&gt;# Total degrees of freedom&lt;/span&gt;
EDF &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(Waist_AT[&lt;span style=&#34;color:#ae81ff&#34;&gt;-1&lt;/span&gt;, ]) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# Error degrees of freedom, where 1 is the number of predictors&lt;/span&gt;
AdjRSq &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; MulRSq) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (TDF&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;EDF) &lt;span style=&#34;color:#75715e&#34;&gt;# Adjusted R square&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Compute Multiple R-squared: &amp;#34;&lt;/span&gt;, AdjRSq, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\n \n&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Note that computed Adjusted R-squared value is matching with lm() Adjusted R-squared value in the above output \n \n&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Note: We are comparing with fit_lm model, not fit_lm2 \n&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;======================================================================= \n&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Compute Multiple R-squared:  0.6669531

Note that computed Adjusted R-squared value is matching with lm() Adjusted R-squared value in the above output

Note: We are comparing with fit_lm model, not fit_lm2
=======================================================================
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Aforementioned measures (Multiple R-squared &amp;amp; Adjusted R-squared) for &lt;strong&gt;Goodness of fit&lt;/strong&gt; are functions of sample and these will vary as sample changes. Similar to &lt;code&gt;t-test&lt;/code&gt; for regression coefficeints we need some statistical test to test model&amp;rsquo;s performance for population.&lt;/p&gt;

&lt;p&gt;Objective is to compare the Mean sum of squares due to regression and Mean sum of squares due to error. &lt;code&gt;F-test&lt;/code&gt; is very helpful to compare the variations.&lt;/p&gt;

&lt;div&gt;$$ F-test = \frac{\frac{1}{p-1}\sum_{i=1}^n (\hat{AT_i} - \bar{AT})^2}{\frac{1}{n-p-1} \sum_{i=1}^n (\hat{AT_i} - AT_i)^2}$$
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Above expression follows F distribution only if, AT follows Normal Distribution&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;RDF &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; TDF &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; EDF
SSE &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SST &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; SSR
MSR &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;RDF)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;SSR
MSE &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;EDF)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;SSE
F_value &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MSR&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;MSE
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Compute F statistic: &amp;#34;&lt;/span&gt;, F_value, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\n \n&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Note that computed F-statistic is matching with lm() F-statistic value in the above output \n \n&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Note: We are comparing with fit_lm model, not fit_lm2 \n&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;======================================================================= \n&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Compute F statistic:  217.2787

Note that computed F-statistic is matching with lm() F-statistic value in the above output

Note: We are comparing with fit_lm model, not fit_lm2
=======================================================================
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;2-multiple-linear-regression-mlr&#34;&gt;2. Multiple Linear Regression (MLR)&lt;/h2&gt;

&lt;p&gt;In multiple linear regression we consider more than one predictor and one dependent variable. Most of the above explanation is valid for MLR too.&lt;/p&gt;

&lt;h3 id=&#34;example-car-s-mpg-miles-per-gallon-prediction&#34;&gt;Example: Car&amp;rsquo;s MPG (Miles Per Gallon) prediction&lt;/h3&gt;

&lt;p&gt;Our interest is to model the MPG of a car based on the other variables.&lt;/p&gt;

&lt;p&gt;Variable Description:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;VOL = cubic feet of cab space&lt;/li&gt;
&lt;li&gt;HP = engine horsepower&lt;/li&gt;
&lt;li&gt;MPG = average miles per gallon&lt;/li&gt;
&lt;li&gt;SP = top speed, miles per hour&lt;/li&gt;
&lt;li&gt;WT = vehicle weight, hundreds of pounds&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Reading Boston housing prices data&lt;/span&gt;
car &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; read.csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Cars.csv&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Number of rows: &amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;nrow&lt;/span&gt;(car), &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\n&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Number of variables: &amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;ncol&lt;/span&gt;(car), &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\n&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;head&lt;/span&gt;(car)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Number of rows:  81
 Number of variables:  5
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;&lt;th scope=col&gt;HP&lt;/th&gt;&lt;th scope=col&gt;MPG&lt;/th&gt;&lt;th scope=col&gt;VOL&lt;/th&gt;&lt;th scope=col&gt;SP&lt;/th&gt;&lt;th scope=col&gt;WT&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;&lt;td&gt;49      &lt;/td&gt;&lt;td&gt;53.70068&lt;/td&gt;&lt;td&gt;89      &lt;/td&gt;&lt;td&gt;104.1854&lt;/td&gt;&lt;td&gt;28.76206&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;55      &lt;/td&gt;&lt;td&gt;50.01340&lt;/td&gt;&lt;td&gt;92      &lt;/td&gt;&lt;td&gt;105.4613&lt;/td&gt;&lt;td&gt;30.46683&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;55      &lt;/td&gt;&lt;td&gt;50.01340&lt;/td&gt;&lt;td&gt;92      &lt;/td&gt;&lt;td&gt;105.4613&lt;/td&gt;&lt;td&gt;30.19360&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;70      &lt;/td&gt;&lt;td&gt;45.69632&lt;/td&gt;&lt;td&gt;92      &lt;/td&gt;&lt;td&gt;113.4613&lt;/td&gt;&lt;td&gt;30.63211&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;53      &lt;/td&gt;&lt;td&gt;50.50423&lt;/td&gt;&lt;td&gt;92      &lt;/td&gt;&lt;td&gt;104.4613&lt;/td&gt;&lt;td&gt;29.88915&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;70      &lt;/td&gt;&lt;td&gt;45.69632&lt;/td&gt;&lt;td&gt;89      &lt;/td&gt;&lt;td&gt;113.1854&lt;/td&gt;&lt;td&gt;29.59177&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Our objective is to model the variation in &lt;code&gt;MPG&lt;/code&gt; using other independent variables. That is,&lt;/p&gt;

&lt;p&gt;$$MPG = \beta_0 + \beta_1 VOL + \beta_2 HP + \beta_3 SP + \beta_4 WT + \epsilon$$&lt;/p&gt;

&lt;p&gt;Where, $\beta_1$ represents the amount of change in &lt;code&gt;MPG&lt;/code&gt; per one unit change in &lt;code&gt;VOL&lt;/code&gt; provided other variables are fixed. Let&amp;rsquo;s consider below two cases,&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Case1:&lt;/strong&gt; HP = 49; VOL = 89; SP = 104.1854; WT = 28.76206 =&amp;gt; MPG = 104.1854&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Case2:&lt;/strong&gt; HP = 49; VOL = 90; SP = 104.1854; WT = 28.76206 =&amp;gt; MPG = 105.2453&lt;/p&gt;

&lt;p&gt;then $\beta_1 = 105.2453 - 104.1854 = 1.0599$. Similarly, $\beta_2, \beta_3, \beta_4$&lt;/p&gt;

&lt;p&gt;The above effect is called as &lt;a href=&#34;https://en.wikipedia.org/wiki/Ceteris_paribus&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;Ceteris Paribus Effect&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But in real world it is very difficult to collect records in above manner. That&amp;rsquo;s why we compute (function of) partial correlation coefficients to quantify the effect of one variable, keeping others constant.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Let&amp;#39;s build MLR model to predict MPG based using other variables&lt;/span&gt;
fit_mlr_actual &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lm(MPG &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;.&lt;/span&gt;, data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; car)
&lt;span style=&#34;color:#66d9ef&#34;&gt;summary&lt;/span&gt;(fit_mlr_actual)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Call:
lm(formula = MPG ~ ., data = car)

Residuals:
     Min       1Q   Median       3Q      Max
-0.94530 -0.32792 -0.04058  0.24256  1.71034

Coefficients:
              Estimate Std. Error t value Pr(&amp;gt;|t|)
(Intercept)  7.100e-17  5.461e-02   0.000   1.0000
HP          -1.285e+00  2.453e-01  -5.239  1.4e-06 ***
VOL         -8.207e-01  1.389e+00  -0.591   0.5563
SP           6.144e-01  2.458e-01   2.500   0.0146 *
WT           3.287e-01  1.390e+00   0.237   0.8136
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.4915 on 76 degrees of freedom
Multiple R-squared:  0.7705,  Adjusted R-squared:  0.7585
F-statistic:  63.8 on 4 and 76 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;One key observation from above output is, Std. Error for &lt;code&gt;VOL&lt;/code&gt; and &lt;code&gt;WT&lt;/code&gt; is very huge comparing to others and this inflates &lt;code&gt;t values&lt;/code&gt; and &lt;code&gt;p value&lt;/code&gt;. Hence, these two variables becomes very insignificant for the model.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s go into deep, what happened to $Var(\hat{\beta_{VOL}})$ and $Var(\hat{\beta_{WT}})$?&lt;/p&gt;

&lt;p&gt;Analogy for $Var(\hat{\beta})$ in MLR is as follows:&lt;/p&gt;

&lt;div&gt;
$$Var(\hat{\beta_{VOL}}) = \frac{\sigma^2}{n\sum_{i=1}^n (VOL_i - \bar{VOL})^2 (1 - R_{VOL}^2)}$$
&lt;/div&gt;

&lt;p&gt;Where, $R_{VOL}^2$ = Multiple R-squared value obtained by regressing VOL on all other independent variables&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Task:&lt;/strong&gt; To understand it more clearly, take few random samples from cars data and run the MLR model and observe the variation in $\hat{\beta_{VOL}}$ and $\hat{\beta_{WT}}$.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Let&amp;#39;s regress VOL on all other independent variables&amp;#39;&lt;/span&gt;
fit_mlr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lm(VOL &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; HP &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; SP &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; WT, data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; car)
&lt;span style=&#34;color:#66d9ef&#34;&gt;summary&lt;/span&gt;(fit_mlr)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Call:
lm(formula = VOL ~ HP + SP + WT, data = car)

Residuals:
      Min        1Q    Median        3Q       Max
-0.068938 -0.031641 -0.008794  0.032018  0.077931

Coefficients:
              Estimate Std. Error t value Pr(&amp;gt;|t|)
(Intercept) -6.155e-18  4.481e-03   0.000    1.000
HP           2.331e-02  1.995e-02   1.168    0.246
SP          -2.294e-02  2.000e-02  -1.147    0.255
WT           9.998e-01  4.557e-03 219.396   &amp;lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.04033 on 77 degrees of freedom
Multiple R-squared:  0.9984,  Adjusted R-squared:  0.9984
F-statistic: 1.637e+04 on 3 and 77 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s surprising that, $R_{VOL}^2$ is 0.9984 and also only &lt;code&gt;WT&lt;/code&gt; is significant. That is, these two predictors (&lt;code&gt;VOL&lt;/code&gt; and &lt;code&gt;WT&lt;/code&gt;) are highly correlated. This inflates $Var(\hat{\beta_{VOL}})$ and thus &lt;code&gt;t value&lt;/code&gt;. We might be missing some of the important information because of high correlation between predictors. This problem is called as &lt;a href=&#34;https://en.wikipedia.org/wiki/Multicollinearity&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Multicollinearity&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One quick solution for this problem is to remove either &lt;code&gt;VOL&lt;/code&gt; or &lt;code&gt;WT&lt;/code&gt; from the model. Let&amp;rsquo;s compute partial correlation coeficient between &lt;code&gt;MPG&lt;/code&gt; and &lt;code&gt;VOL&lt;/code&gt; by removing the effect of &lt;code&gt;WT&lt;/code&gt; (say, $r_{MV.W}$) and partial correlation coeficient between &lt;code&gt;MPG&lt;/code&gt; and &lt;code&gt;WT&lt;/code&gt; by removing the effect of &lt;code&gt;VOL&lt;/code&gt; (say, $r_{MW.V}$).&lt;/p&gt;

&lt;p&gt;To compute $r_{MV.W}$ we need to compute the correlation between (a) part of &lt;code&gt;VOL&lt;/code&gt; which cannot be explained by &lt;code&gt;WT&lt;/code&gt; (regress &lt;code&gt;VOL&lt;/code&gt; on &lt;code&gt;WT&lt;/code&gt; and take the residuals) and (b) the part of &lt;code&gt;MPG&lt;/code&gt; which cannot be explained by &lt;code&gt;WT&lt;/code&gt; (regress &lt;code&gt;MPG&lt;/code&gt; on &lt;code&gt;WT&lt;/code&gt; and take the residuals)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;fit_partial &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lm(VOL &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; WT, data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; car)
fit_partial2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lm(MPG &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; WT, data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; car)
res1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fit_partial&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;residual
res2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fit_partial2&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;residual
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Partial correlation coefficient between MPG and VOL by removing the effect of WT is: &amp;#34;&lt;/span&gt;, cor(res1, res2))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Partial correlation coefficient between MPG and VOL by removing the effect of WT is:  -0.08008873
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;fit_partial3 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lm(WT &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; VOL, data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; car)
fit_partial4 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lm(MPG &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; VOL, data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; car)
res1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fit_partia3&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;residual
res2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fit_partial4&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;residual
&lt;span style=&#34;color:#66d9ef&#34;&gt;cat&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Partial correlation coefficient between MPG and WT by removing the effect of VOL is: &amp;#34;&lt;/span&gt;, cor(res1, res2))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Partial correlation coefficient between MPG and WT by removing the effect of VOL is:  0.05538241
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since, $abs(r_{MV.W}) &amp;gt;= abs(r_{MW.V})$ we may remove &lt;code&gt;WT&lt;/code&gt; from the model.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-R&#34; data-lang=&#34;R&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Remove WT and rerun the model&lt;/span&gt;
fit_mlr_actual2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lm(MPG &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;WT, data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; car)
&lt;span style=&#34;color:#66d9ef&#34;&gt;summary&lt;/span&gt;(fit_mlr_actual2)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Call:
lm(formula = MPG ~ . - WT, data = car)

Residuals:
     Min       1Q   Median       3Q      Max
-0.94036 -0.31695 -0.03457  0.23316  1.71570

Coefficients:
              Estimate Std. Error t value Pr(&amp;gt;|t|)
(Intercept)  7.910e-17  5.427e-02   0.000   1.0000
HP          -1.293e+00  2.415e-01  -5.353 8.64e-07 ***
VOL         -4.925e-01  5.516e-02  -8.928 1.65e-13 ***
SP           6.222e-01  2.421e-01   2.571   0.0121 *
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.4884 on 77 degrees of freedom
Multiple R-squared:  0.7704,  Adjusted R-squared:  0.7614
F-statistic: 86.11 on 3 and 77 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After eliminating &lt;code&gt;WT&lt;/code&gt; from the model there is an increment of ~0.3% in Adjusted R-squared and more importantly, &lt;code&gt;VOL&lt;/code&gt; becomes significant at 0 &lt;a href=&#34;https://en.wikipedia.org/wiki/Statistical_significance&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;los&lt;/a&gt; (level of significance)&lt;/p&gt;

&lt;p&gt;&lt;a id=&#39;Assumptions&#39;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;3-assumptions&#34;&gt;3. Assumptions&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Linear in Parameters:&lt;/strong&gt; We assume that there is a linear relation between dependent and set of independent variables&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Zero conditional mean:&lt;/strong&gt; $E(\epsilon \mid X) = 0$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Homoskedasticity:&lt;/strong&gt; $Var(\epsilon \mid X) = \sigma^2$ (Constant)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;No perfect Collinearity:&lt;/strong&gt; All predecitors must be independent among themselves&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;No serial correlation in errors:&lt;/strong&gt; Erros must be uncorrelated among themselves. In otherwords, observations or records must be independent of each other.&lt;/p&gt;

&lt;p&gt;We discussed first 4 assumptions in section 1 and 2.&lt;/p&gt;

&lt;p&gt;Here is a book that I recommend to learn more about this:&lt;/p&gt;

&lt;p&gt;&lt;a target=&#34;_blank&#34;  href=&#34;https://www.amazon.com/gp/product/1111531048/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1111531048&amp;linkCode=as2&amp;tag=nkaveti-20&amp;linkId=83f6e694209869322f8bfad406883d2f&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1111531048&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=nkaveti-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;//ir-na.amazon-adsystem.com/e/ir?t=nkaveti-20&amp;l=am2&amp;o=1&amp;a=1111531048&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Top advice for a Data Scientist</title>
      <link>https://mlwhiz.com/blog/2017/03/05/think_like_a_data_scientist/</link>
      <pubDate>Sun, 05 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2017/03/05/think_like_a_data_scientist/</guid>
      <description>

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/thinklikeds.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;A data scientist needs to be Critical and always on a lookout of something that misses others. So here are some advices that one can include in day to day data science work to be better at their work:&lt;/p&gt;

&lt;h2 id=&#34;1-beware-of-the-clean-data-syndrome&#34;&gt;1. Beware of the Clean Data Syndrome&lt;/h2&gt;

&lt;p&gt;You need to ask yourself questions even before you start working on the data. &lt;strong&gt;Does this data make sense?&lt;/strong&gt; Falsely assuming that the data is clean could lead you towards wrong Hypotheses. Apart from that, you can discern a lot of important patterns by looking at discrepancies in the data. For example, if you notice that a particular column has more than 50% values missing, you might think about not using the column. Or you may think that some of the data collection instrument has some error.&lt;/p&gt;

&lt;p&gt;Or let&amp;rsquo;s say you have a distribution of Male vs Female as 90:10 in a Female Cosmetic business. You may assume clean data and show the results as it is or you can use common sense and ask if the labels are switched.&lt;/p&gt;

&lt;h2 id=&#34;2-manage-outliers-wisely&#34;&gt;2. Manage Outliers wisely&lt;/h2&gt;

&lt;p&gt;Outliers can help you understand more about the people who are using your website/product 24 hours a day. But including them while building models will skew the models a lot.&lt;/p&gt;

&lt;h2 id=&#34;3-keep-an-eye-out-for-the-abnormal&#34;&gt;3. Keep an eye out for the Abnormal&lt;/h2&gt;

&lt;p&gt;Be on the &lt;strong&gt;lookout for something out of the obvious&lt;/strong&gt;. If you find something you may have hit gold.&lt;/p&gt;

&lt;p&gt;For example, &lt;a href=&#34;https://www.fastcompany.com/1783127/flickr-founders-glitch-can-game-wants-you-play-nice-be-blockbuster&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Flickr started up as a Multiplayer game&lt;/a&gt;. Only when the founders noticed that people were using it as a photo upload service, did they pivot.&lt;/p&gt;

&lt;p&gt;Another example: fab.com started up as fabulis.com, a site to help gay men meet people. One of the site&amp;rsquo;s popular features was the &amp;ldquo;Gay deal of the Day&amp;rdquo;. One day the deal was for Hamburgers - and half of the buyers were women. This caused the team to realize that there was a market for selling goods to women. So Fabulis pivoted to fab as a flash sale site for designer products.&lt;/p&gt;

&lt;h2 id=&#34;4-start-focussing-on-the-right-metrics&#34;&gt;4. Start Focussing on the right metrics&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Beware of Vanity metrics&lt;/strong&gt; For example, # of active users by itself doesn&amp;rsquo;t divulge a lot of information. I would rather say &amp;ldquo;5% MoM increase in active users&amp;rdquo; rather than saying &amp;ldquo; 10000 active users&amp;rdquo;. Even that is a vanity metric as active users would always increase. I would rather keep a track of percentage of users that are active to know how my product is performing.&lt;/li&gt;
&lt;li&gt;Try to find out a &lt;strong&gt;metric that ties with the business goal&lt;/strong&gt;. For example, Average Sales/User for a particular month.&lt;/li&gt;
&lt;/ul&gt;

&lt;script src=&#34;//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;5-statistics-may-lie-too&#34;&gt;5. Statistics may lie too&lt;/h2&gt;

&lt;p&gt;Be critical of everything that gets quoted to you. Statistics has been used to lie in advertisements, in workplaces and a lot of other marketing venues in the past. People will do anything to get sales or promotions.&lt;/p&gt;

&lt;p&gt;For example: &lt;a href=&#34;http://marketinglaw.osborneclarke.com/retailing/colgates-80-of-dentists-recommend-claim-under-fire/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Do you remember Colgate’s claim that 80% of dentists recommended their brand?&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This statistic seems pretty good at first. It turns out that at the time of surveying the dentists, they could choose several brands — not just one. So other brands could be just as popular as Colgate.&lt;/p&gt;

&lt;p&gt;Another Example: &lt;strong&gt;&amp;ldquo;99 percent Accurate&amp;rdquo; doesn&amp;rsquo;t mean shit&lt;/strong&gt;. Ask me to create a cancer prediction model and I could give you a 99 percent accurate model in a single line of code. How? Just predict &amp;ldquo;No Cancer&amp;rdquo; for each one. I will be accurate may be more than 99% of the time as Cancer is a pretty rare disease. Yet I have achieved nothing.&lt;/p&gt;

&lt;h2 id=&#34;6-understand-how-probability-works&#34;&gt;6. Understand how probability works&lt;/h2&gt;

&lt;p&gt;It happened during the summer of 1913 in a Casino in Monaco. Gamblers watched in amazement as a casino&amp;rsquo;s roulette wheel landed on black 26 times in a row. And since the probability of a Red vs Black is exactly half, they were certain that red was &amp;ldquo;due&amp;rdquo;. It was a field day for the Casino. A perfect example of &lt;a href=&#34;https://en.wikipedia.org/wiki/Gambler&#39;s_fallacy&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Gambler&amp;rsquo;s fallacy&lt;/a&gt;, aka the Monte Carlo fallacy.&lt;/p&gt;

&lt;p&gt;And This happens in real life. &lt;a href=&#34;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2538147&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;People tend to avoid long strings of the same answer&lt;/a&gt;. Sometimes sacrificing accuracy of judgment for the sake of getting a pattern of decisions that looks fairer or probable.&lt;/p&gt;

&lt;p&gt;For example, An admissions officer may reject the next application if he has approved three applications in a row, even if the application should have been accepted on merit.&lt;/p&gt;

&lt;h2 id=&#34;7-correlation-does-not-equal-causation&#34;&gt;7. Correlation Does Not Equal Causation&lt;/h2&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/corr_caus.png&#34;  height=&#34;400&#34; width=&#34;500&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;The Holy Grail of a Data scientist toolbox. To see something for what it is. Just because two variables move together in tandem doesn&amp;rsquo;t necessarily mean that one causes the another. There have been hilarious examples for this in the past. Some of my favorites are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Looking at the firehouse department data you infer that the more firemen are sent to a fire, the more damage is done.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;When investigating the cause of crime in New York City in the 80s, an academic found a strong correlation between the amount of serious crime committed and the amount of ice cream sold by street vendors! Obviously, there was an unobserved variable causing both. Summers are when the crime is the greatest and when the most ice cream is sold. So Ice cream sales don&amp;rsquo;t cause crime. Neither crime increases ice cream sales.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;8-more-data-may-help&#34;&gt;8. More data may help&lt;/h2&gt;

&lt;p&gt;Sometimes getting extra data may work wonders. You might be able to model the real world more closely by looking at the problem from all angles. Look for extra data sources.&lt;/p&gt;

&lt;p&gt;For example, Crime data in a city might help banks provide a better credit line to a person living in a troubled neighborhood and in turn increase the bottom line.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Machine Learning Algorithms for Data Scientists</title>
      <link>https://mlwhiz.com/blog/2017/02/05/ml_algorithms_for_data_scientist/</link>
      <pubDate>Sun, 05 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2017/02/05/ml_algorithms_for_data_scientist/</guid>
      <description>

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/mlago_fords.png&#34;  height=&#34;400&#34; width=&#34;600&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;As a data scientist I believe that a lot of work has to be done before Classification/Regression/Clustering methods are applied to the data you get. The data which may be messy, unwieldy and big. So here are the list of algorithms that helps a data scientist to make better models using the data they have:&lt;/p&gt;

&lt;h2 id=&#34;1-sampling-algorithms-in-case-you-want-to-work-with-a-sample-of-data&#34;&gt;1. Sampling Algorithms. In case you want to work with a sample of data.&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Simple Random Sampling :&lt;/strong&gt; &lt;em&gt;Say you want to select a subset of a population in which each member of the subset has an equal probability of being chosen.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stratified Sampling:&lt;/strong&gt; Assume that we need to estimate average number of votes for each candidate in an election. Assume that country has 3 towns : Town A has 1 million factory workers, Town B has 2 million workers and Town C has 3 million retirees. We can choose to get a random sample of size 60 over entire population but there is some chance that the random sample turns out to be not well balanced across these towns and hence is biased causing a significant error in estimation. Instead if we choose to take a random sample of 10, 20 and 30 from Town A, B and C respectively then we can produce a smaller error in estimation for the same total size of sample.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reservoir Sampling&lt;/strong&gt; :&lt;em&gt;Say you have a stream of items of large and unknown length that we can only iterate over once. Create an algorithm that randomly chooses an item from this stream such that each item is equally likely to be selected.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;2-map-reduce-if-you-want-to-work-with-the-whole-data&#34;&gt;2. &lt;strong&gt;Map-Reduce. If you want to work with the whole data&lt;/strong&gt;.&lt;/h2&gt;

&lt;p&gt;Can be used for feature creation. For Example: I had a use case where I had a graph of 60 Million customers and 130 Million accounts. Each account was connected to other account if they had the Same SSN or Same Name+DOB+Address. I had to find customer ID’s for each of the accounts. On a single node parsing such a graph took more than 2 days. On a Hadoop cluster of 80 nodes running a &lt;em&gt;Connected Component Algorithm&lt;/em&gt; took less than 24 minutes. On Spark it is even faster.&lt;/p&gt;

&lt;h2 id=&#34;3-graph-algorithms&#34;&gt;3. &lt;strong&gt;Graph Algorithms.&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Recently I was working on an optimization problem which was focussed on finding shortest distance and routes between two points in a store layout. Routes which don’t pass through different aisles, so we cannot use euclidean distances. We solved this problem by considering turning points in the store layout and the &lt;em&gt;djikstra’s Algorithm.&lt;/em&gt;&lt;/p&gt;

&lt;script src=&#34;//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;4-feature-selection&#34;&gt;4. &lt;strong&gt;Feature Selection.&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Univariate Selection.&lt;/strong&gt; Statistical tests can be used to select those features that have the strongest relationship with the output variable.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;VarianceThreshold.&lt;/strong&gt; Feature selector that removes all low-variance features.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recursive Feature Elimination.&lt;/strong&gt; The goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and weights are assigned to each one of them. Then, features whose absolute weights are the smallest are pruned from the current set features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Feature Importance:&lt;/strong&gt; Methods that use ensembles of decision trees (like Random Forest or Extra Trees) can also compute the relative importance of each attribute. These importance values can be used to inform a feature selection process.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;5-algorithms-to-work-efficiently&#34;&gt;5. &lt;strong&gt;Algorithms to work efficiently.&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Apart from these above algorithms sometimes you may need to write your own algorithms. Now I think of big algorithms as a combination of small but powerful algorithms. You just need to have idea of these algorithms to make a more better/efficient product. So some of these powerful algorithms which can help you are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Recursive Algorithms:&lt;/strong&gt;Binary search algorithm.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Divide and Conquer Algorithms:&lt;/strong&gt; Merge-Sort.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dynamic Programming:&lt;/strong&gt;Solving a complex problem by breaking it down into a collection of simpler subproblems, solving each of those subproblems just once, and storing their solutions.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;6-classification-regression-algorithms-the-usual-suspects-minimum-you-must-know&#34;&gt;6. &lt;strong&gt;Classification/Regression Algorithms.&lt;/strong&gt; The usual suspects. Minimum you must know:&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Linear Regression -&lt;/strong&gt; Ridge Regression, Lasso Regression, ElasticNet&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Logistic Regression&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;From there you can build upon:

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Decision Trees -&lt;/strong&gt; ID3, CART, C4.5, C5.0&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;KNN&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SVM&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ANN&lt;/strong&gt; - Back Propogation, CNN&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;And then on to Ensemble based algorithms:

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Boosting&lt;/strong&gt;: Gradient Boosted Trees&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bagging&lt;/strong&gt;: Random Forests&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Blending&lt;/strong&gt;: Prediction outputs of different learning algorithms are fed into another learning algorithm.&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;7-clustering-methods-for-unsupervised-learning&#34;&gt;7 . &lt;strong&gt;Clustering Methods.&lt;/strong&gt;For unsupervised learning.&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;k-Means&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;k-Medians&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Expectation Maximisation (EM)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hierarchical Clustering&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;8-other-algorithms-you-can-learn-about&#34;&gt;8. &lt;strong&gt;Other algorithms you can learn about:&lt;/strong&gt;&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Apriori algorithm&lt;/strong&gt;- Association Rule Mining&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Eclat algorithm -&lt;/strong&gt; Association Rule Mining&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Item/User Based Similarity -&lt;/strong&gt; Recommender Systems&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reinforcement learning -&lt;/strong&gt; Build your own robot.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Graphical Models&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bayesian Algorithms&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NLP -&lt;/strong&gt; For language based models. Chatbots.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Hope this has been helpful&amp;hellip;..&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Things to see while buying a Mutual Fund</title>
      <link>https://mlwhiz.com/blog/2016/12/24/mutual_fund_ratios/</link>
      <pubDate>Sat, 24 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2016/12/24/mutual_fund_ratios/</guid>
      <description>

&lt;p&gt;This is a post which deviates from my pattern fo blogs that I have wrote till now but I found that Finance also uses up a lot of Statistics. So it won&amp;rsquo;t be a far cry to put this on my blog here. I recently started investing in Mutual funds so thought of rersearching the area before going all in. Here is the result of some of my research.&lt;/p&gt;

&lt;h2 id=&#34;1-load-no-load&#34;&gt;1. Load/No-Load:&lt;/h2&gt;

&lt;p&gt;Always Buy No Load Mutual Funds&lt;/p&gt;

&lt;h2 id=&#34;2-regular-direct&#34;&gt;2. Regular/Direct:&lt;/h2&gt;

&lt;p&gt;There are many differenct sites from where you can buy Mutual funds. Most of these sites take a commision to let you the investor buy and sell from their platform. To overcome this commision you can buy direct Mutual funds from the fund houses themselves. But that would be difficult as their are a lot of fund houses and mmanaging all of that could be quite painful. But with the advent of MFUtility you can buy direct plans from the same platform.&lt;/p&gt;

&lt;h2 id=&#34;3-expense-ratios&#34;&gt;3. Expense Ratios:&lt;/h2&gt;

&lt;p&gt;The expense ratio is a measure of what it costs an investment company to operate a mutual fund.
To see how expense ratios can affect your investments over time, let’s compare the returns of several hypothetical investments that differ only in expense ratio. The following table depicts the returns on a 10,000 initial investment, assuming an average annualized gain of 10%, with different expense ratios (0.5%, 1%, 1.5%, 2% and 2.5%):&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/fund_expense_ratio.jpg&#34;  height=&#34;400&#34; width=&#34;500&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;As the table illustrates, even a small difference in expense ratio can cost you a lot of money in the long run. If you had invested 10,000 in the fund with a 2.5% expense ratio, the value of your fund would be 46,022 after 20 years. Had you instead invested your 10,000 in the fund with a lower, 0.5% expense ratio, your investment would be worth $61,159 after two decades, a 0.33% improvement over the more expensive fund. Keep in mind, this hypothetical example examines funds whose only differences are the expense ratios: all other variables, including initial investment and annualized gains, remain constant (for the example, we must assume identical taxation as well). While two funds are not likely to have the exact same performance over a 20-year period, the table illustrates the effects that small changes in expense ratio can have on your long-term returns.&lt;/p&gt;

&lt;script src=&#34;//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;4-avoid-mutual-funds-with-high-turnover-ratios&#34;&gt;4. Avoid Mutual Funds With High Turnover Ratios:&lt;/h2&gt;

&lt;p&gt;Mutual fund turnover is calculated as the value of all transactions (buying, selling) divided by two, then divided by a fund&amp;rsquo;s total holdings. In simpler terms, mutual fund turnover typically measures the replacement of holdings in a mutual fund, and is commonly presented to investors as a percentage over a one year period. If a fund has 100% turnover, the fund replaces all of its holdings over a 12-month period and that bears cost to the investment company in terms of brokerage etc.&lt;/p&gt;

&lt;h2 id=&#34;5-look-for-ample-diversification-of-assets&#34;&gt;5. Look for Ample Diversification of Assets:&lt;/h2&gt;

&lt;p&gt;Simply owning four different mutual funds specializing in the financial sector (shares of banks, insurance companies, etc.) is not diversification. Don’t own funds that make heavy sector or industry bets. If you choose to despite this warning, make sure that you don’t have a huge portion of your funds invested in them. If it’s a bond fund, you typically want to avoid bets on the direction of interest rates as this is rank speculation.&lt;/p&gt;

&lt;h2 id=&#34;6-not-same-fund-family&#34;&gt;6. Not Same Fund Family:&lt;/h2&gt;

&lt;p&gt;Don’t keep all of your funds within the same fund family. Witness the mutual fund scandal of a few years ago where portfolio management at many firms allowed big traders to market time the funds, essentially stealing money from smaller investors. By spreading your assets out at different companies, you can mitigate the risk of internal turmoil, ethics breaches, and other localized problems.&lt;/p&gt;

&lt;h2 id=&#34;7-keep-track-of-various-risk-ratios&#34;&gt;7. Keep Track of various Risk Ratios:&lt;/h2&gt;

&lt;h3 id=&#34;a-standard-deviation&#34;&gt;a. &lt;strong&gt;&lt;strong&gt;Standard deviation:&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Standard deviation (SD) measures the volatility the fund&amp;rsquo;s returns in relation to its average. It tells
you how much the fund&amp;rsquo;s return can deviate from the historical mean return of the scheme. If a fund
has a 12% average rate of return and a standard deviation of 4%, its return will range from 8-16%&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Computation:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Standard Deviation (SD) = Square root of Variance (V)&lt;/p&gt;

&lt;p&gt;Variance = (Sum of squared difference between each monthly return and its mean / number of monthly return data – 1)&lt;/p&gt;

&lt;h3 id=&#34;b-r-squared&#34;&gt;b. &lt;strong&gt;&lt;strong&gt;R-Squared:&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;R-Squared measures the relationship between a portfolio and its benchmark. It can be thought of as a percentage from 1 to 100. R-squared is not a measure of the performance of a portfolio. A great portfolio can have a very low R-squared. It is simply a measure of the correlation of the portfolio&amp;rsquo;s returns to the benchmark&amp;rsquo;s returns.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Computation:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;R-Squared = Square of Correlation&lt;/p&gt;

&lt;p&gt;Correlation(xy)= Covariance between index and portfolio/(Standard deviation of portfolio * standard deviation of index)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Significance:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If you want a portfolio that moves like the benchmark, you&amp;rsquo;d want a portfolio with a high Rsquared.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;If you want a portfolio that doesn&amp;rsquo;t move at all like the benchmark, you&amp;rsquo;d want a low R-squared.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;General Range for R-Squared:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;70-100% = good correlation between the portfolio&amp;rsquo;s returns and the benchmark&amp;rsquo;s returns&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;40-70% = average correlation between the portfolio&amp;rsquo;s returns and the benchmark&amp;rsquo;s returns&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;1-40% = low correlation between the portfolio&amp;rsquo;s returns and the benchmark&amp;rsquo;s returns&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Index funds will have an R-squared very close to 100.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;R-squared can be used to ascertain the significance of a particular beta or alpha. Generally, a higher R-squared will indicate a more useful beta figure. If the R-squared is lower, then the beta is less relevant to the fund&amp;rsquo;s performance&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Values range from 1 (returns are explained 100% by the market) to 0 (returns bear no association with the market)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;c-beta&#34;&gt;c. &lt;strong&gt;&lt;strong&gt;Beta:&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;A beta of 1.0 indicates that the investment&amp;rsquo;s price will move in lock-step with the market.&lt;/p&gt;

&lt;p&gt;A beta of less than 1.0 indicates that the investment will be less volatile than the market, and, correspondingly, a beta of more than 1.0 indicates that the investment&amp;rsquo;s price will be more volatile than the market.&lt;/p&gt;

&lt;p&gt;For example, if a fund portfolio&amp;rsquo;s beta is 1.2, it&amp;rsquo;s theoretically 20% more volatile than the market. Conservative investors looking to preserve capital should focus on securities and fund portfolios with low betas, whereas those investors willing to take on more risk in search of higher returns should look for high beta investments.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Computation:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Beta = (Standard Deviation of Fund x R-Square) / Standard Deviation of Benchmark&lt;/p&gt;

&lt;p&gt;If a fund has a beta of 1.5, it means that for every 10% upside or downside, the fund&amp;rsquo;s NAV would be 15% in the respective direction.&lt;/p&gt;

&lt;h3 id=&#34;d-jensens-alpha&#34;&gt;d. &lt;strong&gt;&lt;strong&gt;Jensens Alpha:&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Alpha is a measure of an investment&amp;rsquo;s performance on a risk-adjusted basis.&lt;/p&gt;

&lt;p&gt;Simply stated, alpha is often considered to represent the value that a portfolio manager adds or subtracts from a fund portfolio&amp;rsquo;s return.&lt;/p&gt;

&lt;p&gt;A positive alpha of 1.0 means the fund has outperformed its benchmark index by 1%. Correspondingly, a similar negative alpha would indicate an underperformance of 1%.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Computation:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Alpha = {(Fund return-Risk free return) – (Funds beta) *(Benchmark return- risk free return)}&lt;/p&gt;

&lt;p&gt;For example, assume a mutual fund realized a return of 15% last year. The appropriate market index for this fund returned 12%. The beta of the fund versus that same index is 1.2 and the risk-free rate is 3%. The fund&amp;rsquo;s alpha is calculated as:&lt;/p&gt;

&lt;p&gt;Alpha = {(15 -3) – (1.2) *(12- 3)} = 12 - 9 x 1.2 = 12-10.8 = 1.2&lt;/p&gt;

&lt;p&gt;Given a beta of 1.2, the mutual fund is expected to be riskier than the index, and thus earn more. A positive alpha in this example shows that the mutual fund manager earned more than enough return to be compensated for the risk he took over the course of the year. If the mutual fund only returned 13%, the calculated alpha would be -0.8. With a negative alpha, the mutual fund manager would not have earned enough return given the amount of risk he was taking.&lt;/p&gt;

&lt;h3 id=&#34;e-sharpe-ratio&#34;&gt;e. &lt;strong&gt;&lt;strong&gt;Sharpe Ratio:&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Sharpe Ratio measures how well the fund has performed vis-a vis the risk taken by it. It is the excess return over risk-free return (usually return from treasury bills or government securities) divided by the standard deviation. The higher the Sharpe Ratio, the better the fund has performed in proportion to the risk taken by it.
The Sharpe ratio is also known as Reward-to-Variability ratio and it is named after William Forsyth Sharpe.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Computation:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;SR = (Total Return – Risk Free Rate) / SD Of Fund&lt;/p&gt;

&lt;p&gt;For example: Your investor gets 7 per cent return on her investment in a scheme with a standard deviation/volatility of 0.5. We assume risk free rate is 5 per cent.
Sharpe Ratio is 7-&lt;sup&gt;5&lt;/sup&gt;&amp;frasl;&lt;sub&gt;0&lt;/sub&gt;.5 = 4 in this case&lt;/p&gt;

&lt;h2 id=&#34;8-and-finally-always-dollar-cost-average&#34;&gt;8. And Finally Always Dollar-Cost Average:&lt;/h2&gt;

&lt;p&gt;Dollar cost averaging is a technique designed to reduce market risk through the systematic purchase of securities at predetermined intervals and set amounts.Instead of investing assets in a lump sum, the investor works his way into a position by slowly buying smaller amounts over a longer period of time. This spreads the cost basis out over several years, providing insulation against changes in market price.&lt;/p&gt;

&lt;p&gt;Every investor investment strategy differs. These are just some common guidelines to work your way through the market and making informed decisions while buying Mutual Funds.
Normally I work through points 1-6 and get my list to a few mutual funds after which I generally use risk ratios to determine which of the funds I selected might be a winner.
I have a bias towards long term investing when it comes to investing so whatever I wrote here must be taken with a grain of salt just as everything related to investment must be.  Some of you who are doing this for a longer time than I can also tell me about the various other things I can do.
I will try to include those ideas in this post as well.&lt;/p&gt;

&lt;p&gt;To Learn more about Mutual funds and investing in general, take a look at the following two gems:&lt;/p&gt;

&lt;div style=&#34;margin-left:1em ; text-align: center;&#34;&gt;
&lt;a target=&#34;_blank&#34;  href=&#34;https://www.amazon.com/gp/product/0060555661/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0060555661&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=59d5b0af035ad4ba7eda55548194a638&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=0060555661&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=0060555661&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;
&lt;/t&gt;&lt;/t&gt;
&lt;a target=&#34;_blank&#34;  href=&#34;https://www.amazon.com/gp/product/0470138130/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0470138130&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=2f78b02ff1a38e3383c5a8cff52f2a9a&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=0470138130&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=0470138130&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;
&lt;/div&gt;

&lt;p&gt;The Editorial review of The intelligent Investor says &amp;ldquo;Among the library of investment books promising no-fail strategies for riches, Benjamin Graham&amp;rsquo;s classic, The Intelligent Investor, offers no guarantees or gimmicks but overflows with the wisdom at the core of all good portfolio management&amp;rdquo; and it rings true in every sense. A must read for everyone looking to invest seriously.&lt;/p&gt;

&lt;p&gt;Common Sense on Mutual Funds focusses on Mutual funds exclusively. Lets you understand that investing is not difficult. For the not so involved reader.&lt;/p&gt;

&lt;p&gt;Till than Ciao!!!&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References:&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.thebalance.com/picking-winning-mutual-funds-357957&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;https://www.thebalance.com/picking-winning-mutual-funds-357957&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.miraeassetmf.co.in/uploads/TermofWeek/Sharpe_Ratio.pdf&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;http://www.miraeassetmf.co.in/uploads/TermofWeek/Sharpe_Ratio.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.miraeassetmf.co.in/uploads/TermofWeek/Beta_SD_RSquared.pdf&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;http://www.miraeassetmf.co.in/uploads/TermofWeek/Beta_SD_RSquared.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.investopedia.com&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;http://www.investopedia.com&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Pandas For All - Some Basic Pandas Functions</title>
      <link>https://mlwhiz.com/blog/2016/10/27/baby_panda/</link>
      <pubDate>Thu, 27 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2016/10/27/baby_panda/</guid>
      <description>

&lt;p&gt;It has been quite a few days I have been working with Pandas and apparently I feel I have gotten quite good at it. (Quite a Braggard I know)
So thought about adding a post about Pandas usage here. I intend to make this post quite practical and since I find the pandas syntax quite self explanatory, I won&amp;rsquo;t be explaining much of the codes. Just the use cases and the code to achieve them.&lt;/p&gt;

&lt;h2 id=&#34;1-import-pandas&#34;&gt;1. Import Pandas&lt;/h2&gt;

&lt;p&gt;We Start by importing the libraries that we will need to use.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;2-read-a-datasource&#34;&gt;2. Read a Datasource:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Read from csv data files&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# With Header&lt;/span&gt;
df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/Users/ragarw5/Downloads/SalesJan2009.csv&amp;#34;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Without Header. sep param to provide the delimiter&lt;/span&gt;
df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/Users/ragarw5/Downloads/SalesJan2009.csv&amp;#34;&lt;/span&gt;, header&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, sep&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;,&amp;#34;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Reading from SQL Datasource&lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; MySQLdb
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; DataFrame
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pandas.io.sql &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; read_sql

db &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MySQLdb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;connect(host&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;localhost&amp;#34;&lt;/span&gt;,    &lt;span style=&#34;color:#75715e&#34;&gt;# your host, usually localhost&lt;/span&gt;
                     user&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;root&amp;#34;&lt;/span&gt;,         &lt;span style=&#34;color:#75715e&#34;&gt;# your username&lt;/span&gt;
                     passwd&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;password&amp;#34;&lt;/span&gt;,   &lt;span style=&#34;color:#75715e&#34;&gt;# your password&lt;/span&gt;
                     db&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;dbname&amp;#34;&lt;/span&gt;)         &lt;span style=&#34;color:#75715e&#34;&gt;# name of the data base&lt;/span&gt;

query &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SELECT * FROM tablename&amp;#34;&lt;/span&gt;

data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; read_sql(query, db)

&lt;span style=&#34;color:#75715e&#34;&gt;# Reading from ExcelFile&lt;/span&gt;
data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_excel(filename)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For now, we will be working with the file at &lt;a href=&#34;http://samplecsvs.s3.amazonaws.com/SalesJan2009.csv&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;http://samplecsvs.s3.amazonaws.com/SalesJan2009.csv&lt;/a&gt;. The Sales Jan 2009 file contains some “sanitized” sales transactions during the month of January. If you want to work along you can download this file from that location.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/Users/ragarw5/Downloads/SalesJan2009.csv&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;3-see-few-rows-of-data&#34;&gt;3. See few rows of data:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# top 5 rows&lt;/span&gt;
df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()

&lt;span style=&#34;color:#75715e&#34;&gt;# top 50 rows&lt;/span&gt;
df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head(&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# last 5 rows&lt;/span&gt;
df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tail()

&lt;span style=&#34;color:#75715e&#34;&gt;# last 50 rows&lt;/span&gt;
df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tail(&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;4-getting-column-names-in-a-list&#34;&gt;4. Getting Column Names in a list:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;columnnames &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;5-specifying-user-defined-column-names&#34;&gt;5. Specifying user defined Column Names:&lt;/h2&gt;

&lt;p&gt;Sometimes you want to change the column names:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Transdate&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Product&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Price&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;PaymentType&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt;,
       &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;City&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;State&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Country&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;AccountCreated&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;LastLogin&amp;#39;&lt;/span&gt;,
       &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Longitude&amp;#39;&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;6-subsetting-specific-columns&#34;&gt;6. Subsetting specific columns:&lt;/h2&gt;

&lt;p&gt;Sometimes you only need to work with specific columns in a dataframe only. You can subset the columns in the dataframe using&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;newDf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Product&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Price&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;PaymentType&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Name&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;City&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;State&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Country&amp;#39;&lt;/span&gt;]]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;7-seeing-column-types&#34;&gt;7. Seeing column types:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;newDf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dtypes&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;8-change-type-of-a-column&#34;&gt;8. Change type of a column&lt;/h2&gt;

&lt;p&gt;First thing i try is this.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;newDf[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Price&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; newDf[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Price&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;int&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It gives error : ValueError: invalid literal for long() with base 10: &amp;lsquo;13,000&amp;rsquo;. That is you cannot cast a string with &amp;ldquo;,&amp;rdquo; to an int. To do that we first have to get rid of the comma. For that we use a particular lambda-apply functionality which lets us apply functions to each row in the data.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;newDf[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Price&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; newDf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: int(x[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Price&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;,&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;)),axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;script src=&#34;//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;9-simple-dataframe-statistics&#34;&gt;9. Simple Dataframe Statistics:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# To get statistics of numerical columns&lt;/span&gt;
newDf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;describe()

&lt;span style=&#34;color:#75715e&#34;&gt;# To get maximum value of a column. When you take a single column you can think of it as a list and apply functions you would apply to a list&lt;/span&gt;
max(newDf[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Price&amp;#39;&lt;/span&gt;])

&lt;span style=&#34;color:#75715e&#34;&gt;# no of rows in dataframe&lt;/span&gt;
len(newDf)

&lt;span style=&#34;color:#75715e&#34;&gt;# Shape of Dataframe&lt;/span&gt;
newDf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;10-creating-a-new-column&#34;&gt;10. Creating a new column:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create a column Address containing City,State and Country. Simply concat the columns.&lt;/span&gt;
newDf[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Address&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; newDf[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;City&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;,&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; newDf[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;State&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;,&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; newDf[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Country&amp;#39;&lt;/span&gt;]

&lt;span style=&#34;color:#75715e&#34;&gt;# I like to use a function defined approach with lambda-apply as it gives me more flexibility and more options. Like if i want to create a column which is 1 if the price is greater than 1200 and 0 otherwise.&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;gt&lt;/span&gt;(x):
	&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1200&lt;/span&gt;:
		&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
	&lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
		&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;

newDf[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Pricegt1200&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; newDf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: gt(x[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Price&amp;#39;&lt;/span&gt;]),axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;11-subset-a-dataframe&#34;&gt;11. Subset a DataFrame:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Single condition: dataframe with all entries priced greater than 1500&lt;/span&gt;

df_gt_1500 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; newDf[newDf[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Price&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1500&lt;/span&gt;]

&lt;span style=&#34;color:#75715e&#34;&gt;# Multiple conditions: AND - dataframe with all entries priced greater than 1500 and from London&lt;/span&gt;

And_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; newDf[(newDf[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Price&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1500&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; (newDf[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;City&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;London&amp;#39;&lt;/span&gt;)]

&lt;span style=&#34;color:#75715e&#34;&gt;# Multiple conditions: OR - dataframe with all entries priced greater than 1500 or from London&lt;/span&gt;

Or_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; newDf[(newDf[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Price&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1500&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt; (newDf[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;City&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;London&amp;#39;&lt;/span&gt;)]

&lt;span style=&#34;color:#75715e&#34;&gt;# Multiple conditions: NOT - dataframe with all entries priced greater than 1500 or from London have to be excluded&lt;/span&gt;

Not_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; newDf[&lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt;((newDf[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Price&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1500&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt; (newDf[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;City&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;London&amp;#39;&lt;/span&gt;))]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;12-change-the-column-at-particular-places-or-impute&#34;&gt;12. Change the Column at particular places or impute:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# In the state column the state is abbreviated as &amp;#39;TX&amp;#39;. We want the whole name &amp;#39;Texas&amp;#39; in there&lt;/span&gt;
newDf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[newDf[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;State&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;TX&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;State&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Texas&amp;#39;&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# When City is Monaco State is not given. You want to impute &amp;#39;Monaco State&amp;#39; as state also.&lt;/span&gt;
newDf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[newDf[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;City&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Monaco&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;State&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Monaco State&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;13-groupby&#34;&gt;13. GroupBy:&lt;/h2&gt;

&lt;p&gt;One of the most used functionality. One simple example&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Find out the sum of transactions by a state. reset_index() is a function that resets the index of a dataframe. I apply this function ALWAYS whenever I do a groupby and you might think of it as a default syntax for groupby operations&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
newDf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;State&amp;#39;&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;aggregate(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reset_index()

&lt;span style=&#34;color:#75715e&#34;&gt;# You might get a few extra columns that you dont need. Just subset the columns in the dataframe. You could just chain the commands to subset for the columns you need.&lt;/span&gt;
newDf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;State&amp;#39;&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;aggregate(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reset_index()[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;State&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Price&amp;#39;&lt;/span&gt;]]

&lt;span style=&#34;color:#75715e&#34;&gt;# Find minimum transaction in each state&lt;/span&gt;
newDf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;State&amp;#39;&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;aggregate(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;min)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reset_index()[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;State&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Price&amp;#39;&lt;/span&gt;]]

&lt;span style=&#34;color:#75715e&#34;&gt;# You might want to groupby more than one column&lt;/span&gt;

newDf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;State&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;City&amp;#39;&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;aggregate(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reset_index()[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;State&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;City&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Price&amp;#39;&lt;/span&gt;]]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;14-concat&#34;&gt;14. Concat:&lt;/h2&gt;

&lt;p&gt;You have two datarames df1 and df2 you need to concat. Means append one below the other you can do it using:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;concat([df1,df2])&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;15-merge&#34;&gt;15. Merge:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#Suppose in the start, you had two dataframes. One which contains city and price information:&lt;/span&gt;
City_Price &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; newwDf[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;City&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Price&amp;#39;&lt;/span&gt;]]

&lt;span style=&#34;color:#75715e&#34;&gt;#And another which contains &amp;#39;City&amp;#39; and &amp;#39;State&amp;#39; insformation&lt;/span&gt;
City_State &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; newDf[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;City&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;State&amp;#39;&lt;/span&gt;]]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop_duplicates(keep&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reset_index()

&lt;span style=&#34;color:#75715e&#34;&gt;#You need to merge these datatframes on basis of city. You need to do:&lt;/span&gt;
City_Price_State_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;merge(City_Price,City_State,on&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;City&amp;#39;&lt;/span&gt;],how&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;left&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;16-save-a-dataframe-to-external-file&#34;&gt;16. Save a Dataframe to external File:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# To Csv file&lt;/span&gt;
newDf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;NewDfData.csv&amp;#34;&lt;/span&gt;,index&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)

&lt;span style=&#34;color:#75715e&#34;&gt;# To Excel File&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ExcelWriter
writer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  ExcelWriter(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;NewDfData.xlsx&amp;#39;&lt;/span&gt;)
newDf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_excel(writer,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Sheet1&amp;#39;&lt;/span&gt;)
writer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;save()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;17-pushing-pandas-df-to-a-sql-database&#34;&gt;17. Pushing Pandas Df to a sql database:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pandas.io &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; sql
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; MySQLdb

db &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MySQLdb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;connect(host&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;localhost&amp;#34;&lt;/span&gt;,    &lt;span style=&#34;color:#75715e&#34;&gt;# your host, usually localhost&lt;/span&gt;
                     user&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;root&amp;#34;&lt;/span&gt;,         &lt;span style=&#34;color:#75715e&#34;&gt;# your username&lt;/span&gt;
                     passwd&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;password&amp;#34;&lt;/span&gt;,  &lt;span style=&#34;color:#75715e&#34;&gt;# your password&lt;/span&gt;
                     db&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;dbname&amp;#34;&lt;/span&gt;)        &lt;span style=&#34;color:#75715e&#34;&gt;# name of the data base&lt;/span&gt;

newDf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_sql(con &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; db, name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tablename&amp;#39;&lt;/span&gt;,if_exists&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;append&amp;#39;&lt;/span&gt;,flavor&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mysql&amp;#39;&lt;/span&gt;, chunksize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10000&lt;/span&gt;,index&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Hope you found this post useful and worth your time. I tried to make this as simple as possible but You may always &lt;strong&gt;ask me&lt;/strong&gt; or see the documentation for doubts.&lt;/p&gt;

&lt;p&gt;If you have &lt;strong&gt;any more ideas&lt;/strong&gt; on how to use Pandas or &lt;strong&gt;other usecases&lt;/strong&gt;, please suggest in the &lt;strong&gt;comments&lt;/strong&gt; section.&lt;/p&gt;

&lt;p&gt;Till then ciao!!&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://www.gregreda.com/2013/10/26/intro-to-pandas-data-structures/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Intro to Pandas By Greg Rada&lt;/a&gt; What I have written is in a condensed form, If you want to get a detailed description visit Greg Rada&amp;rsquo;s 3 posts series.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://pandas.pydata.org/pandas-docs/stable/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Pandas Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Deploying ML Apps using Python and Flask- Learning about Flask</title>
      <link>https://mlwhiz.com/blog/2016/01/10/deploying_ml_apps_using_python_flask/</link>
      <pubDate>Sun, 10 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2016/01/10/deploying_ml_apps_using_python_flask/</guid>
      <description>

&lt;p&gt;It has been a long time since I wrote anything on my blog. So thought about giving everyone a treat this time. Or so I think it is.&lt;/p&gt;

&lt;p&gt;Recently I was thinking about a way to deploy all these machine learning models I create in python. I searched through the web but couldn&amp;rsquo;t find anything nice and easy.
Then I fell upon &lt;a href=&#34;http://sebastianraschka.com/blog/2015/writing-pymle.html&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;this book&lt;/a&gt; by Sebastian Rashcka and I knew that it was what I was looking for.
To tell you the truth I did had some experience in Flask earlier but this book made it a whole lot easier to deploy a machine learning model in flask.&lt;/p&gt;

&lt;p&gt;So today I am going to give a brief intro about Flask Apps and how to deploy them using a service called Openshift.&lt;/p&gt;

&lt;h4 id=&#34;so-what-is-flask&#34;&gt;So What is flask?&lt;/h4&gt;

&lt;p&gt;Flask is a Python Web Framework that makes it easier to create webapps from python.&lt;/p&gt;

&lt;h4 id=&#34;and-openshift&#34;&gt;And Openshift?&lt;/h4&gt;

&lt;p&gt;Openshift is a free service(if we only use 1 small instance) which lets us use their services to deploy our flask web-apps.&lt;/p&gt;

&lt;p&gt;So that we don&amp;rsquo;t get lost, let me tell you the flow of this post.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;First of all we will learn about the &lt;strong&gt;installation&lt;/strong&gt;* of Openshift and Flask.&lt;/li&gt;
&lt;li&gt;We will create a &lt;strong&gt;Hello World&lt;/strong&gt; application using Flask.&lt;/li&gt;
&lt;li&gt;We will work on creating a very &lt;strong&gt;simple calculator App&lt;/strong&gt; that operates on two numbers provided by the user. This will help us in understanding how user forms work with Flask by implementing a barebones app.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;installation&#34;&gt;Installation:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Create your &lt;a href=&#34;https://www.openshift.com/app/account/new&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;FREE OpenShift account Here&lt;/a&gt; Very simple sign-up email + password only&lt;/li&gt;
&lt;li&gt;Install the &lt;a href=&#34;https://www.openshift.com/developers/install-the-client-tools&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;OpenShift Client Tools&lt;/a&gt;. Use these directions for your particular Operating System these tools have a command line interface and allow more control over your app. The OpenShift tool requires an installation of Ruby.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now once you do this you have installed Openshift Client tools on your system.&lt;/p&gt;

&lt;h2 id=&#34;helloworld&#34;&gt;Helloworld&lt;/h2&gt;

&lt;p&gt;So now I am going to do a lot of things in this post. But don&amp;rsquo;t get bothered much it is just code and HTML quirks. I will try to provide enough details on which parts are necessary.
First of all, you will need to create a domain on Openshift platform. This can be done by using:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;rhc domain create -n DomainName -l EmailAddress -p password&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For this example I created:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;rhc domain create -n mlwhiz -l MyEmailAddress -p Mypassword&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In the free version for Openshift you can run 3 web-apps with a single domain.
For example I can create a maximum of 3 webapps whose web address would be:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;myappname1-mlwhiz.rhcloud.com&lt;/li&gt;
&lt;li&gt;myappname2-mlwhiz.rhcloud.com&lt;/li&gt;
&lt;li&gt;myappname3-mlwhiz.rhcloud.com&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Once we create a domain we need to create a webapp:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;rhc app create HelloWorld python-2.7&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This creates the app named helloworld for us. The app currently resides at this address on web: &lt;a href=&#34;http://helloworld-mlwhiz.rhcloud.com/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;http://helloworld-mlwhiz.rhcloud.com/&lt;/a&gt;
This command also creates a folder where our app resides. cd into this folder.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd helloworld&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now get a basic template to work upon in this directory. You can think of this as a starter code for flask. We can do this by pulling and merging from Github using the following commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git remote add upstream -m master git://github.com/openshift/flask-example.git
git pull -s recursive -X theirs upstream master&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Use Virtualenv to isolate Python development environments. It’s a tool that allows you setup an isolated, self-contained Python environment in a folder on your dev box. This way you can experiment with various versions of Python without affecting your system wide configurations:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;brew install python-virtualenv
cd helloworld/wsgi/
virtualenv venv --python&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;python2.7
&lt;span style=&#34;color:#75715e&#34;&gt;#Activate the virtual environment&lt;/span&gt;
. venv/bin/activate
&lt;span style=&#34;color:#75715e&#34;&gt;# Install all these into your virtual python environment.&lt;/span&gt;
pip install flask flask-wtf flask-babel markdown flup&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now Change the name of flaskapp.py in wsgi to run.py&lt;/p&gt;

&lt;p&gt;put this code in run.py&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; flask &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Flask
app &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Flask(__name__)
&lt;span style=&#34;color:#a6e22e&#34;&gt;@app.route&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;home&lt;/span&gt;():
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Render website&amp;#39;s home page.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Hello World!&amp;#39;&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; __name__ &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;:
    app&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run(debug&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;True&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Also change the file named application to:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/usr/bin/python&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; sys
sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;insert(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dirname(__file__) &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.&amp;#39;&lt;/span&gt;)
PY_DIR &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join(os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;environ[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;OPENSHIFT_HOMEDIR&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;python&amp;#34;&lt;/span&gt;)
virtenv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; PY_DIR &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/virtenv/&amp;#39;&lt;/span&gt;
PY_CACHE &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join(virtenv, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;lib&amp;#39;&lt;/span&gt;, os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;environ[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;OPENSHIFT_PYTHON_VERSION&amp;#39;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;site-packages&amp;#39;&lt;/span&gt;)
os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;environ[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;PYTHON_EGG_CACHE&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join(PY_CACHE)
virtualenv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;path&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join(virtenv, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bin/activate_this.py&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;exec&lt;/span&gt;(open(virtualenv)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read(), dict(__file__&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;virtualenv))
&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;IOError&lt;/span&gt;:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; run &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; app &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; application&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Run this to host your app:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd helloworld/wsgi
python run.py&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;script src=&#34;//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e&#34;&gt;&lt;/script&gt;

&lt;p&gt;You should be able to see your app on: &lt;a href=&#34;http://127.0.0.1:5000/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;http://127.0.0.1:5000/&lt;/a&gt;
You can deploy this webapp to Openshift using:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd helloworld
git add .
git commit -a -m &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Initial deployment of this app to the web&amp;#34;&lt;/span&gt;
git push&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Open &lt;a href=&#34;http://helloworld-mlwhiz.rhcloud.com/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;http://helloworld-mlwhiz.rhcloud.com/&lt;/a&gt; in your browser. You would see Hello World! there. Now we have got a very basic structure complete.&lt;/p&gt;

&lt;h2 id=&#34;our-simple-calculator-app&#34;&gt;Our Simple Calculator App:&lt;/h2&gt;

&lt;p&gt;We will now work on creating a app that operates on two numbers provided by the user. The functions possible are +,- and *.
You can see this web app in action &lt;a href=&#34;http://helloworld-mlwhiz.rhcloud.com/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; before moving on.
This app will help us in understanding how user forms work with Flask and how to manage user inputs in Flask.
First of all change the code in run.py to&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; flask &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Flask,render_template, request
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; wtforms &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Form, TextAreaField, validators,SelectField

app &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Flask(__name__)

&lt;span style=&#34;color:#75715e&#34;&gt;# Code to create a WTForm with three fields. 2 text fields and 1 dropdown menu.&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;OutputForm&lt;/span&gt;(Form):
	myChoices&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;), (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;), (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;*&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;*&amp;#39;&lt;/span&gt;)]
	num1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; TextAreaField(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;,[validators&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataRequired()])
	num2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; TextAreaField(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;,[validators&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataRequired()])
	Operator &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SelectField(&lt;span style=&#34;color:#e6db74&#34;&gt;u&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;, choices &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; myChoices, validators &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [validators&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataRequired()])

&lt;span style=&#34;color:#75715e&#34;&gt;# This uses the render_template method in flask to use a template first_app.html.&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# This html contains placeholders for the form that is provided in the kwargs argument to the function call.&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;@app.route&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;index&lt;/span&gt;():
	&lt;span style=&#34;color:#75715e&#34;&gt;#return &amp;#39;Hello World!&amp;#39;&lt;/span&gt;
	form &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; OutputForm(request&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;form)
	&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; render_template(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;first_app.html&amp;#39;&lt;/span&gt;,form &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; form)

&lt;span style=&#34;color:#75715e&#34;&gt;# This is the output that is displayed. It checks if the form is validated and POST request is made.&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# If true it renders the output.html else renders the main index page.&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# Most of the work is done here. Gets the user inputs using the request.form method.&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;@app.route&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/output&amp;#39;&lt;/span&gt;, methods&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;POST&amp;#39;&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;output&lt;/span&gt;():
	form &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; OutputForm(request&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;form)
	&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; request&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;method &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;POST&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; form&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;validate():
		num1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; request&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;form[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;num1&amp;#39;&lt;/span&gt;]
		num2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; request&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;form[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;num2&amp;#39;&lt;/span&gt;]
		op &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; request&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;form[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Operator&amp;#39;&lt;/span&gt;]
		&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; op&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;+&amp;#34;&lt;/span&gt;:
			name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;str(int(num1)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;int(num2))
		&lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; op&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;-&amp;#34;&lt;/span&gt;:
			name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;str(int(num1)&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;int(num2))
		&lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; op&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;:
			name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;str(int(num1)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;int(num2))
		&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; render_template(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;output.html&amp;#39;&lt;/span&gt;, name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;name)
	&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; render_template(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;first_app.html&amp;#39;&lt;/span&gt;, form&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;form)

&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; __name__ &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;:
    app&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run(debug&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;True&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We use WTF forms here to create a form object. We pass this form object to the HTML render_template method. We have accessed these again in the output function so that we can show them in output.html where all the major work is done for creating the app.&lt;/p&gt;

&lt;p&gt;Now Create a folder named template in helloworld/wsgi and create a file named _formhelpers.html with this content. You really don&amp;rsquo;t need to see the content in this file.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;{% macro render_field(field) %}
	&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;dt&lt;/span&gt;&amp;gt;{{ field.label }}
	&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;dd&lt;/span&gt;&amp;gt;{{ field(**kwargs)|safe }}
	{% if field.errors %}
		&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;ul&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;errors&lt;/span&gt;&amp;gt;
		{% for error in field.errors %}
			&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;li&lt;/span&gt;&amp;gt;{{ error }}&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;li&lt;/span&gt;&amp;gt;
		{% endfor %}
		&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;ul&lt;/span&gt;&amp;gt;
	{% endif %}
	&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;dd&lt;/span&gt;&amp;gt;
{% endmacro %}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Also add another file named first_app.html with this content. Notice how we access the wtform here.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;!doctype html&amp;gt;&lt;/span&gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;html&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;head&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;title&lt;/span&gt;&amp;gt;First app&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;title&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;link&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rel&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;stylesheet&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ url_for(&amp;#39;static&amp;#39;,filename=&amp;#39;style.css&amp;#39;) }}&amp;#34;&lt;/span&gt;&amp;gt;
&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;head&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;body&lt;/span&gt;&amp;gt;
	{% from &amp;#34;_formhelpers.html&amp;#34; import render_field %}
	&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt;&amp;gt;Calculator: Please enter two numbers and a function you want to apply&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt;&amp;gt;
	&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;form&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;method&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;post&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;action&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/output&amp;#34;&lt;/span&gt;&amp;gt;
	{{ render_field(form.num1) }}{{ render_field(form.Operator) }}{{ render_field(form.num2) }}
		&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;input&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;submit&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;value&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Result&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;submit_btn&amp;#39;&lt;/span&gt;&amp;gt;
	&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;form&lt;/span&gt;&amp;gt;
&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;body&lt;/span&gt;&amp;gt;
&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;html&lt;/span&gt;&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Create a file named output.html where the final output will be shown.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;!doctype html&amp;gt;&lt;/span&gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;html&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;head&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;title&lt;/span&gt;&amp;gt;First app&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;title&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;link&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rel&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;stylesheet&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ url_for(&amp;#39;static&amp;#39;,filename=&amp;#39;style.css&amp;#39;) }}&amp;#34;&lt;/span&gt;&amp;gt;
&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;head&lt;/span&gt;&amp;gt;
	&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;body&lt;/span&gt;&amp;gt;
		&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt;&amp;gt;The output is: {{ name }}&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt;&amp;gt;
	&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;body&lt;/span&gt;&amp;gt;
&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;html&lt;/span&gt;&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Also add a style.css file in the static folder. You can put this in it for right now or any other thing you want.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;h1 {
    color: blue;
    font-family: verdana;
    font-size: 300%;
}
p  {
    color: red;
    font-family: courier;
    font-size: 160%;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And we are mostly done. Run run.py in the wsgi directory and you would be able to access the app at : &lt;a href=&#34;http://127.0.0.1:5000/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;http://127.0.0.1:5000/&lt;/a&gt;.
Again deploy this webapp to Openshift using:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd helloworld
git add .
git commit -a -m &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Initial deployment of this app to the web&amp;#34;&lt;/span&gt;
git push&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;endnotes&#34;&gt;Endnotes&lt;/h2&gt;

&lt;p&gt;So here we took inputs from the user and show the output using the flask App. The final app is hosted at &lt;a href=&#34;http://helloworld-mlwhiz.rhcloud.com/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;http://helloworld-mlwhiz.rhcloud.com/&lt;/a&gt; for you to see.
This code provides us with a code skeletn which will be valuable when we will deploy a whole ML model, which is the main motive of this series.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Most of the code here is taken from this awesome book by Sebastian Raschka: &lt;a rel=&#34;nofollow&#34; href=&#34;http://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1783555130&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=QOKIQ2S5LIQI7L2N&#34;&gt;Python Machine Learning&lt;/a&gt;&lt;img src=&#34;http://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=as2&amp;o=1&amp;a=1783555130&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.openshift.com/beginners-guide-to-writing-flask-apps-on-openshift/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;https://blog.openshift.com/beginners-guide-to-writing-flask-apps-on-openshift/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Shell Basics every Data Scientist Should know - Part II(AWK)</title>
      <link>https://mlwhiz.com/blog/2015/10/11/shell_basics_for_data_science_2/</link>
      <pubDate>Sun, 11 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2015/10/11/shell_basics_for_data_science_2/</guid>
      <description>

&lt;p&gt;Yesterday I got introduced to awk programming on the shell and is it cool. It lets you do stuff on the command line which you never imagined. As a matter of fact, it&amp;rsquo;s a whole data analytics software in itself when you think about it. You can do selections, groupby, mean, median, sum, duplication, append. You just ask. There is no limit actually.&lt;/p&gt;

&lt;p&gt;And it is easy to learn.&lt;/p&gt;

&lt;p&gt;In this post, I will try to give you a brief intro about how you could add awk to your daily work-flow.&lt;/p&gt;

&lt;p&gt;Please see my previous &lt;a href=&#34;http://mlwhiz.com/blog/2015/10/09/shell_basics_for_data_science/&#34; target=&#34;_blank&#34; &gt;post&lt;/a&gt; if you want some background or some basic to intermediate understanding of shell commands.&lt;/p&gt;

&lt;h2 id=&#34;basics-fundamentals&#34;&gt;Basics/ Fundamentals&lt;/h2&gt;

&lt;p&gt;So let me start with an example first. Say you wanted to sum a column in a comma delimited file. How would you do that in shell?&lt;/p&gt;

&lt;p&gt;Here is the command. The great thing about awk is that it took me nearly 5 sec to write this command. I did not have to open any text editor to write a python script.&lt;/p&gt;

&lt;p&gt;It lets you do adhoc work quickly.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;BEGIN{ sum=0; FS=&amp;#34;,&amp;#34;} { sum += $5 } END { print sum }&amp;#39;&lt;/span&gt; data.txt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF112&#34;&gt;44662539172
&lt;/pre&gt;

&lt;p&gt;See the command one more time. There is a basic structure to the awk command&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;

&lt;pre&gt;&lt;span class=&#34;n&#34;&gt;BEGIN&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;action&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;pattern&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;action&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;pattern&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;action&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;pattern&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;action&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;END&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;action&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;An awk program consists of:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;An optional BEGIN segment : In the begin part we initialize our variables before we even start reading from the file or the standard input.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;pattern - action pairs: In the middle part we Process the input data. You put multiple pattern action pairs when you want to do multiple things with the same line.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;An optional END segment: In the end part we do something we want to do when we have reached the end of file.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;An awk command is called on a file using:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;BEGIN{SOMETHING HERE} {SOMETHING HERE: could put Multiple Blocks Like this} END {SOMETHING HERE}&amp;#39;&lt;/span&gt; file.txt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You also need to know about these preinitialized variables that awk keeps track of.:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;FS : field separator. Default is whitespace (1 or more spaces or tabs). If you are using any other seperator in the file you should specify it in the Begin Part.&lt;/li&gt;
&lt;li&gt;RS : record separator. Default record separator is newline. Can be changed in BEGIN action.&lt;/li&gt;
&lt;li&gt;NR : NR is the variable whose value is the number of the current record. You normally use it in the action blocks in the middle.&lt;/li&gt;
&lt;li&gt;NF : The Number of Fields after the single line has been split up using FS.&lt;/li&gt;
&lt;li&gt;Dollar variables : awk splits up the line which is coming to it by using the given FS and keeps the split parts in the $ variables. For example column 1 is in &lt;code&gt;$1&lt;/code&gt;, column 2 is in &lt;code&gt;$2&lt;/code&gt;. &lt;code&gt;$0&lt;/code&gt; is the string representation of the whole line. Note that if you want to access last column you don&amp;rsquo;t have to count. You can just use &lt;code&gt;$NF&lt;/code&gt;. For second last column you can use &lt;code&gt;$(NF-1)&lt;/code&gt;. Pretty handy. Right.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So If you are with me till here, the hard part is done. Now the fun part starts. Lets look at the first awk command again and try to understand it.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;BEGIN{ sum=0; FS=&amp;#34;,&amp;#34;} { sum += $5 } END { print sum }&amp;#39;&lt;/span&gt; data.txt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So there is a begin block. Remember before we read any line. We initialize sum to 0 and FS to &amp;ldquo;,&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Now as awk reads its input line by line it increments sum by the value in column 5(as specified by &lt;code&gt;$5&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;Note that there is no pattern specified here so awk will do the action for every line.&lt;/p&gt;

&lt;p&gt;When awk has completed reading the file it prints out the sum.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What if you wanted mean?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We could create a cnt Variable:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;BEGIN{ sum=0;cnt=0; FS=&amp;#34;,&amp;#34;} { sum += $5; cnt+=1 } END { print sum/cnt }&amp;#39;&lt;/span&gt; data.txt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF112&#34;&gt;1.86436e+06
&lt;/pre&gt;

&lt;p&gt;or better yet, use our friend NR which bash is already keeping track of:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;BEGIN{ sum=0; FS=&amp;#34;,&amp;#34;} { sum += $5 } END { print sum/NR }&amp;#39;&lt;/span&gt; data.txt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF112&#34;&gt;1.86436e+06
&lt;/pre&gt;

&lt;h2 id=&#34;filter-a-file&#34;&gt;Filter a file&lt;/h2&gt;

&lt;p&gt;In the mean and sum awk commands we did not put any pattern in our middle commands. Let us use a simple pattern now. Suppose we have a file Salaries.csv which contains:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;head salaries.txt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF112&#34;&gt;yearID,teamID,lgID,playerID,salary
1985,BAL,AL,murraed02,1472819
1985,BAL,AL,lynnfr01,1090000
1985,BAL,AL,ripkeca01,800000
1985,BAL,AL,lacyle01,725000
1985,BAL,AL,flanami01,641667
1985,BAL,AL,boddimi01,625000
1985,BAL,AL,stewasa01,581250
1985,BAL,AL,martide01,560000
1985,BAL,AL,roeniga01,558333
&lt;/pre&gt;

&lt;p&gt;I want to filter records for players who who earn more than 22 M in 2013 just because I want to. You just do:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;BEGIN{FS=&amp;#34;,&amp;#34;} $5&amp;gt;=22000000 &amp;amp;&amp;amp; $1==2013{print $0}&amp;#39;&lt;/span&gt; Salaries.csv&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF112&#34;&gt;2013,DET,AL,fieldpr01,23000000
2013,MIN,AL,mauerjo01,23000000
2013,NYA,AL,rodrial01,29000000
2013,NYA,AL,wellsve01,24642857
2013,NYA,AL,sabatcc01,24285714
2013,NYA,AL,teixema01,23125000
2013,PHI,NL,leecl02,25000000
2013,SFN,NL,linceti01,22250000
&lt;/pre&gt;

&lt;p&gt;Cool right. Now let me explain it a little bit. The part in the command &amp;ldquo;&lt;code&gt;$5&lt;/code&gt;&amp;gt;=22000000 &amp;amp;&amp;amp; &lt;code&gt;$1&lt;/code&gt;==2013&amp;rdquo; is called a pattern. It says that print this line(&lt;code&gt;$0&lt;/code&gt;) if and only if the Salary(&lt;code&gt;$5&lt;/code&gt;) is more than 22M and(&amp;amp;&amp;amp;) year(&lt;code&gt;$1&lt;/code&gt;) is equal to 2013. If the incoming record(line) does not satisfy this pattern it never reaches the inner block.&lt;/p&gt;

&lt;p&gt;So Now you could do basic Select SQL at the command line only if you had:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The logic Operators:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;== equality operator; returns TRUE is both sides are equal&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;!= inverse equality operator&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&amp;amp;&amp;amp; logical AND&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;|| logical OR&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;! logical NOT&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&amp;lt;, &amp;gt;, &amp;lt;=, &amp;gt;= relational operators&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Normal Arithmetic Operators:&lt;/strong&gt; +, -, /, *, %, ^&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Some String Functions:&lt;/strong&gt; length, substr, split&lt;/p&gt;

&lt;h2 id=&#34;groupby&#34;&gt;GroupBy&lt;/h2&gt;

&lt;p&gt;Now you will say: &amp;ldquo;Hey Dude SQL without groupby is incomplete&amp;rdquo;. You are right and for that we can use the associative array. Lets just see the command first and then I will explain. So lets create another useless use case(or may be something useful to someone :)) We want to find out the number of records for each year in the file. i.e we want to find the distribution of years in the file. Here is the command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;BEGIN{FS=&amp;#34;,&amp;#34;}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    {my_array[$1]=my_array[$1]+1}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    END{
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    for (k in my_array){if(k!=&amp;#34;yearID&amp;#34;)print k&amp;#34;|&amp;#34;my_array[k]};
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    }&amp;#39;&lt;/span&gt; Salaries.csv&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF112&#34;&gt;1990|867
1991|685
1996|931
1997|925
...
&lt;/pre&gt;

&lt;p&gt;Now I would like to tell you a secret. You don&amp;rsquo;t really need to declare the variables you want to use in awk. So you did not really needed to define sum, cnt variables before. I only did that because it is good practice. If you don&amp;rsquo;t declare a user defined variable in awk, awk assumes it to be null or zero depending on the context. So in the command above we don&amp;rsquo;t declare our myarray in the begin block and that is fine.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Associative Array&lt;/strong&gt;: The variable myarray is actually an associative array. i.e. It stores data in a key value format.(Python dictionaries anyone). The same array could keep integer keys and String keys. For example, I can do this in a single code.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;

&lt;pre&gt;&lt;span class=&#34;n&#34;&gt;myarray&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&#34;key&#34;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;myarray&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&#39;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mlwhiz&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;
&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;For Loop for associative arrays&lt;/strong&gt;: I could use a for loop to read associative array&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;

&lt;pre&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;array&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DO&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SOMETHING&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;cp&#34;&gt;# Assigns to k each Key of array (unordered)&lt;/span&gt;
&lt;span class=&#34;cp&#34;&gt;# Element is array[k]&lt;/span&gt;
&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;If Statement&lt;/strong&gt;:Uses a syntax like C for the if statement. the else block is optional:&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;

&lt;pre&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&gt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
  &lt;span class=&#34;n&#34;&gt;DO&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SOMETHING&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;n&#34;&gt;DO&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SOMETHING&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;

&lt;/div&gt;

&lt;p&gt;So lets dissect the above command now.&lt;/p&gt;

&lt;p&gt;I set the File separator to &amp;ldquo;,&amp;rdquo; in the beginning. I use the first column as the key of myarray. If the key exists I increment the value by 1.&lt;/p&gt;

&lt;p&gt;At the end, I loop through all the keys and print out key value pairs separated by &amp;ldquo;|&amp;rdquo;&lt;/p&gt;

&lt;p&gt;I know that the header line in my file contains &amp;ldquo;yearID&amp;rdquo; in column 1 and I don&amp;rsquo;t want &amp;lsquo;yearID|1&amp;rsquo; in the output. So I only print when Key is not equal to &amp;lsquo;yearID&amp;rsquo;.&lt;/p&gt;

&lt;h2 id=&#34;groupby-with-case-statement&#34;&gt;GroupBy with case statement:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat Salaries.csv | awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;BEGIN{FS=&amp;#34;,&amp;#34;}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    $5&amp;lt;100000{array5[&amp;#34;[0-100000)&amp;#34;]+=1}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    $5&amp;gt;=100000&amp;amp;&amp;amp;$5&amp;lt;250000{array5[&amp;#34;[100000,250000)&amp;#34;]=array5[&amp;#34;[100000,250000)&amp;#34;]+1}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    $5&amp;gt;=250000&amp;amp;&amp;amp;$5&amp;lt;500000{array5[&amp;#34;[250000-500000)&amp;#34;]=array5[&amp;#34;[250000-500000)&amp;#34;]+1}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    $5&amp;gt;=500000&amp;amp;&amp;amp;$5&amp;lt;1000000{array5[&amp;#34;[500000-1000000)&amp;#34;]=array5[&amp;#34;[500000-1000000)&amp;#34;]+1}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    $5&amp;gt;=1000000{array5[&amp;#34;[1000000)&amp;#34;]=array5[&amp;#34;[1000000)&amp;#34;]+1}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    END{
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    print &amp;#34;VAR Distrib:&amp;#34;;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    for (v in array5){print v&amp;#34;|&amp;#34;array5[v]}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    }&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF112&#34;&gt;VAR Distrib:
[250000-500000)|8326
[0-100000)|2
[1000000)|23661
[100000,250000)|9480
&lt;/pre&gt;

&lt;p&gt;Here we used multiple pattern-action blocks to create a case statement.&lt;/p&gt;

&lt;h2 id=&#34;for-the-brave&#34;&gt;For The Brave:&lt;/h2&gt;

&lt;p&gt;This is a awk code that I wrote to calculate the Mean,Median,min,max and sum of a column simultaneously. Try to go through the code and understand it.I have added comments too. Think of this as an exercise. Try to run this code and play with it. You may learn some new tricks in the process. If you don&amp;rsquo;t understand it do not worry. Just get started writing your own awk codes, you will be able to understand it in very little time.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Create a New file named A.txt to keep only the salary column.&lt;/span&gt;
    cat Salaries.csv | cut -d &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;,&amp;#34;&lt;/span&gt; -f &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; &amp;gt; A.txt
    FILENAME&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;A.txt&amp;#34;&lt;/span&gt;

    &lt;span style=&#34;color:#75715e&#34;&gt;# The first awk counts the number of lines which are numeric. We use a regex here to check if the column is numeric or not.&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#39;;&amp;#39; stands for Synchronous execution i.e sort only runs after the awk is over.&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# The output of both commands are given to awk command which does the whole work.&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# So Now the first line going to the second awk is the number of lines in the file which are numeric.&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# and from the second to the end line the file is sorted.&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;BEGIN {c=0} $1 ~ /^[-0-9]*(\.[0-9]*)?$/ {c=c+1;} END {print c;}&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;$FILENAME&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;            sort -n &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;$FILENAME&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; | awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;      BEGIN {
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        c = 0;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        sum = 0;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        med1_loc = 0;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        med2_loc = 0;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        med1_val = 0;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        med2_val = 0;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        min = 0;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        max = 0;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;      }
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;      NR==1 {
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        LINES = $1
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        # We check whether numlines is even or odd so that we keep only
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        # the locations in the array where the median might be.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        if (LINES%2==0) {med1_loc = LINES/2-1; med2_loc = med1_loc+1;}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        if (LINES%2!=0) {med1_loc = med2_loc = (LINES-1)/2;}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;      }
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;      $1 ~ /^[-0-9]*(\.[0-9]*)?$/  &amp;amp;&amp;amp;  NR!=1 {
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        # setting min value
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        if (c==0) {min = $1;}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        # middle two values in array
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        if (c==med1_loc) {med1_val = $1;}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        if (c==med2_loc) {med2_val = $1;}
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        c++
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        sum += $1
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        max = $1
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;      }
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;      END {
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        ave = sum / c
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        median = (med1_val + med2_val ) / 2
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        print &amp;#34;sum:&amp;#34; sum
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        print &amp;#34;count:&amp;#34; c
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        print &amp;#34;mean:&amp;#34; ave
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        print &amp;#34;median:&amp;#34; median
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        print &amp;#34;min:&amp;#34; min
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        print &amp;#34;max:&amp;#34; max
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;      }
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#39;&lt;/span&gt;

&amp;lt;pre style&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF112&amp;#34;&lt;/span&gt;&amp;gt;sum:44662539172
count:23956
mean:1.86436e+06
median:507950
min:0
max:33000000
&amp;lt;/pre&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;endnote&#34;&gt;Endnote:&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;awk&lt;/strong&gt; is an awesome tool and there are a lot of use-cases where it can make your life simple. There is a sort of a learning curve, but I think that it would be worth it in the long term. I have tried to give you a taste of awk and I have covered a lot of ground here in this post. To tell you a bit more there, awk is a full programming language. There are for loops, while loops, conditionals, booleans, functions and everything else that you would expect from a programming language. So you could look more still.&lt;/p&gt;

&lt;p&gt;To learn more about awk you can use this &lt;a href=&#34;http://ir.nmu.org.ua/bitstream/handle/123456789/143548/ecf2f2d8a72e7c3cffca0036a73aeed4.pdf?sequence=1&amp;amp;&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;book&lt;/a&gt;. This book is a free resource and you could learn more about awk and use cases.&lt;/p&gt;

&lt;p&gt;Or if you like to have your book binded and in paper like me you can buy this book, which is a gem:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.amazon.com/gp/product/1565922255/ref=as_li_tl?ie=UTF8&amp;amp;camp=1789&amp;amp;creative=9325&amp;amp;creativeASIN=1565922255&amp;amp;linkCode=as2&amp;amp;tag=mlwhizcon-20&amp;amp;linkId=YC37WW67AJHS3T6S&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;http://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;amp;ASIN=1565922255&amp;amp;Format=_SL250_&amp;amp;ID=AsinImage&amp;amp;MarketPlace=US&amp;amp;ServiceVersion=20070822&amp;amp;WS=1&amp;amp;tag=mlwhizcon-20&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;img src=&#34;http://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;amp;l=as2&amp;amp;o=1&amp;amp;a=1565922255&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Do leave comments in case you find more use-cases for awk or if you want me to write on new use-cases. Or just comment weather you liked it or not and how I could improve as I am also new and trying to learn more of this.&lt;/p&gt;

&lt;p&gt;Till then Ciao !!!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Shell Basics every Data Scientist Should know -Part I</title>
      <link>https://mlwhiz.com/blog/2015/10/09/shell_basics_for_data_science/</link>
      <pubDate>Fri, 09 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2015/10/09/shell_basics_for_data_science/</guid>
      <description>

&lt;p&gt;Shell Commands are powerful. And life would be like &lt;strong&gt;hell without shell&lt;/strong&gt; is how I like to say it(And that is probably the reason that I dislike windows).&lt;/p&gt;

&lt;p&gt;Consider a case when you have a 6 GB pipe-delimited file sitting on your laptop and you want to find out the count of distinct values in one particular column. You can probably do this in more than one way. You could put that file in a database and run SQL Commands, or you could write a python/perl script.&lt;/p&gt;

&lt;p&gt;Probably whatever you do it won&amp;rsquo;t be simpler/less time consuming than this&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat data.txt | cut -d &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;|&amp;#34;&lt;/span&gt; -f &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; | sort | uniq | wc -l&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;30
&lt;/pre&gt;

&lt;p&gt;And this will &lt;strong&gt;run way faster&lt;/strong&gt; than whatever you do with perl/python script.&lt;/p&gt;

&lt;p&gt;Now this command says&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Use the &lt;strong&gt;cat&lt;/strong&gt; command to print/stream the contents of the file to stdout.&lt;/li&gt;
&lt;li&gt;Pipe the streaming contents from our cat command to the next command &lt;strong&gt;cut&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;cut&lt;/strong&gt; commands specifies the delimiter by the argument &lt;strong&gt;-d&lt;/strong&gt; and the column by the argument &lt;strong&gt;-f&lt;/strong&gt; and streams the output to stdout.&lt;/li&gt;
&lt;li&gt;Pipe the streaming content to the &lt;strong&gt;sort&lt;/strong&gt; command which sorts the input and streams only the distinct values to the stdout. It takes the argument &lt;strong&gt;-u&lt;/strong&gt; that specifies that we only need unique values.&lt;/li&gt;
&lt;li&gt;Pipe the output to the wc -l command which counts the number of lines in the input.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There is a &lt;strong&gt;lot going on here&lt;/strong&gt; and I will try my best to ensure that &lt;strong&gt;you will be able to understand most of it by the end of this Blog post&lt;/strong&gt;.Although I will also try to explain more advanced concepts than the above command in this post.&lt;/p&gt;

&lt;p&gt;Now, I use shell commands extensively at my job. I will try to explain the usage of each of the commands based on use cases that I counter nearly daily at may day job as a data scientist.&lt;/p&gt;

&lt;h2 id=&#34;some-basic-commands-in-shell&#34;&gt;Some Basic Commands in Shell:&lt;/h2&gt;

&lt;p&gt;There are a lot of times when you just need to know a little bit about the data. You just want to see may be a couple of lines to inspect a file. One way of doing this is opening the txt/csv file in the notepad. And that is probably the best way for small files. But you could also do it in the shell using:&lt;/p&gt;

&lt;h3 id=&#34;1-cat&#34;&gt;1. cat&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat data.txt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;
yearID|teamID|lgID|playerID|salary
1985|BAL|AL|murraed02|1472819
1985|BAL|AL|lynnfr01|1090000
1985|BAL|AL|ripkeca01|800000
1985|BAL|AL|lacyle01|725000
1985|BAL|AL|flanami01|641667
1985|BAL|AL|boddimi01|625000
1985|BAL|AL|stewasa01|581250
1985|BAL|AL|martide01|560000
1985|BAL|AL|roeniga01|558333
&lt;/pre&gt;

&lt;p&gt;Now the &lt;a href=&#34;https://en.wikipedia.org/wiki/Cat_%28Unix%29&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;cat&lt;/a&gt; command prints the whole file in the terminal window for you.I have not shown the whole file here.&lt;/p&gt;

&lt;p&gt;But sometimes the files will be so big that you wont be able to open them up in notepad++ or any other software utility and there the cat command will shine.&lt;/p&gt;

&lt;h3 id=&#34;2-head-and-tail&#34;&gt;2. Head and Tail&lt;/h3&gt;

&lt;p&gt;Now you might ask me why would you print the whole file in the terminal itself? Generally I won&amp;rsquo;t. But I just wanted to tell you about the cat command. For the use case when you want only the top/bottom n lines of your data you will generally use the &lt;a href=&#34;https://en.wikipedia.org/wiki/Head_%28Unix%29&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;head&lt;/a&gt;/&lt;a href=&#34;https://en.wikipedia.org/wiki/Tail_%28Unix%29&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;tail&lt;/a&gt; commands. You can use them as below.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;head data.txt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;yearID|teamID|lgID|playerID|salary
1985|BAL|AL|murraed02|1472819
1985|BAL|AL|lynnfr01|1090000
1985|BAL|AL|ripkeca01|800000
1985|BAL|AL|lacyle01|725000
1985|BAL|AL|flanami01|641667
1985|BAL|AL|boddimi01|625000
1985|BAL|AL|stewasa01|581250
1985|BAL|AL|martide01|560000
1985|BAL|AL|roeniga01|558333
&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;head -n &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; data.txt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;yearID|teamID|lgID|playerID|salary
1985|BAL|AL|murraed02|1472819
1985|BAL|AL|lynnfr01|1090000
&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;tail data.txt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;2013|WAS|NL|bernaro01|1212500
2013|WAS|NL|tracych01|1000000
2013|WAS|NL|stammcr01|875000
2013|WAS|NL|dukeza01|700000
2013|WAS|NL|espinda01|526250
2013|WAS|NL|matthry01|504500
2013|WAS|NL|lombast02|501250
2013|WAS|NL|ramoswi01|501250
2013|WAS|NL|rodrihe03|501000
2013|WAS|NL|moorety01|493000
&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;tail -n &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; data.txt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;2013|WAS|NL|rodrihe03|501000
2013|WAS|NL|moorety01|493000
&lt;/pre&gt;

&lt;p&gt;Notice the structure of the shell command here.&lt;/p&gt;

&lt;div class=&#34;highlight&#34;&gt;

&lt;pre&gt;&lt;span class=&#34;n&#34;&gt;CommandName&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;arg1name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;arg1value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;arg2name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;arg2value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;filename&lt;/span&gt;
&lt;/pre&gt;

&lt;/div&gt;

&lt;h3 id=&#34;3-piping&#34;&gt;3. Piping&lt;/h3&gt;

&lt;p&gt;Now we could have also written the same command as:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat data.txt | head&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;yearID|teamID|lgID|playerID|salary
1985|BAL|AL|murraed02|1472819
1985|BAL|AL|lynnfr01|1090000
1985|BAL|AL|ripkeca01|800000
1985|BAL|AL|lacyle01|725000
1985|BAL|AL|flanami01|641667
1985|BAL|AL|boddimi01|625000
1985|BAL|AL|stewasa01|581250
1985|BAL|AL|martide01|560000
1985|BAL|AL|roeniga01|558333
&lt;/pre&gt;

&lt;p&gt;This brings me to one of the most important concepts of Shell usage - &lt;a href=&#34;https://en.wikipedia.org/wiki/Pipeline_%28Unix%29&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;piping&lt;/strong&gt;&lt;/a&gt;. You won&amp;rsquo;t be able to utilize the full power the shell provides without using this concept. And the concept is actually simple.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Just read the &amp;ldquo;|&amp;rdquo; in the command as &amp;ldquo;pass the data on to&amp;rdquo;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;So I would read the above command as:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;cat&lt;/em&gt;(print) the whole data to stream, &lt;strong&gt;pass the data on to&lt;/strong&gt; &lt;em&gt;head&lt;/em&gt; so that it can just give me the first few lines only.&lt;/p&gt;

&lt;p&gt;So did you understood what piping did? &lt;strong&gt;It is providing us a way to use our basic commands in a consecutive manner&lt;/strong&gt;. There are a lot of commands that are fairly basic and it lets us use these basic commands in sequence to do some fairly non trivial things.&lt;/p&gt;

&lt;p&gt;Now let me tell you about a couple of more commands before I show you how we can &lt;strong&gt;chain&lt;/strong&gt; them to do fairly advanced tasks.&lt;/p&gt;

&lt;h3 id=&#34;4-wc&#34;&gt;4. wc&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Wc_%28Unix%29&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;wc&lt;/a&gt; is a fairly useful shell utility/command that lets us &lt;strong&gt;count the number of lines(-l)&lt;/strong&gt;, &lt;strong&gt;words(-w)&lt;/strong&gt; or &lt;strong&gt;characters(-c)&lt;/strong&gt; in a given file&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;wc -l data.txt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;23957 data.txt
&lt;/pre&gt;

&lt;h3 id=&#34;5-grep&#34;&gt;5. grep&lt;/h3&gt;

&lt;p&gt;You may want to print all the lines in your file which have a particular word. Or as a Data case you might like to see the salaries for the team BAL in 2000. In this case we have printed all the lines in the file which contain &amp;ldquo;2000|BAL&amp;rdquo;. &lt;a href=&#34;https://en.wikipedia.org/wiki/Grep&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;grep&lt;/a&gt; is your friend.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;grep &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2000|BAL&amp;#34;&lt;/span&gt; data.txt | head&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;2000|BAL|AL|belleal01|12868670
2000|BAL|AL|anderbr01|7127199
2000|BAL|AL|mussimi01|6786032
2000|BAL|AL|ericksc01|6620921
2000|BAL|AL|ripkeca01|6300000
2000|BAL|AL|clarkwi02|6000000
2000|BAL|AL|johnsch04|4600000
2000|BAL|AL|timlimi01|4250000
2000|BAL|AL|deshide01|4209324
2000|BAL|AL|surhobj01|4146789
&lt;/pre&gt;

&lt;p&gt;you could also use regular expressions with grep.&lt;/p&gt;

&lt;h3 id=&#34;6-sort&#34;&gt;6. sort&lt;/h3&gt;

&lt;p&gt;You may want to &lt;a href=&#34;https://en.wikipedia.org/wiki/Sort_%28Unix%29&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;sort&lt;/a&gt; your dataset on a particular column.Sort is your friend. Say you want to find out the top 10 maximum salaries given to any player in your dataset.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sort -t &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;|&amp;#34;&lt;/span&gt; -k &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; -r -n data.txt | head -10&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;2010|NYA|AL|rodrial01|33000000
2009|NYA|AL|rodrial01|33000000
2011|NYA|AL|rodrial01|32000000
2012|NYA|AL|rodrial01|30000000
2013|NYA|AL|rodrial01|29000000
2008|NYA|AL|rodrial01|28000000
2011|LAA|AL|wellsve01|26187500
2005|NYA|AL|rodrial01|26000000
2013|PHI|NL|leecl02|25000000
2013|NYA|AL|wellsve01|24642857
&lt;/pre&gt;

&lt;p&gt;So there are certainly a lot of options in this command. Lets go through them one by one.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;-t&lt;/strong&gt;: Which delimiter to use?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-k&lt;/strong&gt;: Which column to sort on?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-n&lt;/strong&gt;: If you want Numerical Sorting. Dont use this option if you want Lexographical sorting.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-r&lt;/strong&gt;: I want to sort Descending. Sorts Ascending by Default.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;7-cut&#34;&gt;7. cut&lt;/h3&gt;

&lt;p&gt;This command lets you select certain columns from your data. Sometimes you may want to look at just some of the columns in your data. As in you may want to look only at the year, team and salary and not the other columns. &lt;a href=&#34;https://en.wikipedia.org/wiki/Cut_(Unix)&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;cut&lt;/a&gt; is the command to use.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cut -d &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;|&amp;#34;&lt;/span&gt; -f &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,2,5 data.txt | head&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;yearID|teamID|salary
1985|BAL|1472819
1985|BAL|1090000
1985|BAL|800000
1985|BAL|725000
1985|BAL|641667
1985|BAL|625000
1985|BAL|581250
1985|BAL|560000
1985|BAL|558333
&lt;/pre&gt;

&lt;p&gt;The options are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;-d&lt;/strong&gt;: Which delimiter to use?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-f&lt;/strong&gt;: Which column/columns to cut?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;8-uniq&#34;&gt;8. uniq&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Uniq&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;uniq&lt;/a&gt; is a little bit tricky as in you will want to use this command in sequence with sort. This command removes sequential duplicates. So in conjunction with sort it can be used to get the distinct values in the data. For example if I wanted to find out 10 distinct teamIDs in data, I would use:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat data.txt | cut -d &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;|&amp;#34;&lt;/span&gt; -f &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; | sort | uniq | head&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;ANA
ARI
ATL
BAL
BOS
CAL
CHA
CHN
CIN
CLE
&lt;/pre&gt;

&lt;p&gt;This command could be used with argument &lt;strong&gt;-c&lt;/strong&gt; to count the occurrence of these distinct values. Something akin to &lt;strong&gt;count distinct&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat data.txt | cut -d &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;|&amp;#34;&lt;/span&gt; -f &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; | sort | uniq -c | head&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;247 ANA
458 ARI
838 ATL
855 BAL
852 BOS
368 CAL
812 CHA
821 CHN
46 CIN
867 CLE
&lt;/pre&gt;

&lt;h2 id=&#34;some-other-utility-commands-for-other-operations&#34;&gt;Some Other Utility Commands for Other Operations&lt;/h2&gt;

&lt;p&gt;Some Other command line tools that you could use without going in the specifics as the specifics are pretty hard.&lt;/p&gt;

&lt;h3 id=&#34;1-change-delimiter-in-a-file&#34;&gt;1. Change delimiter in a file&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Find and Replace Magic.&lt;/strong&gt;: You may want to replace certain characters in file with something else using the &lt;a href=&#34;https://en.wikipedia.org/wiki/Tr_%28Unix%29&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;tr&lt;/a&gt; command.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat data.txt | tr &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;|&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;,&amp;#39;&lt;/span&gt; |  head -4&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;yearID,teamID,lgID,playerID,salary
1985,BAL,AL,murraed02,1472819
1985,BAL,AL,lynnfr01,1090000
1985,BAL,AL,ripkeca01,800000
&lt;/pre&gt;

&lt;p&gt;or the &lt;a href=&#34;https://en.wikipedia.org/wiki/Sed&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;sed&lt;/strong&gt;&lt;/a&gt; command&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat data.txt | sed -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;s/|/,/g&amp;#39;&lt;/span&gt; | head -4&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;yearID,teamID,lgID,playerID,salary
1985,BAL,AL,murraed02,1472819
1985,BAL,AL,lynnfr01,1090000
1985,BAL,AL,ripkeca01,800000
&lt;/pre&gt;

&lt;h3 id=&#34;2-sum-of-a-column-in-a-file&#34;&gt;2. Sum of a column in a file&lt;/h3&gt;

&lt;p&gt;Using the &lt;a href=&#34;https://en.wikipedia.org/wiki/AWK&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;awk&lt;/a&gt; command you could find the sum of column in file. Divide it by the number of lines and you can get the mean.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat data.txt | awk -F &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;|&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{ sum += $5 } END { printf sum }&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;44662539172
&lt;/pre&gt;

&lt;p&gt;awk is a powerful command which is sort of a whole language in itself. Do see the wiki page for &lt;a href=&#34;https://en.wikipedia.org/wiki/AWK&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;awk&lt;/a&gt; for a lot of great usecases of awk. I also wrote a post on awk as a second part in this series. Check it &lt;a href=&#34;http://mlwhiz.com/blog/2015/10/11/shell_basics_for_data_science_2/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;HERE&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-find-the-files-in-a-directory-that-satisfy-a-certain-condition&#34;&gt;3. Find the files in a directory that satisfy a certain condition&lt;/h3&gt;

&lt;p&gt;You can do this by using the find command. Lets say you want to &lt;strong&gt;find all the .txt files&lt;/strong&gt; in the current working dir that &lt;strong&gt;start with lowercase h&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;find . -name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;h*.txt&amp;#34;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;./hamlet.txt
&lt;/pre&gt;

&lt;p&gt;To find &lt;strong&gt;all .txt files starting with h regarless of case&lt;/strong&gt; we could use regex.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;find . -name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;[Hh]*.txt&amp;#34;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;./hamlet.txt
./Hamlet1.txt
&lt;/pre&gt;

&lt;h3 id=&#34;4-passing-file-list-as-argument&#34;&gt;4. Passing file list as Argument.&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Xargs&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;xargs&lt;/a&gt; was suggested by Gaurav in the comments, so I read about it and it is actually a very nice command which you could use in a variety of use cases.&lt;/p&gt;

&lt;p&gt;So if you just use a pipe, any command/utility receives data on STDIN (the standard input stream) as a raw pile of data that it can sort through one line at a time. However some programs don&amp;rsquo;t accept their commands on standard in. For example the rm command(which is used to remove files), touch command(used to create file with a given name) or a certain python script you wrote(which takes command line arguments). They expect it to be spelled out in the arguments to the command.&lt;/p&gt;

&lt;p&gt;For example: rm takes a file name as a parameter on the command line like so: rm file1.txt. If I wanted to &lt;strong&gt;delete all &amp;lsquo;.txt&amp;rsquo; files starting with &amp;ldquo;h/H&amp;rdquo;&lt;/strong&gt; from my working directory, the below command won&amp;rsquo;t work because rm expects a file as an input.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;find . -name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;[hH]*.txt&amp;#34;&lt;/span&gt; | rm&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;usage: rm [-f | -i] [-dPRrvW] file ...
unlink file
&lt;/pre&gt;

&lt;p&gt;To get around it we can use the xargs command which reads the STDIN stream data and converts each line into space separated arguments to the command.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;find . -name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;[hH]*.txt&amp;#34;&lt;/span&gt; | xargs&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;./hamlet.txt ./Hamlet1.txt
&lt;/pre&gt;

&lt;p&gt;Now you could use rm to remove all .txt files that start with h/H. A word of advice: Always see the output of xargs first before using rm.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;find . -name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;[hH]*.txt&amp;#34;&lt;/span&gt; | xargs rm&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Another usage of xargs could be in conjunction with grep to &lt;strong&gt;find all files that contain a given string&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;find . -name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;*.txt&amp;#34;&lt;/span&gt; | xargs grep &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;honest soldier&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-size:50%; padding:7px; margin:0em;  background-color:#FFF122&#34;&gt;./Data1.txt:O, farewell, honest soldier;
./Data2.txt:O, farewell, honest soldier;
./Data3.txt:O, farewell, honest soldier;
&lt;/pre&gt;

&lt;p&gt;Hopefully You could come up with varied uses building up on these examples. One other use case could be to use this for &lt;strong&gt;passing arguments to a python script&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&#34;other-cool-tricks&#34;&gt;Other Cool Tricks&lt;/h2&gt;

&lt;p&gt;Sometimes you want your data that you got by some command line utility(Shell commands/ Python scripts) not to be shown on stdout but stored in a textfile. You can use the &lt;strong&gt;&amp;rdquo;&amp;gt;&amp;rdquo;&lt;/strong&gt; operator for that. For Example: You could have stored the file after replacing the delimiters in the previous example into anther file called newdata.txt as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat data.txt | tr &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;|&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;,&amp;#39;&lt;/span&gt; &amp;gt; newdata.txt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I really got confused between &lt;strong&gt;&amp;rdquo;|&amp;rdquo;&lt;/strong&gt; (piping) and &lt;strong&gt;&amp;rdquo;&amp;gt;&amp;rdquo;&lt;/strong&gt; (to_file) operations a lot in the beginning. One way to remember is that you should only use &lt;strong&gt;&amp;rdquo;&amp;gt;&amp;rdquo;&lt;/strong&gt; when you want to write something to a file. &lt;strong&gt;&amp;rdquo;|&amp;rdquo; cannot be used to write to a file.&lt;/strong&gt; Another operation you should know about is the &lt;strong&gt;&amp;rdquo;&amp;gt;&amp;gt;&amp;rdquo;&lt;/strong&gt; operation. It is analogous to &lt;strong&gt;&amp;rdquo;&amp;gt;&amp;rdquo;&lt;/strong&gt; but it appends to an existing file rather that replacing the file and writing over.&lt;/p&gt;

&lt;p&gt;If you would like to know more about commandline, which I guess you would, here are some books that I would recommend for a beginner:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.amazon.com/gp/product/1593273894/ref=as_li_tl?ie=UTF8&amp;amp;camp=1789&amp;amp;creative=9325&amp;amp;creativeASIN=1593273894&amp;amp;linkCode=as2&amp;amp;tag=mlwhizcon-20&amp;amp;linkId=IXZOHV6FHPTYCBCT&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;http://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;amp;ASIN=1593273894&amp;amp;Format=_SL250_&amp;amp;ID=AsinImage&amp;amp;MarketPlace=US&amp;amp;ServiceVersion=20070822&amp;amp;WS=1&amp;amp;tag=mlwhizcon-20&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;img src=&#34;http://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;amp;l=as2&amp;amp;o=1&amp;amp;a=1593273894&#34; alt=&#34;&#34; /&gt; &lt;a href=&#34;http://www.amazon.com/gp/product/0596009658/ref=as_li_tl?ie=UTF8&amp;amp;camp=1789&amp;amp;creative=9325&amp;amp;creativeASIN=0596009658&amp;amp;linkCode=as2&amp;amp;tag=mlwhizcon-20&amp;amp;linkId=2ZHHZIAJBFW3BFF7&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;http://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;amp;ASIN=0596009658&amp;amp;Format=_SL250_&amp;amp;ID=AsinImage&amp;amp;MarketPlace=US&amp;amp;ServiceVersion=20070822&amp;amp;WS=1&amp;amp;tag=mlwhizcon-20&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;img src=&#34;http://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;amp;l=as2&amp;amp;o=1&amp;amp;a=0596009658&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The first book is more of a fun read at leisure type of book. THe second book is a little more serious. Whatever suits you.&lt;/p&gt;

&lt;p&gt;So, this is just the tip of the iceberg. Although I am not an expert in shell usage, these commands reduced my workload to a large extent. If there are some shell commands you use on a regular basis or some shell command that are cool, do tell in the comments. I would love to include it in the blogpost.&lt;/p&gt;

&lt;p&gt;I wrote a blogpost on awk as a second part of this post. Check it &lt;a href=&#34;http://mlwhiz.com/blog/2015/10/11/shell_basics_for_data_science_2/&#34; target=&#34;_blank&#34;&gt;Here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Create basic graph visualizations with SeaBorn- The Most Awesome Python Library For Visualization yet</title>
      <link>https://mlwhiz.com/blog/2015/09/13/seaborn_visualizations/</link>
      <pubDate>Sun, 13 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2015/09/13/seaborn_visualizations/</guid>
      <description>

&lt;p&gt;When it comes to data preparation and getting acquainted with data, the &lt;strong&gt;one step we normally skip is the data visualization&lt;/strong&gt;.
While a part of it could be attributed to the &lt;strong&gt;lack of good visualization tools&lt;/strong&gt; for the platforms we use, most of us also &lt;strong&gt;get lazy&lt;/strong&gt; at times.&lt;/p&gt;

&lt;p&gt;Now as we know of it Python never had any good Visualization library. For most of our plotting needs, I would read up blogs, hack up with StackOverflow solutions and haggle with &lt;a href=&#34;http://matplotlib.org/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Matplotlib&lt;/a&gt; documentation each and every time I needed to make a simple graph. This led me to think that a &lt;strong&gt;Blog post to create common Graph types&lt;/strong&gt; in Python is in order. But being the procrastinator that I am it always got pushed to the back of my head.&lt;/p&gt;

&lt;p&gt;One thing that helped me in pursuit of my data visualization needs in Python was this awesome course about &lt;a href=&#34;https://www.coursera.org/specializations/data-science-python?ranMID=40328&amp;ranEAID=lVarvwc5BD0&amp;ranSiteID=lVarvwc5BD0-SAQTYQNKSERwaOgd07RrHg&amp;siteID=lVarvwc5BD0-SAQTYQNKSERwaOgd07RrHg&amp;utm_content=3&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Data Visualization and applied plotting&lt;/a&gt; from University of Michigan which is a part of a pretty good &lt;a href=&#34;https://www.coursera.org/specializations/data-science-python?ranMID=40328&amp;ranEAID=lVarvwc5BD0&amp;ranSiteID=lVarvwc5BD0-SAQTYQNKSERwaOgd07RrHg&amp;siteID=lVarvwc5BD0-SAQTYQNKSERwaOgd07RrHg&amp;utm_content=3&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Data Science Specialization with Python&lt;/a&gt; in itself. Highly Recommended.&lt;/p&gt;

&lt;p&gt;But, yesterday I got introduced to &lt;strong&gt;&lt;a href=&#34;http://stanford.edu/~mwaskom/software/seaborn/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Seaborn&lt;/a&gt;&lt;/strong&gt; and I must say I am &lt;strong&gt;quite impressed&lt;/strong&gt; with it. It makes &lt;strong&gt;beautiful graphs&lt;/strong&gt; that are in my opinion &lt;strong&gt;better than R&amp;rsquo;s &lt;a href=&#34;http://ggplot2.org&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;ggplot2&lt;/a&gt;&lt;/strong&gt;. Gives you enough options to &lt;strong&gt;customize&lt;/strong&gt; and the best part is that it is so &lt;strong&gt;easy to learn&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;So I am finally writing this blog post with a basic &lt;strong&gt;purpose of creating a code base&lt;/strong&gt; that provides me with ready to use codes which could be put into analysis in a fairly straight-forward manner.&lt;/p&gt;

&lt;p&gt;Right. So here Goes.&lt;/p&gt;

&lt;p&gt;We Start by importing the libraries that we will need to use.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt  &lt;span style=&#34;color:#75715e&#34;&gt;#sets up plotting under plt&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; sns 			&lt;span style=&#34;color:#75715e&#34;&gt;#sets up styles and gives us more plotting options&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd 			&lt;span style=&#34;color:#75715e&#34;&gt;#lets us handle data as dataframes&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To create a use case for our graphs, we will be working with the &lt;strong&gt;Tips data&lt;/strong&gt; that contains the following information.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;tips &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_dataset(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;tips&amp;#34;&lt;/span&gt;)
tips&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/tips.png&#34;  height=&#34;400&#34; width=&#34;500&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h2 id=&#34;scatterplot-with-regression-line&#34;&gt;Scatterplot With Regression Line&lt;/h2&gt;

&lt;p&gt;Now let us work on visualizing this data.
We will use the &lt;strong&gt;&lt;a href=&#34;http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.regplot.html#seaborn.regplot&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;regplot&lt;/a&gt;&lt;/strong&gt; option in seaborn.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# We dont Probably need the Gridlines. Do we? If yes comment this line&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set(style&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ticks&amp;#34;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Here we create a matplotlib axes object. The extra parameters we use&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#34;ci&amp;#34; to remove confidence interval&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#34;marker&amp;#34; to have a x as marker.&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#34;scatter_kws&amp;#34; to provide style info for the points.[s for size]&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#34;line_kws&amp;#34; to provide style info for the line.[lw for line width]&lt;/span&gt;

g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;regplot(x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;tip&amp;#34;&lt;/span&gt;, y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;total_bill&amp;#34;&lt;/span&gt;, data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tips, ci &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False,
	scatter_kws&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;color&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;darkred&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;alpha&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;s&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;90&lt;/span&gt;},
	line_kws&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;color&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;g&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;alpha&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;lw&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;},marker&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;x&amp;#34;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# remove the top and right line in graph&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;despine()

&lt;span style=&#34;color:#75715e&#34;&gt;# Set the size of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_size_inches(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Set the Title of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axes&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Total Bill vs. Tip&amp;#39;&lt;/span&gt;, fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;34&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Set the xlabel of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Tip&amp;#34;&lt;/span&gt;,size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;67&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Set the ylabel of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Total Bill&amp;#34;&lt;/span&gt;,size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;67&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Set the ticklabel size and color of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tick_params(labelsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;14&lt;/span&gt;,labelcolor&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;black&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/regplot.png&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Now that required a bit of a code but i feel that it &lt;strong&gt;looks much better than what either Matplotlib or ggPlot2 could have rendered&lt;/strong&gt;. We got a lot of customization without too much code.&lt;/p&gt;

&lt;p&gt;But that is not really what actually made me like Seaborn. The plot type that actually got my attention was &lt;strong&gt;&lt;a href=&#34;http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.lmplot.html#seaborn.lmplot&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;lmplot&lt;/a&gt;&lt;/strong&gt;, which lets us use &lt;strong&gt;regplot&lt;/strong&gt; in a &lt;strong&gt;faceted&lt;/strong&gt; mode.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# So this function creates a faceted plot. The plot is parameterized by the following:&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# col : divides the data points into days and creates that many plots&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# palette: deep, muted, pastel, bright, dark, and colorblind. change the colors in graph. Experiment with these&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# col_wrap: we want 2 graphs in a row? Yes.We do&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# scatter_kws: attributes for points&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# hue: Colors on a particular column.&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# size: controls the size of graph&lt;/span&gt;

g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lmplot(x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;tip&amp;#34;&lt;/span&gt;, y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;total_bill&amp;#34;&lt;/span&gt;,ci&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None,data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tips, col&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;day&amp;#34;&lt;/span&gt;,
	palette&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;muted&amp;#34;&lt;/span&gt;,col_wrap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,scatter_kws&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;s&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;alpha&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;},
	line_kws&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;lw&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;alpha&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;},hue&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;day&amp;#34;&lt;/span&gt;,x_jitter&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;,y_jitter&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;,size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# remove the top and right line in graph&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;despine()
&lt;span style=&#34;color:#75715e&#34;&gt;# Additional line to adjust some appearance issue&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots_adjust(top&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Set the Title of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fig&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;suptitle(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Total Bill vs. Tip&amp;#39;&lt;/span&gt;, fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;34&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Set the xlabel of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlabels(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Tip&amp;#34;&lt;/span&gt;,size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Set the ylabel of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylabels(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Total Bill&amp;#34;&lt;/span&gt;,size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Set the ticklabel size and color of the graph from here&lt;/span&gt;
titles &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Thursday&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Friday&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Saturday&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Sunday&amp;#39;&lt;/span&gt;]
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; ax,title &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axes&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flat,titles):
    ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tick_params(labelsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;14&lt;/span&gt;,labelcolor&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;black&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/lmplot.png&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;div style=&#34;color:black; background-color: #E9DAEE;&#34;&gt;
&lt;a href=&#34;http://stanford.edu/~mwaskom/software/seaborn/tutorial/color_palettes.html#building-color-palettes-with-color-palette&#34;  target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;&lt;strong&gt;A side Note on Palettes&lt;/strong&gt;&lt;/a&gt;:&lt;br&gt;
You can build your own color palettes using &lt;strong&gt;color_palette()&lt;/strong&gt; function.
color_palette() will accept the name of any &lt;strong&gt;seaborn palette&lt;/strong&gt; or &lt;a href=&#34;http://matplotlib.org/users/colormaps.html&#34;  target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;&lt;strong&gt;matplotlib colormap&lt;/strong&gt;&lt;/a&gt;(except jet, which you should never use). It can also take a &lt;strong&gt;list of colors&lt;/strong&gt; specified in any valid matplotlib format (RGB tuples, &lt;strong&gt;hex color codes&lt;/strong&gt;, or HTML color names).
The return value is always a list of RGB tuples. This allows you to use your own color palettes in graph.
&lt;/div&gt;

&lt;script src=&#34;//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;barplots&#34;&gt;Barplots&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set(style&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ticks&amp;#34;&lt;/span&gt;)

flatui &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;#9b59b6&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;#3498db&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;#95a5a6&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;#e74c3c&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;#34495e&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;#2ecc71&amp;#34;&lt;/span&gt;]

&lt;span style=&#34;color:#75715e&#34;&gt;# This Function takes as input a custom palette&lt;/span&gt;
g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;barplot(x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sex&amp;#34;&lt;/span&gt;, y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;tip&amp;#34;&lt;/span&gt;, hue&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;day&amp;#34;&lt;/span&gt;,
	palette&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;color_palette(flatui),data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;tips,ci&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None)

&lt;span style=&#34;color:#75715e&#34;&gt;# remove the top and right line in graph&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;despine()

&lt;span style=&#34;color:#75715e&#34;&gt;# Set the size of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_size_inches(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Set the Title of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axes&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Do We tend to &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Tip high on Weekends?&amp;#39;&lt;/span&gt;,
	fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;34&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;b&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Set the xlabel of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Gender&amp;#34;&lt;/span&gt;,size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;67&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;g&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Set the ylabel of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Mean Tips&amp;#34;&lt;/span&gt;,size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;67&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Set the ticklabel size and color of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tick_params(labelsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;14&lt;/span&gt;,labelcolor&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;black&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/barplot.png&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h2 id=&#34;histograms-and-distribution-diagrams&#34;&gt;Histograms and Distribution Diagrams&lt;/h2&gt;

&lt;p&gt;They form another part of my workflow. Lets plot the normal Histogram using seaborn.
For this we will use the &lt;strong&gt;&lt;a href=&#34;http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.distplot.html#seaborn.distplot&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;distplot&lt;/a&gt;&lt;/strong&gt; function. This function combines the matplotlib hist function (with automatic calculation of a good default bin size) with the seaborn kdeplot() function.
It can also fit &lt;strong&gt;scipy.stats&lt;/strong&gt; distributions and plot the estimated PDF over the data.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create a list of 1000 Normal RVs&lt;/span&gt;
x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;normal(size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;)

sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_context(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;poster&amp;#34;&lt;/span&gt;)
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_style(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ticks&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# This  Function creates a normed Histogram by default.&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# If we use the parameter kde=False and norm_hist=False then&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# we will be using a count histogram&lt;/span&gt;

g&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(x,
         	kde_kws&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;color&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;g&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;lw&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;label&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KDE Estim&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;alpha&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;},
            hist_kws&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;color&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;alpha&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;label&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Freq&amp;#34;&lt;/span&gt;})


&lt;span style=&#34;color:#75715e&#34;&gt;# remove the top and right line in graph&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;despine()

&lt;span style=&#34;color:#75715e&#34;&gt;# Set the size of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_size_inches(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Set the Title of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axes&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Normal Simulation&amp;#39;&lt;/span&gt;, fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;34&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;b&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Set the xlabel of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;X&amp;#34;&lt;/span&gt;,size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;67&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;g&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Set the ylabel of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Density&amp;#34;&lt;/span&gt;,size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;67&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Set the ticklabel size and color of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tick_params(labelsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;14&lt;/span&gt;,labelcolor&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;black&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/hist_normal.png&#34;&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; scipy.stats &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; stats

a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.5&lt;/span&gt;
b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.5&lt;/span&gt;
x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;)
y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;beta&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rvs(a,b,size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10000&lt;/span&gt;)
y_act &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;beta&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pdf(x,a,b)
g&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distplot(y,kde&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False,norm_hist&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True,
            kde_kws&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;color&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;g&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;lw&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;label&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KDE Estim&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;alpha&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;},
            hist_kws&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;color&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;alpha&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;label&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Freq&amp;#34;&lt;/span&gt;})
&lt;span style=&#34;color:#75715e&#34;&gt;# Note that we plotted on the graph using plt matlabplot function&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(x,y_act)

&lt;span style=&#34;color:#75715e&#34;&gt;# remove the top and right line in graph&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;despine()

&lt;span style=&#34;color:#75715e&#34;&gt;# Set the size of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_size_inches(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Set the Title of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axes&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_title((&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Beta Simulation vs. Calculated Beta Density&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;For a=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;,b=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
	&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;(a,b),fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;34&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;b&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Set the xlabel of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;X&amp;#34;&lt;/span&gt;,size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;67&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;g&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Set the ylabel of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Density&amp;#34;&lt;/span&gt;,size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;67&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# Set the ticklabel size and color of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tick_params(labelsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;14&lt;/span&gt;,labelcolor&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;black&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/hist_beta.png&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h2 id=&#34;pairplots&#34;&gt;PairPlots&lt;/h2&gt;

&lt;p&gt;You need to see how variables vary with one another. What is the distribution of variables in the dataset. This is the graph to use with the &lt;strong&gt;&lt;a href=&#34;http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.pairplot.html#seaborn.pairplot&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;pairplot&lt;/a&gt;&lt;/strong&gt; function. Very helpful And Seaborn males it a joy to use. We will use &lt;strong&gt;Iris Dataset&lt;/strong&gt; here for this example.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;iris &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_dataset(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;iris&amp;#34;&lt;/span&gt;)
iris&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;head()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/iris.png&#34; height=&#34;500&#34; width=&#34;600&#34;&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create a Pairplot&lt;/span&gt;
g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pairplot(iris,hue&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;species&amp;#34;&lt;/span&gt;,palette&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;muted&amp;#34;&lt;/span&gt;,size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,
	vars&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sepal_width&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sepal_length&amp;#34;&lt;/span&gt;],kind&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;reg&amp;#39;&lt;/span&gt;,markers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;o&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;x&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;])

&lt;span style=&#34;color:#75715e&#34;&gt;# To change the size of the scatterpoints in graph&lt;/span&gt;
g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map_offdiag(plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter,  s&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;35&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# remove the top and right line in graph&lt;/span&gt;
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;despine()
&lt;span style=&#34;color:#75715e&#34;&gt;# Additional line to adjust some appearance issue&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots_adjust(top&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.9&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Set the Title of the graph from here&lt;/span&gt;
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fig&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;suptitle(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Relation between Sepal Width and Sepal Length&amp;#39;&lt;/span&gt;,
	fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;34&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;b&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/pairplot.png&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Hope you found this post useful and worth your time. You can find the iPython notebook at &lt;a href=&#34;https://github.com/MLWhiz/visualization/blob/master/Graphs.ipynb&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;github&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I tried to make this as simple as possible but You may always &lt;strong&gt;ask me&lt;/strong&gt; or see the documentation for doubts.&lt;/p&gt;

&lt;p&gt;If you have &lt;strong&gt;any more ideas&lt;/strong&gt; on how to use Seaborn or &lt;strong&gt;which graphs should i add here&lt;/strong&gt;, please suggest in the &lt;strong&gt;comments&lt;/strong&gt; section.&lt;/p&gt;

&lt;p&gt;I will definitely try to add to this post as I start using more visualizations and encounter other libraries as good as seaborn.&lt;/p&gt;

&lt;p&gt;Also since this is my first visualization post on this blog, I would like to call out a good course about &lt;a href=&#34;https://www.coursera.org/specializations/data-science-python?ranMID=40328&amp;ranEAID=lVarvwc5BD0&amp;ranSiteID=lVarvwc5BD0-SAQTYQNKSERwaOgd07RrHg&amp;siteID=lVarvwc5BD0-SAQTYQNKSERwaOgd07RrHg&amp;utm_content=3&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Data Visualization and applied plotting&lt;/a&gt; from University of Michigan which is a part of a pretty good &lt;a href=&#34;https://www.coursera.org/specializations/data-science-python?ranMID=40328&amp;ranEAID=lVarvwc5BD0&amp;ranSiteID=lVarvwc5BD0-SAQTYQNKSERwaOgd07RrHg&amp;siteID=lVarvwc5BD0-SAQTYQNKSERwaOgd07RrHg&amp;utm_content=3&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Data Science Specialization with Python&lt;/a&gt; in itself. Do check it out.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning Spark using Python: Basics and Applications</title>
      <link>https://mlwhiz.com/blog/2015/09/07/spark_basics_explain/</link>
      <pubDate>Mon, 07 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2015/09/07/spark_basics_explain/</guid>
      <description>

&lt;p&gt;I generally have a use case for &lt;a href=&#34;https://hadoop.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Hadoop&lt;/a&gt; in my daily job. It has made my life easier in a sense that I am able to get results which I was not able to see with SQL queries. But still I find it painfully slow.
I have to write procedural programs while I work. As in merge these two datasets and then filter and then merge another dataset and then filter using some condition and yada-yada.
You get the gist. And in hadoop its painstakingly boring to do this. You have to write more than maybe 3 Mapreduce Jobs. One job will read the data line by line and write to the disk.&lt;/p&gt;

&lt;p&gt;There is a lot of data movement that happens in between that further affects the speed.
Another thing I hate is that there is no straight way to pass files to mappers and reducers and that generally adds up another mapreduce job to the whole sequence.&lt;/p&gt;

&lt;p&gt;And that is just procedural tasks. To implement an iterative algorithm even after geting the whole logic of parallelization is again a challenge. There would be a lot of mapreduce tasks, a shell based driver program and a lot of unique thinking to bring everything together. And the running times are like crazy. Though sometimes it has its benefits:&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/compiling.png&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;That makes me think about the whole way Hadoop is implemented. While at the time Hadoop appeared the RAM was costly.
Now that is not the case. We already have 64GB machines in our Hadoop cluster. So is it really a good idea to not use a larger chunk of memory and read line by line.
Also can we have something that allows us to keep a particular piece of data in the memory, So that the next time our program needs it it doesnt have to read it again and waste time.
Wouldnt it be better if we have some variable that lets us keep the state our iterative algorithm is in.&lt;/p&gt;

&lt;h2 id=&#34;the-solution&#34;&gt;The Solution?&lt;/h2&gt;

&lt;p&gt;And here is where &lt;a href=&#34;http://spark.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Spark&lt;/a&gt; comes to rescue. Now working on Spark is very different from Hadoop but when you start using it you find that it makes things so much easier. You still do have to think in the mapreduce way sort of but the way the map and reduce steps are done are a little bit different.&lt;/p&gt;

&lt;p&gt;So lets first get Spark on our System (But keep in mind that for running spark in production environments you will
need whole clusters set up. A liberty which you may or may not have at present)&lt;/p&gt;

&lt;p&gt;The best way that I found to install Spark is following the Apache Spark installation guidelines with the Apache Spark eDx &lt;a href=&#34;https://courses.edx.org/courses/BerkeleyX/CS100.1x/1T2015/courseware&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;course&lt;/a&gt;. It lets you get Spark in your system and work with Spark with iPython notebooks. Something I prefer a lot and find the best way to code in Python.&lt;/p&gt;

&lt;p&gt;The installation instructions can be found &lt;a href=&#34;https://courses.edx.org/courses/BerkeleyX/CS100.1x/1T2015/courseware/d1f293d0cb53466dbb5c0cd81f55b45b/920d3370060540c8b21d56f05c64bdda/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;HERE&lt;/a&gt;. You may have to login in to an edX account to follow these instructions, but it is worth it.&lt;/p&gt;

&lt;p&gt;So once you have gone through all the steps mentioned there and installed spark using these instructions, you would see something like this in your browser.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/ipython_startup.png&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Ahh! so you have got Spark up and running now. That&amp;rsquo;s actually like half the process. I like to learn by examples so let&amp;rsquo;s get done with the &amp;ldquo;Hello World&amp;rdquo; of Distributed computing: The WordCount Program.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;lines &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;textFile(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;shakespeare.txt&amp;#34;&lt;/span&gt;)                   &lt;span style=&#34;color:#75715e&#34;&gt;# Distribute the data - Create a RDD &lt;/span&gt;

counts &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (lines&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatMap(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; &amp;#39;&lt;/span&gt;))          &lt;span style=&#34;color:#75715e&#34;&gt;# Create a list with all words&lt;/span&gt;
                  &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: (x, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))                 &lt;span style=&#34;color:#75715e&#34;&gt;# Create tuple (word,1)&lt;/span&gt;
                  &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduceByKey(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x,y : x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; y))      &lt;span style=&#34;color:#75715e&#34;&gt;# reduce by key i.e. the word&lt;/span&gt;
output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; counts&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)                                 &lt;span style=&#34;color:#75715e&#34;&gt;# get the output on local&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (word, count) &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; output:                             &lt;span style=&#34;color:#75715e&#34;&gt;# print output&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%i&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; (word, count))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/wordcount_result.png&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;So that is a small example. Pretty small code when you compare it with Hadoop. And most of the work gets done in the second command.
Don&amp;rsquo;t worry if you are not able to follow this yet as I need to tell you about the things that make Spark work.&lt;/p&gt;

&lt;p&gt;But before we get into Spark basics, Let us refresh some of our python Basics. Understanding Spark becomes a lot easier if you have used Lambda functions in Python.&lt;/p&gt;

&lt;p&gt;For those of you who haven&amp;rsquo;t used it, below is a brief intro.&lt;/p&gt;

&lt;h2 id=&#34;lambda-functions-in-python&#34;&gt;Lambda Functions in Python&lt;/h2&gt;

&lt;h4 id=&#34;map&#34;&gt;Map&lt;/h4&gt;

&lt;p&gt;Map is used to map a function to a array or a list. Say you want to apply some function to every element in a list. You can do this by simply using a for loop but python lambda functions let you do this in a single line in Python.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;my_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;]
&lt;span style=&#34;color:#75715e&#34;&gt;# Lets say I want to square each term in my_list.&lt;/span&gt;
squared_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; map(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x:x&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,my_list)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; squared_list&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span style=&#34;background-color: #FFF122; color:#000000&#34;&gt;[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;In the above example you could think of map as a function which takes two arguments - A function and a list. It then applies the function to every element of the list. What lambda allows you to do is write an inline function. In here the part &lt;strong&gt;&amp;ldquo;lambda x:x**2&amp;rdquo;&lt;/strong&gt; defines a function that takes x as input and returns x^2.&lt;/p&gt;

&lt;p&gt;You could have also provided a proper function in place of lambda. For Example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;squared&lt;/span&gt;(x):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;br&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;my_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;]
&lt;span style=&#34;color:#75715e&#34;&gt;# Lets say I want to square each term in my_list.&lt;/span&gt;
squared_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; map(squared,my_list)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; squared_list&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span style=&#34;background-color: #FFF122; color:#000000&#34;&gt;[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;The same result, but the lambda expressions make the code compact and a lot more readable.&lt;/p&gt;

&lt;h4 id=&#34;filter&#34;&gt;Filter&lt;/h4&gt;

&lt;p&gt;The other function that is used extensively is the filter function. This function takes two arguments - A condition and the list to filter. If you want to filter your list using some condition you use filter.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;my_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;]
&lt;span style=&#34;color:#75715e&#34;&gt;# Lets say I want only the even numbers in my list.&lt;/span&gt;
filtered_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; filter(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x:x&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,my_list)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; filtered_list&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span style=&#34;background-color: #FFF122; color:#000000&#34;&gt;[2, 4, 6, 8, 10]&lt;/span&gt;&lt;/p&gt;

&lt;h4 id=&#34;reduce&#34;&gt;Reduce&lt;/h4&gt;

&lt;p&gt;The next function is the reduce function. This function will be the workhorse in Spark. This function takes two arguments - a function to reduce that takes two arguments, and a list over which the reduce function is to be applied.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;my_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
&lt;span style=&#34;color:#75715e&#34;&gt;# Lets say I want to sum all elements in my list.&lt;/span&gt;
sum_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; reduce(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x,y:x&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;y,my_list)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; sum_list&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span style=&#34;background-color: #FFF122; color:#000000&#34;&gt;15&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Here the lambda function takes in two values x, y and returns their sum. Intuitively you can think that the reduce function works as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Reduce function first sends 1,2    ; the lambda function returns 3
Reduce function then sends 3,3     ; the lambda function returns 6
Reduce function then sends 6,4     ; the lambda function returns 10
Reduce function finally sends 10,5 ; the lambda function returns 15
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A condition on the lambda function we use in reduce is that it must be commutative that is a + b = b + a and associative that is (a + b) + c == a + (b + c).
In the above case we used sum which is &lt;strong&gt;commutative as well as associative&lt;/strong&gt;. Other functions that we could have used are &lt;strong&gt;max, min, multiplication&lt;/strong&gt; etc.&lt;/p&gt;

&lt;h2 id=&#34;moving-again-to-spark&#34;&gt;Moving Again to Spark&lt;/h2&gt;

&lt;p&gt;As we have now got the fundamentals of Python Functional Programming out of the way, lets again head to Spark.&lt;/p&gt;

&lt;p&gt;But first let us delve a little bit into how spark works. Spark actually consists of two things a driver and workers. Workers normally do all the work and the driver makes them do that work.&lt;/p&gt;

&lt;p&gt;An RDD is defined a parallelized data structure that gets distributed across the worker nodes. In our wordcount example, in the first line&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lines = sc.textFile(&amp;quot;data/cs100/lab1/shakespeare.txt&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We took a text file and distributed it across worker nodes so that they can work on it in parallel.
We could also parallelize lists using the function&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sc.parallelize
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;]
new_rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parallelize(data,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)
new_rdd&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span style=&#34;background-color: #FFF122; color:#000000&#34;&gt;ParallelCollectionRDD[15] at parallelize at PythonRDD.scala:392&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;In Spark we classify the operations into two Basic Types: Transformations and Actions.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Transformations&lt;/strong&gt; : Create new datasets from existing RDDs&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Actions&lt;/strong&gt; : Mechanism to get results out of Spark&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;understanding-transformations&#34;&gt;Understanding Transformations&lt;/h2&gt;

&lt;p&gt;So lets say you have got your data in the form of an RDD. To requote your data is now accesible b all the worker machines. You want to do some transformations on the data now. You may want to filter, Apply some function etc. In Spark this is done using Transformation functions. Spark provides many transformation functions. You can see a comprehensive list &lt;a href=&#34;http://spark.apache.org/docs/latest/programming-guide.html#transformations&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.
Some of the main ones that I use frequently are:&lt;/p&gt;

&lt;h5 id=&#34;1-map&#34;&gt;1. Map:&lt;/h5&gt;

&lt;p&gt;Applies a given function to an RDD. Note that the syntax is a little bit different from python, but it necessarily does the same thing. Don&amp;rsquo;t worry about collet yet. For now just think of it as a function that collects the data in squared_rdd back to a list.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;]
rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parallelize(data,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)
squared_rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x:x&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
squared_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;collect()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span style=&#34;background-color: #FFF122; color:#000000&#34;&gt;[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]&lt;/span&gt;&lt;/p&gt;

&lt;h5 id=&#34;2-filter&#34;&gt;2. Filter:&lt;/h5&gt;

&lt;p&gt;Again no surprises here. Takes as input a condition and keeps only those elements that fulfill that condition.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;]
rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parallelize(data,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)
filtered_rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;filter(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x:x&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
filtered_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;collect()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span style=&#34;background-color: #FFF122; color:#000000&#34;&gt;[2, 4, 6, 8, 10]&lt;/span&gt;&lt;/p&gt;

&lt;h5 id=&#34;3-distinct&#34;&gt;3. Distinct:&lt;/h5&gt;

&lt;p&gt;Returns only distinct elements in an RDD&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;]
rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parallelize(data,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)
distinct_rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;distinct()
distinct_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;collect()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span style=&#34;background-color: #FFF122; color:#000000&#34;&gt;[8, 4, 1, 5, 9, 2, 10, 6, 3, 7]&lt;/span&gt;&lt;/p&gt;

&lt;h5 id=&#34;4-flatmap&#34;&gt;4. Flatmap:&lt;/h5&gt;

&lt;p&gt;Similar to map, but each input item can be mapped to 0 or more output items&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;]
rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parallelize(data,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)
flat_rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;flatMap(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x:[x,x&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;])
flat_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;collect()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span style=&#34;background-color: #FFF122; color:#000000&#34;&gt;[1, 1, 2, 8, 3, 27, 4, 64]&lt;/span&gt;&lt;/p&gt;

&lt;h5 id=&#34;5-reduce-by-key&#34;&gt;5. Reduce By Key:&lt;/h5&gt;

&lt;p&gt;The analogue to the reduce in Hadoop Mapreduce. Now Spark cannot provide the value if it just worked with Lists. In Spark there is a concept of pair RDDs that makes it a lot more flexible. Lets assume we have a data in which we have product, its category and its selling price. We can still parallelize the data.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Apple&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Fruit&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;200&lt;/span&gt;),(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Banana&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Fruit&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;24&lt;/span&gt;),(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Tomato&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Fruit&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;56&lt;/span&gt;),(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Potato&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Vegetable&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;103&lt;/span&gt;),(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Carrot&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Vegetable&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;34&lt;/span&gt;)]
rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parallelize(data,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Right now our RDD rdd holds tuples. Now we want to find out the total sum of revenue that we got from each category. To do that we have to transform our rdd to a pair rdd so that it only contatins key-value pairs/tuples.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;category_price_rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: (x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],x[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]))
category_price_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;collect()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span style=&#34;background-color: #FFF122; color:#000000&#34;&gt;[(&amp;lsquo;Fruit&amp;rsquo;, 200), (&amp;lsquo;Fruit&amp;rsquo;, 24), (&amp;lsquo;Fruit&amp;rsquo;, 56), (&amp;lsquo;Vegetable&amp;rsquo;, 103), (&amp;lsquo;Vegetable&amp;rsquo;, 34)]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Here we used the map function to get it in the format we wanted. When working with textfile, the rdd that gets formed has got a lot of strings. We use map to convert it into a format that we want.&lt;/p&gt;

&lt;p&gt;So now our category_price_rdd contains the product category and the price at which the prouct sold. Now we want to reduce on the key and sum the prices. We can do this by:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;category_total_price_rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; category_price_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduceByKey(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x,y:x&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;y)
category_total_price_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;collect()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span style=&#34;background-color: #FFF122; color:#000000&#34;&gt;[(&amp;lsquo;Vegetable&amp;rsquo;, 137), (&amp;lsquo;Fruit&amp;rsquo;, 280)]&lt;/span&gt;&lt;/p&gt;

&lt;h5 id=&#34;6-group-by-key&#34;&gt;6. Group By Key:&lt;/h5&gt;

&lt;p&gt;Similar to reduce by key but does not reduce just puts all the elements in an iterator. For example if we wanted to keep as key the category and as the value all the products we would use this function.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Apple&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Fruit&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;200&lt;/span&gt;),(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Banana&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Fruit&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;24&lt;/span&gt;),(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Tomato&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Fruit&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;56&lt;/span&gt;),(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Potato&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Vegetable&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;103&lt;/span&gt;),(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Carrot&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Vegetable&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;34&lt;/span&gt;)]
rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parallelize(data,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)
category_product_rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: (x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],x[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]))
category_product_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;collect()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span style=&#34;background-color: #FFF122; color:#000000&#34;&gt;[(&amp;lsquo;Fruit&amp;rsquo;,&amp;lsquo;Apple&amp;rsquo;),(&amp;lsquo;Fruit&amp;rsquo;,&amp;lsquo;Banana&amp;rsquo;),(&amp;lsquo;Fruit&amp;rsquo;,&amp;lsquo;Tomato&amp;rsquo;),(&amp;lsquo;Vegetable&amp;rsquo;,&amp;lsquo;Potato&amp;rsquo;),(&amp;lsquo;Vegetable&amp;rsquo;,&amp;lsquo;Carrot&amp;rsquo;)]&lt;/span&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;grouped_products_by_category_rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; category_product_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupByKey()
findata &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; grouped_products_by_category_rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;collect()
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; data &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; findata:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; data[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],list(data[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span style=&#34;background-color: #FFF122; color:#000000&#34;&gt;Vegetable [&amp;lsquo;Potato&amp;rsquo;, &amp;lsquo;Carrot&amp;rsquo;]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style=&#34;background-color: #FFF122; color:#000000&#34;&gt;Fruit [&amp;lsquo;Apple&amp;rsquo;, &amp;lsquo;Banana&amp;rsquo;, &amp;lsquo;Tomato&amp;rsquo;]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Here the grouped by function worked and it returned the category and the list of products in that category.&lt;/p&gt;

&lt;h2 id=&#34;understanding-actions&#34;&gt;Understanding Actions&lt;/h2&gt;

&lt;p&gt;Now you have filtered your data, mapped some functions on it. Done your computation. Now you want to get the data on your local machine or save it to a file. You will have to use actions for that. A comprehensive list of actions is provided &lt;a href=&#34;http://spark.apache.org/docs/latest/programming-guide.html#actions&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;HERE&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Some of the most common actions that I tend to use are:&lt;/p&gt;

&lt;h5 id=&#34;1-collect&#34;&gt;1. Collect:&lt;/h5&gt;

&lt;p&gt;We have already used this actio many times. It takes the whole rdd and brings it back to the driver program.&lt;/p&gt;

&lt;h5 id=&#34;2-reduce&#34;&gt;2. Reduce:&lt;/h5&gt;

&lt;p&gt;Aggregate the elements of the dataset using a function func (which takes two arguments and returns one). The function should be commutative and associative so that it can be computed correctly in parallel.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parallelize([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;])
rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduce(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x,y : x&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;y)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span style=&#34;background-color: #FFF122; color:#000000&#34;&gt;15&lt;/span&gt;&lt;/p&gt;

&lt;h5 id=&#34;3-take&#34;&gt;3.take:&lt;/h5&gt;

&lt;p&gt;Return an list with the first n elements of the dataset.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parallelize([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;])
rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span style=&#34;background-color: #FFF122; color:#000000&#34;&gt;[1, 2, 3]&lt;/span&gt;&lt;/p&gt;

&lt;h5 id=&#34;4-takeordered&#34;&gt;4. takeOrdered:&lt;/h5&gt;

&lt;p&gt;Return the first n elements of the RDD using either their natural order or a custom comparator.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parallelize([&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;23&lt;/span&gt;])
rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;takeOrdered(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; s:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;s)      &lt;span style=&#34;color:#75715e&#34;&gt;# descending order&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span style=&#34;background-color: #FFF122; color:#000000&#34;&gt;[23, 12, 5]&lt;/span&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;rdd &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parallelize([(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;23&lt;/span&gt;),(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;34&lt;/span&gt;),(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;344&lt;/span&gt;),(&lt;span style=&#34;color:#ae81ff&#34;&gt;23&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;)])
rdd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;takeOrdered(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; s:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;s[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])      &lt;span style=&#34;color:#75715e&#34;&gt;# descending order&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span style=&#34;background-color: #FFF122; color:#000000&#34;&gt;[(12, 344), (3, 34), (23, 29)]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;So now lets take a look at the Wordcount Again&lt;/p&gt;

&lt;h2 id=&#34;understanding-the-wordcount-example&#34;&gt;Understanding The WordCount Example&lt;/h2&gt;

&lt;p&gt;Now we sort of understand the transformations and the actions provided to us by Spark. It should not be difficult to understand the work count program now. Lets go through the program niw line by line.&lt;/p&gt;

&lt;p&gt;The first lines creates a RDD and distributeds to the workers.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lines = sc.textFile(&amp;quot;data/cs100/lab1/shakespeare.txt&amp;quot;)  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This RDD lines contains a list of strings that are actually the line in file. This RDD is of the form:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[&#39;word1 word2 word3&#39;,&#39;word4 word3 word2&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This next line is actually the workhorse function in the whole script.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;counts = (lines.flatMap(lambda x: x.split(&#39; &#39;))          
                  .map(lambda x: (x, 1))                 
                  .reduceByKey(lambda x,y : x + y))      
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It contains a series of transformations that we do to the lines RDD. First of all we do a flatmap transformation. The flatmap transformation takes as input the lines and gives words as output. So after the flatmap transformation the RDD is of the form:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[&#39;word1&#39;,&#39;word2&#39;,&#39;word3&#39;,&#39;word4&#39;,&#39;word3&#39;,&#39;word2&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we do a map transformation on the flatmap output which converts the rdd to :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[(&#39;word1&#39;,1),(&#39;word2&#39;,1),(&#39;word3&#39;,1),(&#39;word4&#39;,1),(&#39;word3&#39;,1),(&#39;word2&#39;,1)]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally we do a reduceByKey transformation which counts the number of time each word appeared. After which the rdd approaches the final desirable form.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[(&#39;word1&#39;,1),(&#39;word2&#39;,2),(&#39;word3&#39;,2),(&#39;word4&#39;,1)]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This next line is an action that takes the first 10 elements of the resulting RDD locally.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;output = counts.take(10)                                 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This line just prints the output&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for (word, count) in output:                 
    print(&amp;quot;%s: %i&amp;quot; % (word, count))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;getting-serious&#34;&gt;Getting Serious&lt;/h2&gt;

&lt;p&gt;So till now we have talked about the Wordcount example and the basic transformations and actions that you could use in Spark. But we don&amp;rsquo;t do wordcount in real life. We have to work on bigger problems which are much more complex. Worry not! whatever we have learned till now will let us do that and more.&lt;/p&gt;

&lt;p&gt;Lets work with a concrete example:
I will work on an example in which Greg Rada Worked on &lt;a href=&#34;http://grouplens.org/datasets/movielens/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Movielens&lt;/a&gt;
Data with &lt;a href=&#34;http://www.gregreda.com/2013/10/26/using-pandas-on-the-movielens-dataset/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Pandas&lt;/a&gt; (BTW a great resource to learn Pandas). This example takes care of every sort of transformation that you may like to do with this data.&lt;/p&gt;

&lt;p&gt;So lets first talk about the dataset. The movielens dataset contains a lot of files but we are going to be working with 3 files only:&lt;/p&gt;

&lt;p&gt;1) Users: This file name is kept as &amp;ldquo;u.user&amp;rdquo;, The columns in this file are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[&#39;user_id&#39;, &#39;age&#39;, &#39;sex&#39;, &#39;occupation&#39;, &#39;zip_code&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2) Ratings: This file name is kept as &amp;ldquo;u.data&amp;rdquo;, The columns in this file are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[&#39;user_id&#39;, &#39;movie_id&#39;, &#39;rating&#39;, &#39;unix_timestamp&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3) Movies: This file name is kept as &amp;ldquo;u.item&amp;rdquo;, The columns in this file are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[&#39;movie_id&#39;, &#39;title&#39;, &#39;release_date&#39;, &#39;video_release_date&#39;, &#39;imdb_url&#39;, and 18 more columns.....]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;##What are the 25 most rated movies?
First of all lets load the data in different rdds. And see what the data contains.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;userRDD &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;textFile(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/vagrant/ml-100k/u.user&amp;#34;&lt;/span&gt;) 
ratingRDD &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;textFile(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/vagrant/ml-100k/u.data&amp;#34;&lt;/span&gt;) 
movieRDD &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;textFile(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/vagrant/ml-100k/u.item&amp;#34;&lt;/span&gt;) 
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;userRDD:&amp;#34;&lt;/span&gt;,userRDD&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ratingRDD:&amp;#34;&lt;/span&gt;,ratingRDD&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;movieRDD:&amp;#34;&lt;/span&gt;,movieRDD&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/data_def.png&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Seeing the data we note that to answer this question we will need to use the ratingRdd. But the ratingRDD does not have movie name. So we would have to merge movieRDD and ratingRDD. So lets see how we would do that in Spark.
Lets first do it step by step.Read the comments.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create a RDD from RatingRDD that only contains the two columns of interest i.e. movie_id,rating.&lt;/span&gt;
RDD_movid_rating &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ratingRDD&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x : (x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;RDD_movid_rating:&amp;#34;&lt;/span&gt;,RDD_movid_rating&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Create a RDD from MovieRDD that only contains the two columns of interest i.e. movie_id,title.&lt;/span&gt;
RDD_movid_title &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; movieRDD&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x : (x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;|&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;|&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;RDD_movid_title:&amp;#34;&lt;/span&gt;,RDD_movid_title&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# merge these two pair RDDs based on movie_id. For this we will use the transformation leftOuterJoin()&lt;/span&gt;
rdd_movid_title_rating &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RDD_movid_rating&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;leftOuterJoin(RDD_movid_title)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rdd_movid_title_rating:&amp;#34;&lt;/span&gt;,rdd_movid_title_rating&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# use the RDD in previous step to create (movie,1) tuple pair RDD&lt;/span&gt;
rdd_title_rating &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rdd_movid_title_rating&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: (x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; ))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rdd_title_rating:&amp;#34;&lt;/span&gt;,rdd_title_rating&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Use the reduceByKey transformation to reduce on the basis of movie_title&lt;/span&gt;
rdd_title_ratingcnt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rdd_title_rating&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reduceByKey(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x,y: x&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;y)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rdd_title_ratingcnt:&amp;#34;&lt;/span&gt;,rdd_title_ratingcnt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Get the final answer by using takeOrdered Transformation&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;#####################################&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;25 most rated movies:&amp;#34;&lt;/span&gt;,rdd_title_ratingcnt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;takeOrdered(&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;,&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;#####################################&amp;#34;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/result_rating_cnt_25.png&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;We could have done all this in a single command using the below command but the code is a little messy now. I did this to show that you can do things sequentially with Spark and you could bypass the process of variable creation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; (((ratingRDD&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x : (x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;
     leftOuterJoin(movieRDD&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x : (x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;|&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;|&amp;#34;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]))))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;
     map(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: (x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;
     reduceByKey(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x,y: x&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;y)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;
     takeOrdered(&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;,&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]))


&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;div style&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;margin-top: 9px; margin-bottom: 10px;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;center&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;lt;&lt;/span&gt;img src&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/images/result_rating_cnt_25_2.png&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;lt;/&lt;/span&gt;center&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;/&lt;/span&gt;div&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;##Which movies are most highly rated?&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we want to find the most highly rated 25 movvies using the same dataset. We actually want only those movies which have been rated atleast 100 times.
Lets do this using Spark:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# We already have the RDD rdd_movid_title_rating: [(u&amp;#39;429&amp;#39;, (u&amp;#39;5&amp;#39;, u&amp;#39;Day the Earth Stood Still, The (1951)&amp;#39;))]&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# We create an RDD that contains sum of all the ratings for a particular movie&lt;/span&gt;

rdd_title_ratingsum &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (rdd_movid_title_rating&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;
                        map(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: (x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],int(x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;
                        reduceByKey(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x,y:x&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;y))
                        
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rdd_title_ratingsum:&amp;#34;&lt;/span&gt;,rdd_title_ratingsum&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Merge this data with the RDD rdd_title_ratingcnt we created in the last step &lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# And use Map function to divide ratingsum by rating count.&lt;/span&gt;

rdd_title_ratingmean_rating_count &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (rdd_title_ratingsum&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;
                                    leftOuterJoin(rdd_title_ratingcnt)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;
                                    map(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x:(x[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],(float(x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]))))
                                    
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rdd_title_ratingmean_rating_count:&amp;#34;&lt;/span&gt;,rdd_title_ratingmean_rating_count&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# We could use take ordered here only but we want to only get the movies which have count&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# of ratings more than or equal to 100 so lets filter the data RDD.&lt;/span&gt;
rdd_title_rating_rating_count_gt_100 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (rdd_title_ratingmean_rating_count&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;
                                        filter(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;))
                                        
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rdd_title_rating_rating_count_gt_100:&amp;#34;&lt;/span&gt;,rdd_title_rating_rating_count_gt_100&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;take(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Get the final answer by using takeOrdered Transformation&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;#####################################&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;25 highly rated movies:&amp;#34;&lt;/span&gt;,
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; rdd_title_rating_rating_count_gt_100&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;takeOrdered(&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;,&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;#####################################&amp;#34;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/result_top25_rating.png&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;So Spark has Already provided an interface where we could apply transformations sequentially much easily than Hadoop.
And it is fast. While in hadoop things are a pain to do sequentially, the infrastructure that Spark provides seem to fit naturally into the analytics use case.&lt;/p&gt;

&lt;p&gt;Hopefully I&amp;rsquo;ve covered the basics well enough to pique your interest and help you get started with Spark. If I&amp;rsquo;ve missed something critical, feel free to let me know on Twitter or in the comments - I&amp;rsquo;d love constructive feedback.&lt;/p&gt;

&lt;p&gt;You can find the Jupyter notebook &lt;a href=&#34;http://nbviewer.ipython.org/github/MLWhiz/Spark_blog/blob/master/Spark_Part1.ipynb&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;HERE&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;One of the newest and best resources that you can keep an eye on is the &lt;a href=&#34;https://www.coursera.org/specializations/big-data?ranMID=40328&amp;ranEAID=lVarvwc5BD0&amp;ranSiteID=lVarvwc5BD0-NVLix0UOweGz5rWmJlt8.A&amp;siteID=lVarvwc5BD0-NVLix0UOweGz5rWmJlt8.A&amp;utm_content=3&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Introduction to Big Data&lt;/a&gt; course in the &lt;a href=&#34;https://www.coursera.org/specializations/big-data?ranMID=40328&amp;ranEAID=lVarvwc5BD0&amp;ranSiteID=lVarvwc5BD0-NVLix0UOweGz5rWmJlt8.A&amp;siteID=lVarvwc5BD0-NVLix0UOweGz5rWmJlt8.A&amp;utm_content=3&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Big Data Specialization&lt;/a&gt; from UCSanDiego&lt;/p&gt;

&lt;p&gt;Look out for these two books to learn more about Spark.&lt;/p&gt;

&lt;div style=&#34;margin-left:1em ; text-align: center;&#34;&gt;
&lt;a target=&#34;_blank&#34; rel=&#34;nofollow&#34; href=&#34;https://www.amazon.com/gp/product/1491912766/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1491912766&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=916f1678fb802e13211b4b1c648be75e&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1491912766&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1491912766&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;
&lt;/t&gt;&lt;/t&gt;
&lt;a target=&#34;_blank&#34; rel=&#34;nofollow&#34; href=&#34;https://www.amazon.com/gp/product/1617292605/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1617292605&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=89da1866198268847438c42ef14c4380&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1617292605&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1617292605&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;
&lt;/div&gt;

&lt;p&gt;The first one of these is a bestseller. It presents 9 case studies of data analysis applications in various domains. The topics are diverse and the authors always use real world datasets. Beside learning Spark and a data science you will also have the opportunity to gain insight about topics like taxi traffic in NYC, deforestation or neuroscience. The second one is more of a reference that takes the reader on a tour of the Spark fundamentals, explaining the RDD data model in detail, after which it dives into the main functionality of Spark: Spark SQL, Spark Streaming, MLLib, SparkML, and GraphX. Later on, it covers the operational aspects of setting up a standalone Spark cluster, as well as running it on YARN and Mesos.&lt;/p&gt;

&lt;script src=&#34;//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e&#34;&gt;&lt;/script&gt;
</description>
    </item>
    
    <item>
      <title>Behold the power of MCMC</title>
      <link>https://mlwhiz.com/blog/2015/08/21/mcmc_algorithm_cryptography/</link>
      <pubDate>Fri, 21 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2015/08/21/mcmc_algorithm_cryptography/</guid>
      <description>

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/mcmc.png&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Last time I wrote an article on MCMC and how they could be useful. We learned how MCMC chains could be used to simulate from a random variable whose distribution is partially known i.e. we don&amp;rsquo;t know the normalizing constant.&lt;/p&gt;

&lt;p&gt;So MCMC Methods may sound interesting to some (for these what follows is a treat) and for those who don&amp;rsquo;t really appreciate MCMC till now, I hope I will be able to pique your interest by the end of this blog post.&lt;/p&gt;

&lt;p&gt;So here goes. This time we will cover some applications of MCMC in various areas of Computer Science using Python. If you feel the problems difficult to follow with, I would advice you to go back and read the &lt;a href=&#34;https://mlwhiz.com/blog/2015/08/19/mcmc_algorithms_beta_distribution/&#34;&gt;previous post&lt;/a&gt;, which tries to explain MCMC Methods. We Will try to solve the following two problems:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Breaking the Code&lt;/strong&gt; - This problem has got somewhat of a great pedigree as this method was suggested by Persi Diaconis- The Mathemagician. So Someone comes to you with the below text. This text looks like gibberish but this is a code, Could you decrypyt it?&lt;br&gt;&lt;br&gt;
&lt;em&gt;XZ STAVRK HXVR MYAZ OAKZM JKSSO SO MYR OKRR XDP JKSJRK XBMASD SO YAZ TWDHZ  MYR JXMBYNSKF BSVRKTRM NYABY NXZ BXKRTRZZTQ OTWDH SVRK MYR AKSD ERPZMRXP  KWZMTRP  MYR JXTR OXBR SO X QSWDH NSIXD NXZ KXAZRP ORRETQ OKSI MYR JATTSN  XDP X OXADM VSABR AIJRKORBMTQ XKMABWTXMRP MYR NSKPZ  TRM IR ZRR MYR BYATP  XDP PAR  MYR ZWKHRSD YXP ERRD ZAMMADH NAMY YAZ OXBR MWKDRP MSNXKPZ MYR OAKR  HAVADH MYR JXTIZ SO YAZ YXDPZ X NXKI XDP X KWE XTMRKDXMRTQ  XZ MYR QSWDH NSIXD ZJSFR  YR KSZR  XDP XPVXDBADH MS MYR ERP Z YRXP  ZXAP  NAMY ISKR FADPDRZZ MYXD IAHYM YXVR ERRD RGJRBMRP SO YAI&lt;/em&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;The Knapsack Problem&lt;/strong&gt; - This problem comes from &lt;a href=&#34;http://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science-ebook/dp/B00MMOJ19I&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Introduction to Probability&lt;/a&gt; by Joseph Blitzstein. You should check out his courses &lt;a href=&#34;http://projects.iq.harvard.edu/stat110/handouts&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;STAT110&lt;/a&gt; and &lt;a href=&#34;http://cm.dce.harvard.edu/2014/01/14328/publicationListing.shtml&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;CS109&lt;/a&gt; as they are awesome. Also as it turns out Diaconis was the advisor of Joseph. So you have Bilbo a Thief who goes to Smaug&amp;rsquo;s Lair. He finds M treasures. Each treasure has some Weight and some Gold value. But Bilbo cannot really take all of that. He could only carry a certain Maximum Weight. But being a smart hobbit, he wants to Maximize the value of the treasures he takes. Given the values for weights and value of the treasures and the maximum weight that Bilbo could carry, could you find a good solution? This is known as the Knapsack Problem in Computer Science.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;breaking-the-code&#34;&gt;Breaking the Code&lt;/h2&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/security.png&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;So we look at the data and form a hypothesis that the data has been scrambled using a Substitution Cipher. We don&amp;rsquo;t know the encryption key, and we would like to know the Decryption Key so that we can decrypt the data and read the code.&lt;/p&gt;

&lt;p&gt;To create this example, this data has actually been taken from Oliver Twist. We scrambled the data using a random encryption key, which we forgot after encrypting and we would like to decrypt this encrypted text using MCMC Chains. The real decryption key actually is &amp;ldquo;ICZNBKXGMPRQTWFDYEOLJVUAHS&amp;rdquo;&lt;/p&gt;

&lt;p&gt;So lets think about this problem for a little bit. The decryption key could be any 26 letter string with all alphabets appearing exactly once. How many string permutations are there like that? That number would come out to be $26! \approx 10^{26}$ permutations. That is a pretty large number. If we go for using a brute force approach we are screwed.
So what could we do? MCMC Chains come to rescue.&lt;/p&gt;

&lt;p&gt;We will devise a Chain whose states theoritically could be any of these permutations. Then we will:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Start by picking up a random current state.&lt;/li&gt;
&lt;li&gt;Create a proposal for a new state by swapping two random letters in the current state.&lt;/li&gt;
&lt;li&gt;Use a Scoring Function which calculates the score of the current state $Score_C$ and the proposed State $Score_P$.&lt;/li&gt;
&lt;li&gt;If the score of the proposed state is more than current state, Move to Proposed State.&lt;/li&gt;
&lt;li&gt;Else flip a coin which has a probability of Heads $Score_P/Score_C$. If it comes heads move to proposed State.&lt;/li&gt;
&lt;li&gt;Repeat from 2nd State.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If we get lucky we may reach a steady state where the chain has the stationary distribution of the needed states and the state that the chain is at could be used as a solution.&lt;/p&gt;

&lt;p&gt;So the Question is what is the scoring function that we will want to use. We want to use a scoring function for each state(Decryption key) which assigns a positive score to each decryption key. This score intuitively should be more if the encrypted text looks more like actual english if decrypted using this decryption key.&lt;/p&gt;

&lt;p&gt;So how can we quantify such a function. We will check a long text and calculate some statistics. See how many times one alphabet comes after another in a legitimate long text like War and Peace. For example we want to find out how many times does &amp;lsquo;BA&amp;rsquo; appears in the text or how many times &amp;lsquo;TH&amp;rsquo; occurs in the text.&lt;/p&gt;

&lt;p&gt;For each pair of characters $\beta_1$ and $\beta_2$ (e.g. $\beta_1$ = T and $\beta_2$ =H), we let $R(\beta_1,\beta_2)$ record the number of times that specific pair(e.g. &amp;ldquo;TH&amp;rdquo;) appears consecutively in the reference text.&lt;/p&gt;

&lt;p&gt;Similarly, for a putative decryption key x, we let $F_x(\beta_1,\beta_2)$ record the number of times that
pair appears when the cipher text is decrypted using the decryption key x.&lt;/p&gt;

&lt;p&gt;We then Score a particular decryption key x using:&lt;/p&gt;

&lt;div&gt;$$Score(x) = \prod R(\beta_1,\beta_2)^{F_x(\beta_1,\beta_2)}$$&lt;/div&gt;

&lt;p&gt;This function can be thought of as multiplying, for each consecutive pair of letters in the decrypted
text, the number of times that pair occurred in the reference text.  Intuitively, the score function
is higher when the pair frequencies in the decrypted text most closely match those of the reference
text,  and  the  decryption  key  is  thus  most  likely  to  be  correct.&lt;/p&gt;

&lt;p&gt;To make life easier with calculations we will calculate $log(Score(x))$&lt;/p&gt;

&lt;p&gt;So lets start working through the problem step by step.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# AIM: To Decrypt a text using MCMC approach. i.e. find decryption key which we will call cipher from now on.&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; string
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; math
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random

&lt;span style=&#34;color:#75715e&#34;&gt;# This function takes as input a decryption key and creates a dict for key where each letter in the decryption key&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# maps to a alphabet For example if the decryption key is &amp;#34;DGHJKL....&amp;#34; this function will create a dict like {D:A,G:B,H:C....} &lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;create_cipher_dict&lt;/span&gt;(cipher):
    cipher_dict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
    alphabet_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(string&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ascii_uppercase)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(cipher)):
        cipher_dict[alphabet_list[i]] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cipher[i]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; cipher_dict

&lt;span style=&#34;color:#75715e&#34;&gt;# This function takes a text and applies the cipher/key on the text and returns text.&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;apply_cipher_on_text&lt;/span&gt;(text,cipher):
    cipher_dict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; create_cipher_dict(cipher) 
    text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(text)
    newtext &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; elem &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; text:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; elem&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;upper() &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; cipher_dict:
            newtext&lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt;cipher_dict[elem&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;upper()]
        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
            newtext&lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; newtext

&lt;span style=&#34;color:#75715e&#34;&gt;# This function takes as input a path to a long text and creates scoring_params dict which contains the &lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# number of time each pair of alphabet appears together&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# Ex. {&amp;#39;AB&amp;#39;:234,&amp;#39;TH&amp;#39;:2343,&amp;#39;CD&amp;#39;:23 ..}&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;create_scoring_params_dict&lt;/span&gt;(longtext_path):
    scoring_params &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
    alphabet_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(string&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ascii_uppercase)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; open(longtext_path) &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; fp:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; line &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; fp:
            data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(line&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strip())
            &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(data)&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
                alpha_i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data[i]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;upper()
                alpha_j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data[i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;upper()
                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; alpha_i &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; alphabet_list &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; alpha_i &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;:
                    alpha_i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;
                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; alpha_j &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; alphabet_list &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; alpha_j &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;:
                    alpha_j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;
                key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; alpha_i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;alpha_j
                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; key &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; scoring_params:
                    scoring_params[key]&lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
                &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
                    scoring_params[key]&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; scoring_params

&lt;span style=&#34;color:#75715e&#34;&gt;# This function takes as input a text and creates scoring_params dict which contains the &lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# number of time each pair of alphabet appears together&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# Ex. {&amp;#39;AB&amp;#39;:234,&amp;#39;TH&amp;#39;:2343,&amp;#39;CD&amp;#39;:23 ..}&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;score_params_on_cipher&lt;/span&gt;(text):
    scoring_params &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
    alphabet_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(string&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ascii_uppercase)
    data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strip())
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(data)&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
        alpha_i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;data[i]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;upper()
        alpha_j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data[i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;upper()
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; alpha_i &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; alphabet_list &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; alpha_i &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;:
            alpha_i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; alpha_j &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; alphabet_list &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; alpha_j &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;:
            alpha_j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;
        key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; alpha_i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;alpha_j
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; key &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; scoring_params:
            scoring_params[key]&lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
            scoring_params[key]&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; scoring_params

&lt;span style=&#34;color:#75715e&#34;&gt;# This function takes the text to be decrypted and a cipher to score the cipher.&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# This function returns the log(score) metric&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_cipher_score&lt;/span&gt;(text,cipher,scoring_params):
    cipher_dict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; create_cipher_dict(cipher)
    decrypted_text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; apply_cipher_on_text(text,cipher)
    scored_f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; score_params_on_cipher(decrypted_text)
    cipher_score &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; k,v &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; scored_f&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iteritems():
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; k &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; scoring_params:
            cipher_score &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; v&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;math&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log(scoring_params[k])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; cipher_score

&lt;span style=&#34;color:#75715e&#34;&gt;# Generate a proposal cipher by swapping letters at two random location&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;generate_cipher&lt;/span&gt;(cipher):
    pos1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randint(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(list(cipher))&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    pos2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randint(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(list(cipher))&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; pos1 &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; pos2:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; generate_cipher(cipher)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
        cipher &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(cipher)
        pos1_alpha &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cipher[pos1]
        pos2_alpha &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cipher[pos2]
        cipher[pos1] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pos2_alpha
        cipher[pos2] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pos1_alpha
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join(cipher)

&lt;span style=&#34;color:#75715e&#34;&gt;# Toss a random coin with robability of head p. If coin comes head return true else false.&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;random_coin&lt;/span&gt;(p):
    unif &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; unif&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt;p:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; False
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; True
    
&lt;span style=&#34;color:#75715e&#34;&gt;# Takes as input a text to decrypt and runs a MCMC algorithm for n_iter. Returns the state having maximum score and also&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# the last few states &lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;MCMC_decrypt&lt;/span&gt;(n_iter,cipher_text,scoring_params):
    current_cipher &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; string&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ascii_uppercase &lt;span style=&#34;color:#75715e&#34;&gt;# Generate a random cipher to start&lt;/span&gt;
    state_keeper &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; set()
    best_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;
    score &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(n_iter):
        state_keeper&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(current_cipher)
        proposed_cipher &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; generate_cipher(current_cipher)
        score_current_cipher &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_cipher_score(cipher_text,current_cipher,scoring_params)
        score_proposed_cipher &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_cipher_score(cipher_text,proposed_cipher,scoring_params)
        acceptance_probability &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; min(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,math&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(score_proposed_cipher&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;score_current_cipher))
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; score_current_cipher&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;score:
            best_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; current_cipher
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; random_coin(acceptance_probability):
            current_cipher &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; proposed_cipher
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;iter&amp;#34;&lt;/span&gt;,i,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;:&amp;#34;&lt;/span&gt;,apply_cipher_on_text(cipher_text,current_cipher)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;99&lt;/span&gt;]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; state_keeper,best_state

&lt;span style=&#34;color:#75715e&#34;&gt;## Run the Main Program:&lt;/span&gt;

scoring_params &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; create_scoring_params_dict(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;war_and_peace.txt&amp;#39;&lt;/span&gt;)

plain_text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;As Oliver gave this first proof of the free and proper action of his lungs, &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;the patchwork coverlet which was carelessly flung over the iron bedstead, rustled; &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;the pale face of a young woman was raised feebly from the pillow; and a faint voice imperfectly &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;articulated the words, Let me see the child, and die. &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;The surgeon had been sitting with his face turned towards the fire: giving the palms of his hands a warm &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;and a rub alternately. As the young woman spoke, he rose, and advancing to the bed&amp;#39;s head, said, with more kindness &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;than might have been expected of him: &amp;#34;&lt;/span&gt;

encryption_key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;XEBPROHYAUFTIDSJLKZMWVNGQC&amp;#34;&lt;/span&gt;
cipher_text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; apply_cipher_on_text(plain_text,encryption_key)
decryption_key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ICZNBKXGMPRQTWFDYEOLJVUAHS&amp;#34;&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Text To Decode:&amp;#34;&lt;/span&gt;, cipher_text
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
states,best_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MCMC_decrypt(&lt;span style=&#34;color:#ae81ff&#34;&gt;10000&lt;/span&gt;,cipher_text,scoring_params)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Decoded Text:&amp;#34;&lt;/span&gt;,apply_cipher_on_text(cipher_text,best_state)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MCMC KEY FOUND:&amp;#34;&lt;/span&gt;,best_state
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ACTUAL DECRYPTION KEY:&amp;#34;&lt;/span&gt;,decryption_key&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/result1_MCMC.png&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;This chain converges around the 2000th iteration and we are able to unscramble the code. That&amp;rsquo;s awesome!!!
Now as you see the MCMC Key found is not exactly the encryption key. So the solution is not a deterministic one, but we can see that it does not actually decrease any of the value that the MCMC Methods provide. Now Lets Help Bilbo :)&lt;/p&gt;

&lt;h2 id=&#34;the-knapsack-problem&#34;&gt;The Knapsack Problem&lt;/h2&gt;

&lt;p&gt;Restating, we have Bilbo a Thief who goes to Smaug&amp;rsquo;s Lair. He finds M treasures. Each treasure has some Weight and some Gold value. But Bilbo cannot really take all of that. He could only carry a certain Maximum Weight. But being a smart hobbit, he wants to Maximize the value of the treasures he takes. Given the values for weights and value of the treasures and the maximum weight that Bilbo could carry, could you find a good solution?&lt;/p&gt;

&lt;p&gt;So in this problem we have an $1$x$M$ array of Weight Values W, Gold Values G and a value for the maximum weight $w_{MAX}$ that Bilbo can carry.
We want to find out an $1$x$M$ array $X$ of 1&amp;rsquo;s and 0&amp;rsquo;s, which holds weather Bilbo Carries a particular treasure or not.
This array needs to follow the constraint $WX^T &amp;lt; w_{MAX}$ and we want to maximize $GX^T$ for a particular state X.(Here the T means transpose)&lt;/p&gt;

&lt;p&gt;So lets first discuss as to how we will create a proposal from a previous state.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Pick a random index from the state and toggle the index value.&lt;/li&gt;
&lt;li&gt;Check if we satisfy our constraint. If yes this state is the proposal state.&lt;/li&gt;
&lt;li&gt;Else pick up another random index and repeat.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We also need to think about the Scoring Function.
We need to give high values to states with high gold value. We will use:
&lt;br&gt;&lt;/p&gt;

&lt;div&gt;$$Score(X)=e^{\beta GX^T}$$&lt;/div&gt;

&lt;p&gt;We give exponentially more value to higher score. The Beta here is a +ve constant. But how to choose it? If $\beta$ is big we will give very high score to good solutions and the chain will not be able to try new solutions as it can get stuck in local optimas. If we give a small value the chain will not converge to very good solutions. So weuse an Optimization Technique called &lt;strong&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Simulated_annealing&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Simulated Annealing&lt;/a&gt;&lt;/strong&gt; i.e. we will start with a small value of $\beta$ and increase as no of iterations go up.
That way the chain will explore in the starting stages and stay at the best solution in the later stages.&lt;/p&gt;

&lt;p&gt;So now we have everything we need to get started&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np

W &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;40&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;60&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;34&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;45&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;67&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;33&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;23&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;34&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;56&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;23&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;56&lt;/span&gt;]
G &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;120&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;420&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;610&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;112&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;341&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;435&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;657&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;363&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;273&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;812&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;534&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;356&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;223&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;516&lt;/span&gt;]
W_max &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;150&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# This function takes a state X , The gold vector G and a Beta Value and return the Log of score&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;score_state_log&lt;/span&gt;(X,G,Beta):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; Beta&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(X,G)

&lt;span style=&#34;color:#75715e&#34;&gt;# This function takes as input a state X and the number of treasures M, The weight vector W and the maximum weight W_max&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# and returns a proposal state&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;create_proposal&lt;/span&gt;(X,W,W_max):
    M &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; len(W)
    random_index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randint(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,M&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    &lt;span style=&#34;color:#75715e&#34;&gt;#print random_index&lt;/span&gt;
    proposal &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(X)
    proposal[random_index] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; proposal[random_index]  &lt;span style=&#34;color:#75715e&#34;&gt;#Toggle&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;#print proposal&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(proposal,W)&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt;W_max:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; proposal
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; create_proposal(X,W,W_max)
    
&lt;span style=&#34;color:#75715e&#34;&gt;# Takes as input a text to decrypt and runs a MCMC algorithm for n_iter. Returns the state having maximum score and also&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# the last few states &lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;MCMC_Golddigger&lt;/span&gt;(n_iter,W,G,W_max, Beta_start &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.05&lt;/span&gt;, Beta_increments&lt;span style=&#34;color:#f92672&#34;&gt;=.&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;02&lt;/span&gt;):
    M &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; len(W)
    Beta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Beta_start
    current_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;M &lt;span style=&#34;color:#75715e&#34;&gt;# We start with all 0&amp;#39;s&lt;/span&gt;
    state_keeper &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    best_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;
    score &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(n_iter):
        state_keeper&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(current_X)
        proposed_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; create_proposal(current_X,W,W_max)

        score_current_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; score_state_log(current_X,G,Beta)
        score_proposed_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; score_state_log(proposed_X,G,Beta)
        acceptance_probability &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; min(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,math&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(score_proposed_X&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;score_current_X))
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; score_current_X&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;score:
            best_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; current_X
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; random_coin(acceptance_probability):
            current_X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; proposed_X
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;500&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
            Beta &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; Beta_increments 
        &lt;span style=&#34;color:#75715e&#34;&gt;# You can use these below two lines to tune value of Beta&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;#if i%20==0:&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;#    print &amp;#34;iter:&amp;#34;,i,&amp;#34; |Beta=&amp;#34;,Beta,&amp;#34; |Gold Value=&amp;#34;,np.dot(current_X,G)&lt;/span&gt;
            
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; state_keeper,best_state&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Running the Main program:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;max_state_value &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; 
Solution_MCMC &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;):
    state_keeper,best_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MCMC_Golddigger(&lt;span style=&#34;color:#ae81ff&#34;&gt;50000&lt;/span&gt;,W,G,W_max,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.0005&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0005&lt;/span&gt;)
    state_value&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(best_state,G)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; state_value&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;max_state_value:
        max_state_value &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; state_value
        Solution_MCMC &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; best_state

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MCMC Solution is :&amp;#34;&lt;/span&gt; , str(Solution_MCMC) , &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;with Gold Value:&amp;#34;&lt;/span&gt;, str(max_state_value)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-family:courier new,monospace; background-color:#f6c6529c; color:#000000&#34;&gt;
MCMC Solution is : [0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0] with Gold Value: 2435
&lt;/pre&gt;

&lt;p&gt;Now I won&amp;rsquo;t say that this is the best solution. The deterministic solution using DP will be the best for such use case but sometimes when the problems gets large, having such techniques at disposal becomes invaluable.&lt;/p&gt;

&lt;p&gt;So tell me What do you think about MCMC Methods?&lt;/p&gt;

&lt;p&gt;Also, If you find any good applications or would like to apply these techniques to some area, I would really be glad to know about them and help if possible.&lt;/p&gt;

&lt;p&gt;The codes for both examples are sourced at &lt;a href=&#34;https://github.com/MLWhiz/MCMC_Project&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Github&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;references-and-sources&#34;&gt;References and Sources:&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science-ebook/dp/B00MMOJ19I&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Introduction to Probability Joseph K Blitzstein, Jessica Hwang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://statweb.stanford.edu/~cgates/PERSI/papers/MCMCRev.pdf&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;The Markov Chain Monte Carlo Revolution, Persi Diaconis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.utstat.toronto.edu/wordpress/WSFiles/technicalreports/1005.pdf&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Decrypting Classical Cipher Text Using Markov Chain Monte Carlo, Jian Chen and Jeffrey S. Rosenthal&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;One of the newest and best resources that you can keep an eye on is the &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;utm_content=2&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bayesian Methods for Machine Learning&lt;/a&gt; course in the &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;utm_content=2&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Advanced machine learning specialization&lt;/a&gt; created jointly by Kazanova(Number 3 Kaggler at the time of writing)&lt;/p&gt;

&lt;p&gt;Apart from that I also found a course on &lt;strong&gt;&lt;a href=&#34;https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;offerid=495576.8910375858&amp;type=2&amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Fbayesian&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bayesian Statistics on Coursera&lt;/a&gt;&lt;/strong&gt;. In the process of doing it right now so couldn&amp;rsquo;t really comment on it. But since I had done an course on &lt;strong&gt;&lt;a href=&#34;https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;offerid=495576.8839843074&amp;type=2&amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Finferential-statistics-intro&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Inferential Statistics&lt;/a&gt;&lt;/strong&gt; taught by the same professor before(Mine Çetinkaya-Rundel), I am very hopeful for this course. Let&amp;rsquo;s see.&lt;/p&gt;

&lt;p&gt;Also look out for these two books to learn more about MCMC. I have not yet read them whole but still I liked whatever I read:&lt;/p&gt;

&lt;div style=&#34;margin-left:1em ; text-align: center;&#34;&gt;

&lt;a target=&#34;_blank&#34; rel=&#34;nofollow&#34; href=&#34;https://www.amazon.com/gp/product/1439840954/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1439840954&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=d55979088adc0aabeaed88f4f14b48b6&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1439840954&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1439840954&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;
&lt;/t&gt;&lt;/t&gt;
&lt;a target=&#34;_blank&#34; rel=&#34;nofollow&#34;  href=&#34;https://www.amazon.com/gp/product/1584885874/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1584885874&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=ee3e2a0bc99359d6c5db0463ab1abb13&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1584885874&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1584885874&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;
&lt;/div&gt;

&lt;p&gt;Both these books are pretty high level and hard on math. But these are the best texts out there too. :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>My Tryst With MCMC Algorithms</title>
      <link>https://mlwhiz.com/blog/2015/08/19/mcmc_algorithms_b_distribution/</link>
      <pubDate>Wed, 19 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2015/08/19/mcmc_algorithms_b_distribution/</guid>
      <description>

&lt;p&gt;The things that I find hard to understand push me to my limits. One of the things that I have always found hard is &lt;strong&gt;Markov Chain Monte Carlo Methods&lt;/strong&gt;.
When I first encountered them, I read a lot about them but mostly it ended like this.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/flabbergasted.png&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;The meaning is normally hidden in deep layers of Mathematical noise and not easy to decipher.
This blog post is intended to clear up the confusion around MCMC methods, Know what they are actually useful for and Get hands on with some applications.&lt;/p&gt;

&lt;h2 id=&#34;so-what-really-are-mcmc-methods&#34;&gt;&lt;strong&gt;So what really are MCMC Methods?&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;First of all we have to understand what are &lt;strong&gt;&lt;em&gt;Monte Carlo&lt;/em&gt;&lt;/strong&gt; Methods!!!&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Monte_Carlo_method&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Monte Carlo&lt;/a&gt; methods derive their name from Monte Carlo Casino in Monaco. There are many card games that need probability of winning against the dealer. Sometimes calculating this probability can be mathematically complex or highly intractable. But we can always run a computer simulation to simulate the whole game many times and see the probability as the number of wins divided by the number of games played.&lt;/p&gt;

&lt;p&gt;So that is all you need to know about Monte carlo Methods. Yes it is just a simple simulation technique with a Fancy Name.&lt;/p&gt;

&lt;p&gt;So as we have got the first part of MCMC, we also need to understand what are &lt;strong&gt;&lt;em&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Markov_chain&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Markov Chains&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;.
Before Jumping onto Markov Chains let us learn a little bit about &lt;strong&gt;Markov Property&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Suppose you have a system of $M$ possible states, and you are hopping from one state to another.
&lt;em&gt;Markov Property&lt;/em&gt; says that given a process which is at a state $X_n$ at a particular point of time, the probability of $X_{n+1} = k$, where $k$ is any of the $M$ states the process can hop to, will only be dependent on which state it is at the given moment of time.
And not on how it reached the current state.&lt;/p&gt;

&lt;p&gt;Mathematically speaking:&lt;/p&gt;

&lt;div&gt; $$P(X_{n+1}=k | X_n=k_n,X_{n-1}=k_{n-1},....,X_1=k_1) = P(X_{n+1}=k|X_n=k_n)$$&lt;/div&gt;

&lt;p&gt;If a process exhibits the Markov Property than it is known as a Markov Process.&lt;/p&gt;

&lt;p&gt;Now Why is a Markov Chain important?
It is important because of its &lt;strong&gt;stationary distribution&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;So what is a &lt;strong&gt;Stationary Distribution&lt;/strong&gt;?&lt;/p&gt;

&lt;p&gt;Assume you have a markov process like below. You start from any state $X_i$ and want to find out the state Probability distribution at $X_{i+1}$.&lt;/p&gt;

&lt;div style=&#34;margin-top: 10px; margin-bottom: -10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/Finance_Markov_chain_example_state_space.svg&#34;&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;You have a matrix of transition probability
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/transition_matrix.png&#34;&gt;&lt;/center&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;which defines the probability of going from a state $X_i$ to $X_j$.
You start calculating the Probability distribution for the next state. If you are at Bull Market State at time $i$ , you have a state Probability distribution as [0,1,0]&lt;/p&gt;

&lt;p&gt;you want to get the state pdf at $X_{i+1}$. That is given by&lt;/p&gt;

&lt;div&gt;&lt;center&gt;$$s_{i+1} = s_{i}Q$$&lt;/center&gt;&lt;/div&gt;

&lt;div&gt;&lt;center&gt;$$ s_{i+1}=\left[ {\begin{array}{cc}   .15 &amp; .8 &amp; .05      \end{array} } \right]$$&lt;/center&gt;&lt;/div&gt;
And the next state distribution could be found out by

&lt;div&gt;&lt;center&gt;$$s_{i+1} = s_iQ^2$$&lt;/center&gt;&lt;/div&gt;div&gt;

and so on. 
Eventually you will reach a stationary state s where:
&lt;center&gt;$$sQ=s$$&lt;/center&gt;
For this transition matrix Q the Stationary distribution $s$ is
&lt;div&gt;&lt;center&gt;$$ s_{i+1}=\left[ {\begin{array}{cc}   .625 &amp; .3125 &amp; .0625      \end{array} } \right]$$&lt;/center&gt;&lt;/div&gt;

&lt;p&gt;The stationary state distribution is important because it lets you define the probability for every state of a system at a random time. That is for this particular example we can say that 62.5% of the times market will be in a bull market state, 31.25% of weeks it will be a bear market and 6.25% of weeks it will be stagnant&lt;/p&gt;

&lt;p&gt;Intuitively you can think of it as an random walk on a chain. You might visit some nodes more often than others based on node probabilities. In the &lt;em&gt;Google Pagerank&lt;/em&gt; problem you might think of a node as a page, and the probability of a page in the stationary distribution as its relative importance.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Woah!&lt;/em&gt;&lt;/strong&gt; That was a lot of information and we have yet not started talking about the MCMC Methods. Well if you are with me till now, we can now get on to the real topic now.&lt;/p&gt;

&lt;h2 id=&#34;so-what-is-mcmc&#34;&gt;So What is MCMC?&lt;/h2&gt;

&lt;p&gt;According to
&lt;a href=&#34;https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Wikipedia&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
**Markov Chain Monte Carlo** (MCMC) methods are a class of algorithms for **sampling from a probability distribution** based on constructing a Markov chain that has the desired distribution as its stationary distribution. The state of the chain after a number of steps is then used as a sample of the desired distribution. The quality of the sample improves as a function of the number of steps.
&lt;/blockquote&gt;

&lt;p&gt;So let&amp;rsquo;s explain this with an example: Assume that &lt;strong&gt;we want to sample from a &lt;a href=&#34;https://en.wikipedia.org/wiki/Beta_distribution&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Beta distribution&lt;/a&gt;&lt;/strong&gt;. The &lt;em&gt;PDF&lt;/em&gt; is:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;$$f(x) = Cx^{\alpha -1}(1-x)^{\beta -1}$$&lt;/center&gt;
where $C$ is the normalizing constant &lt;em&gt;(which we actually don&amp;rsquo;t need to Sample from the distribution as we will see later)&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;This is a &lt;strong&gt;fairly difficult problem&lt;/strong&gt; with the Beta Distribution if not intractable. In reality you might need to work with a lot harder Distribution Functions and sometimes you won&amp;rsquo;t actually know the normalizing constants.&lt;/p&gt;

&lt;p&gt;MCMC methods make life easier for us by providing us with algorithms that could create a Markov Chain which has the Beta distribution as its &lt;strong&gt;stationary distribution&lt;/strong&gt; given that we can sample from a uniform distribution(which is &lt;em&gt;fairly&lt;/em&gt; easy).&lt;/p&gt;

&lt;p&gt;If we start from a random state and traverse to the next state based on some algorithm repeatedly, we will end up creating a Markov Chain which has the Beta distribution as its &lt;strong&gt;stationary distribution&lt;/strong&gt; and the states we are at after a long time could be used as sample from the Beta Distribution.&lt;/p&gt;

&lt;p&gt;One such MCMC Algorithm is the
&lt;strong&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Metropolis Hastings Algorithm&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;metropolis-hastings-algorithm&#34;&gt;Metropolis Hastings Algorithm&lt;/h2&gt;

&lt;p&gt;Let $s=(s_1,s_2,&amp;hellip;.,s_M)$ be the desired stationary distribution. We want to create a Markov Chain that has this stationary distribution. We start with an arbitrary Markov Chain $P$ with $M$ states with transition matrix $Q$, so that $Q_{ij}$ represents the probability of going from state $i$ to $j$. Intuitively we know how to wander around this Markov Chain but this Markov Chain does not have the required Stationary Distribution. This chain does have some stationary distribution(which is not of our use)&lt;/p&gt;

&lt;p&gt;Our Goal is to change the way we wander on the this Markov Chain $P$ so that this chain has the desired Stationary distribution.&lt;/p&gt;

&lt;p&gt;To do this we:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Start at a random initial State $i$.&lt;/li&gt;
&lt;li&gt;Randomly pick a new &lt;em&gt;Proposal State&lt;/em&gt; by looking at the transition probabilities in the ith row of the transition matrix Q.&lt;/li&gt;
&lt;li&gt;Compute an measure called the &lt;em&gt;Acceptance Probability&lt;/em&gt; which is defined as: $a_{ij} = min(s_jp_{ji}/s_{i}p_{ij},1)$&lt;/li&gt;
&lt;li&gt;Now Flip a coin that lands head with probability $a_{ij}$. If the coin comes up heads, accept the proposal i.e move to next state else reject the proposal i.e. stay at the current state.&lt;/li&gt;
&lt;li&gt;Repeat for a long time&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;After a long time this chain will converge and will have a stationary distribution $s$. &lt;strong&gt;We can then use the states of the chain as the sample from any distribution.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;While doing this to sample the Beta Distribution, the only time we are using the PDF is to find the acceptance probability and in that we divide $s_j$ by $s_i$, i.e. the &lt;strong&gt;normalizing constant $C$ gets cancelled&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Now Let&amp;rsquo;s Talk about the intuition. For the Intuition I am quoting an &lt;a href=&#34;http://stats.stackexchange.com/a/12657&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Answer&lt;/a&gt; from the site Stack Exchange,as this was the best intuitive explanation that I could find:
&lt;blockquote&gt;
I think there&amp;rsquo;s a nice and simple intuition to be gained from the (independence-chain) Metropolis-Hastings algorithm.
&lt;br&gt;
&lt;br&gt;
First, what&amp;rsquo;s the goal? The goal of MCMC is to &lt;strong&gt;draw samples from some probability distribution&lt;/strong&gt; without having to know its exact height at any point(We don&amp;rsquo;t need to know C). The way MCMC achieves this is to &lt;strong&gt;&amp;ldquo;wander around&amp;rdquo; on that distribution in such a way that the amount of time spent in each location is proportional to the height of the distribution&lt;/strong&gt;. If the &amp;ldquo;wandering around&amp;rdquo; process is set up correctly, you can make sure that this proportionality (between time spent and height of the distribution) is achieved.
&lt;br&gt;
&lt;br&gt;
Intuitively, what we want to do is to to walk around on some (lumpy) surface in such a way that the amount of time we spend (or # samples drawn) in each location is proportional to the height of the surface at that location. So, e.g., we&amp;rsquo;d like to spend twice as much time on a hilltop that&amp;rsquo;s at an altitude of 100m as we do on a nearby hill that&amp;rsquo;s at an altitude of 50m. The nice thing is that we can do this even if we don&amp;rsquo;t know the absolute heights of points on the surface: all we have to know are the relative heights. e.g., if one hilltop A is twice as high as hilltop B, then we&amp;rsquo;d like to spend twice as much time at A as we spend at B.
&lt;br&gt;
&lt;br&gt;
The simplest variant of the Metropolis-Hastings algorithm (independence chain sampling) achieves this as follows: assume that in every (discrete) time-step, we pick a random new &amp;ldquo;proposed&amp;rdquo; location (selected uniformly across the entire surface). If the proposed location is higher than where we&amp;rsquo;re standing now, move to it. If the proposed location is lower, then move to the new location with probability p, where p is the ratio of the height of that point to the height of the current location. (i.e., flip a coin with a probability p of getting heads; if it comes up heads, move to the new location; if it comes up tails, stay where we are). Keep a list of the locations you&amp;rsquo;ve been at on every time step, and that list will (asyptotically) have the right proportion of time spent in each part of the surface. (And for the A and B hills described above, you&amp;rsquo;ll end up with twice the probability of moving from B to A as you have of moving from A to B).
&lt;br&gt;
&lt;br&gt;
There are more complicated schemes for proposing new locations and the rules for accepting them, but the basic idea is still: &lt;strong&gt;(1) pick a new &amp;ldquo;proposed&amp;rdquo; location; (2) figure out how much higher or lower that location is compared to your current location; (3) probabilistically stay put or move to that location in a way that respects the overall goal of spending time proportional to height of the location.&lt;/strong&gt;
&lt;/blockquote&gt;&lt;/p&gt;

&lt;h2 id=&#34;sampling-from-beta-distribution&#34;&gt;Sampling from Beta Distribution&lt;/h2&gt;

&lt;p&gt;Now Let&amp;rsquo;s Move on to the problem of Simulating from Beta Distribution. Now Beta Distribution is a continuous Distribution on [0,1] and it can have infinite states on [0,1].&lt;/p&gt;

&lt;p&gt;Lets Assume an arbitrary Markov Chain P with infinite states on [0,1] having transition Matrix Q such that $Q_{ij} = Q_{ji} = $ All entries in Matrix. We don&amp;rsquo;t really need the Matrix Q as we will see later, But I want to keep the problem description as close to the algorihm we suggested.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Start at a random &lt;strong&gt;initial State $i$&lt;/strong&gt; given by Unif(0,1).&lt;/li&gt;
&lt;li&gt;Randomly pick a new &lt;strong&gt;Proposal State&lt;/strong&gt; by looking at the transition probabilities in the ith row of the transition matrix Q. Lets say we pick up another Unif(0,1) state as a proposal state $j$.&lt;/li&gt;
&lt;li&gt;Compute an measure called the &lt;strong&gt;Acceptance Probability&lt;/strong&gt; :&lt;/li&gt;
&lt;/ul&gt;

&lt;div&gt;&lt;center&gt;$$a_{ij} = min(s_jp_{ji}/s_{i}p_{ij},1)$$&lt;/center&gt;&lt;/div&gt; which is, &lt;div&gt;&lt;center&gt;$$a_{ij} = min(s_j/s_i,1)$$&lt;/center&gt;&lt;/div&gt; where, &lt;div&gt;&lt;center&gt;$$s_i = Ci^{\alpha -1}(1-i)^{\beta -1}$$&lt;/center&gt;&lt;/div&gt; and, &lt;div&gt;&lt;center&gt;$$s_j = Cj^{\alpha -1}(1-j)^{\beta -1}$$&lt;/center&gt;&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;Now Flip a coin that lands head with probability $a_{ij}$. If the coin comes up heads, accept the proposal i.e move to next state else reject the proposal i.e. stay at the current state.&lt;/li&gt;
&lt;li&gt;Repeat for a long time&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So enough with theory, Let&amp;rsquo;s Move on to python to create our Beta Simulations Now&amp;hellip;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random
&lt;span style=&#34;color:#75715e&#34;&gt;# Lets define our Beta Function to generate s for any particular state. We don&amp;#39;t care for the normalizing constant here.&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta_s&lt;/span&gt;(w,a,b):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; w&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;(a&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;w)&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;(b&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# This Function returns True if the coin with probability P of heads comes heads when flipped.&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;random_coin&lt;/span&gt;(p):
    unif &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; unif&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt;p:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; False
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; True

&lt;span style=&#34;color:#75715e&#34;&gt;# This Function runs the MCMC chain for Beta Distribution.&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta_mcmc&lt;/span&gt;(N_hops,a,b):
    states &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    cur &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,N_hops):
        states&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(cur)
        next &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
        ap &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; min(beta_s(next,a,b)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;beta_s(cur,a,b),&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;# Calculate the acceptance probability&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; random_coin(ap):
            cur &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; next
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; states[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;:] &lt;span style=&#34;color:#75715e&#34;&gt;# Returns the last 100 states of the chain&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Let us check our results of the MCMC Sampled Beta distribution against the actual beta distribution.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pylab &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pl
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; scipy.special &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; ss
&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;matplotlib inline
pl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rcParams[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;figure.figsize&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;17.0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4.0&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;# Actual Beta PDF.&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;beta&lt;/span&gt;(a, b, i):
    e1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ss&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gamma(a &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b)
    e2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ss&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gamma(a)
    e3 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ss&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gamma(b)
    e4 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; (a &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    e5 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; i) &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; (b &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; (e1&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(e2&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;e3)) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; e4 &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; e5

&lt;span style=&#34;color:#75715e&#34;&gt;# Create a function to plot Actual Beta PDF with the Beta Sampled from MCMC Chain.&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;plot_beta&lt;/span&gt;(a, b):
    Ly &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    Lx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    i_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mgrid[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;100j&lt;/span&gt;]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; i_list:
        Lx&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(i)
        Ly&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(beta(a, b, i))
    pl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(Lx, Ly, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Real Distribution: a=&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;str(a)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;, b=&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;str(b))
    pl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hist(beta_mcmc(&lt;span style=&#34;color:#ae81ff&#34;&gt;100000&lt;/span&gt;,a,b),normed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True,bins &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;, histtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;step&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Simulated_MCMC: a=&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;str(a)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;, b=&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;str(b))
    pl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
    pl&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
    
plot_beta(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)
plot_beta(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plot_beta(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: -9px; margin-bottom: 30px;&#34;&gt;
&lt;img src=&#34;https://mlwhiz.com/images/graphs.png&#34;&gt;
&lt;/div&gt;

&lt;p&gt;As we can see our sampled beta values closely resemble the beta distribution.&lt;/p&gt;

&lt;p&gt;So MCMC Methods are useful for the following basic problems.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Simulating from a Random Variable PDF. Example: Simulate from a Beta(0.5,0.5) or from a Normal(0,1).&lt;/li&gt;
&lt;li&gt;Solve problems with a large state space.For Example: Knapsack Problem, Encrytion Cipher etc. We will work on this in the &lt;a href=&#34;https://mlwhiz.com/blog/2015/08/21/mcmc_algorithms_cryptography/&#34;&gt;Next Blog Post&lt;/a&gt; as this one has already gotten bigger than what I expected.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Till Then Ciao!!!!!!&lt;/p&gt;

&lt;h2 id=&#34;references-and-sources&#34;&gt;References and Sources:&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science-ebook/dp/B00MMOJ19I&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Introduction to Probability Joseph K Blitzstein, Jessica Hwang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://stats.stackexchange.com/a/12657&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;StackExchange&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;One of the newest and best resources that you can keep an eye on is the &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;utm_content=2&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bayesian Methods for Machine Learning&lt;/a&gt; course in the &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;utm_content=2&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Advanced machine learning specialization&lt;/a&gt; created jointly by Kazanova(Number 3 Kaggler at the time of writing)&lt;/p&gt;

&lt;p&gt;Apart from that I also found a course on &lt;strong&gt;&lt;a href=&#34;https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;offerid=495576.8910375858&amp;type=2&amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Fbayesian&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Bayesian Statistics on Coursera&lt;/a&gt;&lt;/strong&gt;. In the process of doing it right now so couldn&amp;rsquo;t really comment on it. But since I had done an course on &lt;strong&gt;&lt;a href=&#34;https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;offerid=495576.8839843074&amp;type=2&amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Finferential-statistics-intro&#34; target=&#34;_blank&#34; rel=&#34;nofollow&#34;&gt;Inferential Statistics&lt;/a&gt;&lt;/strong&gt; taught by the same professor before(Mine Çetinkaya-Rundel), I am very hopeful for this course. Let&amp;rsquo;s see.&lt;/p&gt;

&lt;p&gt;Also look out for these two books to learn more about MCMC. I have not yet read them whole but still I liked whatever I read:&lt;/p&gt;

&lt;div style=&#34;margin-left:1em ; text-align: center;&#34;&gt;

&lt;a target=&#34;_blank&#34; rel=&#34;nofollow&#34; href=&#34;https://www.amazon.com/gp/product/1439840954/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1439840954&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=d55979088adc0aabeaed88f4f14b48b6&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1439840954&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1439840954&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;
&lt;/t&gt;&lt;/t&gt;
&lt;a target=&#34;_blank&#34; rel=&#34;nofollow&#34;  href=&#34;https://www.amazon.com/gp/product/1584885874/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1584885874&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=ee3e2a0bc99359d6c5db0463ab1abb13&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1584885874&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1584885874&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;
&lt;/div&gt;

&lt;p&gt;Both these books are pretty high level and hard on math. But these are the best texts out there too. :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hadoop Mapreduce Streaming Tricks and Techniques</title>
      <link>https://mlwhiz.com/blog/2015/05/09/hadoop_mapreduce_streaming_tricks_and_technique/</link>
      <pubDate>Sat, 09 May 2015 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2015/05/09/hadoop_mapreduce_streaming_tricks_and_technique/</guid>
      <description>

&lt;p&gt;I have been using Hadoop a lot now a days and thought about writing some of the novel techniques that a user could use to get the most out of the Hadoop Ecosystem.&lt;/p&gt;

&lt;h2 id=&#34;using-shell-scripts-to-run-your-programs&#34;&gt;Using Shell Scripts to run your Programs&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://mlwhiz.com/images/I-love-bash-1024x220.png&#34; &gt;&lt;/p&gt;

&lt;p&gt;I am not a fan of large bash commands. The ones where you have to specify the whole path of the jar files and the such. &lt;em&gt;You can effectively organize your workflow by using shell scripts.&lt;/em&gt; Now Shell scripts are not as formidable as they sound. We wont be doing programming perse using these shell scripts(Though they are pretty good at that too), we will just use them to store commands that we need to use sequentially.&lt;/p&gt;

&lt;p&gt;Below is a sample of the shell script I use to run my Mapreduce Codes.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/bin/bash
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#Defining program variables&lt;/span&gt;
IP&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/data/input&amp;#34;&lt;/span&gt;
OP&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/data/output&amp;#34;&lt;/span&gt;
HADOOP_JAR_PATH&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/contrib/streaming/hadoop-streaming-2.0.0-mr1-cdh4.5.0.jar&amp;#34;&lt;/span&gt;
MAPPER&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;test_m.py&amp;#34;&lt;/span&gt;
REDUCER&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;test_r.py&amp;#34;&lt;/span&gt;

hadoop fs -rmr -skipTrash&amp;amp;nbsp;$OP
hadoop jar&amp;amp;nbsp;$HADOOP_JAR_PATH &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;-file&amp;amp;nbsp;$MAPPER -mapper &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;python test_m.py&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;-file&amp;amp;nbsp;$REDUCER -reducer &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;python test_r.py&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;-input&amp;amp;nbsp;$IP -output&amp;amp;nbsp;$OP&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I generally save them as test_s.sh and whenever i need to run them i simply type &lt;code&gt;sh test_s.sh&lt;/code&gt;. This helps in three ways.
&lt;ul&gt;&lt;li&gt; It helps me to store hadoop commands in a manageable way. &lt;/li&gt;
&lt;li&gt; It is easy to run the mapreduce code using the shell script. &lt;/li&gt;
&lt;li&gt; &lt;em&gt;&lt;strong&gt;If the code fails, I do not have to manually delete the output directory&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;em&gt;
The simplification of anything is always sensational.
&lt;br&gt;&lt;/em&gt;
&lt;small&gt;Gilbert K. Chesterton&lt;/small&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;using-distributed-cache-to-provide-mapper-with-a-dictionary&#34;&gt;Using Distributed Cache to provide mapper with a dictionary&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://mlwhiz.com/images/Game-Of-Thrones-Wallpaper-House-Sigils-1.png&#34;&gt;&lt;/p&gt;

&lt;p&gt;Often times it happens that you want that your Hadoop Mapreduce program is able to access some static file. This static file could be a dictionary, could be parameters for the program or could be anything. What distributed cache does is that it provides this file to all the mapper nodes so that you can use that file in any way across all your mappers.
Now this concept although simple would help you to think about Mapreduce in a whole new light.
Lets start with an example.
Supppose you have to create a sample Mapreduce program that reads a big file containing the information about all the characters in &lt;a href=&#34;http://www.hbo.com/game-of-thrones&#34;&gt;Game of Thrones&lt;/a&gt; stored as &lt;strong&gt;&lt;code&gt;&amp;rdquo;/data/characters/&amp;rdquo;&lt;/code&gt;&lt;/strong&gt;:
&lt;div style=&#34;width: 50%; margin: 0 auto;&#34;&gt;
&lt;table class=&#34;table&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Cust_ID&lt;/th&gt;
&lt;th&gt;User_Name&lt;/th&gt;
&lt;th&gt;House&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Daenerys Targaryen&lt;/td&gt;
&lt;td&gt;Targaryen&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;Tyrion Lannister&lt;/td&gt;
&lt;td&gt;Lannister&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;Cersei Lannister&lt;/td&gt;
&lt;td&gt;Lannister&lt;/td&gt;
&lt;/tr&gt;
&lt;tr &gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;Robert Baratheon&lt;/td&gt;
&lt;td&gt;Baratheon&lt;/td&gt;
&lt;/tr&gt;
&lt;tr &gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;Robb Stark&lt;/td&gt;
&lt;td&gt;Stark&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;But you dont want to use the dead characters in the file for the analysis you want to do. &lt;em&gt;You want to count the number of living characters in Game of Thrones grouped by their House&lt;/em&gt;. (I know its easy!!!!!)
One thing you could do is include an if statement in your Mapper Code which checks if the persons ID is 4 then exclude it from the mapper and such.
But the problem is that you would have to do it again and again for the same analysis as characters die like flies when it comes to George RR Martin.(Also where is the fun in that)
So you create a file which contains the Ids of all the dead characters at &lt;strong&gt;&lt;code&gt;&amp;rdquo;/data/dead_characters.txt&amp;rdquo;&lt;/code&gt;&lt;/strong&gt;:&lt;/p&gt;

&lt;div style=&#34;width: 50%; margin: 0 auto;&#34;&gt;
&lt;table class=&#34;table&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Died&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Whenever you have to run the analysis you can just add to this file and you wont have to change anything in the code.
Also sometimes this file would be long and you would not want to clutter your code with IDs and such.&lt;/p&gt;

&lt;p&gt;So How Would we do it.
Let&amp;rsquo;s go in a step by step way around this.
We will create a shell script, a mapper script and a reducer script for this task.&lt;/p&gt;

&lt;h2 id=&#34;1-shell-script&#34;&gt;1) Shell Script&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/bin/bash&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#Defining program variables&lt;/span&gt;
DC&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/data/dead_characters.txt&amp;#34;&lt;/span&gt;
IP&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/data/characters&amp;#34;&lt;/span&gt;
OP&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/data/output&amp;#34;&lt;/span&gt;
HADOOP_JAR_PATH&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/contrib/streaming/hadoop-streaming-2.0.0-mr1-cdh4.5.0.jar&amp;#34;&lt;/span&gt;
MAPPER&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;got_living_m.py&amp;#34;&lt;/span&gt;
REDUCER&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;got_living_r.py&amp;#34;&lt;/span&gt;

hadoop jar&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;nbsp;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;HADOOP_JAR_PATH \
&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;file&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;nbsp;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;MAPPER &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;mapper &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;python got_living_m.py&amp;#34;&lt;/span&gt; \
&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;file&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;nbsp;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;REDUCER &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;reducer &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;python got_living_r.py&amp;#34;&lt;/span&gt; \
&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;cacheFile&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;nbsp;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;DC&lt;span style=&#34;color:#75715e&#34;&gt;#ref \&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;input&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;nbsp;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;IP &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;output&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;nbsp;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;$&lt;/span&gt;OP&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note how we use the &lt;code&gt;&amp;rdquo;-cacheFile&amp;rdquo;&lt;/code&gt; option here. We have specified that we will refer to the file that has been provided in the Distributed cache as &lt;code&gt;#ref&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Next is our Mapper Script.&lt;/p&gt;

&lt;h2 id=&#34;2-mapper-script&#34;&gt;2) Mapper Script&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; sys
dead_ids &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; set()

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;read_cache&lt;/span&gt;():
	&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; line &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; open(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ref&amp;#39;&lt;/span&gt;):
		id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; line&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strip()
		dead_ids&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(id)

read_cache()

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; line &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stdin:
	rec &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; line&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strip()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;|&amp;#34;&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;# Split using Delimiter &amp;#34;|&amp;#34;&lt;/span&gt;
	id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rec[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    house &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rec[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; id &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; dead_ids:
    	&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; (house,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And our Reducer Script.&lt;/p&gt;

&lt;h2 id=&#34;3-reducer-script&#34;&gt;3) Reducer Script&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; sys
current_key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; None
key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; None
count &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; line &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stdin:
	line &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; line&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strip()
	rec &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; line&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&lt;/span&gt;)
	key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rec[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]	
	value &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int(rec[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
	
	&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; current_key &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; key:
		count &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; value
	&lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
		&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; current_key:
			&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;(key,str(count))		
		current_key &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; key
		count &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; value

&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; current_key &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; key:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;(key,str(count))	&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This was a simple program and the output will be just what you expected and not very exciting. &lt;em&gt;&lt;strong&gt;But the Technique itself solves a variety of common problems. You can use it to pass any big dictionary to your Mapreduce Program&lt;/strong&gt;&lt;/em&gt;. Atleast thats what I use this feature mostly for.
Hope You liked it. Will try to expand this post with more tricks.&lt;/p&gt;

&lt;p&gt;The codes for this post are posted at github &lt;a href=&#34;https://github.com/MLWhiz/Hadoop-Mapreduce-Tricks&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Other Great Learning Resources For Hadoop:
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;http://www.google.co.in/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0CB0QFjAA&amp;url=http%3A%2F%2Fwww.michael-noll.com%2Ftutorials%2Fwriting-an-hadoop-mapreduce-program-in-python%2F&amp;ei=8RRVVdP2IMe0uQShsYDYBg&amp;usg=AFQjCNH3DqrlSIG8D-K8jgQWTALic1no5A&amp;sig2=BivwTW6mdJs5c9w9VaSK2Q&amp;bvm=bv.93112503,d.c2E&#34;&gt;Michael Noll&amp;rsquo;s Hadoop Mapreduce Tutorial&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://www.google.co.in/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0CCMQFjAB&amp;url=http%3A%2F%2Fhadoop.apache.org%2Fdocs%2Fr1.2.1%2Fstreaming.html&amp;ei=8RRVVdP2IMe0uQShsYDYBg&amp;usg=AFQjCNEIB4jmqcBs-GepHdn7DRxqTI9zXA&amp;sig2=nYkAnDjjjaum5YVlYuMUJQ&amp;bvm=bv.93112503,d.c2E&#34;&gt;Apache&amp;rsquo;s Hadoop Streaming Documentation&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/p&gt;

&lt;p&gt;Also I like these books a lot. Must have for a Hadooper&amp;hellip;.&lt;/p&gt;

&lt;div style=&#34;margin-left:1em ; text-align: center;&#34;&gt;
&lt;a target=&#34;_blank&#34;  href=&#34;https://www.amazon.com/gp/product/1785887211/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1785887211&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=a0e7b4f0b2ea4a5146042890e1c04f7e&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1785887211&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1785887211&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;

&lt;/t&gt;&lt;/t&gt;

&lt;a target=&#34;_blank&#34;  href=&#34;https://www.amazon.com/gp/product/1491901632/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1491901632&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=4122280e94f7bbd0ceebc9d13e60d103&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1491901632&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1491901632&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;
&lt;/div&gt;

&lt;p&gt;The first book is a guide for using Hadoop as well as spark with Python. While the second one contains a detailed overview of all the things in Hadoop. Its the definitive guide.&lt;/p&gt;

&lt;script src=&#34;//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e&#34;&gt;&lt;/script&gt;
</description>
    </item>
    
    <item>
      <title>Exploring Vowpal Wabbit with the Avazu Clickthrough Prediction Challenge</title>
      <link>https://mlwhiz.com/blog/2014/12/01/exploring_vowpal_wabbit_avazu/</link>
      <pubDate>Mon, 01 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2014/12/01/exploring_vowpal_wabbit_avazu/</guid>
      <description>

&lt;p&gt;In online advertising, click-through rate (CTR) is a very important metric for evaluating ad performance. As a result, click prediction systems are essential and widely used for sponsored search and real-time bidding.&lt;/p&gt;

&lt;p&gt;For this competition, we have provided 11 days worth of Avazu data to build and test prediction models. Can you find a strategy that beats standard classification algorithms? The winning models from this competition will be released under an open-source
license.&lt;/p&gt;

&lt;h2 id=&#34;data-fields&#34;&gt;Data Fields&lt;/h2&gt;

&lt;pre style=&#34;font-family:courier new,monospace; background-color:#f6c6529c; color:#000000&#34;&gt;
id: ad identifier
click: 0/1 for non-click/click
hour: format is YYMMDDHH, so 14091123 means 23:00 on Sept. 11, 2014 UTC.
C1 -- anonymized categorical variable
banner_pos
site_id
site_domain
site_category
app_id
app_domain
app_category
device_id
device_ip
device_model
device_type
device_conn_type
C14-C21 -- anonymized categorical variables 
&lt;/pre&gt;
    

&lt;h2 id=&#34;loading-data&#34;&gt;Loading Data&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;## Loading the data &lt;/span&gt;

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; string &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; stri

&lt;span style=&#34;color:#75715e&#34;&gt;#too large data not keeping it in memory.&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# will be using line by line scripting.&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#data = pd.read_csv(&amp;#34;/Users/RahulAgarwal/kaggle_cpr/train&amp;#34;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Since the data is too large around 6 gb , we will proceed by doing line by line analysis of data. We will try to use vowpal wabbit first of all as it is an online model and it also gives us the option of minimizing log loss as a default. It is also very fast to run and will give us quite an intuition as to how good our prediction can be.&lt;/p&gt;

&lt;p&gt;I will use all the variables in the first implementation and we will rediscover things as we move on&lt;/p&gt;

&lt;h2 id=&#34;running-vowpal-wabbit&#34;&gt;Running Vowpal Wabbit&lt;/h2&gt;

&lt;h2 id=&#34;creating-data-in-vowpal-format-one-time-only&#34;&gt;Creating data in vowpal format (One Time Only)&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; datetime &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; datetime

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;csv_to_vw&lt;/span&gt;(loc_csv, loc_output, train&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True):
    start &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; datetime&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;now()
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Turning &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; into &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;. Is_train_set? &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;(loc_csv,loc_output,train))
    i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; open(loc_csv, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;)
    j &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; open(loc_output, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;wb&amp;#39;&lt;/span&gt;)
    counter&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; i &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; infile:
        line_count&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; line &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; infile:
            &lt;span style=&#34;color:#75715e&#34;&gt;# to counter the header&lt;/span&gt;
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; line_count&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
                line_count&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
                &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
            &lt;span style=&#34;color:#75715e&#34;&gt;# The data has all categorical features&lt;/span&gt;
            &lt;span style=&#34;color:#75715e&#34;&gt;#numerical_features = &amp;#34;&amp;#34;&lt;/span&gt;
            categorical_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;
            counter &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; counter&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
            &lt;span style=&#34;color:#75715e&#34;&gt;#print counter&lt;/span&gt;
            line &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; line&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;,&amp;#34;&lt;/span&gt;)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; train:
                &lt;span style=&#34;color:#75715e&#34;&gt;#working on the date column. We will take day , hour&lt;/span&gt;
                a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; line[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]
                new_date&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; datetime(int(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;20&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;a[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]),int(a[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;]),int(a[&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;]))
                day &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; new_date&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strftime(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;%A&amp;#34;&lt;/span&gt;)
                hour&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; a[&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;]
                categorical_features &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; |hr &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; hour
                categorical_features &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; |day &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; day
                &lt;span style=&#34;color:#75715e&#34;&gt;# 24 columns in data    &lt;/span&gt;
                &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;24&lt;/span&gt;):
                    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; line[i] &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;:
                        categorical_features &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;|c&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; (str(i),line[i])
            &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
                a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; line[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
                new_date&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; datetime(int(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;20&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;a[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]),int(a[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;]),int(a[&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;]))
                day &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; new_date&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strftime(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;%A&amp;#34;&lt;/span&gt;)
                hour&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; a[&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;]
                categorical_features &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; |hr &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; hour
                categorical_features &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; |day &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; day
                &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;23&lt;/span&gt;):
                    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; line[i] &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;:
                        categorical_features &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; |c&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; (str(i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),line[i])
  &lt;span style=&#34;color:#75715e&#34;&gt;#Creating the labels&lt;/span&gt;
            &lt;span style=&#34;color:#75715e&#34;&gt;#print &amp;#34;a&amp;#34;&lt;/span&gt;
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; train: &lt;span style=&#34;color:#75715e&#34;&gt;#we care about labels&lt;/span&gt;
                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; line[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt;:
                    label &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
                &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
                    label &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;#we set negative label to -1&lt;/span&gt;
                &lt;span style=&#34;color:#75715e&#34;&gt;#print (numerical_features)&lt;/span&gt;
                &lt;span style=&#34;color:#75715e&#34;&gt;#print categorical_features&lt;/span&gt;
                j&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;write( &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; &amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; (label,line[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],categorical_features))

            &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;: &lt;span style=&#34;color:#75715e&#34;&gt;#we dont care about labels&lt;/span&gt;
                &lt;span style=&#34;color:#75715e&#34;&gt;#print ( &amp;#34;1 &amp;#39;%s |i%s |c%s\n&amp;#34; % (line[0],numerical_features,categorical_features) )&lt;/span&gt;
                j&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;write( &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1 &amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; (line[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],categorical_features) )

  &lt;span style=&#34;color:#75715e&#34;&gt;#Reporting progress&lt;/span&gt;
            &lt;span style=&#34;color:#75715e&#34;&gt;#print counter&lt;/span&gt;
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; counter &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1000000&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
                &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;(counter, str(datetime&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;now() &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; start)))

    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; Task execution time:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;(counter, str(datetime&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;now() &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; start)))

&lt;span style=&#34;color:#75715e&#34;&gt;#csv_to_vw(&amp;#34;/Users/RahulAgarwal/kaggle_cpr/train&amp;#34;, &amp;#34;/Users/RahulAgarwal/kaggle_cpr/click.train_original_data.vw&amp;#34;,train=True)&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#csv_to_vw(&amp;#34;/Users/RahulAgarwal/kaggle_cpr/test&amp;#34;, &amp;#34;/Users/RahulAgarwal/kaggle_cpr/click.test_original_data.vw&amp;#34;,train=False)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;running-vowpal-wabbit-on-the-data&#34;&gt;Running Vowpal Wabbit on the data&lt;/h2&gt;

&lt;p&gt;The Vowpal Wabbit will be run on the command line itself.&lt;/p&gt;

&lt;p&gt;Training VW:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;vw click.train_original_data.vw -f click.model.vw --loss_function logistic&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Testing VW:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;vw click.test_original_data.vw  -t -i click.model.vw -p click.preds.txt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;creating-kaggle-submission-file&#34;&gt;Creating Kaggle Submission File&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; math

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;zygmoid&lt;/span&gt;(x):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; math&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;x))

&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; open(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kaggle.click.submission.csv&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;wb&amp;#34;&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; outfile:
    outfile&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;write(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;id,click&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; line &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; open(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;click.preds.txt&amp;#34;&lt;/span&gt;):
        
        row &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; line&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strip()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
            outfile&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;write(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%s&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%f&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;(row[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],zygmoid(float(row[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]))))
        &lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt;:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;pass&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This solution ranked &lt;sup&gt;211&lt;/sup&gt;&amp;frasl;&lt;sub&gt;371&lt;/sub&gt; submissions at the time and the leaderboard score was 0.4031825 while the best leaderboard score was 0.3901120&lt;/p&gt;

&lt;h2 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Create a better VW model&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Shuffle the data before making the model as the VW algorithm is an online learner and might have given more preference to the latest data&lt;/li&gt;
&lt;li&gt;provide high weights for clicks as data is skewed. How Much?&lt;/li&gt;
&lt;li&gt;tune VW algorithm using vw-hypersearch. What should be tuned?&lt;/li&gt;
&lt;li&gt;Use categorical features like |C1 &amp;ldquo;C1&amp;rdquo;&amp;amp;&amp;ldquo;1&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Create a XGBoost Model.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Create a Sofia-ML Model and see how it works on this data.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;script src=&#34;//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e&#34;&gt;&lt;/script&gt;
</description>
    </item>
    
    <item>
      <title>Data Science 101 : Playing with Scraping in Python</title>
      <link>https://mlwhiz.com/blog/2014/10/02/data_science_101_python_pattern/</link>
      <pubDate>Thu, 02 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2014/10/02/data_science_101_python_pattern/</guid>
      <description>

&lt;p&gt;This is a simple illustration of using Pattern Module to scrape web data using Python. We will be scraping the data from imdb for the top TV Series along with their ratings&lt;/p&gt;

&lt;p&gt;We will be using this link for this:&lt;/p&gt;

&lt;pre style=&#34;font-family:courier new,monospace; background-color:#f6c6529c; color:#000000&#34;&gt;
http://www.imdb.com/search/title?count=100&amp;num_votes=5000,&amp;ref_=gnr_tv_hr&amp;sort=user_rating,desc&amp;start=1&amp;title_type=tv_series,mini_series
&lt;/pre&gt;

&lt;p&gt;This URL gives a list of top Rated TV Series which have number of votes atleast 5000. The Thing to note in this URL is the &amp;ldquo;&amp;amp;start=&amp;rdquo; parameter where we can specify which review should the list begin with. If we specify 1 we will get reviews starting from 1-100, if we specify 101 we get reviews from 101-200 and so on.&lt;/p&gt;

&lt;p&gt;Lets Start by importing some Python Modules that will be needed for Scraping Data:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; requests                     &lt;span style=&#34;color:#75715e&#34;&gt;# This is a module that is used for getting html data from a webpage in the text format&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; pattern &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; web             &lt;span style=&#34;color:#75715e&#34;&gt;# We use this module to parse through the dtaa that we loaded using requests&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;loading-the-data-using-requests-and-pattern&#34;&gt;Loading the data using requests and pattern&lt;/h2&gt;

&lt;p&gt;So the modules are loaded at this point, next we will try to catch the url using python and put this into a dict in python. We will start with a single URL and then try to parse it using pattern module&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;url&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;http://www.imdb.com/search/title?count=100&amp;amp;num_votes=5000,&amp;amp;ref_=gnr_tv_hr&amp;amp;sort=user_rating,desc&amp;amp;start=1&amp;amp;title_type=tv_series,mini_series&amp;#34;&lt;/span&gt;
html_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; requests&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(url)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;text 
dom&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;web&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Element(html_data)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;parsing-the-data&#34;&gt;Parsing the data&lt;/h2&gt;

&lt;p&gt;This is the data of Interest found out after some nspection of the html code. This is for a single TV Series Band of brothers, but if you are able to parse this you just have to move hrough a loop.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;html&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;td&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;title&amp;#34;&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;wlb_wrapper&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;data-tconst&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;tt0185906&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;data-size&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;small&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;data-caller-name&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;search&amp;#34;&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/title/tt0185906/&amp;#34;&lt;/span&gt;&amp;gt;Band of Brothers&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;year_type&amp;#34;&lt;/span&gt;&amp;gt;(2001 Mini-Series)&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;br&lt;/span&gt; /&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;user_rating&amp;#34;&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rating rating-list&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;data-auth&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;BCYm-Mk2Ros7BTxsLNL2XJX_icfZVahNr1bE9-5Ajb2N3381yxcaNN4ZQqyrX7KgEFGqHWmwv10lv7lAnXyC8CCkh9hPqQfzwVTumCeRzjpnndW4_ft97qQkBYLUvFxYnFgR&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;id&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;tt0185906|imdb|9.6|9.6|advsearch&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;data-ga-identifier&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;advsearch&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;title&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Users rated this 9.6/10 (156,073 votes) - click stars to rate&amp;#34;&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rating-bg&amp;#34;&lt;/span&gt;&amp;gt;&amp;amp;nbsp;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rating-imdb&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;style&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;width: 134px&amp;#34;&lt;/span&gt;&amp;gt;&amp;amp;nbsp;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rating-stars&amp;#34;&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/register/login?why=vote&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;title&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Register or login to rate this title&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rel&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nofollow&amp;#34;&lt;/span&gt;&amp;gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;1&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/register/login?why=vote&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;title&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Register or login to rate this title&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rel&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nofollow&amp;#34;&lt;/span&gt;&amp;gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;2&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/register/login?why=vote&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;title&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Register or login to rate this title&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rel&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nofollow&amp;#34;&lt;/span&gt;&amp;gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;3&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/register/login?why=vote&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;title&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Register or login to rate this title&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rel&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nofollow&amp;#34;&lt;/span&gt;&amp;gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;4&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/register/login?why=vote&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;title&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Register or login to rate this title&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rel&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nofollow&amp;#34;&lt;/span&gt;&amp;gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;5&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/register/login?why=vote&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;title&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Register or login to rate this title&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rel&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nofollow&amp;#34;&lt;/span&gt;&amp;gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;6&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/register/login?why=vote&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;title&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Register or login to rate this title&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rel&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nofollow&amp;#34;&lt;/span&gt;&amp;gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;7&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/register/login?why=vote&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;title&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Register or login to rate this title&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rel&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nofollow&amp;#34;&lt;/span&gt;&amp;gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;8&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/register/login?why=vote&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;title&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Register or login to rate this title&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rel&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nofollow&amp;#34;&lt;/span&gt;&amp;gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;9&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/register/login?why=vote&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;title&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Register or login to rate this title&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rel&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nofollow&amp;#34;&lt;/span&gt;&amp;gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;10&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt;
&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rating-rating&amp;#34;&lt;/span&gt;&amp;gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;value&amp;#34;&lt;/span&gt;&amp;gt;9.6&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;grey&amp;#34;&lt;/span&gt;&amp;gt;/&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;grey&amp;#34;&lt;/span&gt;&amp;gt;10&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;rating-cancel&amp;#34;&lt;/span&gt;&amp;gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/title/tt0185906/vote?v=X;k=BCYm-Mk2Ros7BTxsLNL2XJX_icfZVahNr1bE9-5Ajb2N3381yxcaNN4ZQqyrX7KgEFGqHWmwv10lv7lAnXyC8CCkh9hPqQfzwVTumCeRzjpnndW4_ft97qQkBYLUvFxYnFgR&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;title&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Delete&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rel&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nofollow&amp;#34;&lt;/span&gt;&amp;gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;X&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;
&amp;amp;nbsp;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt;&amp;gt;
&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;outline&amp;#34;&lt;/span&gt;&amp;gt;The story of Easy Company of the US Army 101st Airborne division and their mission in WWII Europe from Operation Overlord through V-J Day.&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;credit&amp;#34;&lt;/span&gt;&amp;gt;
    With: &amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/name/nm0342241/&amp;#34;&lt;/span&gt;&amp;gt;Scott Grimes&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt;, &amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/name/nm0500614/&amp;#34;&lt;/span&gt;&amp;gt;Matthew Leitch&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt;, &amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/name/nm0507073/&amp;#34;&lt;/span&gt;&amp;gt;Damian Lewis&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt;
&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;genre&amp;#34;&lt;/span&gt;&amp;gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/genre/action&amp;#34;&lt;/span&gt;&amp;gt;Action&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt; | &amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/genre/drama&amp;#34;&lt;/span&gt;&amp;gt;Drama&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt; | &amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/genre/history&amp;#34;&lt;/span&gt;&amp;gt;History&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt; | &amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/genre/war&amp;#34;&lt;/span&gt;&amp;gt;War&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;certificate&amp;#34;&lt;/span&gt;&amp;gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;title&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;TV_MA&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;us_tv_ma titlePageSprite&amp;#34;&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;runtime&amp;#34;&lt;/span&gt;&amp;gt;705 mins.&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;span&lt;/span&gt;&amp;gt;
&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;td&lt;/span&gt;&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we have loaded the data we need to parse it using the functions from pattern module.
The main function in pattern module is the by_tag() function which lets you get all the elements with that particular tagname.
For us the main interest is this &amp;ldquo;td&amp;rdquo; tag with class as &amp;ldquo;title&amp;rdquo;. This &amp;ldquo;td&amp;rdquo; tag contains:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Title in the &amp;ldquo;a&amp;rdquo; tag&lt;/li&gt;
&lt;li&gt;Rating in the &amp;ldquo;span&amp;rdquo; tag with class &amp;ldquo;value&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Genres in the &amp;ldquo;span&amp;rdquo; tag with class &amp;ldquo;genre&amp;rdquo; and then looping through the &amp;ldquo;a&amp;rdquo; tags&lt;/li&gt;
&lt;li&gt;Runtime in &amp;ldquo;span&amp;rdquo; tag with class &amp;ldquo;runtime&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Artists in &amp;ldquo;span&amp;rdquo; tag with class &amp;ldquo;credit&amp;rdquo; loop through &amp;ldquo;a&amp;rdquo; tags&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now lets write some code to parse this data.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; tv_series &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; dom&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;by_tag(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;td.title&amp;#39;&lt;/span&gt;):    
    title &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tv_series&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;by_tag(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;a&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;content
    genres &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tv_series&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;by_tag(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;span.genre&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;by_tag(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;a&amp;#39;&lt;/span&gt;)
    genres &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;content &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; g &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; genres]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
        runtime &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tv_series&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;by_tag(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;span.runtime&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;content
    &lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt;:
        runtime &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;NA&amp;#34;&lt;/span&gt;
    rating &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tv_series&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;by_tag(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;span.value&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;content
    artists &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tv_series&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;by_tag(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;span.credit&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;by_tag(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;a&amp;#39;&lt;/span&gt;)
    artists &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [a&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;content &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; artists]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; title, genres, runtime, rating, artists&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-family:courier new,monospace; background-color:#f6c6529c; color:#000000&#34;&gt;Band of Brothers [u&#39;Action&#39;, u&#39;Drama&#39;, u&#39;History&#39;, u&#39;War&#39;] 705 mins. 9.6 [u&#39;Scott Grimes&#39;, u&#39;Matthew Leitch&#39;, u&#39;Damian Lewis&#39;]

Breaking Bad [u&#39;Crime&#39;, u&#39;Drama&#39;, u&#39;Thriller&#39;] 45 mins. 9.6 [u&#39;Bryan Cranston&#39;, u&#39;Aaron Paul&#39;, u&#39;Anna Gunn&#39;]

Game of Thrones [u&#39;Adventure&#39;, u&#39;Drama&#39;, u&#39;Fantasy&#39;] 55 mins. 9.5 [u&#39;Lena Headey&#39;, u&#39;Peter Dinklage&#39;, u&#39;Maisie Williams&#39;]&lt;/pre&gt;

&lt;p&gt;So finally we are OK with parsing. We have understood the structure of the webpage, the tags and classes we will need to use and how to use pattern module to find data for a single page. Now lets use the power of for loops to get all the data.&lt;/p&gt;

&lt;h3 id=&#34;getting-whole-data&#34;&gt;Getting Whole Data&lt;/h3&gt;

&lt;p&gt;Lets Go through it the pythonic way. We will create functions and try to execute small chunks of code rather than doing it all at once.
Lets first create a funcion that takes a start_val(for the start parameter) and returns a dom element.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_dom&lt;/span&gt;(start_val):
    url&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;http://www.imdb.com/search/title?count=100&amp;amp;num_votes=5000,&amp;amp;ref_=gnr_tv_hr&amp;amp;sort=user_rating,desc&amp;amp;start=&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;str(start_val)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;amp;title_type=tv_series,mini_series&amp;#34;&lt;/span&gt;
    html_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; requests&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(url)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;text 
    dom&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;web&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Element(html_data)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; dom&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now lets create a function parse_dom that takes as input dom an throws out a list containing all the data. The list is like this :
&lt;pre style=&#34;font-family:courier new,monospace; background-color:#f6c6529c; color:#000000&#34;&gt;
[
[&amp;lsquo;Band of Brothers&amp;rsquo;,&amp;lsquo;Action|Drama|History|War&amp;rsquo;,&amp;lsquo;705 mins.&amp;rsquo;,&amp;lsquo;9.6&amp;rsquo;,&amp;lsquo;Scott Grimes|Matthew Leitch|Damian Lewis&amp;rsquo;],
[&amp;lsquo;Breaking Bad&amp;rsquo;,&amp;lsquo;Crime|Drama|Thriller&amp;rsquo;,&amp;lsquo;45 mins.&amp;rsquo;, &amp;lsquo;9.6&amp;rsquo; ,&amp;lsquo;Bryan Cranston|Aaron Paul|Anna Gunn&amp;rsquo;],&amp;hellip;..
]&lt;br /&gt;
&lt;/pre&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;parse_dom&lt;/span&gt;(dom):
    result&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[]
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; tv_series &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; dom&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;by_tag(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;td.title&amp;#39;&lt;/span&gt;):    
        title &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tv_series&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;by_tag(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;a&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;content
        genres &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tv_series&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;by_tag(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;span.genre&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;by_tag(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;a&amp;#39;&lt;/span&gt;)
        genres &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;|&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join([g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;content &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; g &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; genres])
        &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
            runtime &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tv_series&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;by_tag(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;span.runtime&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;content
        &lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt;:
            runtime &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;NA&amp;#34;&lt;/span&gt;
        rating &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tv_series&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;by_tag(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;span.value&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;content
        artists &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tv_series&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;by_tag(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;span.credit&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;by_tag(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;a&amp;#39;&lt;/span&gt;)
        artists &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;|&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;join([a&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;content &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; artists])
        temp_res&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[]
        temp_res&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;extend([title, genres, runtime, rating, artists])
        result&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(temp_res)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; result&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now Lets Use these functions and a simple while loop to scrap all the pages&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;i&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
all_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; True:
    dom &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_dom(i)
    datalist&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;parse_dom(dom)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(datalist)&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;break&lt;/span&gt;
    all_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; all_data &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; parse_dom(dom)
    i &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Total Elements:&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(len(all_data))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;First Five Elements :&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; str(all_data[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;])&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;pre style=&#34;font-family:courier new,monospace; background-color:#f6c6529c; color:#000000&#34;&gt;    Total Elements:898
    First Five Elements :[[u&#39;Breaking Bad&#39;, u&#39;Crime|Drama|Thriller&#39;, u&#39;45 mins.&#39;, u&#39;9.6&#39;, u&#39;Bryan Cranston|Aaron Paul|Anna Gunn&#39;], [u&#39;Game of Thrones&#39;, u&#39;Adventure|Drama|Fantasy&#39;, u&#39;55 mins.&#39;, u&#39;9.5&#39;, u&#39;Lena Headey|Peter Dinklage|Maisie Williams&#39;], [u&#39;Planet Earth&#39;, u&#39;Documentary&#39;, u&#39;570 mins.&#39;, u&#39;9.5&#39;, u&#39;David Attenborough|Sigourney Weaver|Huw Cordey&#39;], [u&#39;Cosmos: A SpaceTime Odyssey&#39;, u&#39;Documentary&#39;, u&#39;60 mins.&#39;, u&#39;9.5&#39;, u&#39;Neil deGrasse Tyson|Stoney Emshwiller|Piotr Michael&#39;]]
&lt;/pre&gt;

&lt;p&gt;Voila!!! The number of elements we had to scrap were 898 and We got all of them. And to tell you, IMDB is one of the worst written HTML&amp;rsquo;s. So that&amp;rsquo;s Great.&lt;/p&gt;

&lt;p&gt;In the next part of the tutorial we will run exploratory data analysis on this data using pandas and maplotlib.&lt;/p&gt;

&lt;p&gt;Till then keep learning.&lt;/p&gt;

&lt;script src=&#34;//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e&#34;&gt;&lt;/script&gt;
</description>
    </item>
    
    <item>
      <title>Dictvectorizer for One Hot Encoding of Categorical Data</title>
      <link>https://mlwhiz.com/blog/2014/09/30/dictvectorizer_one_hot_encoding/</link>
      <pubDate>Tue, 30 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2014/09/30/dictvectorizer_one_hot_encoding/</guid>
      <description>

&lt;h2 id=&#34;the-problem&#34;&gt;THE PROBLEM:&lt;/h2&gt;

&lt;p&gt;Recently I was working on the Criteo Advertising Competition on Kaggle. The competition was a classification problem which basically involved predicting the click through rates based on several features provided in the train data. Seeing the size of the data (11 GB Train), I felt that going with Vowpal Wabbit might be a better option.&lt;/p&gt;

&lt;p&gt;But after getting to an CV error of .47 on the Kaggle LB and being stuck there , I felt the need to go back to Scikit learn. While SciKit learn seemed to have a partial_fit method in SGDClassifier, I still could not find a partial_fit method in the OneHotEncoder or DictVectorizer class which made me look to the internet again. Now while I could find many advices on how to use OneHotEncoding and DictVectorizer on small data, I cannot find something relate to data too big to store in the memory. How do I OneHotEncode such a large data file?&lt;/p&gt;

&lt;h2 id=&#34;dictvectorizer&#34;&gt;DICTVECTORIZER&lt;/h2&gt;

&lt;p&gt;How does a DictVectorizer works. There is a lot of stuff around the net for this but I dint get to understand much around it. This blog from Zygmuntz of Fastml came to rescue then. Although still it didn’t resolve how to apply that to such large amount of data.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.feature_extraction &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; DictVectorizer &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; DV
&lt;span style=&#34;color:#75715e&#34;&gt;# Create Vectorizer&lt;/span&gt;
vectorizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; DV( sparse &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False )
&lt;span style=&#34;color:#75715e&#34;&gt;# Read the whole Data&lt;/span&gt;
traindata &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(train_file, header&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, sep&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;,&amp;#39;&lt;/span&gt;, names &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; colnames)
&lt;span style=&#34;color:#75715e&#34;&gt;# Retain the categorical Columns&lt;/span&gt;
train_df   &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; traindata[cat_col]
&lt;span style=&#34;color:#75715e&#34;&gt;# Convert Panda Data frame to Dict&lt;/span&gt;
train_dict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_dict()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values()
&lt;span style=&#34;color:#75715e&#34;&gt;# Create Fit&lt;/span&gt;
vectorizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(test_dict)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;the-data&#34;&gt;THE DATA&lt;/h2&gt;

&lt;p&gt;The data was basically comprised of 40 Features with: 1. First two Columns as ID, Label 2. Next 13 columns Continuous columns labelled I1-I13 3. Next 26 Columns Categorical labelled C1-C26 Further the categorical columns were very sparse and some of the categorical variables could take more than a million different values.&lt;/p&gt;

&lt;h2 id=&#34;the-workarounds&#34;&gt;THE WORKAROUNDS&lt;/h2&gt;

&lt;p&gt;The main problem that I faced was that I could not fit that much data in a DataFrame, even when I have a machine of 16GB, and that lead me to think that do I have a need for such a large data frame. And that lead me to the first part of the solution. I don’t need to load the whole data at once. I just needed to create another dictionary with all the possible combinations and then fit my dictvectorizer on it.&lt;/p&gt;

&lt;p&gt;I know that it is a lot to take in, so let’s take an example to understand it: Let’s say we have a data of infinite size, which has 3 categorical variables: C1 could take values 1-100 C2 could take values 1-3 C3 could take values 1-1000 Then we just have to find which category could take the maximum number of values (i.e. C3 in the above case) and make a dict which contains other categories replicated to contain as many values In other words, we need to make a dict like: {C1 : [1,2,3,……,97,98,99,100]*10  , C2 : [1,2,3]*333+[1]  , C3: [1….1000]} Notice the star sign at the last of the list. That means that for every key in the dict the number of values is now 1000(i.e. the maximum number of features).&lt;/p&gt;

&lt;p&gt;And so that is what I did. After we have the Vectorizer Fit, the next task was to transform the data. I took the data transformed it and sent it to my model line by line. P.S. Don’t store the transformed data as around a 100000 records takes ~ 10GB of Hard Disk Space due to the high number of features.&lt;/p&gt;

&lt;p&gt;Hope you find it Informative and happy learning.&lt;/p&gt;

&lt;script src=&#34;//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e&#34;&gt;&lt;/script&gt;
</description>
    </item>
    
    <item>
      <title>Learning pyspark – Installation – Part 1</title>
      <link>https://mlwhiz.com/blog/2014/09/28/learning_pyspark/</link>
      <pubDate>Sun, 28 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2014/09/28/learning_pyspark/</guid>
      <description>

&lt;p&gt;This is part one of a learning series of pyspark, which is a python binding to the spark program written in Scala.&lt;/p&gt;

&lt;p&gt;The installation is pretty simple. These steps were done on Mac OS Mavericks but should work for Linux too. Here are the steps for the installation:&lt;/p&gt;

&lt;h2 id=&#34;1-download-the-binaries&#34;&gt;1. Download the Binaries:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;Spark : http:&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;spark&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apache&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;org&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;downloads&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;html
Scala : http:&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;www&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scala&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;lang&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;org&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;download&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;

Dont use Latest Version of Scala, Use Scala &lt;span style=&#34;color:#ae81ff&#34;&gt;2.10&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;x&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;2-add-these-lines-to-your-bash-profile&#34;&gt;2. Add these lines to your .bash_profile:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;export SCALA_HOME&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;your_path_to_scala
export SPARK_HOME&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;your_path_to_spark&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;3-build-spark-this-will-take-time&#34;&gt;3. Build Spark(This will take time):&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;brew install sbt
cd $SPARK_HOME
sbt/sbt assembly&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;4-start-the-pyspark-shell&#34;&gt;4. Start the Pyspark Shell:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$SPARK_HOME/bin/pyspark&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And Voila. You are running pyspark on your Machine&lt;/p&gt;

&lt;p&gt;To check that everything is properly installed, Lets run a simple program:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;test &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parallelize([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;])
test&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;count()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This should return 3.
So Now Just Run Hadoop On your Machine and then run pyspark Using:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd /usr/local/hadoop/
bin/start-all.sh
jps
$SPARK_HOME/bin/pyspark&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;script src=&#34;//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e&#34;&gt;&lt;/script&gt;
</description>
    </item>
    
    <item>
      <title>Hadoop, Mapreduce and More – Part 1</title>
      <link>https://mlwhiz.com/blog/2014/09/27/hadoop_mapreduce/</link>
      <pubDate>Sat, 27 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2014/09/27/hadoop_mapreduce/</guid>
      <description>

&lt;p&gt;It has been some time since I was stalling learning Hadoop. Finally got some free time and realized that Hadoop may not be so difficult after all.
What I understood finally is that Hadoop is basically comprised of 3 elements:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A File System&lt;/li&gt;
&lt;li&gt;Map – Reduce&lt;/li&gt;
&lt;li&gt;Its many individual Components.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let’s go through each of them one by one.&lt;/p&gt;

&lt;h2 id=&#34;1-hadoop-as-a-file-system&#34;&gt;1. Hadoop as a File System:&lt;/h2&gt;

&lt;p&gt;One of the main things that Hadoop provides is cheap data storage. What happens intrinsically is that the Hadoop system takes a file, cuts it into chunks and keeps those chunks at different places in a cluster. Suppose you have a big big file in your local system and you want that file to be:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;On the cloud for easy access&lt;/li&gt;
&lt;li&gt;Processable in human time&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The one thing you can look forward to is Hadoop.&lt;/p&gt;

&lt;p&gt;Assuming that you have got hadoop installed on the amazon cluster you are working on.&lt;/p&gt;

&lt;h3 id=&#34;start-the-hadoop-cluster&#34;&gt;Start the Hadoop Cluster:&lt;/h3&gt;

&lt;p&gt;You need to run the following commands to start the hadoop cluster(Based on location of hadoop installation directory):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd /usr/local/hadoop/
bin/start-all.sh
jps&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Adding File to HDFS:&lt;/strong&gt; Every command in Hadoop starts with hadoop fs and the rest of it works like the UNIX syntax. To add a file “purchases.txt” to the hdfs system:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;hadoop fs -put purchases.txt /usr/purchases.txt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;2-hadoop-for-map-reduce&#34;&gt;2. Hadoop for Map-Reduce:&lt;/h2&gt;

&lt;p&gt;MapReduce is a programming model and an associated implementation for processing and generating large data sets with a parallel, distributed algorithm on a cluster.&lt;/p&gt;

&lt;p&gt;While Hadoop is implemented in Java, you can use almost any language to do map-reduce in hadoop using hadoop streaming. Suppose you have a big file containing the Name of store and sales of store each hour. And you want to find out the sales per store using map-reduce. Lets Write a sample code for that:&lt;/p&gt;

&lt;p&gt;InputFile&lt;/p&gt;

&lt;pre style=&#34;font-family:courier new,monospace; background-color:#f6c6529c; color:#000000&#34;&gt;A,300,12:00
B,234,1:00
C,234,2:00
D,123,3:00
A,123,1:00
B,346,2:00
&lt;/pre&gt;

&lt;p&gt;Mapper.py&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; sys
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mapper&lt;/span&gt;():
    &lt;span style=&#34;color:#75715e&#34;&gt;# The Mapper takes inputs from stdin and prints out store name and value&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; line &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stdin:
        data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; line&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strip()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;,&amp;#34;&lt;/span&gt;)
        storeName,Value,time&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;data
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{0},{1}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(storeName,Value)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Reducer.py&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; sys
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;reducer&lt;/span&gt;():
    &lt;span style=&#34;color:#75715e&#34;&gt;# The reducer takes inputs from mapper and prints out aggregated store name and value&lt;/span&gt;
    salesTotal &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    oldKey &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; None
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; line &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stdin:
        data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; line&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strip()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;,&amp;#34;&lt;/span&gt;)
        &lt;span style=&#34;color:#75715e&#34;&gt;#Adding a little bit of Defensive programming&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(data) &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;continue&lt;/span&gt;
        curKey,curVal &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; oldKey adn oldKey &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; curKey:
            &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{0},{1}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(oldKey,salesTotal)
            salesTotal&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
        oldKey&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;curKey
        salesTotal &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; curVal
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; oldkey&lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt;None:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{0},{1}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(oldKey,salesTotal)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Running the program on shell using pipes&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;textfile.txt | ./mapper.py | sort | ./reducer.py&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Running the program on mapreduce using Hadoop Streaming&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;hadoop jar contrib/streaming/hadoop-*streaming*.jar /
-file mapper.py -mapper mapper.py /
-file reducer.py -reducer reducer.py /
-input /inputfile -output /outputfile&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;3-hadoop-components&#34;&gt;3. Hadoop Components:&lt;/h2&gt;

&lt;p&gt;Now if you have been following Hadoop you might have heard about Apache, Cloudera, HortonWorks etc. All of these are Hadoop vendors who provide Hadoop Along with its components. I will talk about the main component of Hadoop here – Hive.
So what exactly is Hive: Hive is a SQL like interface to map-reduce queries. So if you don’t understand all the hocus-pocus of map-reduce but know SQL, you can do map-reduce via Hive.
Seems Promising? It is.
While the syntax is mainly SQL, it is still a little different and there are some quirks that we need to understand to work with Hive.
First of all lets open hive command prompt: For that you just have to type “hive”, and voila you are in.
Here are some general commands&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;show databases  &lt;span style=&#34;color:#75715e&#34;&gt;#   -- See all Databases&lt;/span&gt;
use database     &lt;span style=&#34;color:#75715e&#34;&gt;#     -- Use a particular Database&lt;/span&gt;
show tables       &lt;span style=&#34;color:#75715e&#34;&gt;#     -- See all tables in a particular Database&lt;/span&gt;
describe table    &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Creating an external table:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;CREATE EXTERNAL TABLE IF NOT EXISTS BXDataSet
&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;ISBN STRING,BookTitle STRING, ImageURLL STRING&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
ROW FORMAT DELIMITED  FIELDS TERMINATED BY ‘;’ STORED AS TEXTFILE;
LOAD DATA INPATH ‘/user/book.csv’ OVERWRITE INTO TABLE BXDataSet;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The query commands work the same way as in SQL. You can do all the group by and hive will automatically convert it in map-reduce:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;select&lt;/span&gt; * from tablename;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Stay Tuned for Part 2 – Where we will talk about another components of Hadoop – PIG
To learn more about hadoop in the meantime these are the books I recommend:&lt;/p&gt;

&lt;div style=&#34;text-align: center;&#34;&gt;
&lt;a target=&#34;_blank&#34;  href=&#34;https://www.amazon.com/gp/product/1491901632/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1491901632&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=4122280e94f7bbd0ceebc9d13e60d103&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1491901632&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20&#34; &gt;&lt;/a&gt;&lt;img src=&#34;//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1491901632&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;
&lt;/div&gt;

&lt;script src=&#34;//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e&#34;&gt;&lt;/script&gt;
</description>
    </item>
    
  </channel>
</rss>