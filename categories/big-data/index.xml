<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Big Data on Helping You Learn Data Science!</title><link>https://mlwhiz.com/categories/big-data/</link><description>Recent content in Big Data on Helping You Learn Data Science!</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 04 Aug 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://mlwhiz.com/categories/big-data/index.xml" rel="self" type="application/rss+xml"/><item><title>Accelerating Spark 3.0 Google DataProc Project with NVIDIA GPUs in 6 simple steps</title><link>https://mlwhiz.com/blog/2020/08/04/spark_dataproc/</link><pubDate>Tue, 04 Aug 2020 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2020/08/04/spark_dataproc/</guid><description>Data Exploration is a key part of Data Science. And does it take long?</description></item><item><title>The Most Complete Guide to pySpark DataFrames</title><link>https://mlwhiz.com/blog/2020/06/06/spark_df_complete_guide/</link><pubDate>Wed, 24 Jun 2020 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2020/06/06/spark_df_complete_guide/</guid><description>Big Data has become synonymous with Data engineering. But the line between Data Engineering and Data scientists is blurring day by day.</description></item><item><title>Practical Spark Tips for Data Scientists</title><link>https://mlwhiz.com/blog/2020/03/20/practicalspark/</link><pubDate>Fri, 20 Mar 2020 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2020/03/20/practicalspark/</guid><description>I know — Spark is sometimes frustrating to work with.</description></item><item><title>5 Ways to add a new column in a PySpark Dataframe</title><link>https://mlwhiz.com/blog/2020/02/24/sparkcolumns/</link><pubDate>Mon, 24 Feb 2020 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2020/02/24/sparkcolumns/</guid><description>Too much data is getting generated day by day.
Although sometimes we can manage our big data using tools like Rapids or Parallelization , Spark is an excellent tool to have in your repertoire if you are working with Terabytes of data.</description></item><item><title>100x faster Hyperparameter Search Framework with Pyspark</title><link>https://mlwhiz.com/blog/2020/02/22/hyperspark/</link><pubDate>Sat, 22 Feb 2020 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2020/02/22/hyperspark/</guid><description>Recently I was working on tuning hyperparameters for a huge Machine Learning model.</description></item><item><title>The Hitchhikers guide to handle Big Data using Spark</title><link>https://mlwhiz.com/blog/2019/07/07/spark_hitchhiker/</link><pubDate>Sun, 07 Jul 2019 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2019/07/07/spark_hitchhiker/</guid><description>Big Data has become synonymous with Data engineering.
But the line between Data Engineering and Data scientists is blurring day by day.</description></item><item><title>To all Data Scientists - The one Graph Algorithm you need to know</title><link>https://mlwhiz.com/blog/2018/12/07/connected_components/</link><pubDate>Fri, 07 Dec 2018 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2018/12/07/connected_components/</guid><description>Graphs provide us with a very useful data structure. They can help us to find structure within our data.</description></item><item><title>Learning Spark using Python: Basics and Applications</title><link>https://mlwhiz.com/blog/2015/09/07/spark_basics_explain/</link><pubDate>Mon, 07 Sep 2015 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2015/09/07/spark_basics_explain/</guid><description>I generally have a use case for Hadoop in my daily job.</description></item><item><title>Hadoop Mapreduce Streaming Tricks and Techniques</title><link>https://mlwhiz.com/blog/2015/05/09/hadoop_mapreduce_streaming_tricks_and_technique/</link><pubDate>Sat, 09 May 2015 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2015/05/09/hadoop_mapreduce_streaming_tricks_and_technique/</guid><description>I have been using Hadoop a lot now a days and thought about writing some of the novel techniques that a user could use to get the most out of the Hadoop Ecosystem.</description></item><item><title>Hadoop, Mapreduce and More – Part 1</title><link>https://mlwhiz.com/blog/2014/09/27/hadoop_mapreduce/</link><pubDate>Sat, 27 Sep 2014 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2014/09/27/hadoop_mapreduce/</guid><description>It has been some time since I was stalling learning Hadoop.</description></item><item><title>Hadoop, Mapreduce and More – Part 1</title><link>https://mlwhiz.com/blog/2014/09/27/hadoop_mapreduce/</link><pubDate>Sat, 27 Sep 2014 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2014/09/27/hadoop_mapreduce/</guid><description>It has been some time since I was stalling learning Hadoop.</description></item></channel></rss>