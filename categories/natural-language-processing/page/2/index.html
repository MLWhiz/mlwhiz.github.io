<!doctype html><html lang=en-us><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-F34XSWQ5N4"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-F34XSWQ5N4")</script><meta charset=utf-8><title>Natural Language Processing - MLWhiz</title>
<meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content="Want to Learn Computer Vision and NLP? - MLWhiz"><meta name=author content="Rahul Agarwal"><meta name=generator content="Hugo 0.139.2"><link rel=stylesheet href=https://mlwhiz.com/plugins/compressjscss/main.css><meta property="og:title" content="Natural Language Processing - MLWhiz"><meta property="og:description" content="Want to Learn Computer Vision and NLP? - MLWhiz"><meta property="og:type" content="website"><meta property="og:url" content="https://mlwhiz.com/categories/natural-language-processing/"><meta property="og:image" content="https://mlwhiz.com/nlp_bg.jpg"><meta property="og:image:secure_url" content="https://mlwhiz.com/nlp_bg.jpg"><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=alternate type=application/rss+xml href=https://mlwhiz.com/categories/natural-language-processing/index.xml title="MLWhiz - Your Home for DS, ML, AI!"><link rel=stylesheet href=https://mlwhiz.com/scss/style.min.css media=screen><link rel=stylesheet href=/css/style.css><link rel=stylesheet type=text/css href=/css/font/flaticon.css><link rel="shortcut icon" href=https://mlwhiz.com/images/logos/favicon-32x32.png type=image/x-icon><link rel=icon href=https://mlwhiz.com/images/logos/favicon.ico type=image/x-icon><link rel=canonical href=https://mlwhiz.com/categories/natural-language-processing/><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js></script><script async data-uid=a0ebaf958d src=https://mlwhiz.ck.page/a0ebaf958d/index.js></script><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var e,t=MathJax.Hub.getAllJax();for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"}),MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:"AMS"}}})</script><link href=//apps.shareaholic.com/assets/pub/shareaholic.js as=script><script type=text/javascript data-cfasync=false async src=//apps.shareaholic.com/assets/pub/shareaholic.js data-shr-siteid=fd1ffa7fd7152e4e20568fbe49a489d0></script><script>!function(e,t,n,s,o,i,a){if(e.fbq)return;o=e.fbq=function(){o.callMethod?o.callMethod.apply(o,arguments):o.queue.push(arguments)},e._fbq||(e._fbq=o),o.push=o,o.loaded=!0,o.version="2.0",o.queue=[],i=t.createElement(n),i.async=!0,i.src=s,a=t.getElementsByTagName(n)[0],a.parentNode.insertBefore(i,a)}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js"),fbq("init","402633927768628"),fbq("track","PageView")</script><noscript><img height=1 width=1 style=display:none src="https://www.facebook.com/tr?id=402633927768628&ev=PageView&noscript=1"></noscript><meta property="fb:pages" content="213104036293742"><meta name=facebook-domain-verification content="qciidcy7mm137sewruizlvh8zbfnv4"><meta name=impact-site-verification value=1670148355></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NMQD44T" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><div class=preloader></div><header class=navigation><div class=container><nav class="navbar navbar-expand-lg navbar-white bg-transparent border-bottom pl-0"><a class="navbar-brand mobile-view" href=https://mlwhiz.com/><img class=img-fluid src=https://mlwhiz.com/images/logos/logo.svg alt="MLWhiz - Your Home for DS, ML, AI!"></a>
<button class="navbar-toggler border-0" type=button data-toggle=collapse data-target=#navigation>
<i class="ti-menu h3"></i></button><div class="collapse navbar-collapse text-center" id=navigation><div class=desktop-view><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href="https://linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&amp;followMember=rahulagwl"><i class=ti-linkedin></i></a></li><li class=nav-item><a class=nav-link href=https://mlwhiz.medium.com/><i class=ti-book></i></a></li><li class=nav-item><a class=nav-link href=https://twitter.com/MLWhiz><i class=ti-twitter-alt></i></a></li><li class=nav-item><a class=nav-link href=https://www.facebook.com/mlwhizblog><i class=ti-facebook></i></a></li><li class=nav-item><a class=nav-link href=https://github.com/MLWhiz><i class=ti-github></i></a></li></ul></div><a class="navbar-brand mx-auto desktop-view" href=https://mlwhiz.com/><img class=img-fluid-custom src=https://mlwhiz.com/images/logos/logo.svg alt="MLWhiz - Your Home for DS, ML, AI!"></a><ul class=navbar-nav><li class=nav-item><a class=nav-link href=https://mlwhiz.com/about>About</a></li><li class=nav-item><a class=nav-link href=https://mlwhiz.com/blog>Blog</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Topics</a><div class=dropdown-menu><a class=dropdown-item href=https://mlwhiz.com/categories/natural-language-processing>NLP</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/computer-vision>Computer Vision</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/deep-learning>Deep Learning</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/data-science>DS/ML</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/big-data>Big Data</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/awesome-guides>My Best Content</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/learning-resources>Learning Resources</a></div></li></ul><div class="search pl-lg-4"><button id=searchOpen class=search-btn><i class=ti-search></i></button><div class=search-wrapper><form action=https://mlwhiz.com//search class=h-100><input class="search-box px-4" id=search-query name=s type=search placeholder="Type & Hit Enter..."></form><button id=searchClose class=search-close><i class="ti-close text-dark"></i></button></div></div></div></nav></div></header><section id=hero class="block block-hero has-gradient outer" style=padding-top:3.5em;padding-bottom:3.5em><div class=bg-img style=background-image:url(/images/category_bgs/nlp_bg.jpg)></div><div class=inner-sm><div class=block-header><i class=flaticon-translate></i><h1 class=block-title>Natural Language Processing</h1><h4 style=color:#fff;width:80%>Natural Language Processing is a vastly inetersting field but it is inherently hard to learn because of its vastness. I myself had a tough time understanding just where to start. It comprises of tasks such as Sequence Classification, Named Entity Recognition, Translation, Text to Speech, Question Answering, Language Modeling, Summarization etc.</h4></div><div class=block-content style=font-color:white><p style=color:#fff;font-size:1em>So, Want to Learn Natural Language Processing with Me?</p></div><div class=block-buttons><a class=herobutton style=font-size:1em data-formkit-toggle=a0ebaf958d href=https://mlwhiz.ck.page/a0ebaf958d>Sure</a></div></div></section><section class=section-sm><div class=container><div class=row><div class="col-lg-8 mb-5 mb-lg-0"><div class=row><div class="col-md-6 mb-4"><article class=card><a href=https://mlwhiz.com/blog/2019/04/15/chatbot/><img src=https://mlwhiz.com/images/chatbot/dvader_hu8013402041369703160.jpeg class=card-img-top alt="Chatbots  aren&rsquo;t as difficult to make as You Think"></a><div class="card-body px-0"><a href=/categories/natural-language-processing class=categoryStyle>Natural Language Processing</a>
<a href=/categories/deep-learning class=categoryStyle>Deep Learning</a>
<a href=/categories/awesome-guides class=categoryStyle>Awesome Guides</a>
<a href=https://mlwhiz.com/blog/2019/04/15/chatbot/ class="h5 d-block my-3">Chatbots aren&rsquo;t as difficult to make as You Think</a><div class="mb-3 post-meta"><span>By Rahul Agarwal</span>
<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
<span>15 April 2019</span></div><p class=card-text><p>Chatbots are the in thing now. Every website must implement it. Every Data Scientist must know about them. Anytime we talk about AI; Chatbots must be discussed. But they look intimidating to someone very new to the field. We struggle with a lot of questions before we even begin to start working on them.
Are they hard to create? What technologies should I know before attempting to work on them? In the end, we end up discouraged reading through many posts on the internet and effectively accomplishing nothing.</p></p><a href=https://mlwhiz.com/blog/2019/04/15/chatbot/ class=rmStyle>read more</a></div></article></div><div class="col-md-6 mb-4"><article class=card><a href=https://mlwhiz.com/blog/2019/03/30/transfer_learning_text_classification/><img src=https://mlwhiz.com/images/nlp_tl/spiderman_hu1701086482625991202.jpeg class=card-img-top alt="NLP  Learning Series: Part 4 - Transfer Learning Intuition for Text Classification"></a><div class="card-body px-0"><a href=/categories/natural-language-processing class=categoryStyle>Natural Language Processing</a>
<a href=/categories/deep-learning class=categoryStyle>Deep Learning</a>
<a href=/categories/awesome-guides class=categoryStyle>Awesome Guides</a>
<a href=https://mlwhiz.com/blog/2019/03/30/transfer_learning_text_classification/ class="h5 d-block my-3">NLP Learning Series: Part 4 - Transfer Learning Intuition for Text Classification</a><div class="mb-3 post-meta"><span>By Rahul Agarwal</span>
<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
<span>30 March 2019</span></div><p class=card-text><p>This post is the fourth post of the NLP Text classification series. To give you a recap, I started up with an NLP text classification competition on Kaggle called Quora Question insincerity challenge. So I thought to share the knowledge via a series of blog posts on text classification. The
<a href=/blog/2019/01/17/deeplearning_nlp_preprocess/>first post</a>
talked about the different <strong>preprocessing techniques that work with Deep learning models</strong> and <strong>increasing embeddings coverage</strong>. In the
<a href=/blog/2019/02/08/deeplearning_nlp_conventional_methods/>second post</a>
, I talked through some <strong>basic conventional models</strong> like TFIDF, Count Vectorizer, Hashing, etc. that have been used in text classification and tried to access their performance to create a baseline. In the
<a href=/blog/2019/03/09/deeplearning_architectures_text_classification/>third post</a>
, I delved deeper into <strong>Deep learning models and the various architectures</strong> we could use to solve the text Classification problem. In this post, I will try to use ULMFit model which is a transfer learning approach to this data.</p></p><a href=https://mlwhiz.com/blog/2019/03/30/transfer_learning_text_classification/ class=rmStyle>read more</a></div></article></div><div class="col-md-6 mb-4"><article class=card><a href=https://mlwhiz.com/blog/2019/03/09/deeplearning_architectures_text_classification/><img src=https://mlwhiz.com/images/birnn_hu13730678206037602286.png class=card-img-top alt="NLP  Learning Series: Part 3 - Attention, CNN and what not for Text Classification"></a><div class="card-body px-0"><a href=/categories/natural-language-processing class=categoryStyle>Natural Language Processing</a>
<a href=/categories/deep-learning class=categoryStyle>Deep Learning</a>
<a href=/categories/awesome-guides class=categoryStyle>Awesome Guides</a>
<a href=https://mlwhiz.com/blog/2019/03/09/deeplearning_architectures_text_classification/ class="h5 d-block my-3">NLP Learning Series: Part 3 - Attention, CNN and what not for Text Classification</a><div class="mb-3 post-meta"><span>By Rahul Agarwal</span>
<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
<span>09 March 2019</span></div><p class=card-text><p>This post is the third post of the NLP Text classification series. To give you a recap, I started up with an NLP text classification competition on Kaggle called Quora Question insincerity challenge. So I thought to share the knowledge via a series of blog posts on text classification. The
<a href=/blog/2019/01/17/deeplearning_nlp_preprocess/>first post</a>
talked about the different <strong>preprocessing techniques that work with Deep learning models</strong> and <strong>increasing embeddings coverage</strong>. In the
<a href=/blog/2019/02/08/deeplearning_nlp_conventional_methods/>second post</a>
, I talked through some <strong>basic conventional models</strong> like TFIDF, Count Vectorizer, Hashing, etc. that have been used in text classification and tried to access their performance to create a baseline. In this post, I delve deeper into <strong>Deep learning models and the various architectures</strong> we could use to solve the text Classification problem. To make this post platform generic, I am going to code in both Keras and Pytorch. I will use various other models which we were not able to use in this competition like <strong>ULMFit transfer learning</strong> approaches in the fourth post in the series.</p></p><a href=https://mlwhiz.com/blog/2019/03/09/deeplearning_architectures_text_classification/ class=rmStyle>read more</a></div></article></div><div class="col-md-6 mb-4"><article class=card><a href=https://mlwhiz.com/blog/2019/02/19/siver_medal_kaggle_learnings/><img src=https://mlwhiz.com/images/silver/CV_vs_LB_hu12757389222124146982.png class=card-img-top alt="What my first Silver Medal taught me about Text Classification and Kaggle in general?"></a><div class="card-body px-0"><a href=/categories/natural-language-processing class=categoryStyle>Natural Language Processing</a>
<a href=/categories/deep-learning class=categoryStyle>Deep Learning</a>
<a href=/categories/awesome-guides class=categoryStyle>Awesome Guides</a>
<a href=https://mlwhiz.com/blog/2019/02/19/siver_medal_kaggle_learnings/ class="h5 d-block my-3">What my first Silver Medal taught me about Text Classification and Kaggle in general?</a><div class="mb-3 post-meta"><span>By Rahul Agarwal</span>
<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
<span>19 February 2019</span></div><p class=card-text><p>Kaggle is an excellent place for learning. And I learned a lot of things from the recently concluded competition on <strong>Quora Insincere questions classification</strong> in which I got a rank of <strong><code>182/4037</code></strong>. In this post, I will try to provide a summary of the things I tried. I will also try to summarize the ideas which I missed but were a part of other winning solutions.</p></p><a href=https://mlwhiz.com/blog/2019/02/19/siver_medal_kaggle_learnings/ class=rmStyle>read more</a></div></article></div><div class="col-md-6 mb-4"><article class=card><a href=https://mlwhiz.com/blog/2019/02/08/deeplearning_nlp_conventional_methods/><img src=https://mlwhiz.com/images/tfidf_hu11651012409244153511.png class=card-img-top alt="NLP  Learning Series: Part 2 - Conventional Methods for Text Classification"></a><div class="card-body px-0"><a href=/categories/natural-language-processing class=categoryStyle>Natural Language Processing</a>
<a href=/categories/deep-learning class=categoryStyle>Deep Learning</a>
<a href=/categories/awesome-guides class=categoryStyle>Awesome Guides</a>
<a href=https://mlwhiz.com/blog/2019/02/08/deeplearning_nlp_conventional_methods/ class="h5 d-block my-3">NLP Learning Series: Part 2 - Conventional Methods for Text Classification</a><div class="mb-3 post-meta"><span>By Rahul Agarwal</span>
<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
<span>08 February 2019</span></div><p class=card-text><p>This is the second post of the NLP Text classification series. To give you a recap, recently I started up with an NLP text classification competition on Kaggle called Quora Question insincerity challenge. And I thought to share the knowledge via a series of blog posts on text classification. The
<a href=/blog/2019/01/17/deeplearning_nlp_preprocess/>first post</a>
talked about the various <strong>preprocessing techniques that work with Deep learning models</strong> and <strong>increasing embeddings coverage</strong>. In this post, I will try to take you through some <strong>basic conventional models</strong> like TFIDF, Count Vectorizer, Hashing etc. that have been used in text classification and try to access their performance to create a baseline. We will delve deeper into <strong>Deep learning models</strong> in the third post which will focus on different architectures for solving the text classification problem. We will try to use various other models which we were not able to use in this competition like <strong>ULMFit transfer learning</strong> approaches in the fourth post in the series.</p></p><a href=https://mlwhiz.com/blog/2019/02/08/deeplearning_nlp_conventional_methods/ class=rmStyle>read more</a></div></article></div><div class="col-md-6 mb-4"><article class=card><a href=https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/><img src=https://mlwhiz.com/images/text_processing_flow_1.png class=card-img-top alt="NLP  Learning Series: Part 1 - Text Preprocessing Methods for Deep Learning"></a><div class="card-body px-0"><a href=/categories/natural-language-processing class=categoryStyle>Natural Language Processing</a>
<a href=/categories/deep-learning class=categoryStyle>Deep Learning</a>
<a href=/categories/awesome-guides class=categoryStyle>Awesome Guides</a>
<a href=https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/ class="h5 d-block my-3">NLP Learning Series: Part 1 - Text Preprocessing Methods for Deep Learning</a><div class="mb-3 post-meta"><span>By Rahul Agarwal</span>
<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
<span>17 January 2019</span></div><p class=card-text><p>Recently, I started up with an NLP competition on Kaggle called Quora Question insincerity challenge. It is an NLP Challenge on text classification and as the problem has become more clear after working through the competition as well as by going through the invaluable kernels put up by the kaggle experts, I thought of sharing the knowledge.</p></p><a href=https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/ class=rmStyle>read more</a></div></article></div><div class="col-md-6 mb-4"><article class=card><a href=https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/><img src=https://mlwhiz.com/images/artificial-neural-network.png class=card-img-top alt="A Layman guide to moving from Keras to Pytorch"></a><div class="card-body px-0"><a href=/categories/natural-language-processing class=categoryStyle>Natural Language Processing</a>
<a href=/categories/deep-learning class=categoryStyle>Deep Learning</a>
<a href=/categories/computer-vision class=categoryStyle>Computer Vision</a>
<a href=/categories/awesome-guides class=categoryStyle>Awesome Guides</a>
<a href=https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/ class="h5 d-block my-3">A Layman guide to moving from Keras to Pytorch</a><div class="mb-3 post-meta"><span>By Rahul Agarwal</span>
<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
<span>06 January 2019</span></div><p class=card-text><div style=margin-top:9px;margin-bottom:10px><center><img src=/images/artificial-neural-network.png height=350 width=700></center></div><p>Recently I started up with a competition on kaggle on text classification, and as a part of the competition, I had to somehow move to Pytorch to get deterministic results. Now I have always worked with Keras in the past and it has given me pretty good results, but somehow I got to know that the <strong>CuDNNGRU/CuDNNLSTM layers in keras are not deterministic</strong>, even after setting the seeds. So Pytorch did come to rescue. And am I glad that I moved.</p></p><a href=https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/ class=rmStyle>read more</a></div></article></div><div class="col-md-6 mb-4"><article class=card><a href=https://mlwhiz.com/blog/2018/12/17/text_classification/><img src=https://mlwhiz.com/images/text_convolution_hu4255449226706830151.png class=card-img-top alt="What Kagglers are using for Text Classification"></a><div class="card-body px-0"><a href=/categories/natural-language-processing class=categoryStyle>Natural Language Processing</a>
<a href=/categories/deep-learning class=categoryStyle>Deep Learning</a>
<a href=/categories/awesome-guides class=categoryStyle>Awesome Guides</a>
<a href=https://mlwhiz.com/blog/2018/12/17/text_classification/ class="h5 d-block my-3">What Kagglers are using for Text Classification</a><div class="mb-3 post-meta"><span>By Rahul Agarwal</span>
<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
<span>17 December 2018</span></div><p class=card-text><p>With the problem of Image Classification is more or less solved by Deep learning, <em>Text Classification is the next new developing theme in deep learning</em>. For those who don&rsquo;t know, Text classification is a common task in natural language processing, which transforms a sequence
of text of indefinite length into a category of text. How could you use that?</p></p><a href=https://mlwhiz.com/blog/2018/12/17/text_classification/ class=rmStyle>read more</a></div></article></div><div class="col-md-6 mb-4"><article class=card><a href=https://mlwhiz.com/blog/2017/04/09/word_vec_embeddings_examples_understanding/><img src=https://mlwhiz.com/images/category_bgs/default_bg_hu7063601076218545216.jpg class=card-img-top alt="Today I Learned This Part I: What are word2vec Embeddings?"></a><div class="card-body px-0"><a href=/categories/natural-language-processing class=categoryStyle>Natural Language Processing</a>
<a href=/categories/deep-learning class=categoryStyle>Deep Learning</a>
<a href=https://mlwhiz.com/blog/2017/04/09/word_vec_embeddings_examples_understanding/ class="h5 d-block my-3">Today I Learned This Part I: What are word2vec Embeddings?</a><div class="mb-3 post-meta"><span>By Rahul Agarwal</span>
<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
<span>09 April 2017</span></div><p class=card-text><p>Recently Quora put out a
<a href=https://www.kaggle.com/c/quora-question-pairs target=_blank rel="nofollow noopener">Question similarity</a>
competition on Kaggle. This is the first time I was attempting an NLP problem so a lot to learn. The one thing that blew my mind away was the word2vec embeddings.</p></p><a href=https://mlwhiz.com/blog/2017/04/09/word_vec_embeddings_examples_understanding/ class=rmStyle>read more</a></div></article></div></div></div><div class=col-lg-4><div class=widget><script type=text/javascript src=https://ko-fi.com/widgets/widget_2.js></script><script type=text/javascript>kofiwidget2.init("Support Me on Ko-fi","#972EB4","S6S3NPCD"),kofiwidget2.draw()</script></div><div class=widget><h4 class=widget-title>About Me</h4><img src=https://mlwhiz.com/images/author.jpg alt class="img-fluid author-thumb-sm d-block mx-auto rounded-circle mb-4"><p><p>I’m a Machine Learning Engineer based in London, where I am currently working with <strong>Roku</strong> .</p></p><a href=https://mlwhiz.com/about/ class="btn btn-outline-primary">Know More</a></div><div class=widget><h4 class=widget-title>Topics</h4><ul class=list-unstyled><li><a class="categoryStyle text-white" href=/categories/awesome-guides>Awesome Guides</a></li><li><a class="categoryStyle text-white" href=/categories/bash>Bash</a></li><li><a class="categoryStyle text-white" href=/categories/big-data>Big Data</a></li><li><a class="categoryStyle text-white" href=/categories/chatgpt-series>Chatgpt Series</a></li><li><a class="categoryStyle text-white" href=/categories/computer-vision>Computer Vision</a></li><li><a class="categoryStyle text-white" href=/categories/data-science>Data Science</a></li><li><a class="categoryStyle text-white" href=/categories/deep-learning>Deep Learning</a></li><li><a class="categoryStyle text-white" href=/categories/learning-resources>Learning Resources</a></li><li><a class="categoryStyle text-white" href=/categories/machine-learning>Machine Learning</a></li><li><a class="categoryStyle text-white" href=/categories/natural-language-processing>Natural Language Processing</a></li><li><a class="categoryStyle text-white" href=/categories/opinion>Opinion</a></li><li><a class="categoryStyle text-white" href=/categories/programming>Programming</a></li></ul></div><div class=widget><h4 class=widget-title>Tags</h4><ul class=list-inline><li class=list-inline-item><a class="tagStyle text-white" href=/tags/algorithms>Algorithms</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/artificial-intelligence>Artificial Intelligence</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/awesome-guides>Awesome Guides</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/best-content>Best Content</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/big-data>Big Data</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/chatgpt>Chatgpt</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/computer-vision>Computer Vision</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/curated-resources>Curated Resources</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/dask>Dask</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/data-science>Data Science</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/deep-learning>Deep Learning</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/deployment>Deployment</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/ec2>Ec2</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/generative-adversarial-networks>Generative Adversarial Networks</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/graphs>Graphs</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/image-classification>Image Classification</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/instance-segmentation>Instance Segmentation</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/interpretability>Interpretability</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/jobs>Jobs</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/kaggle>Kaggle</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/language-modeling>Language Modeling</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/learning-resources>Learning Resources</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/machine-learning>Machine Learning</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/math>Math</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/multiprocessing>Multiprocessing</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/natural-language-processing>Natural Language Processing</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/object-detection>Object Detection</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/oop>Oop</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/opinion>Opinion</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/pandas>Pandas</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/production>Production</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/productivity>Productivity</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/python>Python</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/pytorch>Pytorch</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/spark>Spark</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/sql>SQL</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/statistics>Statistics</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/streamlit>Streamlit</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/text-classification>Text Classification</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/timeseries>Timeseries</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/tools>Tools</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/transformers>Transformers</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/translation>Translation</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/visualization>Visualization</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/xgboost>Xgboost</a></li></ul></div><div class=widget><h4 class=widget-title>Connect With Me</h4><ul class="list-inline social-links"><li class=list-inline-item><a href="https://linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&amp;followMember=rahulagwl"><i class=ti-linkedin></i></a></li><li class=list-inline-item><a href=https://mlwhiz.medium.com/><i class=ti-book></i></a></li><li class=list-inline-item><a href=https://twitter.com/MLWhiz><i class=ti-twitter-alt></i></a></li><li class=list-inline-item><a href=https://www.facebook.com/mlwhizblog><i class=ti-facebook></i></a></li><li class=list-inline-item><a href=https://github.com/MLWhiz><i class=ti-github></i></a></li></ul></div><script async data-uid=bfe9f82f10 src=https://mlwhiz.ck.page/bfe9f82f10/index.js></script><script async data-uid=3452d924e2 src=https://mlwhiz.ck.page/3452d924e2/index.js></script></div><div class="col-12 mt-5"><ul class="pagination pagination-default"><li class=page-item><a href=/categories/natural-language-processing/ aria-label=First class=page-link role=button><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/categories/natural-language-processing/ aria-label=Previous class=page-link role=button><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a href=/categories/natural-language-processing/ aria-label="Page 1" class=page-link role=button>1</a></li><li class="page-item active"><a aria-current=page aria-label="Page 2" class=page-link role=button>2</a></li><li class="page-item disabled"><a aria-disabled=true aria-label=Next class=page-link role=button tabindex=-1><span aria-hidden=true>&#187;</span></a></li><li class="page-item disabled"><a aria-disabled=true aria-label=Last class=page-link role=button tabindex=-1><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div></div></section><footer><div class=container><div class=row><div class="col-12 text-center mb-5"><a href=https://mlwhiz.com/><img src=https://mlwhiz.com/images/logos/mlwhiz_black.png class=img-fluid-custom-bottom alt="MLWhiz - Your Home for DS, ML, AI!"></a></div><div class="col-12 border-top py-4 text-center">Copyright © 2020 <a href=https://mlwhiz.com style=color:#972eb4>MLWhiz</a> All Rights Reserved</div></div></div></footer><script>var indexURL="https://mlwhiz.com/index.json"</script><script src=https://mlwhiz.com/plugins/compressjscss/main.js></script><script src=https://mlwhiz.com/js/script.min.js></script><script>(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","//www.google-analytics.com/analytics.js","ga"),ga("create","UA-54777926-1","auto"),ga("send","pageview")</script></body></html>