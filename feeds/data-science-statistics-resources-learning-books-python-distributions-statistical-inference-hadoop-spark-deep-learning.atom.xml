<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>mlwhiz</title><link href="http://mlwhiz.github.io/" rel="alternate"></link><link href="http://mlwhiz.github.io/feeds/data-science-statistics-resources-learning-books-python-distributions-statistical-inference-hadoop-spark-deep-learning.atom.xml" rel="self"></link><id>http://mlwhiz.github.io/</id><updated>2017-03-26T13:43:00-03:00</updated><entry><title>Top Data Science Resources on the Internet right now</title><link href="http://mlwhiz.github.io/blog/2017/03/26/top_data_science_resources_on_the_internet_right_now/" rel="alternate"></link><updated>2017-03-26T13:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2017-03-26:blog/2017/03/26/top_data_science_resources_on_the_internet_right_now/</id><summary type="html">&lt;p&gt;I have been looking to create this list for a while now. There are many people on quora who ask me how I started in the data science field. And so I wanted to create this reference.&lt;/p&gt;
&lt;p&gt;To be frank, when I first started learning it all looked very utopian and out of the world. The Andrew Ng course felt like black magic. And it still doesn't cease to amaze me. After all, we are predicting the future. Take the case of Nate Silver - What else can you call his success if not Black Magic?&lt;/p&gt;
&lt;p&gt;But it is not magic. And this is a way an aspiring guy could take to become a &lt;b&gt;&lt;u&gt;self-trained data scientist&lt;/u&gt;&lt;/b&gt;. Follow in order. I have tried to include everything that comes to my mind. So here goes:&lt;/p&gt;
&lt;h2&gt;1. &lt;a href="http://projects.iq.harvard.edu/stat110/youtube"&gt;Stat 110: Introduction to Probability: Joe Blitzstein - Harvard University&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;The one stat course you gotta take&lt;/em&gt;. If not for the content then for Prof. Blitzstein sense of humor. I took this course to enhance my understanding of probability distributions and statistics, but this course taught me a lot more than that. Apart from Learning to think conditionally, this also taught me how to explain difficult concepts with a story.&lt;/p&gt;
&lt;p&gt;This was a Hard Class but most definitely fun. The focus was not only on getting Mathematical proofs but also on understanding the intuition behind them and how intuition can help in deriving them more easily. Sometimes the same proof was done in different ways to facilitate learning of a concept.&lt;/p&gt;
&lt;p&gt;One of the things I liked most about this course is the focus on concrete examples while explaining abstract concepts. The inclusion of &lt;strong&gt; Gambler’s Ruin Problem, Matching Problem, Birthday Problem, Monty Hall, Simpsons Paradox, St. Petersberg Paradox &lt;/strong&gt; etc. made this course much much more exciting than a normal Statistics Course.&lt;/p&gt;
&lt;p&gt;It will help you understand Discrete (Bernoulli, Binomial, Hypergeometric, Geometric, Negative Binomial, FS, Poisson) and Continuous (Uniform, Normal, expo, Beta, Gamma) Distributions and the stories behind them. Something that I was always afraid of.&lt;/p&gt;
&lt;p&gt;He got a textbook out based on this course which is clearly a great text:&lt;/p&gt;
&lt;div style="margin-left:1em ; text-align: center;"&gt;
&lt;a href="https://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science-ebook/dp/B00MMOJ19I/ref=as_li_ss_il?ie=UTF8&amp;linkCode=li3&amp;tag=mlwhizcon-20&amp;linkId=7254baef925507e0d8dfd07cca2f519d" target="_blank"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=B00MMOJ19I&amp;Format=_SL250_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li3&amp;o=1&amp;a=B00MMOJ19I" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;

&lt;h2&gt;2. &lt;a href="http://cs109.github.io/2015/"&gt;Data Science CS109&lt;/a&gt;: -&lt;/h2&gt;
&lt;p&gt;Again by Professor Blitzstein. Again an awesome course. &lt;em&gt;Watch it after Stat110 as you will be able to understand everything much better with a thorough grinding in Stat110 concepts&lt;/em&gt;. You will learn about &lt;em&gt;Python Libraries&lt;/em&gt; like &lt;strong&gt;Numpy,Pandas&lt;/strong&gt; for data science, along with a thorough intuitive grinding for various Machine learning Algorithms. Course description from Website:&lt;/p&gt;
&lt;div style="color:black; background-color: #E9DAEE;"&gt;
Learning from data in order to gain useful predictions and insights. This course introduces methods for five key facets of an investigation: data wrangling, cleaning, and sampling to get a suitable data set; data management to be able to access big data quickly and reliably; exploratory data analysis to generate hypotheses and intuition; prediction based on statistical methods such as regression and classification; and communication of results through visualization, stories, and interpretable summaries.
&lt;/div&gt;

&lt;h2&gt;3. &lt;a href="https://www.coursera.org/learn/machine-learning"&gt;CS229: Andrew Ng&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After doing these two above courses you will gain the status of what I would like to call a &lt;strong&gt;"Beginner"&lt;/strong&gt;. Congrats!!!. &lt;em&gt;You know stuff, you know how to implement stuff&lt;/em&gt;. Yet you do not fully understand all the math and grind that goes behind all this.&lt;/p&gt;
&lt;p&gt;Here comes the Game Changer machine learning course. Contains the maths behind many of the Machine Learning algorithms.  I will put this course as the &lt;em&gt;one course you gotta take&lt;/em&gt; as this course motivated me into getting in this field and Andrew Ng is a great instructor. Also this was the first course that I took.&lt;/p&gt;
&lt;p&gt;Also recently Andrew Ng Released a new Book. You can get the Draft chapters by subcribing on his website &lt;a href="http://www.mlyearning.org/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You are done with the three musketeers of the trade. You know Python, you understand Statistics and you have gotten the taste of the math behind ML approaches. Now it is time for the new kid on the block. D'artagnan. This kid has skills. While the three musketeers are masters in their trade, this guy brings qualities that adds a new freshness to our data science journey. Here comes Big Data for you.&lt;/p&gt;
&lt;h2&gt;4. &lt;a href="https://www.udacity.com/course/intro-to-hadoop-and-mapreduce--ud617"&gt;Intro to Hadoop &amp;amp; Mapreduce - Udacity&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Let us first focus on the literal elephant in the room - Hadoop.&lt;/em&gt; Short and Easy Course. Taught the Fundamentals of Hadoop streaming with Python. Taken by Cloudera on Udacity. I am doing much more advanced stuff with python and Mapreduce now but this is one of the courses that laid the foundation there.&lt;/p&gt;
&lt;p&gt;Once  you are done through this course you would have gained quite a basic understanding of concepts and you would have installed a Hadoop VM in your own machine. You would also have solved the Basic Wordcount Problem.
Read this amazing Blog Post from Michael Noll: &lt;a href="http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/"&gt;Writing An Hadoop MapReduce Program In Python - Michael G. Noll&lt;/a&gt;.  Just read the basic mapreduce codes. Don't use Iterators and Generators yet. This has been a starting point for many of us Hadoop developers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Now try to solve these two problems from the CS109 Harvard course from 2013:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A.&lt;/strong&gt; First, grab the file word_list.txt from &lt;a href="https://raw.github.com/cs109/content/master/labs/lab8/word_list.txt"&gt;here&lt;/a&gt;.  This contains a list of six-letter words. To keep things simple, all of  the words consist of lower-case letters only.Write a mapreduce job that  finds all anagrams in word_list.txt.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;B.&lt;/strong&gt; For the next problem, download the file &lt;a href="https://raw.github.com/cs109/content/master/labs/lab8/baseball_friends.csv"&gt;baseball_friends.csv&lt;/a&gt;. Each row of this csv file contains the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A person's name&lt;/li&gt;
&lt;li&gt;The team that person is rooting for -- either "Cardinals" or "Red Sox"&lt;/li&gt;
&lt;li&gt;A list of that person's friends, which could have arbitrary length&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;For  example:&lt;/em&gt; The first line tells us that Aaden is a Red Sox friend and he  has 65  friends, who are all listed here. For this problem, it's safe to  assume  that all of the names are unique and that the friendship  structure is  symmetric (i.e. if Alannah shows up in Aaden's friends list, then Aaden will show up in Alannah's friends list).
Write  an mr job that lists each person's name, their favorite  team, the  number of Red Sox fans they are friends with, and the number  of  Cardinals fans they are friends with.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Try to do this yourself.&lt;/strong&gt; Don't use the mrjob (pronounced Mr. Job) way that  they use in the CS109 2013 class. Use the proper Hadoop Streaming way as taught in the Udacity class as it is much more customizable in the long run.&lt;/p&gt;
&lt;p&gt;If you are done with these, you can safely call yourself as someone who could &lt;strong&gt;"think in Mapreduce"&lt;/strong&gt; as how people like to call it.Try to do groupby, filter and joins using Hadoop. You can read up some good tricks from my blog:&lt;br&gt;
&lt;a href="http://mlwhiz.com/blog/2015/05/09/Hadoop_Mapreduce_Streaming_Tricks_and_Techniques/"&gt;Hadoop Mapreduce Streaming Tricks and Techniques&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you are someone who likes learning from a book you can get:
&lt;div style="margin-left:1em ; text-align: center;"&gt;
&lt;a href="https://www.amazon.com/Hadoop-Definitive-Storage-Analysis-Internet/dp/1491901632/ref=as_li_ss_il?s=books&amp;ie=UTF8&amp;qid=1490543345&amp;sr=1-1&amp;keywords=hadoop+python&amp;linkCode=li2&amp;tag=mlwhizcon-20&amp;linkId=e0a6c64497866b874326afa08a069654" target="_blank"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1491901632&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li2&amp;o=1&amp;a=1491901632" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;h2&gt;5. Spark - In memory Big Data tool.&lt;/h2&gt;
&lt;p&gt;Now  comes the next part of your learning process. This should be undertaken after a little bit of experience with Hadoop. Spark will provide you with the speed and tools that Hadoop couldn't.&lt;/p&gt;
&lt;p&gt;Now Spark is used for data preparation as well as Machine learning purposes. I would encourage you to take a look at the series of courses on edX provided by Berkeley instructors. This course delivers on what it says. It teaches Spark. Total beginners will have difficulty following the course as the course progresses very fast. That said anyone with a decent understanding of how big data works will be OK.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.edx.org/xseries/data-science-engineering-apacher-sparktm"&gt;Data Science and Engineering with Apache® Spark™&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I have written a little bit about Basic data processing with Spark here. Take a look:
&lt;a href="http://mlwhiz.com/blog/2015/09/07/Spark_Basics_Explained/"&gt;Learning Spark using Python: Basics and Applications&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Also take a look at some of the projects I did as part of course at &lt;a href="http://www.github.com/MLWhiz/Spark_Projects/"&gt;github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you would like a book to read:
&lt;div style="margin-left:1em ; text-align: center;"&gt;
&lt;a href="https://www.amazon.com/Advanced-Analytics-Spark-Patterns-Learning/dp/1491912766/ref=as_li_ss_il?s=books&amp;ie=UTF8&amp;qid=1490543902&amp;sr=1-1&amp;keywords=spark+python&amp;linkCode=li2&amp;tag=mlwhizcon-20&amp;linkId=85591cf408de278e23e8570b7e9c284b" target="_blank"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1491912766&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li2&amp;o=1&amp;a=1491912766" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;If you don't go through the courses, &lt;strong&gt;try solving the same two problems above that you solved by Hadoop using Spark too&lt;/strong&gt;. Otherwise the problem sets in the courses are more than enough.&lt;/p&gt;
&lt;h2&gt;6. Understand Linux Shell:&lt;/h2&gt;
&lt;p&gt;Shell is a big friend for data scientists. It allows you to do simple data related tasks in the terminal itself. I couldn't emphasize how much time shell saves for me everyday.&lt;/p&gt;
&lt;p&gt;Read these tutorials by me for doing that:&lt;br&gt;
&lt;a href="http://mlwhiz.com/blog/2015/10/09/shell_basics_for_data_science/"&gt;Shell Basics every Data Scientist Should know -Part I&lt;/a&gt;
&lt;a href="http://mlwhiz.com/blog/2015/10/11/shell_basics_for_data_science_2/"&gt;Shell Basics every Data Scientist Should know - Part II(AWK)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you would like a course you can go for &lt;a href="https://www.edx.org/course/introduction-linux-linuxfoundationx-lfs101x-1#!"&gt;this course on edX&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you want a book, go for:&lt;/p&gt;
&lt;div style="margin-left:1em ; text-align: center;"&gt;
&lt;a href="https://www.amazon.com/Linux-Command-Line-Complete-Introduction/dp/1593273894/ref=as_li_ss_il?s=books&amp;ie=UTF8&amp;qid=1490544715&amp;sr=1-1&amp;keywords=the+linux+command+line&amp;linkCode=li2&amp;tag=mlwhizcon-20&amp;linkId=9f155a16f16c7ae34e682e0e0312ee8f" target="_blank"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1593273894&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li2&amp;o=1&amp;a=1593273894" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Congrats you are an "Hacker" now.&lt;/strong&gt; You have got all the main tools in your belt to be a data scientist. On to more advanced topics. From here it depends on you what you want to learn. You may want to take a totally different approach than what I took going from here. There is no particular order. &lt;strong&gt;"All Roads lead to Rome"&lt;/strong&gt; as long as you are running.&lt;/p&gt;
&lt;h2&gt;7. &lt;a href="https://www.coursera.org/specializations/statistics"&gt;Learn Statistical Inference and Bayesian Statistics&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I took the previous version of the specialization which was a single course taught by Mine Çetinkaya-Rundel. She is a great instrucor and explains the fundamentals of Statistical inference nicely. A must take course. You will learn about hypothesis testing, confidence intervals, and statistical inference methods for numerical and categorical data.
You can also use these books:&lt;/p&gt;
&lt;div style="margin-left:1em ; text-align: center;"&gt;
&lt;a href="https://www.amazon.com/dp/1943450056/ref=as_li_ss_il?m=A3EEBE82C3HYRD&amp;linkCode=li2&amp;tag=mlwhizcon-20&amp;linkId=cfd246ebddfde379bc01dcb2c467c199" target="_blank"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1943450056&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li2&amp;o=1&amp;a=1943450056" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/t&gt;&lt;/t&gt;
&lt;a href="https://www.amazon.com/Probability-Statistics-4th-Morris-DeGroot/dp/0321500466/ref=as_li_ss_il?ie=UTF8&amp;qid=1490547535&amp;sr=8-1&amp;keywords=degroot+statistics&amp;linkCode=li2&amp;tag=mlwhizcon-20&amp;linkId=fc106a3b8c56be8baf34793816762ec8" target="_blank"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=0321500466&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li2&amp;o=1&amp;a=0321500466" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;

&lt;h2&gt;8. Deep Learning&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://www.fast.ai/"&gt;Intro&lt;/a&gt; - Making neural nets uncool again. An awesome Deep learning class from Kaggle Master Jeremy Howard. Entertaining and enlightening at the same time.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://cs231n.github.io/"&gt;Advanced&lt;/a&gt; - A series of notes from the Stanford CS class CS231n: Convolutional Neural Networks for Visual Recognition.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://neuralnetworksanddeeplearning.com/"&gt;Bonus&lt;/a&gt; - A free online book by Michael Nielsen.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://amzn.to/2npItnM"&gt;Advanced Math Book&lt;/a&gt; - A math intensive book by Yoshua Bengio &amp;amp; Ian Goodfellow&lt;/p&gt;
&lt;h2&gt;9. &lt;a href="https://www.youtube.com/watch?v=xoA5v9AO7S0&amp;amp;list=PLLssT5z_DsK9JDLcT8T62VtzwyW9LNepV"&gt;Algorithms, Graph Algorithms, Recommendation Systems, Pagerank and More&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This course used to be there on Coursera but now only video links on youtube available.
You can learn from this book too:
&lt;div style="margin-left:1em ; text-align: center;"&gt;
&lt;a href="https://www.amazon.com/Mining-Massive-Datasets-Jure-Leskovec/dp/1107077230/ref=as_li_ss_il?ie=UTF8&amp;linkCode=li2&amp;tag=mlwhizcon-20&amp;linkId=ba893a022640a279d427fd0c5ea44c1a" target="_blank"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1107077230&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li2&amp;o=1&amp;a=1107077230" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;h2&gt;10. Advanced Maths:&lt;/h2&gt;
&lt;p&gt;Couldn't write enough of the importance of Math. But here are a few awesome resources that you can go for.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/"&gt;Linear Algebra By Gilbert Strang&lt;/a&gt; - A Great Class by a great Teacher. I Would definitely recommend this class to anyone who wants to learn LA.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ocw.mit.edu/courses/mathematics/18-02sc-multivariable-calculus-fall-2010/"&gt;Multivariate Calculus - MIT OCW&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://lagunita.stanford.edu/courses/Engineering/CVX101/Winter2014/about"&gt;Convex Optimization&lt;/a&gt; - a MOOC on optimization from Stanford, by Steven Boyd, an authority on the subject.&lt;/p&gt;
&lt;p&gt;The Machine learning field is evolving and new advancements are made every day. That's why I didn't put a third tier. The maximum I can call myself is a "Hacker" and my learning continues. Hope you do the same.&lt;/p&gt;
&lt;p&gt;Hope you like this list. Please provide your inputs in comments on more learning resources as you see fit.&lt;/p&gt;
&lt;p&gt;Till then. Ciao!!!&lt;/p&gt;</summary><category term="Data Science"></category><category term="Statistics"></category><category term="Resources"></category><category term="Learning"></category><category term="Books"></category><category term="Python"></category><category term="Distributions"></category><category term="Statistical Inference"></category><category term="hadoop"></category><category term="spark"></category><category term="deep learning"></category></entry><entry><title>Top advice for a Data Scientist</title><link href="http://mlwhiz.github.io/blog/2017/03/05/think_like_a_data_scientist/" rel="alternate"></link><updated>2017-03-05T04:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2017-03-05:blog/2017/03/05/think_like_a_data_scientist/</id><summary type="html">&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/thinklikeds.png"  height="400" width="700" &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;A data scientist needs to be Critical and always on a lookout of something that misses others. So here are some advices that one can include in day to day data science work to be better at their work:&lt;/p&gt;
&lt;h2&gt;1. Beware of the Clean Data Syndrome&lt;/h2&gt;
&lt;p&gt;You need to ask yourself questions even before you start working on the data. &lt;strong&gt;Does this data make sense?&lt;/strong&gt; Falsely assuming that the data is clean could lead you towards wrong Hypotheses. Apart from that, you can discern a lot of important patterns by looking at discrepancies in the data. For example, if you notice that a particular column has more than 50% values missing, you might think about not using the column. Or you may think that some of the data collection instrument has some error.&lt;/p&gt;
&lt;p&gt;Or let's say you have a distribution of Male vs Female as 90:10 in a Female Cosmetic business. You may assume clean data and show the results as it is or you can use common sense and ask if the labels are switched.&lt;/p&gt;
&lt;h2&gt;2. Manage Outliers wisely&lt;/h2&gt;
&lt;p&gt;Outliers can help you understand more about the people who are using your website/product 24 hours a day. But including them while building models will skew the models a lot.&lt;/p&gt;
&lt;h2&gt;3. Keep an eye out for the Abnormal&lt;/h2&gt;
&lt;p&gt;Be on the &lt;strong&gt;lookout for something out of the obvious&lt;/strong&gt;. If you find something you may have hit gold.&lt;/p&gt;
&lt;p&gt;For example, &lt;a href="https://www.fastcompany.com/1783127/flickr-founders-glitch-can-game-wants-you-play-nice-be-blockbuster"&gt;Flickr started up as a Multiplayer game&lt;/a&gt;. Only when the founders noticed that people were using it as a photo upload service, did they pivot.&lt;/p&gt;
&lt;p&gt;Another example: fab.com started up as fabulis.com, a site to help gay men meet people. One of the site's popular features was the "Gay deal of the Day". One day the deal was for Hamburgers - and half of the buyers were women. This caused the team to realize that there was a market for selling goods to women. So Fabulis pivoted to fab as a flash sale site for designer products.&lt;/p&gt;
&lt;h2&gt;4. Start Focussing on the right metrics&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Beware of Vanity metrics&lt;/strong&gt; For example, # of active users by itself doesn't divulge a lot of information. I would rather say "5% MoM increase in active users" rather than saying " 10000 active users". Even that is a vanity metric as active users would always increase. I would rather keep a track of percentage of users that are active to know how my product is performing.&lt;/li&gt;
&lt;li&gt;Try to find out a &lt;strong&gt;metric that ties with the business goal&lt;/strong&gt;. For example, Average Sales/User for a particular month.&lt;/li&gt;
&lt;/ul&gt;
&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;

&lt;h2&gt;5. Statistics may lie too&lt;/h2&gt;
&lt;p&gt;Be critical of everything that gets quoted to you. Statistics has been used to lie in advertisements, in workplaces and a lot of other marketing venues in the past. People will do anything to get sales or promotions.&lt;/p&gt;
&lt;p&gt;For example: &lt;a href="http://marketinglaw.osborneclarke.com/retailing/colgates-80-of-dentists-recommend-claim-under-fire/"&gt;Do you remember Colgate’s claim that 80% of dentists recommended their brand?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This statistic seems pretty good at first. It turns out that at the time of surveying the dentists, they could choose several brands — not just one. So other brands could be just as popular as Colgate.&lt;/p&gt;
&lt;p&gt;Another Example: &lt;strong&gt;"99 percent Accurate" doesn't mean shit&lt;/strong&gt;. Ask me to create a cancer prediction model and I could give you a 99 percent accurate model in a single line of code. How? Just predict "No Cancer" for each one. I will be accurate may be more than 99% of the time as Cancer is a pretty rare disease. Yet I have achieved nothing.&lt;/p&gt;
&lt;h2&gt;6. Understand how probability works&lt;/h2&gt;
&lt;p&gt;It happened during the summer of 1913 in a Casino in Monaco. Gamblers watched in amazement as a casino's roulette wheel landed on black 26 times in a row. And since the probability of a Red vs Black is exactly half, they were certain that red was "due". It was a field day for the Casino. A perfect example of &lt;a href="https://en.wikipedia.org/wiki/Gambler's_fallacy"&gt;Gambler's fallacy&lt;/a&gt;, aka the Monte Carlo fallacy.&lt;/p&gt;
&lt;p&gt;And This happens in real life. &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2538147"&gt;People tend to avoid long strings of the same answer&lt;/a&gt;. Sometimes sacrificing accuracy of judgment for the sake of getting a pattern of decisions that looks fairer or probable.&lt;/p&gt;
&lt;p&gt;For example, An admissions officer may reject the next application if he has approved three applications in a row, even if the application should have been accepted on merit.&lt;/p&gt;
&lt;h2&gt;7. Correlation Does Not Equal Causation&lt;/h2&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/corr_caus.png"  height="400" width="500" &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;The Holy Grail of a Data scientist toolbox. To see something for what it is. Just because two variables move together in tandem doesn't necessarily mean that one causes the another. There have been hilarious examples for this in the past. Some of my favorites are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Looking at the firehouse department data you infer that the more firemen are sent to a fire, the more damage is done.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When investigating the cause of crime in New York City in the 80s, an academic found a strong correlation between the amount of serious crime committed and the amount of ice cream sold by street vendors! Obviously, there was an unobserved variable causing both. Summers are when the crime is the greatest and when the most ice cream is sold. So Ice cream sales don't cause crime. Neither crime increases ice cream sales.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;8. More data may help&lt;/h2&gt;
&lt;p&gt;Sometimes getting extra data may work wonders. You might be able to model the real world more closely by looking at the problem from all angles. Look for extra data sources.&lt;/p&gt;
&lt;p&gt;For example, Crime data in a city might help banks provide a better credit line to a person living in a troubled neighborhood and in turn increase the bottom line.&lt;/p&gt;</summary><category term="Data Science"></category><category term="Statistics"></category><category term="Resources"></category><category term="Learning"></category><category term="Books"></category><category term="Python"></category><category term="Distributions"></category><category term="Statistical Inference"></category><category term="hadoop"></category><category term="spark"></category><category term="deep learning"></category></entry></feed>