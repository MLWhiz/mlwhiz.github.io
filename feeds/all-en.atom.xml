<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>mlwhiz</title><link href="http://mlwhiz.github.io/" rel="alternate"></link><link href="http://mlwhiz.github.io/feeds/all-en.atom.xml" rel="self"></link><id>http://mlwhiz.github.io/</id><updated>2017-03-26T13:43:00-03:00</updated><entry><title>Top Data Science Resources on the internet right now</title><link href="http://mlwhiz.github.io/blog/2017/03/26/top_data_science_resources_on_the_internet_right_now/" rel="alternate"></link><updated>2017-03-26T13:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2017-03-26:blog/2017/03/26/top_data_science_resources_on_the_internet_right_now/</id><summary type="html">&lt;p&gt;I have been looking to create this list for a while now. There are many people on quora who ask me how I started in the data science field. And so I wanted to create this reference. To be frank when I first started learning it all looked very eutopian and out of the world. The Andrew Ng course felt like black magic. And it still doesn't cease to amaze me. After all we are predicting the future. Take the case of Nate Silver - What else can you call his success if not Black Magic?&lt;/p&gt;
&lt;p&gt;But it is not magic. And this is a way an aspiring guy could take to become a self-trained data scientist. Follow in order. So here goes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://projects.iq.harvard.edu/stat110/youtube"&gt;Stat 110: Introduction to Probability: Joe Blitzstein - Harvard University&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The one stat course you gotta take. If not for the content then for Prof. Blitzstein sense of humor. I took this course to enhance my understanding of probability distributions and statistics, but this course taught me a lot more than that. Apart from Learning to think conditionally, this also taught me how to explain difficult concepts with a story.&lt;/p&gt;
&lt;p&gt;This was a Hard Class but most definitely fun. The focus was not only on getting Mathematical proofs but also on understanding the intuition behind them and how intuition can help in deriving them more easily.Sometimes the same proof was done in different ways to facilitate learning of a concept.&lt;/p&gt;
&lt;p&gt;One of the things I liked most about this course is the focus on concrete examples while explaining abstract concepts. The inclusion of &lt;strong&gt; Gambler’s Ruin Problem, Matching Problem, Birthday Problem, Monty Hall, Simpsons Paradox, St. Petersberg Paradox &lt;/strong&gt; etc. made this course much much more exciting than a normal Statistics Course.&lt;/p&gt;
&lt;p&gt;It will help you understand Discrete (Bernoulli, Binomial, Hypergeometric, Geometric, Negative Binomial, FS, Poisson) and Continuous (Uniform, Normal, expo, Beta, Gamma) Distributions and the stories behind them. Something that I was always afraid of.&lt;/p&gt;
&lt;p&gt;He got a textbook out based on this course which is clearly a great text:&lt;/p&gt;
&lt;div style="margin-left:1em ; text-align: center;"&gt;
&lt;a href="https://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science-ebook/dp/B00MMOJ19I/ref=as_li_ss_il?ie=UTF8&amp;linkCode=li3&amp;tag=mlwhizcon-20&amp;linkId=7254baef925507e0d8dfd07cca2f519d" target="_blank"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=B00MMOJ19I&amp;Format=_SL250_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li3&amp;o=1&amp;a=B00MMOJ19I" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href="http://cs109.github.io/2015/"&gt;Data Science CS109&lt;/a&gt;: -&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Again by Professor Blitzstein. Again an awesome course. Watch it after Stat110 as you will be able to understand everything much better with a thorough grinding in Stat110 concepts. You will learn about Python Libraries for data science, along with a thorough intuitive grinding for various Machine learning Algorithms. Course description from Website:&lt;/p&gt;
&lt;p&gt;Learning from data in order to gain useful predictions and insights. This course introduces methods for five key facets of an investigation: data wrangling, cleaning, and sampling to get a suitable data set; data management to be able to access big data quickly and reliably; exploratory data analysis to generate hypotheses and intuition; prediction based on statistical methods such as regression and classification; and communication of results through visualization, stories, and interpretable summaries.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.coursera.org/learn/machine-learning"&gt;CS229: Andrew Ng&lt;/a&gt;
After doing these two above courses you will gain the status of what I would like to call a "Beginner". Congrats. You know stuff, you know how to implement stuff. Yet you do not fully understand all the math and grind that goes behind all this.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here comes the Game Changer machine learning course. Contains the maths behind many of the Machine Learning algorithms.  I will put this course as the one course you gotta take as this course motivated me into getting in this field and Andrew Ng is a great instructor. Also this was the first course that I took.&lt;/p&gt;
&lt;p&gt;Also recently Andrew Ng Released a new Book. You can get the Draft chapters by subcribing on his website &lt;a href="http://www.mlyearning.org/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You are done with the three musketeers of the trade. You know Python, you understand Statistics and you have gotten the taste of the math behind ML approaches. Now it is time for the new kid on the block. D'artagnan. This kid has skills. While the three musketeers are masters in their trade, this guy brings qualities that adds a new freshness to our data science journey. Here comes Big Data for you.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.udacity.com/course/intro-to-hadoop-and-mapreduce--ud617"&gt;Intro to Hadoop &amp;amp; Mapreduce - Udacity&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let us first focus on the literal elephant in the room - Hadoop. Short and Easy Course. Taught the Fundamentals of Hadoop streaming with Python. Taken by Cloudera on Udacity. I am doing much more advanced stuff with python and Mapreduce now but this is one of the courses that laid the foundation there.&lt;/p&gt;
&lt;p&gt;Once  you are done through this course you would have gained quite a basic understanding of concepts and you would have installed a Hadoop VM in your own machine. You would also have solved the Basic Wordcount Problem.
Read this amazing Blog Post from Michael Noll: &lt;a href="http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/"&gt;Writing An Hadoop MapReduce Program In Python - Michael G. Noll&lt;/a&gt;.  Just read the basic mapreduce codes. Don't use Iterators and Generators yet. This has been a starting point for many of us Hadoop developers.&lt;/p&gt;
&lt;p&gt;Now try to solve these two problems from the CS109 Harvard course from 2013:&lt;/p&gt;
&lt;p&gt;A. First, grab the file word_list.txt from &lt;a href="https://raw.github.com/cs109/content/master/labs/lab8/word_list.txt"&gt;here&lt;/a&gt;.  This contains a list of six-letter words. To keep things simple, all of  the words consist of lower-case letters only.Write a mapreduce job that  finds all anagrams in word_list.txt.&lt;/p&gt;
&lt;p&gt;B. For the next problem, download the file &lt;a href="https://raw.github.com/cs109/content/master/labs/lab8/baseball_friends.csv"&gt;baseball_friends.csv&lt;/a&gt;. Each row of this csv file contains the following:
A person's name
The team that person is rooting for -- either "Cardinals" or "Red Sox"
A list of that person's friends, which could have arbitrary length&lt;/p&gt;
&lt;p&gt;For  example: The first line tells us that Aaden is a Red Sox friend and he  has 65  friends, who are all listed here. For this problem, it's safe to  assume  that all of the names are unique and that the friendship  structure is  symmetric (i.e. if Alannah shows up in Aaden's friends list, then Aaden will show up in Alannah's friends list).
Write  an mr job that lists each person's name, their favorite  team, the  number of Red Sox fans they are friends with, and the number  of  Cardinals fans they are friends with.&lt;/p&gt;
&lt;p&gt;Try to do this yourself. Don't use the mrjob (pronounced Mr. Job) way that  they use in the CS109 2013 class. Use the proper Hadoop Streaming way as taught in the Udacity class as it is much more customizable in the long run.&lt;/p&gt;
&lt;p&gt;If you are done with these, you can safely call yourself as someone who could "think in Mapreduce" as how people like to call it.Try to do groupby, filter and joins using Hadoop. You can read up some good tricks from my blog:
&lt;a href="http://mlwhiz.com/blog/2015/05/09/Hadoop_Mapreduce_Streaming_Tricks_and_Techniques/"&gt;Hadoop Mapreduce Streaming Tricks and Techniques&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you are someone who likes learning from a book you can get:
&lt;div style="margin-left:1em ; text-align: center;"&gt;
&lt;a href="https://www.amazon.com/Hadoop-Definitive-Storage-Analysis-Internet/dp/1491901632/ref=as_li_ss_il?s=books&amp;ie=UTF8&amp;qid=1490543345&amp;sr=1-1&amp;keywords=hadoop+python&amp;linkCode=li2&amp;tag=mlwhizcon-20&amp;linkId=e0a6c64497866b874326afa08a069654" target="_blank"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1491901632&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li2&amp;o=1&amp;a=1491901632" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Spark - In memory Big Data tool.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now  comes the next part of your learning process. This should be undertaken  after a little bit of experience with Hadoop. Spark Will provide you with the speed and tools that Hadoop couldn't.&lt;/p&gt;
&lt;p&gt;Now Spark is used for data preparation as well as Machine learning purposes. I would encourage you to take a look at the series of courses on edX provided by Berkeley instructors. This course delivers on what it says. It teaches Spark. Total beginners will have difficulty following the course as the course progresses very fast. That said anyone with a decent understanding of how big data works will be OK.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.edx.org/xseries/data-science-engineering-apacher-sparktm"&gt;Data Science and Engineering with Apache® Spark™&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I have written a little bit about Basic data processing with Spark here. Take a look:
&lt;a href="http://mlwhiz.com/blog/2015/09/07/Spark_Basics_Explained/"&gt;Learning Spark using Python: Basics and Applications&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Also take a look at some of the projects I did as part of course at &lt;a href="http://www.github.com/MLWhiz/Spark_Projects/"&gt;github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you would like a book to read:
&lt;div style="margin-left:1em ; text-align: center;"&gt;
&lt;a href="https://www.amazon.com/Advanced-Analytics-Spark-Patterns-Learning/dp/1491912766/ref=as_li_ss_il?s=books&amp;ie=UTF8&amp;qid=1490543902&amp;sr=1-1&amp;keywords=spark+python&amp;linkCode=li2&amp;tag=mlwhizcon-20&amp;linkId=85591cf408de278e23e8570b7e9c284b" target="_blank"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1491912766&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li2&amp;o=1&amp;a=1491912766" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;If you don't go through the courses, try solving the same two problems above that you solved by Hadoop using Spark too. Otherwise the problem sets in the courses are more than enough.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Understand Linux Shell:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Shell is a big friend for data scientists. It allows you to do simple data related tasks in the terminal itself. I couldn't emphasize how much time shell saves for me everyday.&lt;/p&gt;
&lt;p&gt;Read these tutorials by me for doing that:
&lt;a href="http://mlwhiz.com/blog/2015/10/09/shell_basics_for_data_science/"&gt;Shell Basics every Data Scientist Should know -Part I&lt;/a&gt;
&lt;a href="http://mlwhiz.com/blog/2015/10/11/shell_basics_for_data_science_2/"&gt;Shell Basics every Data Scientist Should know - Part II(AWK)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you would like a course you can go for &lt;a href="https://www.edx.org/course/introduction-linux-linuxfoundationx-lfs101x-1#!"&gt;this course on edX&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you want a book, go for:&lt;/p&gt;
&lt;div style="margin-left:1em ; text-align: center;"&gt;
&lt;a href="https://www.amazon.com/Linux-Command-Line-Complete-Introduction/dp/1593273894/ref=as_li_ss_il?s=books&amp;ie=UTF8&amp;qid=1490544715&amp;sr=1-1&amp;keywords=the+linux+command+line&amp;linkCode=li2&amp;tag=mlwhizcon-20&amp;linkId=9f155a16f16c7ae34e682e0e0312ee8f" target="_blank"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1593273894&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li2&amp;o=1&amp;a=1593273894" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;

&lt;p&gt;Congrats you are an "Hacker" now. You have got all the main tools in your belt to be a data scientist. On to more advanced topics. From here it depends on you what you want to learn. You may want to take a totally different approach than what I took going from here. There is no particular order. "All Roads lead to Rome" as long as you are running.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.coursera.org/specializations/statistics"&gt;Learn Statistical Inference and Bayesian Statistics&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I took the previous version of the specialization which was a single course taught by Mine Çetinkaya-Rundel. She is a great instrucor and explains the fundamentals of Statistical inference nicely. A must take course. You will learn about hypothesis testing, confidence intervals, and statistical inference methods for numerical nad categorical data.
You can also use these book:&lt;/p&gt;
&lt;div style="margin-left:1em ; text-align: center;"&gt;
&lt;a href="https://www.amazon.com/dp/1943450056/ref=as_li_ss_il?m=A3EEBE82C3HYRD&amp;linkCode=li2&amp;tag=mlwhizcon-20&amp;linkId=cfd246ebddfde379bc01dcb2c467c199" target="_blank"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1943450056&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li2&amp;o=1&amp;a=1943450056" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/t&gt;&lt;/t&gt;
&lt;a href="https://www.amazon.com/Probability-Statistics-4th-Morris-DeGroot/dp/0321500466/ref=as_li_ss_il?ie=UTF8&amp;qid=1490547535&amp;sr=8-1&amp;keywords=degroot+statistics&amp;linkCode=li2&amp;tag=mlwhizcon-20&amp;linkId=fc106a3b8c56be8baf34793816762ec8" target="_blank"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=0321500466&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li2&amp;o=1&amp;a=0321500466" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;Deep Learning&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="http://www.fast.ai/"&gt;Intro&lt;/a&gt; - Making neural nets uncool again. An awesome Deep learning class from Kaggle Master Jeremy Howard. Entertaining and enlightening at the same time.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://cs231n.github.io/"&gt;Advanced&lt;/a&gt; - A series of notes from the Stanford CS class CS231n: Convolutional Neural Networks for Visual Recognition.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://neuralnetworksanddeeplearning.com/"&gt;Bonus&lt;/a&gt; - A free online book by Michael Nielsen.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://amzn.to/2npItnM"&gt;Advanced Math Book&lt;/a&gt; - A math intensive book by Yoshua Bengio &amp;amp; Ian Goodfellow&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=xoA5v9AO7S0&amp;amp;list=PLLssT5z_DsK9JDLcT8T62VtzwyW9LNepV"&gt;Algorithms, Graph Algorithms, Recommendation Systems, Pagerank and More&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This course used to be there on Coursera but now only video links on youtube available.
You can learn from this book too:
&lt;div style="margin-left:1em ; text-align: center;"&gt;
&lt;a href="https://www.amazon.com/Mining-Massive-Datasets-Jure-Leskovec/dp/1107077230/ref=as_li_ss_il?ie=UTF8&amp;linkCode=li2&amp;tag=mlwhizcon-20&amp;linkId=ba893a022640a279d427fd0c5ea44c1a" target="_blank"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1107077230&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="https://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=li2&amp;o=1&amp;a=1107077230" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Advanced Maths:
Couldn't write enough of the iprtance of Math. But here are a few awesome resources that you can go for.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href="http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/"&gt;Linear Algebra By Gilbert Strang&lt;/a&gt; - A Great Class by a great Teacher. I Would definitely recommend this class to anyone who wants to learn LA.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ocw.mit.edu/courses/mathematics/18-02sc-multivariable-calculus-fall-2010/"&gt;Multivariate Calculus - MIT OCW&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://lagunita.stanford.edu/courses/Engineering/CVX101/Winter2014/about"&gt;Convex Optimization&lt;/a&gt; - a MOOC on optimization from Stanford, by Steven Boyd, an authority on the subject.&lt;/p&gt;
&lt;p&gt;The Machine learning field is evolving and new advancements are made every day. That's why I didn't put a third tier. The maximum I can call myself is a "Hacker" and my learning continues. Hope you do the same.&lt;/p&gt;
&lt;p&gt;Please provide your inputs in comments on more learning resources as you see fit.&lt;/p&gt;
&lt;p&gt;Till then. Ciao!!!&lt;/p&gt;</summary><category term="Data Science"></category><category term="Statistics"></category><category term="Resources"></category><category term="Learning"></category><category term="Books"></category><category term="Python"></category><category term="Distributions"></category><category term="Statistical Inference"></category><category term="hadoop"></category><category term="spark"></category><category term="deep learning"></category></entry><entry><title>Basics Of Linear Regression</title><link href="http://mlwhiz.github.io/blog/2017/03/23/basics_of_linear_regression/" rel="alternate"></link><updated>2017-03-23T04:43:00-03:00</updated><author><name>Naveen Kumar Kaveti</name></author><id>tag:mlwhiz.github.io,2017-03-23:blog/2017/03/23/basics_of_linear_regression/</id><summary type="html">&lt;p&gt;Today we will look into the basics of linear regression. Here we go :&lt;/p&gt;
&lt;h2&gt;Contents&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Simple Linear Regression (SLR)&lt;/li&gt;
&lt;li&gt;Multiple Linear Regression (MLR)&lt;/li&gt;
&lt;li&gt;Assumptions&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;1. Simple Linear Regression&lt;/h2&gt;
&lt;p&gt;Regression is the process of building a relationship between a dependent variable and set of independent variables. Linear Regression restricts this relationship to be linear in terms of coefficients. In SLR, we consider only one independent variable.&lt;/p&gt;
&lt;h3&gt;Example: The Waist Circumference – Adipose Tissue data&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Studies have shown that individuals with excess Adipose tissue (AT) in the abdominal region have a higher risk of cardio-vascular diseases&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Computed Tomography, commonly called the CT Scan is the only technique that allows for the precise and reliable measurement of the AT (at any site in the body)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The problems with using the CT scan are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Many physicians do not have access to this technology&lt;/li&gt;
&lt;li&gt;Irradiation of the patient (suppresses the immune system)&lt;/li&gt;
&lt;li&gt;Expensive&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Is there a simpler yet reasonably accurate way to predict the AT area? i.e.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Easily available&lt;/li&gt;
&lt;li&gt;Risk free&lt;/li&gt;
&lt;li&gt;Inexpensive&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A group of researchers  conducted a study with the aim of predicting abdominal AT area using simple anthropometric measurements i.e. measurements on the human body&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Waist Circumference – Adipose Tissue data is a part of this study wherein the aim is to study how well waist circumference(WC) predicts the AT area&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c1"&gt;# Setting working directory&lt;/span&gt;
filepath &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/Users/nkaveti/Documents/Work_Material/Statistics Learning/&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
setwd&lt;span class="p"&gt;(&lt;/span&gt;filepath&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Reading data&lt;/span&gt;
Waist_AT &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; read.csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;adipose_tissue.csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
cat&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Number of rows: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; nrow&lt;span class="p"&gt;(&lt;/span&gt;Waist_AT&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
head&lt;span class="p"&gt;(&lt;/span&gt;Waist_AT&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Number&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mi"&gt;109&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;&lt;th scope=col&gt;Waist&lt;/th&gt;&lt;th scope=col&gt;AT&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;&lt;td&gt;74.75&lt;/td&gt;&lt;td&gt;25.72&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;72.60&lt;/td&gt;&lt;td&gt;25.89&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;81.80&lt;/td&gt;&lt;td&gt;42.60&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;83.95&lt;/td&gt;&lt;td&gt;42.80&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;74.65&lt;/td&gt;&lt;td&gt;29.84&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;71.85&lt;/td&gt;&lt;td&gt;21.68&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Let's start with a scatter plot of &lt;strong&gt;Waist&lt;/strong&gt; Vs &lt;strong&gt;AT&lt;/strong&gt;, to understand the relationship between these two variables.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;AT&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="n"&gt;Waist&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="png" src="output_6_0.png" /&gt;&lt;/p&gt;
&lt;p&gt;Any observations from above plot?&lt;/p&gt;
&lt;p&gt;Now the objective is to find a linear relation between &lt;code&gt;Waist&lt;/code&gt; and &lt;code&gt;AT&lt;/code&gt;. In otherwords, finding the amount of change in &lt;code&gt;AT&lt;/code&gt; per one unit change (increment/decrement) in &lt;code&gt;Waist&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In SLR, it is equivalent to finding an optimal straight line equation such that the sum of squares of differences between straight line and the points will be minimum. This method of estimation is called as &lt;a href="https://en.wikipedia.org/wiki/Ordinary_least_squares"&gt;Ordiany Least Squares (OLS)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$AT  = \beta_0 + \beta_1 \ Waist + \epsilon$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$Min_{\beta_0 , \beta_1} \ \ \epsilon^\intercal \epsilon \implies Min_{\beta_0 , \beta_1} \ \ (AT  - \beta_0 - \beta_1 \ Waist)^\intercal (AT  - \beta_0 - \beta_1 \ Waist)$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Where, &lt;span class="math"&gt;\(\beta_1\)&lt;/span&gt; represents the amount of change in &lt;code&gt;AT&lt;/code&gt; per one unit change in &lt;code&gt;Waist&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now our problem becomes an unconstrained optimization problem. We can find optimal values for &lt;span class="math"&gt;\(\beta_0\)&lt;/span&gt; and &lt;span class="math"&gt;\(\beta_1\)&lt;/span&gt; using basic calculus.&lt;/p&gt;
&lt;p&gt;Lets re-write above regression equation in matrix form&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$ AT = X \beta + \epsilon$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Where, &lt;span class="math"&gt;\( X = [1 \ \ Waist]\)&lt;/span&gt; 1 is a vector of ones and &lt;span class="math"&gt;\(\beta = (\beta_0, \ \beta_1)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$
\begin{equation}
\begin{split}
\epsilon^\intercal \epsilon &amp;amp; = {(AT - X \beta)}^\intercal {(AT - X \beta)} \\
&amp;amp; = AT^\intercal AT - AT^\intercal X \beta - {(X \beta)}^\intercal AT + {(X \beta)}^\intercal (X \beta)
\end{split}
\end{equation}
$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Now differentiate this w.r.t to &lt;span class="math"&gt;\(\beta\)&lt;/span&gt; and equate it to zero. Then we have,
&lt;div class="math"&gt;$$\hat{\beta} = (X^\intercal X)^{-1} X^\intercal AT $$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Now we can find the fitted values of model by substituting &lt;span class="math"&gt;\(\hat{\beta}\)&lt;/span&gt; in above regression equation
&lt;div class="math"&gt;$$\hat{AT} = X \hat{\beta}=X(X^\intercal X)^{-1} X^\intercal AT$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; We are arriving to above equation through an assumption&lt;a href="#Assumptions"&gt;&lt;span class="math"&gt;\(^1\)&lt;/span&gt;&lt;/a&gt; of &lt;span class="math"&gt;\(E(\epsilon)=0\)&lt;/span&gt;. What happens if this assumption violates?&lt;/p&gt;
&lt;p&gt;Let, &lt;span class="math"&gt;\(X(X^\intercal X)^{-1} X^\intercal = H\)&lt;/span&gt;
&lt;div class="math"&gt;$$\hat{AT} = H \ AT$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;We call H as an hat matrix, because it transforms &lt;span class="math"&gt;\(AT\)&lt;/span&gt; into &lt;span class="math"&gt;\(\hat{AT}\)&lt;/span&gt; :D&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="cp"&gt;# Lets compute the hat matrix&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cbind&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Waist&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;temp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;solve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%*%&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%*%&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;betahat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;temp&lt;/span&gt; &lt;span class="o"&gt;%*%&lt;/span&gt; &lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;AT&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Estimated&lt;/span&gt; &lt;span class="n"&gt;coefficients&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Let&amp;#39;s compare the computed values with lm() output: &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Computed Coefficients: &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;frame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Intercept&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;betahat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;Waist&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;betahat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;======================================================================= &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="cp"&gt;#cat(&amp;quot;Optimal value for beta_0 is: &amp;quot;, betahat[1], &amp;quot;and for beta_1 is: &amp;quot;, betahat[2], &amp;quot;\n \n&amp;quot;)&lt;/span&gt;
&lt;span class="n"&gt;fit_lm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;AT&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="n"&gt;Waist&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="cp"&gt;#cat(&amp;quot;Compare our computed estimates with lm() estimates&amp;quot;, &amp;quot;\n&amp;quot;)&lt;/span&gt;
&lt;span class="n"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fit_lm&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;======================================================================= &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;H&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;%*%&lt;/span&gt; &lt;span class="n"&gt;temp&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Computing&lt;/span&gt; &lt;span class="n"&gt;hat&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;
&lt;span class="n"&gt;AThat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;H&lt;/span&gt; &lt;span class="o"&gt;%*%&lt;/span&gt; &lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;AT&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Computing&lt;/span&gt; &lt;span class="n"&gt;predicted&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Therefore, there is a&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;betahat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;increment in AT per one unit change in Waist &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Let&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;compare&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;computed&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt; &lt;span class="n"&gt;with&lt;/span&gt; &lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;

&lt;span class="n"&gt;Computed&lt;/span&gt; &lt;span class="n"&gt;Coefficients&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;

  &lt;span class="n"&gt;Intercept&lt;/span&gt;    &lt;span class="n"&gt;Waist&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;215.9815&lt;/span&gt; &lt;span class="mf"&gt;3.458859&lt;/span&gt;
&lt;span class="o"&gt;=======================================================================&lt;/span&gt;

&lt;span class="nl"&gt;Call:&lt;/span&gt;
&lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;formula&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AT&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="n"&gt;Waist&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nl"&gt;Coefficients:&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Intercept&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;        &lt;span class="n"&gt;Waist&lt;/span&gt;
   &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;215.981&lt;/span&gt;        &lt;span class="mf"&gt;3.459&lt;/span&gt;

&lt;span class="o"&gt;=======================================================================&lt;/span&gt;

&lt;span class="n"&gt;Therefore&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;there&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="mf"&gt;3.458859&lt;/span&gt; &lt;span class="n"&gt;increment&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;AT&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;one&lt;/span&gt; &lt;span class="n"&gt;unit&lt;/span&gt; &lt;span class="n"&gt;change&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;Waist&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;What's next?&lt;/h2&gt;
&lt;p&gt;We succesfully computed estimates for regression coefficients and fitted values.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;We are working on only one sample, how can we generalise these results to population?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How to measure model's performance quantitatively?&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;  We are working on only one sample, how can we generalise these results to population? &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let's focus on question 1. Our regression coefficients are computed using only one sample and these values will change, if we change the sample. But how much they vary? We need to estimate the variation for each beta coefficient to check whether the corresponding regressor is consistently explaining the same behaviour even if we change the sample.&lt;/p&gt;
&lt;p&gt;Now the big problem is collecting multiple samples to check the above hypothesis. Hence, we use distributions to check statistical significance of regressors.&lt;/p&gt;
&lt;p&gt;For our example, we need to test below two hypotheses.&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$ Null \ Hypothesis: \beta_{0} = 0 $$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$ Alternative \ Hypothesis: \beta_{0} \neq 0$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$ Null \ Hypothesis: \beta_{1} = 0 $$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$ Alternative \ Hypothesis: \beta_{1} \neq 0$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Test Statistic for these hypotheses is,&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$t = \frac{\hat{\beta_{i}}}{\sqrt{Var(\hat{\beta_{i}})}}$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Test statistic &lt;code&gt;t&lt;/code&gt; follows &lt;code&gt;t-distribution&lt;/code&gt;, assuming&lt;a href="#Assumptions"&gt;&lt;span class="math"&gt;\(^2\)&lt;/span&gt;&lt;/a&gt; dependent variable follows &lt;code&gt;normal distribution&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Suggestion:&lt;/strong&gt; If your not aware of &lt;a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing"&gt;testing of hypothesis&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Probability_distribution"&gt;probability distributions&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/P-value"&gt;p-values&lt;/a&gt; please browse through the Google.&lt;/p&gt;
&lt;p&gt;Let's recall that,  &lt;span class="math"&gt;\(\hat{\beta} = (X^\intercal X)^{-1} X^\intercal AT\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$\begin{equation}
\begin{split}
Var(\hat{\beta}) &amp;amp; = Var((X^\intercal X)^{-1} X^\intercal AT) \\
 &amp;amp; = (X^\intercal X)^{-1} X^\intercal \ Var(AT) \ X(X^\intercal X)^{-1} \\
 &amp;amp; = (X^\intercal X)^{-1} X^\intercal \ X(X^\intercal X)^{-1} \ \sigma^2 \\
 &amp;amp; = (X^\intercal X)^{-1} \sigma^2
\end{split}
\end{equation}
$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; In the above calculations we assumed&lt;a href="#Assumptions"&gt;&lt;span class="math"&gt;\(^3\)&lt;/span&gt;&lt;/a&gt; &lt;span class="math"&gt;\(Var(AT) = \sigma^2\)&lt;/span&gt; (Constant). Where, &lt;span class="math"&gt;\(\sigma^2\)&lt;/span&gt; is variation in population AT.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Suggestion:&lt;/strong&gt; Try solving &lt;span class="math"&gt;\((X^\intercal X)^{-1}\)&lt;/span&gt; with &lt;span class="math"&gt;\(X = [1, \  x]\)&lt;/span&gt; where &lt;span class="math"&gt;\(x = (x_1, x_2, x_3 ... x_n)\)&lt;/span&gt;. You will get the following expression.&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$
\
Var(\hat{\beta}) =
\frac{1}{n \sum x_i^2 - (\sum x_i)^2}
\begin{bmatrix}
    \sum_{i=1}^n x_i^2 &amp;amp; -\sum x_i \\
    -\sum x_i &amp;amp; n
\end{bmatrix}
\sigma^2
\
$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Diagonal elements of above matrix are varinaces of &lt;span class="math"&gt;\(\beta_0\)&lt;/span&gt; and &lt;span class="math"&gt;\(\beta_1\)&lt;/span&gt; respectively. Off-diagonal element is covariance between &lt;span class="math"&gt;\(\beta_0\)&lt;/span&gt; and &lt;span class="math"&gt;\(\beta_1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Hence,&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$Var(\hat{\beta_0}) = \frac{\sigma^2 \sum_{i = 1}^n x_i^2}{n \sum_{i = 1}^n (x_i - \bar{x})^2}$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$Var(\hat{\beta_1}) = \frac{\sigma^2}{\sum_{i = 1}^n (x_i - \bar{x})^2}$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;One important observation from &lt;span class="math"&gt;\(Var(\hat{\beta})\)&lt;/span&gt; expressions is, &lt;span class="math"&gt;\(Var(x)\)&lt;/span&gt; is inversely proportional to &lt;span class="math"&gt;\(Var(\hat{\beta})\)&lt;/span&gt;. That is, we will get more consistent estimators if there is high variation in corresponding predictors.&lt;/p&gt;
&lt;p&gt;Recall that, &lt;span class="math"&gt;\(\sigma^2\)&lt;/span&gt; in above expression is the population variance, not the sample. Hence, we need to estimate this using the sample that we have.&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$\hat{\sigma^2} = \frac{1}{n-2} \sum_{i = 1}^n e_i^2$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Where, &lt;span class="math"&gt;\(e_i = AT_i - \hat{AT}_i\)&lt;/span&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="cp"&gt;# Let&amp;#39;s compute variances of beta hat and test statistic &amp;#39;t&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;sigmasq&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;AThat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)]))&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;AThat&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;AT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;VarBeta0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sigmasq&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Waist&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;AThat&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Waist&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Waist&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;VarBeta1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sigmasq&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Waist&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Waist&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Let&amp;#39;s compare the computed values with lm() output: &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;======================================================================= &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Computed Coefficients: &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;frame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Estimate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;betahat&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Std&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Error&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;VarBeta0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;VarBeta1&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;t_value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;betahat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;VarBeta0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;betahat&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;VarBeta1&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;names&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;(Intercept)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Waist&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;p_value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;pt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;t_value&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;nrow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tail&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;=======================================================================&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fit_lm&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;=======================================================================&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Let&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;compare&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;computed&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt; &lt;span class="n"&gt;with&lt;/span&gt; &lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;

&lt;span class="o"&gt;=======================================================================&lt;/span&gt;
&lt;span class="n"&gt;Computed&lt;/span&gt; &lt;span class="n"&gt;Coefficients&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;

               &lt;span class="n"&gt;Estimate&lt;/span&gt;  &lt;span class="n"&gt;Std&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Error&lt;/span&gt;   &lt;span class="n"&gt;t_value&lt;/span&gt;      &lt;span class="n"&gt;p_value&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Intercept&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;215.981488&lt;/span&gt; &lt;span class="mf"&gt;21.7962708&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;9.909103&lt;/span&gt; &lt;span class="mf"&gt;7.507198e-17&lt;/span&gt;
&lt;span class="n"&gt;Waist&lt;/span&gt;          &lt;span class="mf"&gt;3.458859&lt;/span&gt;  &lt;span class="mf"&gt;0.2346521&lt;/span&gt; &lt;span class="mf"&gt;14.740376&lt;/span&gt; &lt;span class="mf"&gt;1.297124e-27&lt;/span&gt;
&lt;span class="o"&gt;=======================================================================&lt;/span&gt;



&lt;span class="nl"&gt;Call:&lt;/span&gt;
&lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;formula&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AT&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="n"&gt;Waist&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nl"&gt;Residuals:&lt;/span&gt;
     &lt;span class="n"&gt;Min&lt;/span&gt;       &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;Q&lt;/span&gt;   &lt;span class="n"&gt;Median&lt;/span&gt;       &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="n"&gt;Q&lt;/span&gt;      &lt;span class="n"&gt;Max&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;107.288&lt;/span&gt;  &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;19.143&lt;/span&gt;   &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;2.939&lt;/span&gt;   &lt;span class="mf"&gt;16.376&lt;/span&gt;   &lt;span class="mf"&gt;90.342&lt;/span&gt;

&lt;span class="nl"&gt;Coefficients:&lt;/span&gt;
             &lt;span class="n"&gt;Estimate&lt;/span&gt; &lt;span class="n"&gt;Std&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Error&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="n"&gt;Pr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;|&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Intercept&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;215.9815&lt;/span&gt;    &lt;span class="mf"&gt;21.7963&lt;/span&gt;  &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;9.909&lt;/span&gt;   &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mf"&gt;2e-16&lt;/span&gt; &lt;span class="o"&gt;***&lt;/span&gt;
&lt;span class="n"&gt;Waist&lt;/span&gt;          &lt;span class="mf"&gt;3.4589&lt;/span&gt;     &lt;span class="mf"&gt;0.2347&lt;/span&gt;  &lt;span class="mf"&gt;14.740&lt;/span&gt;   &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mf"&gt;2e-16&lt;/span&gt; &lt;span class="o"&gt;***&lt;/span&gt;
&lt;span class="o"&gt;---&lt;/span&gt;
&lt;span class="n"&gt;Signif&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;codes&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;***&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.001&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.01&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.05&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt; &lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="n"&gt;Residual&lt;/span&gt; &lt;span class="n"&gt;standard&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;33.06&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="mi"&gt;107&lt;/span&gt; &lt;span class="n"&gt;degrees&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;freedom&lt;/span&gt;
&lt;span class="n"&gt;Multiple&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;squared&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;   &lt;span class="mf"&gt;0.67&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Adjusted&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;squared&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.667&lt;/span&gt;
&lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;statistic&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;217.3&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt; &lt;span class="mi"&gt;107&lt;/span&gt; &lt;span class="n"&gt;DF&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;2.2e-16&lt;/span&gt;



&lt;span class="o"&gt;=======================================================================&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Residual standard error = &lt;span class="math"&gt;\(\sqrt{sigmasq}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How to measure model's performance quantitatively?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let's focus on question 2 (How to measure model's performance quantitatively?). Recall that, our objective of building model is to explain the variation in &lt;code&gt;AT&lt;/code&gt; using the variation in &lt;code&gt;Waist&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Total variation in AT is, &lt;span class="math"&gt;\(\sum_{i=1}^n (AT - mean(AT))^2\)&lt;/span&gt; this can be splitted into two parts as follows:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$
\begin{equation}
\begin{split}
\sum_{i=1}^n (AT_i - \bar{AT})^2 &amp;amp; = \sum_{i=1}^n (AT  - \hat{AT_i} + \hat{AT_i} - \bar{AT})^2 \\
&amp;amp; = \sum_{i = 1}^n (\hat{AT_i} - \bar{AT})^2 + \sum_{i=1}^n (AT_i - \hat{AT_i})^2
\end{split}
\end{equation}
$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Where, &lt;span class="math"&gt;\(\sum_{i=1}^n (AT_i - \bar{AT})^2\)&lt;/span&gt; is the total variation in AT, &lt;span class="math"&gt;\(\sum_{i = 1}^n (\hat{AT_i} - \bar{AT})^2\)&lt;/span&gt; is the explained variation in AT, this is also called as &lt;strong&gt;Regression Sum of Squares&lt;/strong&gt; and &lt;span class="math"&gt;\(\sum_{i=1}^n (AT_i - \hat{AT_i})^2\)&lt;/span&gt; is the unexplained variation in AT, this is also called as &lt;strong&gt;Error Sum of Squares&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We can measure our model using the proportion of total variation explained by independent variable(s). That is, &lt;span class="math"&gt;\(\frac{Regression \  Sum \ of \ Squares}{Total \ Sum \ of \ Squares}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The above measure is called as Multiple R-squared:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$Multiple \ R-squared = \frac{\sum_{i = 1}^n (\hat{AT_i} - \bar{AT})^2}{\sum_{i=1}^n (AT_i - \bar{AT})^2}$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Interesting facts:&lt;/strong&gt; Multiple R-squared value in SLR is equals to &lt;span class="math"&gt;\(r^2\)&lt;/span&gt; and (1 - Multiple R-squared) is equals to the variance in residuals.&lt;/p&gt;
&lt;p&gt;Where, r is &lt;a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient"&gt;pearson's correlation coefficient&lt;/a&gt; between dependent and independent variable.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="cp"&gt;# Let&amp;#39;s compute Multiple R-squared measure for our example&lt;/span&gt;
&lt;span class="n"&gt;SSR&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;AThat&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;AT&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;SST&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;AT&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;AT&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;MulRSq&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SSR&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;SST&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Compute Multiple R-squared: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;MulRSq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Note that computed R squared value is matching with lm() Multiple R-squared value in above output &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;======================================================================= &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Compute&lt;/span&gt; &lt;span class="n"&gt;Multiple&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;squared&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.6700369&lt;/span&gt;

&lt;span class="n"&gt;Note&lt;/span&gt; &lt;span class="n"&gt;that&lt;/span&gt; &lt;span class="n"&gt;computed&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt; &lt;span class="n"&gt;squared&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;matching&lt;/span&gt; &lt;span class="n"&gt;with&lt;/span&gt; &lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="n"&gt;Multiple&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;squared&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;above&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;

&lt;span class="o"&gt;=======================================================================&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;What happens to the Multiple R-squared value when you add an irrelevant variable to the model?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In the below model, I am generating a random sample of uniform numbers between 1 to 100 and considering this as one of indepedent variable.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;set&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1234&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;fit_lm2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;AT&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="n"&gt;Waist&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;runif&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nrow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fit_lm2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;======================================================================= &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Call&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;formula&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AT&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="n"&gt;Waist&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;runif&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nrow&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;Residuals&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;Min&lt;/span&gt;      &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;Q&lt;/span&gt;  &lt;span class="n"&gt;Median&lt;/span&gt;      &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="n"&gt;Q&lt;/span&gt;     &lt;span class="n"&gt;Max&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;106.06&lt;/span&gt;  &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;17.53&lt;/span&gt;   &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;3.63&lt;/span&gt;   &lt;span class="mf"&gt;13.70&lt;/span&gt;   &lt;span class="mf"&gt;91.36&lt;/span&gt;

&lt;span class="n"&gt;Coefficients&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
                               &lt;span class="n"&gt;Estimate&lt;/span&gt; &lt;span class="n"&gt;Std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Error&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="n"&gt;Pr&lt;/span&gt;&lt;span class="o"&gt;(&amp;gt;|&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;|)&lt;/span&gt;
&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Intercept&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;                   &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;226.2894&lt;/span&gt;    &lt;span class="mf"&gt;23.4350&lt;/span&gt;  &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;9.656&lt;/span&gt; &lt;span class="mf"&gt;3.33&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="o"&gt;***&lt;/span&gt;
&lt;span class="n"&gt;Waist&lt;/span&gt;                            &lt;span class="mf"&gt;3.5060&lt;/span&gt;     &lt;span class="mf"&gt;0.2376&lt;/span&gt;  &lt;span class="mf"&gt;14.757&lt;/span&gt;  &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="o"&gt;***&lt;/span&gt;
&lt;span class="n"&gt;runif&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nrow&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;    &lt;span class="mf"&gt;0.1397&lt;/span&gt;     &lt;span class="mf"&gt;0.1181&lt;/span&gt;   &lt;span class="mf"&gt;1.183&lt;/span&gt;    &lt;span class="mf"&gt;0.239&lt;/span&gt;
&lt;span class="o"&gt;---&lt;/span&gt;
&lt;span class="n"&gt;Signif&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;codes&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;***&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.001&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.01&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.05&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt; &lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="n"&gt;Residual&lt;/span&gt; &lt;span class="n"&gt;standard&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;33&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="mi"&gt;106&lt;/span&gt; &lt;span class="n"&gt;degrees&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;freedom&lt;/span&gt;
&lt;span class="n"&gt;Multiple&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;squared&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.6743&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;Adjusted&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;squared&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.6682&lt;/span&gt;
&lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;statistic&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;109.7&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt; &lt;span class="mi"&gt;106&lt;/span&gt; &lt;span class="n"&gt;DF&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;2.2&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;



&lt;span class="o"&gt;=======================================================================&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Multiple R-squared value increases irrespective of quality of explanation, which is incorrect. We should penalize our model performance if the quality of explanation is poor, that is why we need to adjust our R-squared value.&lt;/p&gt;
&lt;p&gt;To penalize the explained part of AT, we inflate the unexplained part of AT with &lt;span class="math"&gt;\(\frac{Total \ degrees \ of \ freedom}{Error \ degrees \ of \ freedom}\)&lt;/span&gt;. That is,&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$Adjusted \ R-squared = 1 - (1 - R^2) \frac{n-1}{n-p-1}$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Where, n = Total number of observations; p = Total number of predictors (excluding intercept)&lt;/p&gt;
&lt;p&gt;Adding a new independent variable will increase &lt;span class="math"&gt;\(\frac{n-1}{n-p-1}\)&lt;/span&gt; and &lt;span class="math"&gt;\(R^2\)&lt;/span&gt;. If the amount of increment in &lt;span class="math"&gt;\(R^2\)&lt;/span&gt; is less than the amount of increment in &lt;span class="math"&gt;\(\frac{n-1}{n-p-1}\)&lt;/span&gt; than it will decrease the Adjusted R-squared value.&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;fit_lm2&lt;/code&gt; model Adjusted R-squared decreases when we add randomly generated variable into the model.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="cp"&gt;# Let&amp;#39;s compute adjusted R-squared  for our example&lt;/span&gt;
&lt;span class="n"&gt;TDF&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nrow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Total&lt;/span&gt; &lt;span class="n"&gt;degrees&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;freedom&lt;/span&gt;
&lt;span class="n"&gt;EDF&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nrow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Waist_AT&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Error&lt;/span&gt; &lt;span class="n"&gt;degrees&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;freedom&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;where&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;number&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;predictors&lt;/span&gt;
&lt;span class="n"&gt;AdjRSq&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;MulRSq&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TDF&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;EDF&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Adjusted&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt; &lt;span class="n"&gt;square&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Compute Multiple R-squared: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;AdjRSq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Note that computed Adjusted R-squared value is matching with lm() Adjusted R-squared value in the above output &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Note: We are comparing with fit_lm model, not fit_lm2 &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;======================================================================= &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Compute&lt;/span&gt; &lt;span class="n"&gt;Multiple&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;squared&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.6669531&lt;/span&gt;

&lt;span class="n"&gt;Note&lt;/span&gt; &lt;span class="n"&gt;that&lt;/span&gt; &lt;span class="n"&gt;computed&lt;/span&gt; &lt;span class="n"&gt;Adjusted&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;squared&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;matching&lt;/span&gt; &lt;span class="n"&gt;with&lt;/span&gt; &lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="n"&gt;Adjusted&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;squared&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;above&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;

&lt;span class="nl"&gt;Note:&lt;/span&gt; &lt;span class="n"&gt;We&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="n"&gt;comparing&lt;/span&gt; &lt;span class="n"&gt;with&lt;/span&gt; &lt;span class="n"&gt;fit_lm&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;not&lt;/span&gt; &lt;span class="n"&gt;fit_lm2&lt;/span&gt;
&lt;span class="o"&gt;=======================================================================&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Aforementioned measures (Multiple R-squared &amp;amp; Adjusted R-squared) for &lt;strong&gt;Goodness of fit&lt;/strong&gt; are functions of sample and these will vary as sample changes. Similar to &lt;code&gt;t-test&lt;/code&gt; for regression coefficeints we need some statistical test to test model's performance for population.&lt;/p&gt;
&lt;p&gt;Objective is to compare the Mean sum of squares due to regression and Mean sum of squares due to error. &lt;code&gt;F-test&lt;/code&gt; is very helpful to compare the variations.&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$ F-test = \frac{\frac{1}{p-1}\sum_{i=1}^n (\hat{AT_i} - \bar{AT})^2}{\frac{1}{n-p-1} \sum_{i=1}^n (\hat{AT_i} - AT_i)^2}$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Above expression follows F distribution only if, AT follows Normal Distribution&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;RDF&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TDF&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;EDF&lt;/span&gt;
&lt;span class="n"&gt;SSE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SST&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;SSR&lt;/span&gt;
&lt;span class="n"&gt;MSR&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;RDF&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;SSR&lt;/span&gt;
&lt;span class="n"&gt;MSE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;EDF&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;SSE&lt;/span&gt;
&lt;span class="n"&gt;F_value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MSR&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;MSE&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Compute F statistic: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;F_value&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Note that computed F-statistic is matching with lm() F-statistic value in the above output &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Note: We are comparing with fit_lm model, not fit_lm2 &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;======================================================================= &lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Compute&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt; &lt;span class="n"&gt;statistic&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;217.2787&lt;/span&gt;

&lt;span class="n"&gt;Note&lt;/span&gt; &lt;span class="n"&gt;that&lt;/span&gt; &lt;span class="n"&gt;computed&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;statistic&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;matching&lt;/span&gt; &lt;span class="n"&gt;with&lt;/span&gt; &lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;statistic&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;above&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;

&lt;span class="nl"&gt;Note:&lt;/span&gt; &lt;span class="n"&gt;We&lt;/span&gt; &lt;span class="n"&gt;are&lt;/span&gt; &lt;span class="n"&gt;comparing&lt;/span&gt; &lt;span class="n"&gt;with&lt;/span&gt; &lt;span class="n"&gt;fit_lm&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;not&lt;/span&gt; &lt;span class="n"&gt;fit_lm2&lt;/span&gt;
&lt;span class="o"&gt;=======================================================================&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;2. Multiple Linear Regression (MLR)&lt;/h2&gt;
&lt;p&gt;In multiple linear regression we consider more than one predictor and one dependent variable. Most of the above explanation is valid for MLR too.&lt;/p&gt;
&lt;h3&gt;Example: Car's MPG (Miles Per Gallon) prediction&lt;/h3&gt;
&lt;p&gt;Our interest is to model the MPG of a car based on the other variables.&lt;/p&gt;
&lt;p&gt;Variable Description:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;VOL = cubic feet of cab space&lt;/li&gt;
&lt;li&gt;HP = engine horsepower&lt;/li&gt;
&lt;li&gt;MPG = average miles per gallon&lt;/li&gt;
&lt;li&gt;SP = top speed, miles per hour&lt;/li&gt;
&lt;li&gt;WT = vehicle weight, hundreds of pounds&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="cp"&gt;# Reading Boston housing prices data&lt;/span&gt;
&lt;span class="n"&gt;car&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Cars.csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Number of rows: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nrow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;car&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Number of variables: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ncol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;car&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;car&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Number&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mi"&gt;81&lt;/span&gt;
 &lt;span class="n"&gt;Number&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;variables&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;&lt;th scope=col&gt;HP&lt;/th&gt;&lt;th scope=col&gt;MPG&lt;/th&gt;&lt;th scope=col&gt;VOL&lt;/th&gt;&lt;th scope=col&gt;SP&lt;/th&gt;&lt;th scope=col&gt;WT&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;&lt;td&gt;49      &lt;/td&gt;&lt;td&gt;53.70068&lt;/td&gt;&lt;td&gt;89      &lt;/td&gt;&lt;td&gt;104.1854&lt;/td&gt;&lt;td&gt;28.76206&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;55      &lt;/td&gt;&lt;td&gt;50.01340&lt;/td&gt;&lt;td&gt;92      &lt;/td&gt;&lt;td&gt;105.4613&lt;/td&gt;&lt;td&gt;30.46683&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;55      &lt;/td&gt;&lt;td&gt;50.01340&lt;/td&gt;&lt;td&gt;92      &lt;/td&gt;&lt;td&gt;105.4613&lt;/td&gt;&lt;td&gt;30.19360&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;70      &lt;/td&gt;&lt;td&gt;45.69632&lt;/td&gt;&lt;td&gt;92      &lt;/td&gt;&lt;td&gt;113.4613&lt;/td&gt;&lt;td&gt;30.63211&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;53      &lt;/td&gt;&lt;td&gt;50.50423&lt;/td&gt;&lt;td&gt;92      &lt;/td&gt;&lt;td&gt;104.4613&lt;/td&gt;&lt;td&gt;29.88915&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;70      &lt;/td&gt;&lt;td&gt;45.69632&lt;/td&gt;&lt;td&gt;89      &lt;/td&gt;&lt;td&gt;113.1854&lt;/td&gt;&lt;td&gt;29.59177&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Our objective is to model the variation in &lt;code&gt;MPG&lt;/code&gt; using other independent variables. That is,&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$MPG = \beta_0 + \beta_1 VOL + \beta_2 HP + \beta_3 SP + \beta_4 WT + \epsilon$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Where, &lt;span class="math"&gt;\(\beta_1\)&lt;/span&gt; represents the amount of change in &lt;code&gt;MPG&lt;/code&gt; per one unit change in &lt;code&gt;VOL&lt;/code&gt; provided other variables are fixed. Let's consider below two cases,&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Case1:&lt;/strong&gt; HP = 49; VOL = 89; SP = 104.1854; WT = 28.76206 =&amp;gt; MPG = 104.1854&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Case2:&lt;/strong&gt; HP = 49; VOL = 90; SP = 104.1854; WT = 28.76206 =&amp;gt; MPG = 105.2453&lt;/p&gt;
&lt;p&gt;then &lt;span class="math"&gt;\(\beta_1 = 105.2453 - 104.1854 = 1.0599\)&lt;/span&gt;. Similarly, &lt;span class="math"&gt;\(\beta_2, \beta_3, \beta_4\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The above effect is called as &lt;a href="https://en.wikipedia.org/wiki/Ceteris_paribus"&gt;&lt;code&gt;Ceteris Paribus Effect&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But in real world it is very difficult to collect records in above manner. That's why we compute (function of) partial correlation coefficients to quantify the effect of one variable, keeping others constant.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="cp"&gt;# Let&amp;#39;s build MLR model to predict MPG based using other variables&lt;/span&gt;
&lt;span class="n"&gt;fit_mlr_actual&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MPG&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="p"&gt;.,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fit_mlr_actual&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Call&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;formula&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MPG&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="o"&gt;.,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;Residuals&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
     &lt;span class="n"&gt;Min&lt;/span&gt;       &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;Q&lt;/span&gt;   &lt;span class="n"&gt;Median&lt;/span&gt;       &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="n"&gt;Q&lt;/span&gt;      &lt;span class="n"&gt;Max&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.94530&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.32792&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.04058&lt;/span&gt;  &lt;span class="mf"&gt;0.24256&lt;/span&gt;  &lt;span class="mf"&gt;1.71034&lt;/span&gt;

&lt;span class="n"&gt;Coefficients&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
              &lt;span class="n"&gt;Estimate&lt;/span&gt; &lt;span class="n"&gt;Std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Error&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="n"&gt;Pr&lt;/span&gt;&lt;span class="o"&gt;(&amp;gt;|&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;|)&lt;/span&gt;
&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Intercept&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;  &lt;span class="mf"&gt;7.100&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;17&lt;/span&gt;  &lt;span class="mf"&gt;5.461&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;   &lt;span class="mf"&gt;0.000&lt;/span&gt;   &lt;span class="mf"&gt;1.0000&lt;/span&gt;
&lt;span class="n"&gt;HP&lt;/span&gt;          &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.285&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;  &lt;span class="mf"&gt;2.453&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;01&lt;/span&gt;  &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;5.239&lt;/span&gt;  &lt;span class="mf"&gt;1.4&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;06&lt;/span&gt; &lt;span class="o"&gt;***&lt;/span&gt;
&lt;span class="n"&gt;VOL&lt;/span&gt;         &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;8.207&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;01&lt;/span&gt;  &lt;span class="mf"&gt;1.389&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;  &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.591&lt;/span&gt;   &lt;span class="mf"&gt;0.5563&lt;/span&gt;
&lt;span class="n"&gt;SP&lt;/span&gt;           &lt;span class="mf"&gt;6.144&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;01&lt;/span&gt;  &lt;span class="mf"&gt;2.458&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;01&lt;/span&gt;   &lt;span class="mf"&gt;2.500&lt;/span&gt;   &lt;span class="mf"&gt;0.0146&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="n"&gt;WT&lt;/span&gt;           &lt;span class="mf"&gt;3.287&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;01&lt;/span&gt;  &lt;span class="mf"&gt;1.390&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;   &lt;span class="mf"&gt;0.237&lt;/span&gt;   &lt;span class="mf"&gt;0.8136&lt;/span&gt;
&lt;span class="o"&gt;---&lt;/span&gt;
&lt;span class="n"&gt;Signif&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;codes&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;***&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.001&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.01&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.05&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt; &lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="n"&gt;Residual&lt;/span&gt; &lt;span class="n"&gt;standard&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.4915&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="mi"&gt;76&lt;/span&gt; &lt;span class="n"&gt;degrees&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;freedom&lt;/span&gt;
&lt;span class="n"&gt;Multiple&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;squared&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.7705&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;Adjusted&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;squared&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.7585&lt;/span&gt;
&lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;statistic&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;63.8&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt; &lt;span class="mi"&gt;76&lt;/span&gt; &lt;span class="n"&gt;DF&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;2.2&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;One key observation from above output is, Std. Error for &lt;code&gt;VOL&lt;/code&gt; and &lt;code&gt;WT&lt;/code&gt; is very huge comparing to others and this inflates &lt;code&gt;t values&lt;/code&gt; and &lt;code&gt;p value&lt;/code&gt;. Hence, these two variables becomes very insignificant for the model.&lt;/p&gt;
&lt;p&gt;Let's go into deep, what happened to &lt;span class="math"&gt;\(Var(\hat{\beta_{VOL}})\)&lt;/span&gt; and &lt;span class="math"&gt;\(Var(\hat{\beta_{WT}})\)&lt;/span&gt;?&lt;/p&gt;
&lt;p&gt;Analogy for &lt;span class="math"&gt;\(Var(\hat{\beta})\)&lt;/span&gt; in MLR is as follows:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$Var(\hat{\beta_{VOL}}) = \frac{\sigma^2}{n\sum_{i=1}^n (VOL_i - \bar{VOL})^2 (1 - R_{VOL}^2)}$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Where, &lt;span class="math"&gt;\(R_{VOL}^2\)&lt;/span&gt; = Multiple R-squared value obtained by regressing VOL on all other independent variables&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Task:&lt;/strong&gt; To understand it more clearly, take few random samples from cars data and run the MLR model and observe the variation in &lt;span class="math"&gt;\(\hat{\beta_{VOL}}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\hat{\beta_{WT}}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="cp"&gt;# Let&amp;#39;s regress VOL on all other independent variables&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;fit_mlr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;VOL&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="n"&gt;HP&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;SP&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;WT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fit_mlr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Call&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;formula&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;VOL&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="n"&gt;HP&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;SP&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;WT&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;Residuals&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
      &lt;span class="n"&gt;Min&lt;/span&gt;        &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;Q&lt;/span&gt;    &lt;span class="n"&gt;Median&lt;/span&gt;        &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="n"&gt;Q&lt;/span&gt;       &lt;span class="n"&gt;Max&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.068938&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.031641&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.008794&lt;/span&gt;  &lt;span class="mf"&gt;0.032018&lt;/span&gt;  &lt;span class="mf"&gt;0.077931&lt;/span&gt;

&lt;span class="n"&gt;Coefficients&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
              &lt;span class="n"&gt;Estimate&lt;/span&gt; &lt;span class="n"&gt;Std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Error&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="n"&gt;Pr&lt;/span&gt;&lt;span class="o"&gt;(&amp;gt;|&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;|)&lt;/span&gt;
&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Intercept&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;6.155&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;  &lt;span class="mf"&gt;4.481&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;03&lt;/span&gt;   &lt;span class="mf"&gt;0.000&lt;/span&gt;    &lt;span class="mf"&gt;1.000&lt;/span&gt;
&lt;span class="n"&gt;HP&lt;/span&gt;           &lt;span class="mf"&gt;2.331&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;  &lt;span class="mf"&gt;1.995&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;   &lt;span class="mf"&gt;1.168&lt;/span&gt;    &lt;span class="mf"&gt;0.246&lt;/span&gt;
&lt;span class="n"&gt;SP&lt;/span&gt;          &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;2.294&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;  &lt;span class="mf"&gt;2.000&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;  &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.147&lt;/span&gt;    &lt;span class="mf"&gt;0.255&lt;/span&gt;
&lt;span class="n"&gt;WT&lt;/span&gt;           &lt;span class="mf"&gt;9.998&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;01&lt;/span&gt;  &lt;span class="mf"&gt;4.557&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;03&lt;/span&gt; &lt;span class="mf"&gt;219.396&lt;/span&gt;   &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="o"&gt;***&lt;/span&gt;
&lt;span class="o"&gt;---&lt;/span&gt;
&lt;span class="n"&gt;Signif&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;codes&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;***&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.001&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.01&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.05&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt; &lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="n"&gt;Residual&lt;/span&gt; &lt;span class="n"&gt;standard&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.04033&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="mi"&gt;77&lt;/span&gt; &lt;span class="n"&gt;degrees&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;freedom&lt;/span&gt;
&lt;span class="n"&gt;Multiple&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;squared&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.9984&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;Adjusted&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;squared&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.9984&lt;/span&gt;
&lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;statistic&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;1.637&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;04&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt; &lt;span class="mi"&gt;77&lt;/span&gt; &lt;span class="n"&gt;DF&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;2.2&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It's surprising that, &lt;span class="math"&gt;\(R_{VOL}^2\)&lt;/span&gt; is 0.9984 and also only &lt;code&gt;WT&lt;/code&gt; is significant. That is, these two predictors (&lt;code&gt;VOL&lt;/code&gt; and &lt;code&gt;WT&lt;/code&gt;) are highly correlated. This inflates &lt;span class="math"&gt;\(Var(\hat{\beta_{VOL}})\)&lt;/span&gt; and thus &lt;code&gt;t value&lt;/code&gt;. We might be missing some of the important information because of high correlation between predictors. This problem is called as &lt;a href="https://en.wikipedia.org/wiki/Multicollinearity"&gt;Multicollinearity&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;One quick solution for this problem is to remove either &lt;code&gt;VOL&lt;/code&gt; or &lt;code&gt;WT&lt;/code&gt; from the model. Let's compute partial correlation coeficient between &lt;code&gt;MPG&lt;/code&gt; and &lt;code&gt;VOL&lt;/code&gt; by removing the effect of &lt;code&gt;WT&lt;/code&gt; (say, &lt;span class="math"&gt;\(r_{MV.W}\)&lt;/span&gt;) and partial correlation coeficient between &lt;code&gt;MPG&lt;/code&gt; and &lt;code&gt;WT&lt;/code&gt; by removing the effect of &lt;code&gt;VOL&lt;/code&gt; (say, &lt;span class="math"&gt;\(r_{MW.V}\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;To compute &lt;span class="math"&gt;\(r_{MV.W}\)&lt;/span&gt; we need to compute the correlation between (a) part of &lt;code&gt;VOL&lt;/code&gt; which cannot be explained by &lt;code&gt;WT&lt;/code&gt; (regress &lt;code&gt;VOL&lt;/code&gt; on &lt;code&gt;WT&lt;/code&gt; and take the residuals) and (b) the part of &lt;code&gt;MPG&lt;/code&gt; which cannot be explained by &lt;code&gt;WT&lt;/code&gt; (regress &lt;code&gt;MPG&lt;/code&gt; on &lt;code&gt;WT&lt;/code&gt; and take the residuals)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;fit_partial&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;VOL&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="n"&gt;WT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;fit_partial2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MPG&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="n"&gt;WT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;res1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fit_partial&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;residual&lt;/span&gt;
&lt;span class="n"&gt;res2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fit_partial2&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;residual&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Partial correlation coefficient between MPG and VOL by removing the effect of WT is: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;res2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Partial&lt;/span&gt; &lt;span class="n"&gt;correlation&lt;/span&gt; &lt;span class="n"&gt;coefficient&lt;/span&gt; &lt;span class="n"&gt;between&lt;/span&gt; &lt;span class="n"&gt;MPG&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt; &lt;span class="n"&gt;VOL&lt;/span&gt; &lt;span class="n"&gt;by&lt;/span&gt; &lt;span class="n"&gt;removing&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;effect&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;WT&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.08008873&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;fit_partial3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;WT&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="n"&gt;VOL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;fit_partial4&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MPG&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="n"&gt;VOL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;res1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fit_partia3&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;residual&lt;/span&gt;
&lt;span class="n"&gt;res2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fit_partial4&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;residual&lt;/span&gt;
&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Partial correlation coefficient between MPG and WT by removing the effect of VOL is: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;res2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Partial&lt;/span&gt; &lt;span class="n"&gt;correlation&lt;/span&gt; &lt;span class="n"&gt;coefficient&lt;/span&gt; &lt;span class="n"&gt;between&lt;/span&gt; &lt;span class="n"&gt;MPG&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt; &lt;span class="n"&gt;WT&lt;/span&gt; &lt;span class="n"&gt;by&lt;/span&gt; &lt;span class="n"&gt;removing&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;effect&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;VOL&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.05538241&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Since, &lt;span class="math"&gt;\(abs(r_{MV.W}) &amp;gt;= abs(r_{MW.V})\)&lt;/span&gt; we may remove &lt;code&gt;WT&lt;/code&gt; from the model.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="cp"&gt;# Remove WT and rerun the model&lt;/span&gt;
&lt;span class="n"&gt;fit_mlr_actual2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MPG&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fit_mlr_actual2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Call&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;lm&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;formula&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MPG&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;WT&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;car&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;Residuals&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
     &lt;span class="n"&gt;Min&lt;/span&gt;       &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;Q&lt;/span&gt;   &lt;span class="n"&gt;Median&lt;/span&gt;       &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="n"&gt;Q&lt;/span&gt;      &lt;span class="n"&gt;Max&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.94036&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.31695&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.03457&lt;/span&gt;  &lt;span class="mf"&gt;0.23316&lt;/span&gt;  &lt;span class="mf"&gt;1.71570&lt;/span&gt;

&lt;span class="n"&gt;Coefficients&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
              &lt;span class="n"&gt;Estimate&lt;/span&gt; &lt;span class="n"&gt;Std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;Error&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="n"&gt;Pr&lt;/span&gt;&lt;span class="o"&gt;(&amp;gt;|&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;|)&lt;/span&gt;
&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Intercept&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;  &lt;span class="mf"&gt;7.910&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;17&lt;/span&gt;  &lt;span class="mf"&gt;5.427&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;   &lt;span class="mf"&gt;0.000&lt;/span&gt;   &lt;span class="mf"&gt;1.0000&lt;/span&gt;
&lt;span class="n"&gt;HP&lt;/span&gt;          &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.293&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;  &lt;span class="mf"&gt;2.415&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;01&lt;/span&gt;  &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;5.353&lt;/span&gt; &lt;span class="mf"&gt;8.64&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;07&lt;/span&gt; &lt;span class="o"&gt;***&lt;/span&gt;
&lt;span class="n"&gt;VOL&lt;/span&gt;         &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;4.925&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;01&lt;/span&gt;  &lt;span class="mf"&gt;5.516&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;  &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;8.928&lt;/span&gt; &lt;span class="mf"&gt;1.65&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="o"&gt;***&lt;/span&gt;
&lt;span class="n"&gt;SP&lt;/span&gt;           &lt;span class="mf"&gt;6.222&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;01&lt;/span&gt;  &lt;span class="mf"&gt;2.421&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;01&lt;/span&gt;   &lt;span class="mf"&gt;2.571&lt;/span&gt;   &lt;span class="mf"&gt;0.0121&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="o"&gt;---&lt;/span&gt;
&lt;span class="n"&gt;Signif&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;codes&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;***&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.001&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.01&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.05&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt; &lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="n"&gt;Residual&lt;/span&gt; &lt;span class="n"&gt;standard&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.4884&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="mi"&gt;77&lt;/span&gt; &lt;span class="n"&gt;degrees&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;freedom&lt;/span&gt;
&lt;span class="n"&gt;Multiple&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;squared&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.7704&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;Adjusted&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;squared&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="mf"&gt;0.7614&lt;/span&gt;
&lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;statistic&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;86.11&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt; &lt;span class="mi"&gt;77&lt;/span&gt; &lt;span class="n"&gt;DF&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;2.2&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After eliminating &lt;code&gt;WT&lt;/code&gt; from the model there is an increment of ~0.3% in Adjusted R-squared and more importantly, &lt;code&gt;VOL&lt;/code&gt; becomes significant at 0 &lt;a href="https://en.wikipedia.org/wiki/Statistical_significance"&gt;los&lt;/a&gt; (level of significance)&lt;/p&gt;
&lt;p&gt;&lt;a id='Assumptions'&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;3. Assumptions&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Linear in Parameters:&lt;/strong&gt; We assume that there is a linear relation between dependent and set of independent variables&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Zero conditional mean:&lt;/strong&gt; &lt;span class="math"&gt;\(E(\epsilon \mid X) = 0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Homoskedasticity:&lt;/strong&gt; &lt;span class="math"&gt;\(Var(\epsilon \mid X) = \sigma^2\)&lt;/span&gt; (Constant)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;No perfect Collinearity:&lt;/strong&gt; All predecitors must be independent among themselves&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;No serial correlation in errors:&lt;/strong&gt; Erros must be uncorrelated among themselves. In otherwords, observations or records must be independent of each other.&lt;/p&gt;
&lt;p&gt;We discussed first 4 assumptions in section 1 and 2.&lt;/p&gt;
&lt;p&gt;Here is a book that I recommend to learn more about this:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank"  href="https://www.amazon.com/gp/product/1111531048/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1111531048&amp;linkCode=as2&amp;tag=nkaveti-20&amp;linkId=83f6e694209869322f8bfad406883d2f"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1111531048&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=nkaveti-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=nkaveti-20&amp;l=am2&amp;o=1&amp;a=1111531048" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processClass: 'mathjax', " +
        "        ignoreClass: 'no-mathjax', " +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="SLR"></category><category term="MLR"></category><category term="Linear Regression"></category><category term="Statistic"></category><category term="Basics"></category><category term="Layman Explanations"></category></entry><entry><title>How to think like a Data Scientist</title><link href="http://mlwhiz.github.io/blog/2017/03/05/think_like_a_data_scientist/" rel="alternate"></link><updated>2017-03-05T04:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2017-03-05:blog/2017/03/05/think_like_a_data_scientist/</id><summary type="html">&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/thinklikeds.png"  height="400" width="700" &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;A data scientist needs to be Critical and always on a lookout of something that misses others. So here are some advices that one can include in day to day data science work to be better at their work:&lt;/p&gt;
&lt;h2&gt;1. Beware of the Clean Data Syndrome&lt;/h2&gt;
&lt;p&gt;You need to ask yourself questions even before you start working on the data. &lt;strong&gt;Does this data make sense?&lt;/strong&gt; Falsely assuming that the data is clean could lead you towards wrong Hypotheses. Apart from that, you can discern a lot of important patterns by looking at discrepancies in the data. For example, if you notice that a particular column has more than 50% values missing, you might think about not using the column. Or you may think that some of the data collection instrument has some error.&lt;/p&gt;
&lt;p&gt;Or let's say you have a distribution of Male vs Female as 90:10 in a Female Cosmetic business. You may assume clean data and show the results as it is or you can use common sense and ask if the labels are switched.&lt;/p&gt;
&lt;h2&gt;2. Manage Outliers wisely&lt;/h2&gt;
&lt;p&gt;Outliers can help you understand more about the people who are using your website/product 24 hours a day. But including them while building models will skew the models a lot.&lt;/p&gt;
&lt;h2&gt;3. Keep an eye out for the Abnormal&lt;/h2&gt;
&lt;p&gt;Be on the &lt;strong&gt;lookout for something out of the obvious&lt;/strong&gt;. If you find something you may have hit gold.&lt;/p&gt;
&lt;p&gt;For example, &lt;a href="https://www.fastcompany.com/1783127/flickr-founders-glitch-can-game-wants-you-play-nice-be-blockbuster"&gt;Flickr started up as a Multiplayer game&lt;/a&gt;. Only when the founders noticed that people were using it as a photo upload service, did they pivot.&lt;/p&gt;
&lt;p&gt;Another example: fab.com started up as fabulis.com, a site to help gay men meet people. One of the site's popular features was the "Gay deal of the Day". One day the deal was for Hamburgers - and half of the buyers were women. This caused the team to realize that there was a market for selling goods to women. So Fabulis pivoted to fab as a flash sale site for designer products.&lt;/p&gt;
&lt;h2&gt;4. Start Focussing on the right metrics&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Beware of Vanity metrics&lt;/strong&gt; For example, # of active users by itself doesn't divulge a lot of information. I would rather say "5% MoM increase in active users" rather than saying " 10000 active users". Even that is a vanity metric as active users would always increase. I would rather keep a track of percentage of users that are active to know how my product is performing.&lt;/li&gt;
&lt;li&gt;Try to find out a &lt;strong&gt;metric that ties with the business goal&lt;/strong&gt;. For example, Average Sales/User for a particular month.&lt;/li&gt;
&lt;/ul&gt;
&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;

&lt;h2&gt;5. Statistics may lie too&lt;/h2&gt;
&lt;p&gt;Be critical of everything that gets quoted to you. Statistics has been used to lie in advertisements, in workplaces and a lot of other marketing venues in the past. People will do anything to get sales or promotions.&lt;/p&gt;
&lt;p&gt;For example: &lt;a href="http://marketinglaw.osborneclarke.com/retailing/colgates-80-of-dentists-recommend-claim-under-fire/"&gt;Do you remember Colgate’s claim that 80% of dentists recommended their brand?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This statistic seems pretty good at first. It turns out that at the time of surveying the dentists, they could choose several brands — not just one. So other brands could be just as popular as Colgate.&lt;/p&gt;
&lt;p&gt;Another Example: &lt;strong&gt;"99 percent Accurate" doesn't mean shit&lt;/strong&gt;. Ask me to create a cancer prediction model and I could give you a 99 percent accurate model in a single line of code. How? Just predict "No Cancer" for each one. I will be accurate may be more than 99% of the time as Cancer is a pretty rare disease. Yet I have achieved nothing.&lt;/p&gt;
&lt;h2&gt;6. Understand how probability works&lt;/h2&gt;
&lt;p&gt;It happened during the summer of 1913 in a Casino in Monaco. Gamblers watched in amazement as a casino's roulette wheel landed on black 26 times in a row. And since the probability of a Red vs Black is exactly half, they were certain that red was "due". It was a field day for the Casino. A perfect example of &lt;a href="https://en.wikipedia.org/wiki/Gambler's_fallacy"&gt;Gambler's fallacy&lt;/a&gt;, aka the Monte Carlo fallacy.&lt;/p&gt;
&lt;p&gt;And This happens in real life. &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2538147"&gt;People tend to avoid long strings of the same answer&lt;/a&gt;. Sometimes sacrificing accuracy of judgment for the sake of getting a pattern of decisions that looks fairer or probable.&lt;/p&gt;
&lt;p&gt;For example, An admissions officer may reject the next application if he has approved three applications in a row, even if the application should have been accepted on merit.&lt;/p&gt;
&lt;h2&gt;7. Correlation Does Not Equal Causation&lt;/h2&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/corr_caus.png"  height="400" width="500" &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;The Holy Grail of a Data scientist toolbox. To see something for what it is. Just because two variables move together in tandem doesn't necessarily mean that one causes the another. There have been hilarious examples for this in the past. Some of my favorites are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Looking at the firehouse department data you infer that the more firemen are sent to a fire, the more damage is done.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When investigating the cause of crime in New York City in the 80s, an academic found a strong correlation between the amount of serious crime committed and the amount of ice cream sold by street vendors! Obviously, there was an unobserved variable causing both. Summers are when the crime is the greatest and when the most ice cream is sold. So Ice cream sales don't cause crime. Neither crime increases ice cream sales.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;8. More data may help&lt;/h2&gt;
&lt;p&gt;Sometimes getting extra data may work wonders. You might be able to model the real world more closely by looking at the problem from all angles. Look for extra data sources.&lt;/p&gt;
&lt;p&gt;For example, Crime data in a city might help banks provide a better credit line to a person living in a troubled neighborhood and in turn increase the bottom line.&lt;/p&gt;</summary><category term="statistics"></category><category term="data science"></category></entry><entry><title>Machine Learning algorithms for Data Scientists</title><link href="http://mlwhiz.github.io/blog/2017/02/05/Machine_learning_algorithms_for_data_scientist/" rel="alternate"></link><updated>2017-02-05T04:43:00-02:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2017-02-05:blog/2017/02/05/Machine_learning_algorithms_for_data_scientist/</id><summary type="html">&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/mlago_fords.png"  height="400" width="600" &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;As a data scientist I believe that a lot of work has to be done before Classification/Regression/Clustering methods are applied to the data you get. The data which may be messy, unwieldy and big. So here are the list of algorithms that helps a data scientist to make better models using the data they have:&lt;/p&gt;
&lt;h2&gt;1. Sampling Algorithms. In case you want to work with a sample of data.&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Simple Random Sampling :&lt;/strong&gt;&lt;em&gt; Say you want to select a subset of a population in which each member of the subset has an equal probability of being chosen.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stratified Sampling : &lt;/strong&gt;Assume that we need to estimate average number of votes for each candidate in an election. Assume that country has 3 towns : Town A has 1 million factory workers, Town B has 2 million workers and Town C has 3 million retirees. We can choose to get a random sample of size 60 over entire population but there is some chance that the random sample turns out to be not well balanced across these towns and hence is biased causing a significant error in estimation. Instead if we choose to take a random sample of 10, 20 and 30 from Town A, B and C respectively then we can produce a smaller error in estimation for the same total size of sample.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reservoir Sampling&lt;/strong&gt; :&lt;em&gt; Say you have a stream of items of large and unknown length that we can only iterate over once. Create an algorithm that randomly chooses an item from this stream such that each item is equally likely to be selected.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;2. &lt;strong&gt;Map-Reduce. If you want to work with the whole data&lt;/strong&gt;.&lt;/h2&gt;
&lt;p&gt;Can be used for feature creation. For Example: I had a use case where I had a graph of 60 Million customers and 130 Million accounts. Each account was connected to other account if they had the Same SSN or Same Name+DOB+Address. I had to find customer ID’s for each of the accounts. On a single node parsing such a graph took more than 2 days. On a Hadoop cluster of 80 nodes running a&lt;em&gt; Connected Component Algorithm &lt;/em&gt;took less than 24 minutes. On Spark it is even faster.&lt;/p&gt;
&lt;h2&gt;3. &lt;strong&gt;Graph Algorithms.&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Recently I was working on an optimization problem which was focussed on finding shortest distance and routes between two points in a store layout. Routes which don’t pass through different aisles, so we cannot use euclidean distances. We solved this problem by considering turning points in the store layout and the&lt;em&gt; djikstra’s Algorithm.&lt;/em&gt;&lt;/p&gt;
&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;

&lt;h2&gt;4. &lt;strong&gt;Feature Selection.&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Univariate Selection. &lt;/strong&gt;Statistical tests can be used to select those features that have the strongest relationship with the output variable.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;VarianceThreshold.&lt;/strong&gt; Feature selector that removes all low-variance features.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recursive Feature Elimination.&lt;/strong&gt; The goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and weights are assigned to each one of them. Then, features whose absolute weights are the smallest are pruned from the current set features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Feature Importance: &lt;/strong&gt;Methods that use ensembles of decision trees (like Random Forest or Extra Trees) can also compute the relative importance of each attribute. These importance values can be used to inform a feature selection process.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;5. &lt;strong&gt;Algorithms to work efficiently.&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Apart from these above algorithms sometimes you may need to write your own algorithms. Now I think of big algorithms as a combination of small but powerful algorithms. You just need to have idea of these algorithms to make a more better/efficient product. So some of these powerful algorithms which can help you are:
- &lt;strong&gt;Recursive Algorithms: &lt;/strong&gt;Binary search algorithm.
- &lt;strong&gt;Divide and Conquer Algorithms:&lt;/strong&gt; Merge-Sort.
- &lt;strong&gt;Dynamic Programming: &lt;/strong&gt;Solving a complex problem by breaking it down into a collection of simpler subproblems, solving each of those subproblems just once, and storing their solutions.&lt;/p&gt;
&lt;h2&gt;6. &lt;strong&gt;Classification/Regression Algorithms.&lt;/strong&gt; The usual suspects. Minimum you must know:&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Linear Regression -&lt;/strong&gt; Ridge Regression, Lasso Regression, ElasticNet&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Logistic Regression&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;From there you can build upon:&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Decision Trees -&lt;/strong&gt; ID3, CART, C4.5, C5.0&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;KNN&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SVM&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ANN&lt;/strong&gt; - Back Propogation, CNN&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;And then on to Ensemble based algorithms:&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Boosting&lt;/strong&gt;: Gradient Boosted Trees&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bagging&lt;/strong&gt;: Random Forests&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Blending&lt;/strong&gt;: Prediction outputs of different learning algorithms are fed into another learning algorithm.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;7. &lt;strong&gt;Clustering Methods. &lt;/strong&gt;For unsupervised learning.&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;k-Means&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;k-Medians&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Expectation Maximisation (EM)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hierarchical Clustering&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;8. &lt;strong&gt;Other algorithms you can learn about:&lt;/strong&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Apriori algorithm &lt;/strong&gt;- Association Rule Mining&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Eclat algorithm -&lt;/strong&gt; Association Rule Mining&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Item/User Based Similarity -&lt;/strong&gt; Recommender Systems&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reinforcement learning -&lt;/strong&gt; Build your own robot.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Graphical Models&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bayesian Algorithms&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NLP -&lt;/strong&gt; For language based models. Chatbots.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Hope this has been helpful.....&lt;/p&gt;</summary><category term="statistics"></category><category term="data science"></category></entry><entry><title>Things to see while buying a Mutual Fund</title><link href="http://mlwhiz.github.io/blog/2016/12/24/mutual_fund_ratios/" rel="alternate"></link><updated>2016-12-24T04:43:00-02:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2016-12-24:blog/2016/12/24/mutual_fund_ratios/</id><summary type="html">&lt;p&gt;This is a post which deviates from my pattern fo blogs that I have wrote till now but I found that Finance also uses up a lot of Statistics. So it won't be a far cry to put this on my blog here. I recently started investing in Mutual funds so thought of rersearching the area before going all in. Here is the result of some of my research.&lt;/p&gt;
&lt;h2&gt;1. Load/No-Load:&lt;/h2&gt;
&lt;p&gt;Always Buy No Load Mutual Funds&lt;/p&gt;
&lt;h2&gt;2. Regular/Direct:&lt;/h2&gt;
&lt;p&gt;There are many differenct sites from where you can buy Mutual funds. Most of these sites take a commision to let you the investor buy and sell from their platform. To overcome this commision you can buy direct Mutual funds from the fund houses themselves. But that would be difficult as their are a lot of fund houses and mmanaging all of that could be quite painful. But with the advent of MFUtility you can buy direct plans from the same platform.&lt;/p&gt;
&lt;h2&gt;3. Expense Ratios:&lt;/h2&gt;
&lt;p&gt;The expense ratio is a measure of what it costs an investment company to operate a mutual fund.
To see how expense ratios can affect your investments over time, let’s compare the returns of several hypothetical investments that differ only in expense ratio. The following table depicts the returns on a 10,000 initial investment, assuming an average annualized gain of 10%, with different expense ratios (0.5%, 1%, 1.5%, 2% and 2.5%):&lt;/p&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/fund_expense_ratio.jpg"  height="400" width="500" &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;As the table illustrates, even a small difference in expense ratio can cost you a lot of money in the long run. If you had invested 10,000 in the fund with a 2.5% expense ratio, the value of your fund would be 46,022 after 20 years. Had you instead invested your 10,000 in the fund with a lower, 0.5% expense ratio, your investment would be worth $61,159 after two decades, a 0.33% improvement over the more expensive fund. Keep in mind, this hypothetical example examines funds whose only differences are the expense ratios: all other variables, including initial investment and annualized gains, remain constant (for the example, we must assume identical taxation as well). While two funds are not likely to have the exact same performance over a 20-year period, the table illustrates the effects that small changes in expense ratio can have on your long-term returns.&lt;/p&gt;
&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;

&lt;h2&gt;4. Avoid Mutual Funds With High Turnover Ratios:&lt;/h2&gt;
&lt;p&gt;Mutual fund turnover is calculated as the value of all transactions (buying, selling) divided by two, then divided by a fund's total holdings. In simpler terms, mutual fund turnover typically measures the replacement of holdings in a mutual fund, and is commonly presented to investors as a percentage over a one year period. If a fund has 100% turnover, the fund replaces all of its holdings over a 12-month period and that bears cost to the investment company in terms of brokerage etc.&lt;/p&gt;
&lt;h2&gt;5. Look for Ample Diversification of Assets:&lt;/h2&gt;
&lt;p&gt;Simply owning four different mutual funds specializing in the financial sector (shares of banks, insurance companies, etc.) is not diversification. Don’t own funds that make heavy sector or industry bets. If you choose to despite this warning, make sure that you don’t have a huge portion of your funds invested in them. If it’s a bond fund, you typically want to avoid bets on the direction of interest rates as this is rank speculation.&lt;/p&gt;
&lt;h2&gt;6. Not Same Fund Family:&lt;/h2&gt;
&lt;p&gt;Don’t keep all of your funds within the same fund family. Witness the mutual fund scandal of a few years ago where portfolio management at many firms allowed big traders to market time the funds, essentially stealing money from smaller investors. By spreading your assets out at different companies, you can mitigate the risk of internal turmoil, ethics breaches, and other localized problems.&lt;/p&gt;
&lt;h2&gt;7. Keep Track of various Risk Ratios:&lt;/h2&gt;
&lt;h3&gt;a. &lt;strong&gt;&lt;strong&gt;Standard deviation:&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Standard deviation (SD) measures the volatility the fund's returns in relation to its average. It tells
you how much the fund's return can deviate from the historical mean return of the scheme. If a fund
has a 12% average rate of return and a standard deviation of 4%, its return will range from 8-16%&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Computation:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Standard Deviation (SD) = Square root of Variance (V)&lt;/p&gt;
&lt;p&gt;Variance = (Sum of squared difference between each monthly return and its mean / number of monthly return data – 1)
&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;b. &lt;strong&gt;&lt;strong&gt;R-Squared:&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;R-Squared measures the relationship between a portfolio and its benchmark. It can be thought of as a percentage from 1 to 100. R-squared is not a measure of the performance of a portfolio. A great portfolio can have a very low R-squared. It is simply a measure of the correlation of the portfolio's returns to the benchmark's returns.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Computation:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;R-Squared = Square of Correlation&lt;/p&gt;
&lt;p&gt;Correlation(xy)= Covariance between index and portfolio/(Standard deviation of portfolio * standard deviation of index)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Significance:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If you want a portfolio that moves like the benchmark, you'd want a portfolio with a high Rsquared.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you want a portfolio that doesn't move at all like the benchmark, you'd want a low R-squared.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;General Range for R-Squared:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;70-100% = good correlation between the portfolio's returns and the benchmark's returns&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;40-70% = average correlation between the portfolio's returns and the benchmark's returns&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;1-40% = low correlation between the portfolio's returns and the benchmark's returns&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Index funds will have an R-squared very close to 100.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;R-squared can be used to ascertain the significance of a particular beta or alpha. Generally, a higher R-squared will indicate a more useful beta figure. If the R-squared is lower, then the beta is less relevant to the fund's performance&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Values range from 1 (returns are explained 100% by the market) to 0 (returns bear no association with the market)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;c. &lt;strong&gt;&lt;strong&gt;Beta:&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;A beta of 1.0 indicates that the investment's price will move in lock-step with the market.&lt;/p&gt;
&lt;p&gt;A beta of less than 1.0 indicates that the investment will be less volatile than the market, and, correspondingly, a beta of more than 1.0 indicates that the investment's price will be more volatile than the market.&lt;/p&gt;
&lt;p&gt;For example, if a fund portfolio's beta is 1.2, it's theoretically 20% more volatile than the market. Conservative investors looking to preserve capital should focus on securities and fund portfolios with low betas, whereas those investors willing to take on more risk in search of higher returns should look for high beta investments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Computation:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Beta = (Standard Deviation of Fund x R-Square) / Standard Deviation of Benchmark&lt;/p&gt;
&lt;p&gt;If a fund has a beta of 1.5, it means that for every 10% upside or downside, the fund's NAV would be 15% in the respective direction.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;d. &lt;strong&gt;&lt;strong&gt;Jensens Alpha:&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Alpha is a measure of an investment's performance on a risk-adjusted basis.&lt;/p&gt;
&lt;p&gt;Simply stated, alpha is often considered to represent the value that a portfolio manager adds or subtracts from a fund portfolio's return.&lt;/p&gt;
&lt;p&gt;A positive alpha of 1.0 means the fund has outperformed its benchmark index by 1%. Correspondingly, a similar negative alpha would indicate an underperformance of 1%.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Computation:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Alpha = {(Fund return-Risk free return) – (Funds beta) *(Benchmark return- risk free return)}&lt;/p&gt;
&lt;p&gt;For example, assume a mutual fund realized a return of 15% last year. The appropriate market index for this fund returned 12%. The beta of the fund versus that same index is 1.2 and the risk-free rate is 3%. The fund's alpha is calculated as:&lt;/p&gt;
&lt;p&gt;Alpha = {(15 -3) – (1.2) *(12- 3)} = 12 - 9 x 1.2 = 12-10.8 = 1.2&lt;/p&gt;
&lt;p&gt;Given a beta of 1.2, the mutual fund is expected to be riskier than the index, and thus earn more. A positive alpha in this example shows that the mutual fund manager earned more than enough return to be compensated for the risk he took over the course of the year. If the mutual fund only returned 13%, the calculated alpha would be -0.8. With a negative alpha, the mutual fund manager would not have earned enough return given the amount of risk he was taking.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;e. &lt;strong&gt;&lt;strong&gt;Sharpe Ratio:&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Sharpe Ratio measures how well the fund has performed vis-a vis the risk taken by it. It is the excess return over risk-free return (usually return from treasury bills or government securities) divided by the standard deviation. The higher the Sharpe Ratio, the better the fund has performed in proportion to the risk taken by it.
The Sharpe ratio is also known as Reward-to-Variability ratio and it is named after William Forsyth Sharpe.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Computation:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;SR = (Total Return – Risk Free Rate) / SD Of Fund&lt;/p&gt;
&lt;p&gt;For example: Your investor gets 7 per cent return on her investment in a scheme with a standard deviation/volatility of 0.5. We assume risk free rate is 5 per cent.
Sharpe Ratio is 7-5/0.5 = 4 in this case&lt;/p&gt;
&lt;h2&gt;8. And Finally Always Dollar-Cost Average:&lt;/h2&gt;
&lt;p&gt;Dollar cost averaging is a technique designed to reduce market risk through the systematic purchase of securities at predetermined intervals and set amounts.Instead of investing assets in a lump sum, the investor works his way into a position by slowly buying smaller amounts over a longer period of time. This spreads the cost basis out over several years, providing insulation against changes in market price.&lt;/p&gt;
&lt;p&gt;Every investor investment strategy differs. These are just some common guidelines to work your way through the market and making informed decisions while buying Mutual Funds.
Normally I work through points 1-6 and get my list to a few mutual funds after which I generally use risk ratios to determine which of the funds I selected might be a winner.
I have a bias towards long term investing when it comes to investing so whatever I wrote here must be taken with a grain of salt just as everything related to investment must be.  Some of you who are doing this for a longer time than I can also tell me about the various other things I can do.
I will try to include those ideas in this post as well.&lt;/p&gt;
&lt;p&gt;To Learn more about Mutual funds and investing in general, take a look at the following two gems:&lt;/p&gt;
&lt;div style="margin-left:1em ; text-align: center;"&gt;
&lt;a target="_blank"  href="https://www.amazon.com/gp/product/0060555661/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0060555661&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=59d5b0af035ad4ba7eda55548194a638"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=0060555661&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=0060555661" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/t&gt;&lt;/t&gt;
&lt;a target="_blank"  href="https://www.amazon.com/gp/product/0470138130/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0470138130&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=2f78b02ff1a38e3383c5a8cff52f2a9a"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=0470138130&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=0470138130" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;

&lt;p&gt;The Editorial review of The intelligent Investor says "Among the library of investment books promising no-fail strategies for riches, Benjamin Graham's classic, The Intelligent Investor, offers no guarantees or gimmicks but overflows with the wisdom at the core of all good portfolio management" and it rings true in every sense. A must read for everyone looking to invest seriously.&lt;/p&gt;
&lt;p&gt;Common Sense on Mutual Funds focusses on Mutual funds exclusively. Lets you understand that investing is not difficult. For the not so involved reader.&lt;/p&gt;
&lt;p&gt;Till than Ciao!!!&lt;/p&gt;
&lt;h2&gt;References:&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;https://www.thebalance.com/picking-winning-mutual-funds-357957&lt;/li&gt;
&lt;li&gt;http://www.miraeassetmf.co.in/uploads/TermofWeek/Sharpe_Ratio.pdf&lt;/li&gt;
&lt;li&gt;http://www.miraeassetmf.co.in/uploads/TermofWeek/Beta_SD_RSquared.pdf&lt;/li&gt;
&lt;li&gt;http://www.investopedia.com&lt;/li&gt;
&lt;/ol&gt;</summary><category term="statistics"></category></entry><entry><title>Donald Trump : Two new Survey Biases</title><link href="http://mlwhiz.github.io/blog/2016/11/10/trump_really/" rel="alternate"></link><updated>2016-11-10T04:43:00-02:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2016-11-10:blog/2016/11/10/trump_really/</id><summary type="html">&lt;p&gt;The US elections have got everyone startled. &lt;strong&gt;Trump&lt;/strong&gt;. Seriously. The most powerful man on the entire earth is Donald Trump. Just think about it for a second. The most coveted post in all world and America could not find a better person to fill it? Now to tell you the truth I was not at all surprised to see it happen. I don’t know if America has ever seen this brand of politics, we indians have seen this brand of politics many a times and have suffered a lot because of it.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;To put my case forward we have many a examples in our country like &lt;strong&gt;Bal Thackeray&lt;/strong&gt; whose slogan was “Uthao lungi aur bajao pungi” which basically meant send away the south indians back from Mumbai. He was worshipped in Mumbai by the local People for the same and around 1.5 Million people came to attend his funeral. His son Raj Thackeray has the same brand of politics but he wants to send away North Indians. Wow!&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Then there are issues of Caste based politics where people like Mulayam Singh and Mayawati would use reservations in India to their advantage to pull the caste vote bank.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Trump Brand of politics was pretty much the same — &lt;strong&gt;Divisive&lt;/strong&gt;. Get people against each other. Now that I think of it Hitler had the same formula.
The way this formula works is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Target a minority community by telling other community how its presence is badly effecting them.&lt;/li&gt;
&lt;li&gt;Promise to eliminate them.&lt;/li&gt;
&lt;li&gt;Win.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;This election could be posed as a study in psyche of a developed nation such as America. America as a nation may call itself inclusive, non sexist, and secular but a Trump win tells that people are two-faced. The one face that they want the world to see and the other they know they are.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;The pre election polls all had Hillary in the lead, but surveys forget the one element of Human Nature- the human psyche. How many people that supported trump would openly admit that they would vote for him? They don’t want to be branded sexist, misogynist, racist. But they picked a president which is all three.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;This election essentially provided us with two different types of bias that could occur in surveys.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;

&lt;h3&gt;Lie Bias:&lt;/h3&gt;
&lt;p&gt;People lied in the surveys. That much is certain. To say that they would support Trump was shameful to a lot of people. This bias could be linked to the response Bias in a way but here the people did not lie because they wanted to appease the questioner, they lied to appease themselves.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;Undecideds Bias:&lt;/h3&gt;
&lt;p&gt;The night before the elections the polls stood at 42% Trump, 46% Hillary, 12% Undecided. I would focus on the 12 % here. Where do you think these 12% votes went. This is just a speculation but there is a high chance that the undecideds were not undecideds at all. Most of them wanted to support Trump while keeping it under wraps and not lying. The undecided group proportion was high as compared to other election years. In 2008 and 2012 the undecideds were 4% and 3% respectively. so there is a ~8% increase in number of undecideds, and to what can we attribute that? The only thing that comes to my mind is that the people who were gonna vote trump were calling themselves undecided.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Now I would sincerely thank Mr Trump who put us in such a diabolical situation that provides us with such twisted biases and thereby close my rant.&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Pandas For All - Some Basic Pandas Functions</title><link href="http://mlwhiz.github.io/blog/2016/10/27/baby_panda/" rel="alternate"></link><updated>2016-10-27T04:43:00-02:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2016-10-27:blog/2016/10/27/baby_panda/</id><summary type="html">&lt;p&gt;It has been quite a few days I have been working with Pandas and apparently I feel I have gotten quite good at it. (Quite a Braggard I know)
So thought about adding a post about Pandas usage here. I intend to make this post quite practical and since I find the pandas syntax quite self explanatory, I won't be explaining much of the codes. Just the use cases and the code to achieve them.&lt;/p&gt;
&lt;h2&gt;1. Import Pandas&lt;/h2&gt;
&lt;p&gt;We Start by importing the libraries that we will need to use.&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;import pandas as pd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;2. Read a Datasource:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# Read from csv data files

# With Header
df = pd.read_csv("/Users/ragarw5/Downloads/SalesJan2009.csv")

# Without Header. sep param to provide the delimiter
df = pd.read_csv("/Users/ragarw5/Downloads/SalesJan2009.csv", header=None, sep= ",")

# Reading from SQL Datasource

import MySQLdb
from pandas import DataFrame
from pandas.io.sql import read_sql

db = MySQLdb.connect(host="localhost",    # your host, usually localhost
                     user="root",         # your username
                     passwd="password",   # your password
                     db="dbname")         # name of the data base

query = "SELECT * FROM tablename"

data = read_sql(query, db)

# Reading from ExcelFile
data = pd.read_excel(filename)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
For now, we will be working with the file at http://samplecsvs.s3.amazonaws.com/SalesJan2009.csv. The Sales Jan 2009 file contains some “sanitized” sales transactions during the month of January. If you want to work along you can download this file from that location.&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;df = pd.read_csv("/Users/ragarw5/Downloads/SalesJan2009.csv")
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;3. See few rows of data:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# top 5 rows
df.head()

# top 50 rows
df.head(50)

# last 5 rows
df.tail()

# last 50 rows
df.tail(50)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;4. Getting Column Names in a list:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;columnnames = df.columns
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;5. Specifying user defined Column Names:&lt;/h2&gt;
&lt;p&gt;Sometimes you want to change the column names:&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;df.columns = ['Transdate', 'Product', 'Price', 'PaymentType', 'Name',
       'City', 'State', 'Country', 'AccountCreated', 'LastLogin',
       'Latitude', 'Longitude']
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;6. Subsetting specific columns:&lt;/h2&gt;
&lt;p&gt;Sometimes you only need to work with specific columns in a dataframe only. You can subset the columns in the dataframe using&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;newDf = df[['Product', 'Price', 'PaymentType', 'Name', 'City', 'State', 'Country']]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;7. Seeing column types:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;newDf.dtypes&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;8. Change type of a column&lt;/h2&gt;
&lt;p&gt;First thing i try is this.
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;newDf['Price'] = newDf['Price'].astype('int')&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;It gives error : ValueError: invalid literal for long() with base 10: '13,000'. That is you cannot cast a string with "," to an int. To do that we first have to get rid of the comma. For that we use a particular lambda-apply functionality which lets us apply functions to each row in the data.&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;newDf['Price'] = newDf.apply(lambda x: int(x['Price'].replace(',', '')),axis=1)&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;

&lt;h2&gt;9. Simple Dataframe Statistics:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# To get statistics of numerical columns
newDf.describe()

# To get maximum value of a column. When you take a single column you can think of it as a list and apply functions you would apply to a list
max(newDf['Price'])

# no of rows in dataframe
len(newDf)

# Shape of Dataframe
newDf.shape&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;10. Creating a new column:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# Create a column Address containing City,State and Country. Simply concat the columns.
newDf['Address'] = newDf['City'] +","+ newDf['State'] +","+ newDf['Country']

# I like to use a function defined approach with lambda-apply as it gives me more flexibility and more options. Like if i want to create a column which is 1 if the price is greater than 1200 and 0 otherwise.

def gt(x):
    if x&gt;1200:
        return 1
    else:
        return 0

newDf['Pricegt1200'] = newDf.apply(lambda x: gt(x['Price']),axis=1)&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;11. Subset a DataFrame:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# Single condition: dataframe with all entries priced greater than 1500

df_gt_1500 = newDf[newDf['Price']&gt;1500]

# Multiple conditions: AND - dataframe with all entries priced greater than 1500 and from London

And_df = newDf[(newDf['Price']&gt;1500) &amp; (newDf['City']=='London')]

# Multiple conditions: OR - dataframe with all entries priced greater than 1500 or from London

Or_df = newDf[(newDf['Price']&gt;1500) | (newDf['City']=='London')]

# Multiple conditions: NOT - dataframe with all entries priced greater than 1500 or from London have to be excluded

Not_df = newDf[~((newDf['Price']&gt;1500) | (newDf['City']=='London'))]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;12. Change the Column at particular places or impute:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# In the state column the state is abbreviated as 'TX'. We want the whole name 'Texas' in there
newDf.loc[newDf['State']=='TX','State'] = 'Texas'

# When City is Monaco State is not given. You want to impute 'Monaco State' as state also.
newDf.loc[newDf['City']=='Monaco','State'] = 'Monaco State'
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;13. GroupBy:&lt;/h2&gt;
&lt;p&gt;One of the most used functionality. One simple example&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# Find out the sum of transactions by a state. reset_index() is a function that resets the index of a dataframe. I apply this function ALWAYS whenever I do a groupby and you might think of it as a default syntax for groupby operations
import numpy as np
newDf.groupby(['State']).aggregate(np.sum).reset_index()

# You might get a few extra columns that you dont need. Just subset the columns in the dataframe. You could just chain the commands to subset for the columns you need.
newDf.groupby(['State']).aggregate(np.sum).reset_index()[['State','Price']]

# Find minimum transaction in each state
newDf.groupby(['State']).aggregate(np.min).reset_index()[['State','Price']]

# You might want to groupby more than one column

newDf.groupby(['State','City']).aggregate(np.sum).reset_index()[['State','City','Price']]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;14. Concat:&lt;/h2&gt;
&lt;p&gt;You have two datarames df1 and df2 you need to concat. Means append one below the other you can do it using:&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;pd.concat([df1,df2])&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;15. Merge:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;#Suppose in the start, you had two dataframes. One which contains city and price information:
City_Price = newwDf[['City','Price']]

#And another which contains 'City' and 'State' insformation
City_State = newDf[['City','State']].drop_duplicates(keep=False).reset_index()

#You need to merge these datatframes on basis of city. You need to do:
City_Price_State_df = pd.merge(City_Price,City_State,on=['City'],how='left')
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;16. Save a Dataframe to external File:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# To Csv file
newDf.to_csv("NewDfData.csv",index=False)

# To Excel File
from pandas import ExcelWriter
writer =  ExcelWriter('NewDfData.xlsx')
newDf.to_excel(writer,'Sheet1')
writer.save()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;17. Pushing Pandas Df to a sql database:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;from pandas.io import sql
import MySQLdb

db = MySQLdb.connect(host="localhost",    # your host, usually localhost
                     user="root",         # your username
                     passwd="password",  # your password
                     db="dbname")        # name of the data base

newDf.to_sql(con = db, name='tablename',if_exists='append',flavor='mysql', chunksize=10000,index=False)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Hope you found this post useful and worth your time. I tried to make this as simple as possible but You may always &lt;strong&gt;ask me&lt;/strong&gt; or see the documentation for doubts.&lt;/p&gt;
&lt;p&gt;If you have &lt;strong&gt;any more ideas&lt;/strong&gt; on how to use Pandas or &lt;strong&gt;other usecases&lt;/strong&gt;, please suggest in the &lt;strong&gt;comments&lt;/strong&gt; section.&lt;/p&gt;
&lt;p&gt;Till then ciao!!&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://www.gregreda.com/2013/10/26/intro-to-pandas-data-structures/"&gt;Intro to Pandas By Greg Rada&lt;/a&gt; What I have written is in a condensed form, If you want to get a detailed description visit Greg Rada's 3 posts series.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pandas.pydata.org/pandas-docs/stable/"&gt;Pandas Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</summary><category term="Python"></category><category term="dataframe"></category><category term="data munging"></category><category term="pandas"></category></entry><entry><title>Deploying ML Apps using Python and Flask- Learning about Flask - Part 1</title><link href="http://mlwhiz.github.io/blog/2016/01/10/deploying_ML_Apps_using_Python_and_Flask/" rel="alternate"></link><updated>2016-01-10T04:43:00-02:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2016-01-10:blog/2016/01/10/deploying_ML_Apps_using_Python_and_Flask/</id><summary type="html">&lt;p&gt;It has been a long time since I wrote anything on my blog. So thought about giving everyone a treat this time. Or so I think it is.&lt;/p&gt;
&lt;p&gt;Recently I was thinking about a way to deploy all these machine learning models I create in python. I searched through the web but couldn't find anything nice and easy.
Then I fell upon &lt;a href="http://sebastianraschka.com/blog/2015/writing-pymle.html"&gt;this book&lt;/a&gt; by Sebastian Rashcka and I knew that it was what I was looking for.
To tell you the truth I did had some experience in Flask earlier but this book made it a whole lot easier to deploy a machine learning model in flask.&lt;/p&gt;
&lt;p&gt;So today I am going to give a brief intro about Flask Apps and how to deploy them using a service called Openshift.&lt;/p&gt;
&lt;h4&gt;So What is flask?&lt;/h4&gt;
&lt;p&gt;Flask is a Python Web Framework that makes it easier to create webapps from python.&lt;/p&gt;
&lt;h4&gt;And Openshift?&lt;/h4&gt;
&lt;p&gt;Openshift is a free service(if we only use 1 small instance) which lets us use their services to deploy our flask web-apps.&lt;/p&gt;
&lt;p&gt;So that we don't get lost, let me tell you the flow of this post.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First of all we will learn about the &lt;strong&gt;installation&lt;/strong&gt;* of Openshift and Flask.&lt;/li&gt;
&lt;li&gt;We will create a &lt;strong&gt;Hello World&lt;/strong&gt; application using Flask.&lt;/li&gt;
&lt;li&gt;We will work on creating a very &lt;strong&gt;simple calculator App&lt;/strong&gt; that operates on two numbers provided by the user. This will help us in understanding how user forms work with Flask by implementing a barebones app.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Installation:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Create your &lt;a href="https://www.openshift.com/app/account/new"&gt;FREE OpenShift account Here&lt;/a&gt; Very simple sign-up email + password only&lt;/li&gt;
&lt;li&gt;Install the &lt;a href="https://www.openshift.com/developers/install-the-client-tools"&gt;OpenShift Client Tools&lt;/a&gt;. Use these directions for your particular Operating System these tools have a command line interface and allow more control over your app. The OpenShift tool requires an installation of Ruby.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now once you do this you have installed Openshift Client tools on your system.&lt;/p&gt;
&lt;h2&gt;Helloworld&lt;/h2&gt;
&lt;p&gt;So now I am going to do a lot of things in this post. But don't get bothered much it is just code and HTML quirks. I will try to provide enough details on which parts are necessary.
First of all, you will need to create a domain on Openshift platform. This can be done by using:
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;rhc domain create -n DomainName -l EmailAddress -p password
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
For this example I created:
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;rhc domain create -n mlwhiz -l MyEmailAddress -p Mypassword
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
In the free version for Openshift you can run 3 web-apps with a single domain.
For example I can create a maximum of 3 webapps whose web address would be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;myappname1-mlwhiz.rhcloud.com&lt;/li&gt;
&lt;li&gt;myappname2-mlwhiz.rhcloud.com&lt;/li&gt;
&lt;li&gt;myappname3-mlwhiz.rhcloud.com&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once we create a domain we need to create a webapp:
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;rhc app create HelloWorld python-2.7
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
This creates the app named helloworld for us. The app currently resides at this address on web: http://helloworld-mlwhiz.rhcloud.com/
This command also creates a folder where our app resides. cd into this folder.
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cd helloworld
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
Now get a basic template to work upon in this directory. You can think of this as a starter code for flask. We can do this by pulling and merging from Github using the following commands.&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;git remote add upstream -m master git://github.com/openshift/flask-example.git
git pull -s recursive -X theirs upstream master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
Use Virtualenv to isolate Python development environments. It’s a tool that allows you setup an isolated, self-contained Python environment in a folder on your dev box. This way you can experiment with various versions of Python without affecting your system wide configurations:&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;brew install python-virtualenv
cd helloworld/wsgi/
virtualenv venv --python=python2.7
#Activate the virtual environment
. venv/bin/activate
# Install all these into your virtual python environment.
pip install flask flask-wtf flask-babel markdown flup
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
Now Change the name of flaskapp.py in wsgi to run.py&lt;/p&gt;
&lt;p&gt;put this code in run.py
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;import os
from flask import Flask
app = Flask(&lt;strong&gt;name&lt;/strong&gt;)
@app.route('/')
def home():
    """Render website's home page."""
    return 'Hello World!'
if &lt;strong&gt;name&lt;/strong&gt; == '&lt;strong&gt;main&lt;/strong&gt;':
    app.run(debug="True")
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Also change the file named application to:
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;#!/usr/bin/python
import os
import sys
sys.path.insert(0, os.path.dirname(&lt;strong&gt;file&lt;/strong&gt;) or '.')
PY_DIR = os.path.join(os.environ['OPENSHIFT_HOMEDIR'], "python")
virtenv = PY_DIR + '/virtenv/'
PY_CACHE = os.path.join(virtenv, 'lib', os.environ['OPENSHIFT_PYTHON_VERSION'], 'site-packages')
os.environ['PYTHON_EGG_CACHE'] = os.path.join(PY_CACHE)
virtualenv = os.path.join(virtenv, 'bin/activate_this.py')
try:
    exec(open(virtualenv).read(), dict(&lt;strong&gt;file&lt;/strong&gt;=virtualenv))
except IOError:
    pass
from run import app as application
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Run this to host your app:
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cd helloworld/wsgi
python run.py
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;&lt;/p&gt;
&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;

&lt;p&gt;You should be able to see your app on: http://127.0.0.1:5000/
You can deploy this webapp to Openshift using:
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cd helloworld
git add .
git commit -a -m "Initial deployment of this app to the web"
git push
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Open http://helloworld-mlwhiz.rhcloud.com/ in your browser. You would see Hello World! there. Now we have got a very basic structure complete.&lt;/p&gt;
&lt;h2&gt;Our Simple Calculator App:&lt;/h2&gt;
&lt;p&gt;We will now work on creating a app that operates on two numbers provided by the user. The functions possible are +,- and *.
You can see this web app in action &lt;a href="http://helloworld-mlwhiz.rhcloud.com/"&gt;here&lt;/a&gt; before moving on.
This app will help us in understanding how user forms work with Flask and how to manage user inputs in Flask.
First of all change the code in run.py to&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;import os
from flask import Flask,render_template, request
from wtforms import Form, TextAreaField, validators,SelectField

app = Flask(__name__)

# Code to create a WTForm with three fields. 2 text fields and 1 dropdown menu.
class OutputForm(Form):
    myChoices=[('+', '+'), ('-', '-'), ('*', '*')]
    num1 = TextAreaField('',[validators.DataRequired()])
    num2 = TextAreaField('',[validators.DataRequired()])
    Operator = SelectField(u'', choices = myChoices, validators = [validators.DataRequired()])

# This uses the render_template method in flask to use a template first_app.html.
# This html contains placeholders for the form that is provided in the kwargs argument to the function call.
@app.route('/')
def index():
    #return 'Hello World!'
    form = OutputForm(request.form)
    return render_template('first_app.html',form = form)

# This is the output that is displayed. It checks if the form is validated and POST request is made.
# If true it renders the output.html else renders the main index page.
# Most of the work is done here. Gets the user inputs using the request.form method.
@app.route('/output', methods=['POST'])
def output():
    form = OutputForm(request.form)
    if request.method == 'POST' and form.validate():
        num1 = request.form['num1']
        num2 = request.form['num2']
        op = request.form['Operator']
        if op=="+":
            name=str(int(num1)+int(num2))
        elif op=="-":
            name=str(int(num1)-int(num2))
        elif op=="*":
            name=str(int(num1)*int(num2))
        return render_template('output.html', name=name)
    return render_template('first_app.html', form=form)

if __name__ == '__main__':
    app.run(debug="True")
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;We use WTF forms here to create a form object. We pass this form object to the HTML render_template method. We have accessed these again in the output function so that we can show them in output.html where all the major work is done for creating the app.&lt;/p&gt;
&lt;p&gt;Now Create a folder named template in helloworld/wsgi and create a file named _formhelpers.html with this content. You really don't need to see the content in this file.
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="html"&gt;{% macro render_field(field) %}
    &amp;lt;dt&amp;gt;{{ field.label }}
    &amp;lt;dd&amp;gt;{{ field(**kwargs)|safe }}
    {% if field.errors %}
        &amp;lt;ul class=errors&amp;gt;
        {% for error in field.errors %}
            &amp;lt;li&amp;gt;{{ error }}&amp;lt;/li&amp;gt;
        {% endfor %}
        &amp;lt;/ul&amp;gt;
    {% endif %}
    &amp;lt;/dd&amp;gt;
{% endmacro %}
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Also add another file named first_app.html with this content. Notice how we access the wtform here.&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="html"&gt;&amp;lt;!doctype html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;First app&amp;lt;/title&amp;gt;
&amp;lt;link rel="stylesheet" href="{{ url_for('static',filename='style.css') }}"&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
    {% from "_formhelpers.html" import render_field %}
    &amp;lt;div&amp;gt;Calculator: Please enter two numbers and a function you want to apply&amp;lt;/div&amp;gt;
    &amp;lt;form method=post action="/output"&amp;gt;
    {{ render_field(form.num1) }}{{ render_field(form.Operator) }}{{ render_field(form.num2) }}
        &amp;lt;input type=submit value='Result' name='submit_btn'&amp;gt;
    &amp;lt;/form&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Create a file named output.html where the final output will be shown.&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="html"&gt;&amp;lt;!doctype html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;First app&amp;lt;/title&amp;gt;
&amp;lt;link rel="stylesheet" href="{{ url_for('static',filename='style.css') }}"&amp;gt;
&amp;lt;/head&amp;gt;
    &amp;lt;body&amp;gt;
        &amp;lt;div&amp;gt;The output is: {{ name }}&amp;lt;/div&amp;gt;
    &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Also add a style.css file in the static folder. You can put this in it for right now or any other thing you want.
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="html"&gt;h1 {
    color: blue;
    font-family: verdana;
    font-size: 300%;
}
p  {
    color: red;
    font-family: courier;
    font-size: 160%;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
And we are mostly done. Run run.py in the wsgi directory and you would be able to access the app at : http://127.0.0.1:5000/.
Again deploy this webapp to Openshift using:&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cd helloworld
git add .
git commit -a -m "Initial deployment of this app to the web"
git push
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;Endnotes&lt;/h2&gt;
&lt;p&gt;So here we took inputs from the user and show the output using the flask App. The final app is hosted at http://helloworld-mlwhiz.rhcloud.com/ for you to see.
This code provides us with a code skeletn which will be valuable when we will deploy a whole ML model, which is the main motive of this series.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Most of the code here is taken from this awesome book by Sebastian Raschka: &lt;a rel="nofollow" href="http://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1783555130&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=QOKIQ2S5LIQI7L2N"&gt;Python Machine Learning&lt;/a&gt;&lt;img src="http://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=as2&amp;o=1&amp;a=1783555130" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;&lt;/li&gt;
&lt;li&gt;https://blog.openshift.com/beginners-guide-to-writing-flask-apps-on-openshift/&lt;/li&gt;
&lt;/ol&gt;</summary><category term="FlaskApp"></category><category term="Deploy ML Models"></category><category term="Openshift"></category></entry><entry><title>Shell Basics every Data Scientist Should know - Part II(AWK)</title><link href="http://mlwhiz.github.io/blog/2015/10/11/shell_basics_for_data_science_2/" rel="alternate"></link><updated>2015-10-11T04:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2015-10-11:blog/2015/10/11/shell_basics_for_data_science_2/</id><summary type="html">&lt;div class="entry-content"&gt;&lt;p&gt;Yesterday I got introduced to awk programming on the shell and is it cool.
It lets you do stuff on the command line which you never imagined. As a matter of fact, it's a whole data analytics software in itself when you think about it. You can do selections, groupby, mean, median, sum, duplication, append. You just ask. There is no limit actually.&lt;/p&gt;
&lt;p&gt;And it is easy to learn.&lt;/p&gt;
&lt;p&gt;In this post, I will try to give you a brief intro about how you could add awk to your daily work-flow.&lt;/p&gt;
&lt;p&gt;Please see my previous &lt;a href="http://mlwhiz.com/blog/2015/10/09/shell_basics_for_data_science/"&gt;post&lt;/a&gt; if you want some background or some basic to intermediate understanding of shell commands.&lt;/p&gt;
&lt;h2&gt;Basics/ Fundamentals&lt;/h2&gt;
&lt;p&gt;So let me start with an example first. Say you wanted to sum a column in a comma delimited file. How would you do that in shell? &lt;/p&gt;
&lt;p&gt;Here is the command. The great thing about awk is that it took me nearly 5 sec to write this command. I did not have to open any text editor to write a python script. &lt;/p&gt;
&lt;p&gt;It lets you do adhoc work quickly.&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;awk 'BEGIN{ sum=0; FS=","} { sum += $5 } END { print sum }' data.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
44662539172
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;See the command one more time. There is a basic structure to the awk command&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;BEGIN&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;END&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;An awk program consists of:&lt;/p&gt;
&lt;div class="no-mathjax"  style="margin-left:1em;"&gt;
&lt;li&gt;An optional BEGIN segment : In the begin part we initialize our variables before we even start reading from the file or the standard input.&lt;/li&gt;
&lt;li&gt;pattern - action pairs: In the middle part we Process the input data. You put multiple pattern action pairs when you want to do multiple things with the same line.&lt;/li&gt;
&lt;li&gt;An optional END segment: In the end part we do something we want to do when we have reached the end of file.&lt;/li&gt;
&lt;/div&gt;

&lt;p&gt;An awk command is called on a file using:
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;awk 'BEGIN{SOMETHING HERE} {SOMETHING HERE: could put Multiple Blocks Like this} END {SOMETHING HERE}' file.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
You also need to know about these preinitialized variables that awk keeps track of.:
&lt;div class="no-mathjax"  style="margin-left:2em;"&gt;
&lt;ol&gt;&lt;li&gt;FS : field separator. Default is whitespace (1 or more spaces or tabs). If you are using any other seperator in the file you should specify it in the Begin Part.&lt;/li&gt;
&lt;li&gt;RS : record separator. Default record separator is newline. Can be changed in BEGIN action.&lt;/li&gt;
&lt;li&gt;NR : NR is the variable whose value is the number of the current record. You normally use it in the action blocks in the middle.&lt;/li&gt;
&lt;li&gt;NF : The Number of Fields after the single line has been split up using FS.&lt;/li&gt;
&lt;li&gt;Dollar variables : awk splits up the line which is coming to it by using the given FS and keeps the split parts in the $ variables. For example column 1 is in $1, column 2 is in $2. $0 is the string representation of the whole line. Note that if you want to access last column you don't have to count. You can just use $NF. For second last column you can use $(NF-1). Pretty handy. Right.&lt;/li&gt;&lt;/ol&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;So If you are with me till here, the hard part is done. Now the fun part starts. Lets look at the first awk command again and try to understand it.&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;awk 'BEGIN{ sum=0; FS=","} { sum += $5 } END { print sum }' data.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;So there is a begin block. Remember before we read any line. We initialize sum to 0 and FS to ",".&lt;/p&gt;
&lt;div class="no-mathjax"&gt;
Now as awk reads its input line by line it increments sum by the value in column 5(as specified by $5).
&lt;/div&gt;

&lt;p&gt;Note that there is no pattern specified here so awk will do the action for every line. &lt;/p&gt;
&lt;p&gt;When awk has completed reading the file it prints out the sum.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What if you wanted mean?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We could create a cnt Variable:&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;awk 'BEGIN{ sum=0;cnt=0; FS=","} { sum += $5; cnt+=1 } END { print sum/cnt }' data.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
1.86436e+06
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
or better yet, use our friend NR which bash is alreay keeping track of:
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;awk 'BEGIN{ sum=0; FS=","} { sum += $5 } END { print sum/NR }' data.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
1.86436e+06
&lt;/pre&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;Filter a file&lt;/h2&gt;
&lt;p&gt;In the mean and sum awk commands we did not put any pattern in our middle commands. Let us use a simple pattern now. Suppose we have a file Salaries.csv which contains:&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;head salaries.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
yearID,teamID,lgID,playerID,salary
1985,BAL,AL,murraed02,1472819
1985,BAL,AL,lynnfr01,1090000
1985,BAL,AL,ripkeca01,800000
1985,BAL,AL,lacyle01,725000
1985,BAL,AL,flanami01,641667
1985,BAL,AL,boddimi01,625000
1985,BAL,AL,stewasa01,581250
1985,BAL,AL,martide01,560000
1985,BAL,AL,roeniga01,558333
&lt;/pre&gt;

&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;

&lt;p&gt;&lt;br&gt;
I want to filter records for players who who earn more than 22 M in 2013 just because I want to. You just do:
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;awk 'BEGIN{FS=","} $5&amp;gt;=22000000 &amp;amp;&amp;amp; $1==2013{print $0}' Salaries.csv
&lt;/code&gt;&lt;/pre&gt;
&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
2013,DET,AL,fieldpr01,23000000
2013,MIN,AL,mauerjo01,23000000
2013,NYA,AL,rodrial01,29000000
2013,NYA,AL,wellsve01,24642857
2013,NYA,AL,sabatcc01,24285714
2013,NYA,AL,teixema01,23125000
2013,PHI,NL,leecl02,25000000
2013,SFN,NL,linceti01,22250000
&lt;/pre&gt;
&lt;br&gt;
&lt;div class="no-mathjax"&gt;
Cool right. Now let me explain it a little bit. The part in the command "$5&amp;gt;=22000000 &amp;amp;&amp;amp; $1==2013" is called a pattern. It says that print this line($0) if and only if the Salary($5) is more than 22M and(&amp;amp;&amp;amp;) year($1) is equal to 2013. If the incoming record(line) does not satisfy this pattern it never reaches the inner block.
&lt;/div&gt;
So Now you could do basic Select SQL at the command line only if you had:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The logic Operators:&lt;/strong&gt;
&lt;div class="no-mathjax"  style="margin-left:1em;"&gt;
&lt;li&gt;  == equality operator; returns TRUE is both sides are equal&lt;/li&gt;
&lt;li&gt; != inverse equality operator&lt;/li&gt;
&lt;li&gt; &amp;amp;&amp;amp; logical AND&lt;/li&gt;
&lt;li&gt; || logical OR&lt;/li&gt;
&lt;li&gt; ! logical NOT&lt;/li&gt;
&lt;li&gt; &amp;lt;, &amp;gt;, &amp;lt;=, &amp;gt;= relational operators&lt;/li&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Normal Arithmetic Operators:&lt;/strong&gt; +, -, /, *, %, ^&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Some String Functions:&lt;/strong&gt; length, substr, split&lt;/p&gt;
&lt;h2&gt;GroupBy&lt;/h2&gt;
&lt;p&gt;Now you will say: "Hey Dude SQL without groupby is incomplete". You are right and for that we can use the associative array. Lets just see the command first and then I will explain. So lets create another useless use case(or may be something useful to someone :))
We want to find out the number of records for each year in the file. i.e we want to find the distribution of years in the file. Here is the command:&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;awk 'BEGIN{FS=","}
{my_array[$1]=my_array[$1]+1}
END{
for (k in my_array){if(k!="yearID")print k"|"my_array[k]};
}' Salaries.csv
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
1990|867
1991|685
1996|931
1997|925
...
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
Now I would like to tell you a secret. You don't really need to declare the variables you want to use in awk. So you did not really needed to define sum, cnt variables before. I only did that because it is good practice. If you don't declare a user defined variable in awk, awk assumes it to be null or zero depending on the context. So in the command above we don't declare our myarray in the begin block and that is fine.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Associative Array&lt;/strong&gt;: The variable myarray is actually an associative array. i.e. It stores data in a key value format.(Python dictionaries anyone). The same array could keep integer keys and String keys. For example, I can do this in a single code.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;myarray&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;key&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;myarray&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;mlwhiz&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;For Loop for associative arrays&lt;/strong&gt;: I could use a for loop to read associative array&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;DO&lt;/span&gt; &lt;span class="n"&gt;SOMETHING&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="cp"&gt;# Assigns to k each Key of array (unordered)&lt;/span&gt;
&lt;span class="cp"&gt;# Element is array[k]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;If Statement&lt;/strong&gt;:Uses a syntax like C for the if statement. the else block is optional: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
  &lt;span class="n"&gt;DO&lt;/span&gt; &lt;span class="n"&gt;SOMETHING&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;DO&lt;/span&gt; &lt;span class="n"&gt;SOMETHING&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So lets dissect the above command now.&lt;/p&gt;
&lt;p&gt;I set the File separator to "," in the beginning. I use the first column as the key of myarray. If the key exists I increment the value by 1.&lt;/p&gt;
&lt;p&gt;At the end, I loop through all the keys and print out key value pairs separated by "|"&lt;/p&gt;
&lt;p&gt;I know that the header line in my file contains "yearID" in column 1 and I don't want 'yearID|1' in the output. So I only print when Key is not equal to 'yearID'.&lt;/p&gt;
&lt;h2&gt;GroupBy with case statement:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat Salaries.csv | awk 'BEGIN{FS=","}
$5&lt;100000{array5["[0-100000)"]+=1}
$5&gt;=100000&amp;&amp;$5&lt;250000{array5["[100000,250000)"]=array5["[100000,250000)"]+1}
$5&gt;=250000&amp;&amp;$5&lt;500000{array5["[250000-500000)"]=array5["[250000-500000)"]+1}
$5&gt;=500000&amp;&amp;$5&lt;1000000{array5["[500000-1000000)"]=array5["[500000-1000000)"]+1}
$5&gt;=1000000{array5["[1000000)"]=array5["[1000000)"]+1}
END{
print "VAR Distrib:";
for (v in array5){print v"|"array5[v]}
}'
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
VAR Distrib:
[250000-500000)|8326
[0-100000)|2
[1000000)|23661
[100000,250000)|9480
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
Here we used multiple pattern-action blocks to create a case statement.&lt;/p&gt;
&lt;h2&gt;For The Brave:&lt;/h2&gt;
&lt;p&gt;This is a awk code that I wrote to calculate the Mean,Median,min,max and sum of a column simultaneously. Try to go through the code and understand it.I have added comments too.
Think of this as an exercise. Try to run this code and play with it. You may learn some new tricks in the process.
If you don't understand it do not worry. Just get started writing your own awk codes, you will be able to understand it in very little time.&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;# Create a New file named A.txt to keep only the salary column.
cat Salaries.csv | cut -d "," -f 5 &gt; A.txt
FILENAME="A.txt"

# The first awk counts the number of lines which are numeric. We use a regex here to check if the column is numeric or not.
# ';' stands for Synchronous execution i.e sort only runs after the awk is over.
# The output of both commands are given to awk command which does the whole work.
# So Now the first line going to the second awk is the number of lines in the file which are numeric.
# and from the second to the end line the file is sorted.
(awk 'BEGIN {c=0} $1 ~ /^[-0-9]*(\.[0-9]*)?$/ {c=c+1;} END {print c;}' "$FILENAME"; \
        sort -n "$FILENAME") | awk '
  BEGIN {
    c = 0;
    sum = 0;
    med1_loc = 0;
    med2_loc = 0;
    med1_val = 0;
    med2_val = 0;
    min = 0;
    max = 0;
  }

  NR==1 {
    LINES = $1
    # We check whether numlines is even or odd so that we keep only
    # the locations in the array where the median might be.
    if (LINES%2==0) {med1_loc = LINES/2-1; med2_loc = med1_loc+1;}
    if (LINES%2!=0) {med1_loc = med2_loc = (LINES-1)/2;}
  }

  $1 ~ /^[-0-9]*(\.[0-9]*)?$/  &amp;&amp;  NR!=1 {
    # setting min value
    if (c==0) {min = $1;}
    # middle two values in array
    if (c==med1_loc) {med1_val = $1;}
    if (c==med2_loc) {med2_val = $1;}
    c++
    sum += $1
    max = $1
  }
  END {
    ave = sum / c
    median = (med1_val + med2_val ) / 2
    print "sum:" sum
    print "count:" c
    print "mean:" ave
    print "median:" median
    print "min:" min
    print "max:" max
  }
'
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
sum:44662539172
count:23956
mean:1.86436e+06
median:507950
min:0
max:33000000
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;Endnote:&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;awk&lt;/strong&gt; is an awesome tool and there are a lot of use-cases where it can make your life simple. There is a sort of a learning curve, but I think that it would be worth it in the long term. I have tried to give you a taste of awk and I have covered a lot of ground here in this post. To tell you a bit more there, awk is a full programming language. There are for loops, while loops, conditionals, booleans, functions and everything else that you would expect from a programming language. So you could look more still. &lt;/p&gt;
&lt;p&gt;To learn more about awk you can use this &lt;a href="http://ir.nmu.org.ua/bitstream/handle/123456789/143548/ecf2f2d8a72e7c3cffca0036a73aeed4.pdf?sequence=1&amp;amp;"&gt;book&lt;/a&gt;. This book is a free resource and you could learn more about awk and use cases.&lt;/p&gt;
&lt;p&gt;Or if you like to have your book binded and in paper like me you can buy this book, which is a gem:&lt;/p&gt;
&lt;div style="text-align: center;"&gt;
&lt;a href="http://www.amazon.com/gp/product/1565922255/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1565922255&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=YC37WW67AJHS3T6S"&gt;&lt;img border="0" src="http://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1565922255&amp;Format=_SL250_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="http://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=as2&amp;o=1&amp;a=1565922255" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;

&lt;p&gt;Do leave comments in case you find more use-cases for awk or if you want me to write on new use-cases. Or just comment weather you liked it or not and how I could improve as I am also new and trying to learn more of this.&lt;/p&gt;
&lt;p&gt;Till then Ciao !!!&lt;/p&gt;&lt;/div&gt;</summary><category term="bash commands"></category><category term="bash for data science"></category></entry><entry><title>Shell Basics every Data Scientist Should know -Part I</title><link href="http://mlwhiz.github.io/blog/2015/10/09/shell_basics_for_data_science/" rel="alternate"></link><updated>2015-10-09T04:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2015-10-09:blog/2015/10/09/shell_basics_for_data_science/</id><summary type="html">&lt;p&gt;&lt;div class="entry-content"&gt;&lt;p&gt;Shell Commands are powerful. And life would be like &lt;strong&gt;hell without shell&lt;/strong&gt; is how I like to say it(And that is probably the reason that I dislike windows).&lt;/p&gt;
&lt;p&gt;Consider a case when you have a 6 GB pipe-delimited file sitting on your laptop and you want to find out the count of distinct values in one particular column. You can probably do this in more than one way. You could put that file in a database and run SQL Commands, or you could write a python/perl script.&lt;/p&gt;
&lt;p&gt;Probably whatever you do it won't be simpler/less time consuming than this&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat data.txt | cut -d "|" -f 1 | sort | uniq | wc -l
&lt;/code&gt;&lt;/pre&gt;
&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;30
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;And this will &lt;strong&gt;run way faster&lt;/strong&gt; than whatever you do with perl/python script.&lt;/p&gt;

&lt;p&gt;Now this command says:
&lt;div style="margin-left:1em;"&gt;
&lt;ul&gt;
&lt;li&gt; Use the &lt;strong&gt;cat&lt;/strong&gt; command to print/stream the contents of the file to stdout.&lt;/li&gt;
&lt;li&gt; Pipe the streaming contents from our cat command to the next command &lt;strong&gt;cut&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt; The &lt;strong&gt;cut&lt;/strong&gt; commands specifies the delimiter by the argument &lt;strong&gt;-d&lt;/strong&gt; and the column by the argument &lt;strong&gt;-f&lt;/strong&gt; and streams the output to stdout.&lt;/li&gt;
&lt;li&gt; Pipe the streaming content to the &lt;strong&gt;sort&lt;/strong&gt; command which sorts the input and streams only the distinct values to the stdout. It takes the argument &lt;strong&gt;-u&lt;/strong&gt; that specifies that we only need unique values.&lt;/li&gt;
&lt;li&gt; Pipe the output to the wc -l  command which counts the number of lines in the input.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;There is a &lt;strong&gt;lot going on here&lt;/strong&gt; and I will try my best to ensure that &lt;strong&gt;you will be able to understand most of it by the end of this Blog post&lt;/strong&gt;.Although I will also try to explain more advanced concepts than the above command in this post.&lt;/p&gt;

&lt;p&gt;Now, I use shell commands extensively at my job. I will try to explain the usage of each of the commands based on use cases that I counter nearly daily at may day job as a data scientist.&lt;/p&gt;

&lt;h2&gt;Some Basic Commands in Shell:&lt;/h2&gt;

&lt;p&gt;There are a lot of times when you just need to know a little bit about the data. You just want to see may be a couple of lines to inspect a file. One way of doing this is opening the txt/csv file in the notepad. And that is probably the best way for small files. But you could also do it in the shell using:&lt;/p&gt;

&lt;h2&gt;1. cat&lt;/h2&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat data.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
yearID|teamID|lgID|playerID|salary
1985|BAL|AL|murraed02|1472819
1985|BAL|AL|lynnfr01|1090000
1985|BAL|AL|ripkeca01|800000
1985|BAL|AL|lacyle01|725000
1985|BAL|AL|flanami01|641667
1985|BAL|AL|boddimi01|625000
1985|BAL|AL|stewasa01|581250
1985|BAL|AL|martide01|560000
1985|BAL|AL|roeniga01|558333
&lt;/pre&gt;

&lt;p&gt;Now the &lt;a href="https://en.wikipedia.org/wiki/Cat_%28Unix%29"&gt;cat&lt;/a&gt; command prints the whole file in the terminal window for you.I have not shown the whole file here.&lt;/p&gt;

&lt;p&gt;But sometimes the files will be so big that you wont be able to open them up in notepad++ or any other software utility and there the cat command will shine.&lt;/p&gt;

&lt;h2&gt;2. Head and Tail&lt;/h2&gt;

&lt;p&gt;Now you might ask me why would you print the whole file in the terminal itself? Generally I won't. But I just wanted to tell you about the cat command. For the use case when you want only the top/bottom n lines of your data you will generally use the &lt;a href="https://en.wikipedia.org/wiki/Head_%28Unix%29"&gt;head&lt;/a&gt;/&lt;a href="https://en.wikipedia.org/wiki/Tail_%28Unix%29"&gt;tail&lt;/a&gt; commands. You can use them as below.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;head data.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
yearID|teamID|lgID|playerID|salary
1985|BAL|AL|murraed02|1472819
1985|BAL|AL|lynnfr01|1090000
1985|BAL|AL|ripkeca01|800000
1985|BAL|AL|lacyle01|725000
1985|BAL|AL|flanami01|641667
1985|BAL|AL|boddimi01|625000
1985|BAL|AL|stewasa01|581250
1985|BAL|AL|martide01|560000
1985|BAL|AL|roeniga01|558333
&lt;/pre&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;head -n 3 data.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
yearID|teamID|lgID|playerID|salary
1985|BAL|AL|murraed02|1472819
1985|BAL|AL|lynnfr01|1090000
&lt;/pre&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;tail data.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
2013|WAS|NL|bernaro01|1212500
2013|WAS|NL|tracych01|1000000
2013|WAS|NL|stammcr01|875000
2013|WAS|NL|dukeza01|700000
2013|WAS|NL|espinda01|526250
2013|WAS|NL|matthry01|504500
2013|WAS|NL|lombast02|501250
2013|WAS|NL|ramoswi01|501250
2013|WAS|NL|rodrihe03|501000
2013|WAS|NL|moorety01|493000
&lt;/pre&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;tail -n 2 data.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
2013|WAS|NL|rodrihe03|501000
2013|WAS|NL|moorety01|493000
&lt;/pre&gt;

&lt;p&gt;Notice the structure of the shell command here. &lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;CommandName&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;arg1name&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;arg1value&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;arg2name&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;arg2value&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;3. Piping&lt;/h2&gt;

&lt;p&gt;Now we could have also written the same command as:&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat data.txt | head
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
yearID|teamID|lgID|playerID|salary
1985|BAL|AL|murraed02|1472819
1985|BAL|AL|lynnfr01|1090000
1985|BAL|AL|ripkeca01|800000
1985|BAL|AL|lacyle01|725000
1985|BAL|AL|flanami01|641667
1985|BAL|AL|boddimi01|625000
1985|BAL|AL|stewasa01|581250
1985|BAL|AL|martide01|560000
1985|BAL|AL|roeniga01|558333
&lt;/pre&gt;

&lt;p&gt;This brings me to one of the most important concepts of Shell usage - &lt;a href="https://en.wikipedia.org/wiki/Pipeline_%28Unix%29"&gt;&lt;strong&gt;piping&lt;/strong&gt;&lt;/a&gt;.
You won't be able to utilize the full power the shell provides without using this concept.
And the concept is actually simple.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Just read the "|" in the command as "pass the data on to"&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;So I would read the above command as:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;cat&lt;/em&gt;(print) the whole data to stream, &lt;strong&gt;pass the data on to&lt;/strong&gt; &lt;em&gt;head&lt;/em&gt; so that it can just give me the first few lines only.&lt;/p&gt;

&lt;p&gt;So did you understood what piping did? &lt;strong&gt;It is providing us a way to use our basic commands in a consecutive manner&lt;/strong&gt;. There are a lot of commands that are fairly basic and it lets us use these basic commands in sequence to do some fairly non trivial things.&lt;/p&gt;

&lt;p&gt;Now let me tell you about a couple of more commands before I show you how we can &lt;strong&gt;chain&lt;/strong&gt; them to do fairly advanced tasks.&lt;/p&gt;

&lt;h2&gt;4. wc&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Wc_%28Unix%29"&gt;wc&lt;/a&gt; is a fairly useful shell utility/command that lets us &lt;strong&gt;count the number of lines(-l)&lt;/strong&gt;, &lt;strong&gt;words(-w)&lt;/strong&gt; or &lt;strong&gt;characters(-c)&lt;/strong&gt; in a given file&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;wc -l data.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
23957 data.txt
&lt;/pre&gt;

&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2&gt;5. grep&lt;/h2&gt;

&lt;p&gt;You may want to print all the lines in your file which have a particular word. Or as a Data case you might like to see the salaries for the team BAL in 2000. In this case we have printed all the lines in the file which contain "2000|BAL". &lt;a href="https://en.wikipedia.org/wiki/Grep"&gt;grep&lt;/a&gt; is your friend.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;grep "2000|BAL" data.txt | head
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
2000|BAL|AL|belleal01|12868670
2000|BAL|AL|anderbr01|7127199
2000|BAL|AL|mussimi01|6786032
2000|BAL|AL|ericksc01|6620921
2000|BAL|AL|ripkeca01|6300000
2000|BAL|AL|clarkwi02|6000000
2000|BAL|AL|johnsch04|4600000
2000|BAL|AL|timlimi01|4250000
2000|BAL|AL|deshide01|4209324
2000|BAL|AL|surhobj01|4146789
&lt;/pre&gt;

&lt;p&gt;you could also use regular expressions with grep. &lt;/p&gt;

&lt;h2&gt;6. sort&lt;/h2&gt;

&lt;p&gt;You may want to &lt;a href="https://en.wikipedia.org/wiki/Sort_%28Unix%29"&gt;sort&lt;/a&gt; your dataset on a particular column.Sort is your friend.
Say you want to find out the top 10 maximum salaries given to any player in your dataset.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;sort -t "|" -k 5 -r -n data.txt | head -10
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
2010|NYA|AL|rodrial01|33000000
2009|NYA|AL|rodrial01|33000000
2011|NYA|AL|rodrial01|32000000
2012|NYA|AL|rodrial01|30000000
2013|NYA|AL|rodrial01|29000000
2008|NYA|AL|rodrial01|28000000
2011|LAA|AL|wellsve01|26187500
2005|NYA|AL|rodrial01|26000000
2013|PHI|NL|leecl02|25000000
2013|NYA|AL|wellsve01|24642857
&lt;/pre&gt;

&lt;p&gt;So there are certainly a lot of options in this command. Lets go through them one by one.&lt;/p&gt;

&lt;div style="margin-left:1em"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;-t&lt;/strong&gt;: Which delimiter to use?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-k&lt;/strong&gt;: Which column to sort on?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-n&lt;/strong&gt;: If you want Numerical Sorting. Dont use this option if you want Lexographical sorting.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-r&lt;/strong&gt;: I want to sort Descending. Sorts Ascending by Default.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;h2&gt;7. cut&lt;/h2&gt;

&lt;p&gt;This command lets you select certain columns from your data. Sometimes you may want to look at just some of the columns in your data. As in you may want to look only at the year, team and salary and not the other columns. &lt;a href="https://en.wikipedia.org/wiki/Cut_(Unix)"&gt;cut&lt;/a&gt; is the command to use.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cut -d "|" -f 1,2,5 data.txt | head
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
yearID|teamID|salary
1985|BAL|1472819
1985|BAL|1090000
1985|BAL|800000
1985|BAL|725000
1985|BAL|641667
1985|BAL|625000
1985|BAL|581250
1985|BAL|560000
1985|BAL|558333
&lt;/pre&gt;

&lt;p&gt;The options are:
&lt;div style="margin-left:1em"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;-d&lt;/strong&gt;: Which delimiter to use?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-f&lt;/strong&gt;: Which column/columns to cut?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;h2&gt;8. uniq&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Uniq"&gt;uniq&lt;/a&gt; is a little bit tricky as in you will want to use this command in sequence with sort. This command removes sequential duplicates. So in conjunction with sort it can be used to get the distinct values in the data. For example if I wanted to find out 10 distinct teamIDs in data, I would use:&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat data.txt | cut -d "|" -f 2 | sort | uniq | head
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
ANA
ARI
ATL
BAL
BOS
CAL
CHA
CHN
CIN
CLE
&lt;/pre&gt;

&lt;p&gt;This command could be used with argument &lt;strong&gt;-c&lt;/strong&gt; to count the occurrence of these distinct values. Something akin to &lt;strong&gt;count distinct&lt;/strong&gt;.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat data.txt | cut -d "|" -f 2 | sort | uniq -c | head
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
247 ANA
458 ARI
838 ATL
855 BAL
852 BOS
368 CAL
812 CHA
821 CHN
46 CIN
867 CLE
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2&gt;Some Other Utility Commands for Other Operations&lt;/h2&gt;

&lt;p&gt;Some Other command line tools that you could use without going in the specifics as the specifics are pretty hard.&lt;/p&gt;

&lt;h2&gt;1. Change delimiter in a file&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Find and Replace Magic.&lt;/strong&gt;: You may want to replace certain characters in file with something else using the &lt;a href="https://en.wikipedia.org/wiki/Tr_%28Unix%29"&gt;tr&lt;/a&gt; command.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat data.txt | tr '|' ',' |  head -4
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
yearID,teamID,lgID,playerID,salary
1985,BAL,AL,murraed02,1472819
1985,BAL,AL,lynnfr01,1090000
1985,BAL,AL,ripkeca01,800000
&lt;/pre&gt;

&lt;p&gt;or the &lt;a href="https://en.wikipedia.org/wiki/Sed"&gt;&lt;strong&gt;sed&lt;/strong&gt;&lt;/a&gt; command&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat data.txt | sed -e 's/|/,/g' | head -4
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
yearID,teamID,lgID,playerID,salary
1985,BAL,AL,murraed02,1472819
1985,BAL,AL,lynnfr01,1090000
1985,BAL,AL,ripkeca01,800000
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2&gt;2. Sum of a column in a file&lt;/h2&gt;

&lt;p&gt;Using the &lt;a href="https://en.wikipedia.org/wiki/AWK"&gt;awk&lt;/a&gt; command you could find the sum of column in file. Divide it by the number of lines and you can get the mean.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat data.txt | awk -F "|" '{ sum += $5 } END { printf sum }'
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
44662539172
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
awk is a powerful command which is sort of a whole language in itself. Do see the wiki page for &lt;a href="https://en.wikipedia.org/wiki/AWK"&gt;awk&lt;/a&gt; for a lot of great usecases of awk. I also wrote a post on awk as a second part in this series. Check it &lt;a href="http://mlwhiz.com/blog/2015/10/11/shell_basics_for_data_science_2/"&gt;HERE&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;3. Find the files in a directory that satisfy a certain condition&lt;/h2&gt;

&lt;p&gt;You can do this by using the find command. Lets say you want to &lt;strong&gt;find all the .txt files&lt;/strong&gt; in the current working dir that &lt;strong&gt;start with lowercase h&lt;/strong&gt;.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;find . -name "h*.txt"
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
./hamlet.txt
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;To find &lt;strong&gt;all .txt files starting with h regarless of case&lt;/strong&gt; we could use regex.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;find . -name "[Hh]*.txt"
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
./hamlet.txt
./Hamlet1.txt
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2&gt;4. Passing file list as Argument.&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Xargs"&gt;xargs&lt;/a&gt; was suggested by Gaurav in the comments, so I read about it and it is actually a very nice command which you could use in a variety of use cases.&lt;/p&gt;

&lt;p&gt;So if you just use a pipe, any command/utility receives data on STDIN (the standard input stream) as a raw pile of data that it can sort through one line at a time. However some programs don't accept their commands on standard in. For example the rm command(which is used to remove files), touch command(used to create file with a given name) or a certain python script you wrote(which takes command line arguments). They expect it to be spelled out in the arguments to the command.
&lt;br&gt;&lt;/p&gt;

&lt;p&gt;For example:
rm takes a file name as a parameter on the command line like so: rm file1.txt.
If I wanted to &lt;strong&gt;delete all '.txt' files starting with "h/H"&lt;/strong&gt; from my working directory, the below command won't work because rm expects a file as an input.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;find . -name "[hH]*.txt" | rm
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
usage: rm [-f | -i] [-dPRrvW] file ...
unlink file
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;To get around it we can use the xargs command which reads the STDIN stream data and converts each line into space separated arguments to the command.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;find . -name "[hH]*.txt" | xargs
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
./hamlet.txt ./Hamlet1.txt
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Now you could use rm to remove all .txt files that start with h/H. A word of advice: Always see the output of xargs first before using rm.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;find . -name "[hH]*.txt" | xargs rm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Another usage of xargs could be in conjunction with grep to &lt;strong&gt;find all files that contain a given string&lt;/strong&gt;. &lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;find . -name "*.txt" | xargs grep 'honest soldier'
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
./Data1.txt:O, farewell, honest soldier;
./Data2.txt:O, farewell, honest soldier;
./Data3.txt:O, farewell, honest soldier;
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
Hopefully You could come up with varied uses building up on these examples. One other use case could be to use this for &lt;strong&gt;passing arguments to a python script&lt;/strong&gt;.
&lt;br&gt;&lt;/p&gt;

&lt;h2&gt;Other Cool Tricks&lt;/h2&gt;

&lt;p&gt;Sometimes you want your data that you got by some command line utility(Shell commands/ Python scripts) not to be shown on stdout but stored in a textfile. You can use the &lt;strong&gt;"&amp;gt;"&lt;/strong&gt; operator for that. For Example: You could have stored the file after replacing the delimiters in the previous example into anther file called newdata.txt as follows:&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat data.txt | tr '|' ',' &gt; newdata.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I really got confused between &lt;strong&gt;"|"&lt;/strong&gt; (piping) and &lt;strong&gt;"&amp;gt;"&lt;/strong&gt; (to_file) operations a lot in the beginning. One way to remember is that you should only use &lt;strong&gt;"&amp;gt;"&lt;/strong&gt; when you want to write something to a file. &lt;strong&gt;"|" cannot be used to write to a file.&lt;/strong&gt;
Another operation you should know about is the &lt;strong&gt;"&amp;gt;&amp;gt;"&lt;/strong&gt; operation. It is analogous to &lt;strong&gt;"&amp;gt;"&lt;/strong&gt; but it appends to an existing file rather that replacing the file and writing over.&lt;/p&gt;

&lt;p&gt;If you would like to know more about commandline, which I guess you would, here are some books that I would recommend for a beginner:&lt;/p&gt;

&lt;div style="margin-left:1em ; text-align: center;"&gt;

&lt;a href="http://www.amazon.com/gp/product/1593273894/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1593273894&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=IXZOHV6FHPTYCBCT"&gt;&lt;img border="0" src="http://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1593273894&amp;Format=_SL250_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="http://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=as2&amp;o=1&amp;a=1593273894" width="1" height="1" border="0" alt="" style="border:none !important; margin:80px !important;" /&gt;
&lt;/t&gt;&lt;/t&gt;
&lt;a href="http://www.amazon.com/gp/product/0596009658/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0596009658&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=2ZHHZIAJBFW3BFF7"&gt;&lt;img border="0" src="http://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=0596009658&amp;Format=_SL250_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="http://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=as2&amp;o=1&amp;a=0596009658" width="1" height="1" border="0" alt="" style="border:none !important; margin:30px !important;" /&gt;

&lt;/div&gt;

&lt;p&gt;The first book is more of a fun read at leisure type of book. THe second book is a little more serious. Whatever suits you. &lt;/p&gt;

&lt;p&gt;So, this is just the tip of the iceberg. Although I am not an expert in shell usage, these commands reduced my workload to a large extent.
If there are some shell commands you use on a regular basis or some shell command that are cool, do tell in the comments.
I would love to include it in the blogpost.&lt;/p&gt;

&lt;p&gt;I wrote a blogpost on awk as a second part of this post. Check it &lt;a href="http://mlwhiz.com/blog/2015/10/11/shell_basics_for_data_science_2/"&gt;Here&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;</summary><category term="bash commands"></category><category term="bash for data science"></category></entry><entry><title>Create basic graph visualizations with SeaBorn- The Most Awesome Python Library For Visualization yet</title><link href="http://mlwhiz.github.io/blog/2015/09/13/seaborn_visualizations/" rel="alternate"></link><updated>2015-09-13T04:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2015-09-13:blog/2015/09/13/seaborn_visualizations/</id><summary type="html">&lt;p&gt;When it comes to data preparation and getting acquainted with data, the &lt;strong&gt;one step we normally skip is the data visualization&lt;/strong&gt;.
While a part of it could be attributed to the &lt;strong&gt;lack of good visualization tools&lt;/strong&gt; for the platforms we use, most of us also &lt;strong&gt;get lazy&lt;/strong&gt; at times.&lt;/p&gt;
&lt;p&gt;Now as we know of it Python never had any good Visualization library. For most of our plotting needs, I would read up blogs, hack up with StackOverflow solutions and haggle with &lt;a href="http://matplotlib.org/"&gt;Matplotlib&lt;/a&gt; documentation each and every time I needed to make a simple graph. This led me to think that a &lt;strong&gt;Blog post to create common Graph types&lt;/strong&gt; in Python is in order. But being the procrastinator that I am it always got pushed to the back of my head.&lt;/p&gt;
&lt;p&gt;But, yesterday I got introduced to &lt;a href="http://stanford.edu/~mwaskom/software/seaborn/"&gt;&lt;strong&gt;Seaborn&lt;/strong&gt;&lt;/a&gt; and I must say I am &lt;strong&gt;quite impressed&lt;/strong&gt; with it. It makes &lt;strong&gt;beautiful graphs&lt;/strong&gt; that are in my opinion &lt;strong&gt;better than R's &lt;a href="http://ggplot2.org/"&gt;ggplot2&lt;/a&gt;&lt;/strong&gt;. Gives you enough options to &lt;strong&gt;customize&lt;/strong&gt; and the best part is that it is so &lt;strong&gt;easy to learn&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;So I am finally writing this blog post with a basic &lt;strong&gt;purpose of creating a code base&lt;/strong&gt; that provides me with ready to use codes which could be put into analysis in a fairly straight-forward manner.&lt;/p&gt;
&lt;p&gt;Right. So here Goes.&lt;/p&gt;
&lt;p&gt;We Start by importing the libraries that we will need to use.&lt;/p&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;import matplotlib.pyplot as plt  #sets up plotting under plt
import seaborn as sns           #sets up styles and gives us more plotting options
import pandas as pd             #lets us handle data as dataframes
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To create a use case for our graphs, we will be working with the &lt;strong&gt;Tips data&lt;/strong&gt; that contains the following information.&lt;/p&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;tips = sns.load_dataset("tips")
tips.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/tips.png"  height="400" width="500" &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h2&gt;Scatterplot With Regression Line&lt;/h2&gt;
&lt;p&gt;Now let us work on visualizing this data.
We will use the &lt;a href="http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.regplot.html#seaborn.regplot"&gt;&lt;strong&gt;regplot&lt;/strong&gt;&lt;/a&gt; option in seaborn.&lt;/p&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# We dont Probably need the Gridlines. Do we? If yes comment this line
sns.set(style="ticks")

# Here we create a matplotlib axes object. The extra parameters we use
# "ci" to remove confidence interval
# "marker" to have a x as marker.
# "scatter_kws" to provide style info for the points.[s for size]
# "line_kws" to provide style info for the line.[lw for line width]

g = sns.regplot(x="tip", y="total_bill", data=tips, ci = False,
    scatter_kws={"color":"darkred","alpha":0.3,"s":90},
    line_kws={"color":"g","alpha":0.5,"lw":4},marker="x")

# remove the top and right line in graph
sns.despine()

# Set the size of the graph from here
g.figure.set_size_inches(12,8)
# Set the Title of the graph from here
g.axes.set_title('Total Bill vs. Tip', fontsize=34,color="r",alpha=0.5)
# Set the xlabel of the graph from here
g.set_xlabel("Tip",size = 67,color="r",alpha=0.5)
# Set the ylabel of the graph from here
g.set_ylabel("Total Bill",size = 67,color="r",alpha=0.5)
# Set the ticklabel size and color of the graph from here
g.tick_params(labelsize=14,labelcolor="black")
&lt;/code&gt;&lt;/pre&gt;

&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/regplot.png"&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Now that required a bit of a code but i feel that it &lt;strong&gt;looks much better than what either Matplotlib or ggPlot2 could have rendered&lt;/strong&gt;. We got a lot of customization without too much code.&lt;/p&gt;
&lt;p&gt;But that is not really what actually made me like Seaborn. The plot type that actually got my attention was &lt;a href="http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.lmplot.html#seaborn.lmplot"&gt;&lt;strong&gt;lmplot&lt;/strong&gt;&lt;/a&gt;, which lets us use &lt;strong&gt;regplot&lt;/strong&gt; in a &lt;strong&gt;faceted&lt;/strong&gt; mode.&lt;/p&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# So this function creates a faceted plot. The plot is parameterized by the following:

# col : divides the data points into days and creates that many plots
# palette: deep, muted, pastel, bright, dark, and colorblind. change the colors in graph. Experiment with these
# col_wrap: we want 2 graphs in a row? Yes.We do
# scatter_kws: attributes for points
# hue: Colors on a particular column.
# size: controls the size of graph

g = sns.lmplot(x="tip", y="total_bill",ci=None,data=tips, col="day",
    palette="muted",col_wrap=2,scatter_kws={"s": 100,"alpha":.5},
    line_kws={"lw":4,"alpha":0.5},hue="day",x_jitter=1.0,y_jitter=1.0,size=6)

# remove the top and right line in graph
sns.despine()
# Additional line to adjust some appearance issue
plt.subplots_adjust(top=0.9)

# Set the Title of the graph from here
g.fig.suptitle('Total Bill vs. Tip', fontsize=34,color="r",alpha=0.5)

# Set the xlabel of the graph from here
g.set_xlabels("Tip",size = 50,color="r",alpha=0.5)

# Set the ylabel of the graph from here
g.set_ylabels("Total Bill",size = 50,color="r",alpha=0.5)

# Set the ticklabel size and color of the graph from here
titles = ['Thursday','Friday','Saturday','Sunday']
for ax,title in zip(g.axes.flat,titles):
    ax.tick_params(labelsize=14,labelcolor="black")
&lt;/code&gt;&lt;/pre&gt;

&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/lmplot.png"&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;div style="color:black; background-color: #E9DAEE;"&gt;
&lt;a href="http://stanford.edu/~mwaskom/software/seaborn/tutorial/color_palettes.html#building-color-palettes-with-color-palette"&gt;&lt;strong&gt;A side Note on Palettes&lt;/strong&gt;&lt;/a&gt;:&lt;br&gt;
You can build your own color palettes using &lt;strong&gt;color_palette()&lt;/strong&gt; function.
color_palette() will accept the name of any &lt;strong&gt;seaborn palette&lt;/strong&gt; or &lt;a href="http://matplotlib.org/users/colormaps.html"&gt;&lt;strong&gt;matplotlib colormap&lt;/strong&gt;&lt;/a&gt;(except jet, which you should never use). It can also take a &lt;strong&gt;list of colors&lt;/strong&gt; specified in any valid matplotlib format (RGB tuples, &lt;strong&gt;hex color codes&lt;/strong&gt;, or HTML color names).
The return value is always a list of RGB tuples. This allows you to use your own color palettes in graph.
&lt;/div&gt;

&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;

&lt;h2&gt;Barplots&lt;/h2&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;sns.set(style="ticks")

flatui = ["#9b59b6", "#3498db", "#95a5a6", "#e74c3c", "#34495e", "#2ecc71"]

# This Function takes as input a custom palette
g = sns.barplot(x="sex", y="tip", hue="day",
    palette=sns.color_palette(flatui),data=tips,ci=None)

# remove the top and right line in graph
sns.despine()

# Set the size of the graph from here
g.figure.set_size_inches(12,7)
# Set the Title of the graph from here
g.axes.set_title('Do We tend to \nTip high on Weekends?',
    fontsize=34,color="b",alpha=0.3)
# Set the xlabel of the graph from here
g.set_xlabel("Gender",size = 67,color="g",alpha=0.5)
# Set the ylabel of the graph from here
g.set_ylabel("Mean Tips",size = 67,color="r",alpha=0.5)
# Set the ticklabel size and color of the graph from here
g.tick_params(labelsize=14,labelcolor="black")
&lt;/code&gt;&lt;/pre&gt;

&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/barplot.png"&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h2&gt;Histograms and Distribution Diagrams&lt;/h2&gt;
&lt;p&gt;They form another part of my workflow. Lets plot the normal Histogram using seaborn.
For this we will use the &lt;a href="http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.distplot.html#seaborn.distplot"&gt;&lt;strong&gt;distplot&lt;/strong&gt;&lt;/a&gt; function. This function combines the matplotlib hist function (with automatic calculation of a good default bin size) with the seaborn kdeplot() function.
It can also fit &lt;strong&gt;scipy.stats&lt;/strong&gt; distributions and plot the estimated PDF over the data.&lt;/p&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# Create a list of 1000 Normal RVs
x = np.random.normal(size=1000)

sns.set_context("poster")
sns.set_style("ticks")
# This  Function creates a normed Histogram by default.
# If we use the parameter kde=False and norm_hist=False then
# we will be using a count histogram

g=sns.distplot(x,
            kde_kws={"color":"g","lw":4,"label":"KDE Estim","alpha":0.5},
            hist_kws={"color":"r","alpha":0.3,"label":"Freq"})


# remove the top and right line in graph
sns.despine()

# Set the size of the graph from here
g.figure.set_size_inches(12,7)
# Set the Title of the graph from here
g.axes.set_title('Normal Simulation', fontsize=34,color="b",alpha=0.3)
# Set the xlabel of the graph from here
g.set_xlabel("X",size = 67,color="g",alpha=0.5)
# Set the ylabel of the graph from here
g.set_ylabel("Density",size = 67,color="r",alpha=0.5)
# Set the ticklabel size and color of the graph from here
g.tick_params(labelsize=14,labelcolor="black")
&lt;/code&gt;&lt;/pre&gt;

&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/hist_normal.png"&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;pre style="font-size:80%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;import scipy.stats as stats

a = 1.5
b = 1.5
x = np.arange(0.01, 1, 0.01)
y = stats.beta.rvs(a,b,size=10000)
y_act = stats.beta.pdf(x,a,b)
g=sns.distplot(y,kde=False,norm_hist=True,
            kde_kws={"color":"g","lw":4,"label":"KDE Estim","alpha":0.5},
            hist_kws={"color":"r","alpha":0.3,"label":"Freq"})
# Note that we plotted on the graph using plt matlabplot function
plt.plot(x,y_act)

# remove the top and right line in graph
sns.despine()

# Set the size of the graph from here
g.figure.set_size_inches(12,7)
# Set the Title of the graph from here
g.axes.set_title(("Beta Simulation vs. Calculated Beta Density\nFor a=%s,b=%s")
    %(a,b),fontsize=34,color="b",alpha=0.3)
# Set the xlabel of the graph from here
g.set_xlabel("X",size = 67,color="g",alpha=0.5)
# Set the ylabel of the graph from here
g.set_ylabel("Density",size = 67,color="r",alpha=0.5)
# Set the ticklabel size and color of the graph from here
g.tick_params(labelsize=14,labelcolor="black")
&lt;/code&gt;&lt;/pre&gt;

&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/hist_beta.png"&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h2&gt;PairPlots&lt;/h2&gt;
&lt;p&gt;You need to see how variables vary with one another. What is the distribution of variables in the dataset. This is the graph to use with the &lt;a href="http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.pairplot.html#seaborn.pairplot"&gt;&lt;strong&gt;pairplot&lt;/strong&gt;&lt;/a&gt; function. Very helpful And Seaborn males it a joy to use. We will use &lt;strong&gt;Iris Dataset&lt;/strong&gt; here for this example.&lt;/p&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;iris = sns.load_dataset("iris")
iris.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/iris.png" height="500" width="600"&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;pre style="font-size:80%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# Create a Pairplot
g = sns.pairplot(iris,hue="species",palette="muted",size=5,
    vars=["sepal_width", "sepal_length"],kind='reg',markers=['o','x','+'])

# To change the size of the scatterpoints in graph
g = g.map_offdiag(plt.scatter,  s=35,alpha=0.5)

# remove the top and right line in graph
sns.despine()
# Additional line to adjust some appearance issue
plt.subplots_adjust(top=0.9)

# Set the Title of the graph from here
g.fig.suptitle('Relation between Sepal Width and Sepal Length',
    fontsize=34,color="b",alpha=0.3)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/pairplot.png"&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Hope you found this post useful and worth your time. You can find the iPython notebook at &lt;a href="https://github.com/MLWhiz/visualization/blob/master/Graphs.ipynb"&gt;github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I tried to make this as simple as possible but You may always &lt;strong&gt;ask me&lt;/strong&gt; or see the documentation for doubts.&lt;/p&gt;
&lt;p&gt;If you have &lt;strong&gt;any more ideas&lt;/strong&gt; on how to use Seaborn or &lt;strong&gt;which graphs should i add here&lt;/strong&gt;, please suggest in the &lt;strong&gt;comments&lt;/strong&gt; section.&lt;/p&gt;
&lt;p&gt;I will definitely try to add to this post as I start using more visualizations and encounter other libraries as good as seaborn.&lt;/p&gt;
&lt;p&gt;Also since this is my first visualization post on this blog, I would like to call out some of the most awesome visualization books out there, since I like books:&lt;/p&gt;
&lt;div style="margin-left:1em ; text-align: center;"&gt;
&lt;a target="_blank"  href="https://www.amazon.com/gp/product/1930824130/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1930824130&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=32575b0a314fb37f8728123f098d3e47"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1930824130&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1930824130" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/t&gt;&lt;/t&gt;
&lt;a target="_blank"  href="https://www.amazon.com/gp/product/1119002257/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1119002257&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=9e0aa9b9b8fcf4c3d2bec136e3b10175"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1119002257&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1119002257" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;

&lt;p&gt;Both of these are awesome reads. The first one is a classic on which most of the other visualization work is based. The other one takes a highly practical approach to storytelling with data.&lt;/p&gt;</summary><category term="Python Visualizations"></category><category term="Seaborn"></category><category term="Matplotlib"></category><category term="ggplot2"></category><category term="stanford software seaborn"></category><category term="regplot"></category><category term="lmplot seaborn"></category><category term="pairplot seaborn"></category><category term=""></category></entry><entry><title>Learning Spark using Python: Basics and Applications</title><link href="http://mlwhiz.github.io/blog/2015/09/07/Spark_Basics_Explained/" rel="alternate"></link><updated>2015-09-07T04:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2015-09-07:blog/2015/09/07/Spark_Basics_Explained/</id><summary type="html">&lt;p&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I generally have a use case for &lt;a href="https://hadoop.apache.org/"&gt;Hadoop&lt;/a&gt; in my daily job. It has made my life easier in a sense that I am able to get results which I was not able to see with SQL queries. But still I find it painfully slow. I have to write procedural programs while I work. As in merge these two datasets and then filter and then merge another dataset and then filter using some condition and yada-yada. You get the gist. And in hadoop its painstakingly boring to do this. You have to write more than maybe 3 Mapreduce Jobs. One job will read the data line by line and write to the disk.&lt;/p&gt;
&lt;p&gt;There is a lot of data movement that happens in between that further affects the speed. Another thing I hate is that there is no straight way to pass files to mappers and reducers and that generally adds up another mapreduce job to the whole sequence.&lt;/p&gt;
&lt;p&gt;And that is just procedural tasks. To implement an iterative algorithm even after geting the whole logic of parallelization is again a challenge. There would be a lot of mapreduce tasks, a shell based driver program and a lot of unique thinking to bring everything together. And the running times are like crazy. Though sometimes it has its benefits:&lt;/p&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/compiling.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;That makes me think about the whole way Hadoop is implemented. While at the time Hadoop appeared the RAM was costly. Now that is not the case. We already have 64GB machines in our Hadoop cluster. So is it really a good idea to not use a larger chunk of memory and read line by line. Also can we have something that allows us to keep a particular piece of data in the memory, So that the next time our program needs it it doesnt have to read it again and waste time. Wouldnt it be better if we have some variable that lets us keep the state our iterative algorithm is in.&lt;/p&gt;
&lt;h2 id="the-solution"&gt;The Solution?&lt;/h2&gt;
&lt;p&gt;And here is where &lt;a href="http://spark.apache.org/"&gt;Spark&lt;/a&gt; comes to rescue. Now working on Spark is very different from Hadoop but when you start using it you find that it makes things so much easier. You still do have to think in the mapreduce way sort of but the way the map and reduce steps are done are a little bit different.&lt;/p&gt;
&lt;p&gt;So lets first get Spark on our System (But keep in mind that for running spark in production environments you will need whole clusters set up. A liberty which you may or may not have at present)&lt;/p&gt;
&lt;p&gt;The best way that I found to install Spark is following the Apache Spark installation guidelines with the Apache Spark eDx &lt;a href="https://courses.edx.org/courses/BerkeleyX/CS100.1x/1T2015/courseware"&gt;course&lt;/a&gt;. It lets you get Spark in your system and work with Spark with iPython notebooks. Something I prefer a lot and find the best way to code in Python.&lt;/p&gt;
&lt;p&gt;The installation instructions can be found &lt;a href="https://courses.edx.org/courses/BerkeleyX/CS100.1x/1T2015/courseware/d1f293d0cb53466dbb5c0cd81f55b45b/920d3370060540c8b21d56f05c64bdda/"&gt;HERE&lt;/a&gt;. You may have to login int an edX account to follow these instructions, but it is worth it.&lt;/p&gt;
&lt;p&gt;So once you have gone through all the steps mentioned there and installed spark using these instructions, you would see something like this in your browser.&lt;/p&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/ipython_startup.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;Ahh! so you have got Spark up and running now. That's actually like half the process. I like to learn by examples so let's get done with the Hello World of Distributed computing: The WordCount Program.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;lines = sc.textFile("shakespeare.txt")                   # Distribute the data - Create a RDD 

counts = (lines.flatMap(lambda x: x.split(' '))          # Create a list with all words
                  .map(lambda x: (x, 1))                 # Create tuple (word,1)
                  .reduceByKey(lambda x,y : x + y))      # reduce by key i.e. the word
output = counts.take(10)                                 # get the output on local
for (word, count) in output:                             # print output
    print("%s: %i" % (word, count))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/wordcount_result.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;So that is a small example. Pretty small code when you compare it with Hadoop. And most of the work gets done in the second command. Don't worry if you are not able to follow this yet as I need to tell you about the things that make Spark work.&lt;/p&gt;
&lt;p&gt;But before we get into Spark basics, Let us refresh some of our python Basics. Understanding Spark becomes a lot easier if you have used Lambda functions in Python.&lt;/p&gt;
&lt;p&gt;For those of you who haven't used it, below is a brief intro.&lt;/p&gt;
&lt;h2 id="lambda-functions-in-python"&gt;Lambda Functions in Python&lt;/h2&gt;
&lt;h4 id="map"&gt;Map&lt;/h4&gt;
&lt;p&gt;Map is used to map a function to a array or a list. Say you want to apply some function to every element in a list. You can do this by simply using a for loop but python lambda functions let you do this in a single line in Python.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;my_list = [1,2,3,4,5,6,7,8,9,10]
# Lets say I want to square each term in my_list.
squared_list = map(lambda x:x**2,my_list)
print squared_list
    &lt;span style="background-color: #FFFFFF; color:#000000"&gt;[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]&lt;span style="background-color: #FFFFFF; color:#000000"&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In the above example you could think of map as a function which takes two arguments - A function and a list. It then applies the function to every element of the list. What lambda allows you to do is write an inline function. In here the part &lt;strong&gt;&amp;quot;lambda x:x**2&amp;quot;&lt;/strong&gt; defines a function that takes x as input and returns x^2.&lt;/p&gt;
&lt;p&gt;You could have also provided a proper function in place of lambda. For Example:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;def squared(x):
    return x**2
&lt;br&gt;my_list = [1,2,3,4,5,6,7,8,9,10]
# Lets say I want to square each term in my_list.
squared_list = map(squared,my_list)
print squared_list

    &lt;span style="background-color: #FFFFFF; color:#000000"&gt;[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The same result, but the lambda expressions make the code compact and a lot more readable.&lt;/p&gt;
&lt;h4 id="filter"&gt;Filter&lt;/h4&gt;
&lt;p&gt;The other function that is used extensively is the filter function. This function takes two arguments - A condition and the list to filter. If you want to filter your list using some condition you use filter.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;my_list = [1,2,3,4,5,6,7,8,9,10]
# Lets say I want only the even numbers in my list.
filtered_list = filter(lambda x:x%2==0,my_list)
print filtered_list
    &lt;span style="background-color: #FFFFFF; color:#000000"&gt;[2, 4, 6, 8, 10]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="reduce"&gt;Reduce&lt;/h4&gt;
&lt;p&gt;The next function is the reduce function. This function will be the workhorse in Spark. This function takes two arguments - a function to reduce that takes two arguments, and a list over which the reduce function is to be applied.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;my_list = [1,2,3,4,5]
\# Lets say I want to sum all elements in my list.
sum_list = reduce(lambda x,y:x+y,my_list)
print sum_list

    &lt;span style="background-color: #FFFFFF; color:#000000"&gt;15&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Here the lambda function takes in two values x, y and returns their sum. Intuitively you can think that the reduce function works as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Reduce function first sends 1,2    ; the lambda function returns 3
Reduce function then sends 3,3     ; the lambda function returns 6
Reduce function then sends 6,4     ; the lambda function returns 10
Reduce function finally sends 10,5 ; the lambda function returns 15&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A condition on the lambda function we use in reduce is that it must be commutative that is a + b = b + a and associative that is (a + b) + c == a + (b + c). In the above case we used sum which is &lt;strong&gt;commutative as well as associative&lt;/strong&gt;. Other functions that we could have used are &lt;strong&gt;max, min, multiplication&lt;/strong&gt; etc.&lt;/p&gt;
&lt;h2 id="moving-again-to-spark"&gt;Moving Again to Spark&lt;/h2&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;As we have now got the fundamentals of Python Functional Programming out of the way, lets again head to Spark.&lt;/p&gt;
&lt;p&gt;But first let us delve a little bit into how spark works. Spark actually consists of two things a driver and workers. Workers normally do all the work and the driver makes them do that work.&lt;/p&gt;
&lt;p&gt;An RDD is defined a parallelized data structure that gets distributed across the worker nodes. In our wordcount example, in the first line&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lines = sc.textFile(&amp;quot;data/cs100/lab1/shakespeare.txt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We took a text file and distributed it across worker nodes so that they can work on it in parallel. We could also parallelize lists using the function&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sc.parallelize&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;data = [1,2,3,4,5,6,7,8,9,10]
new_rdd = sc.parallelize(data,4)
new_rdd

    &lt;span style="background-color: #FFFFFF; color:#000000"&gt;ParallelCollectionRDD[15] at parallelize at PythonRDD.scala:392&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In Spark we classify the operations into two Basic Types: Transformations and Actions. 1. &lt;strong&gt;Transformations&lt;/strong&gt; : Create new datasets from existing RDDs 2. &lt;strong&gt;Actions&lt;/strong&gt; : Mechanism to get results out of Spark&lt;/p&gt;
&lt;h2 id="understanding-transformations"&gt;Understanding Transformations&lt;/h2&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;So lets say you have got your data in the form of an RDD. To requote your data is now accesible b all the worker machines. You want to do some transformations on the data now. You may want to filter, Apply some function etc. In Spark this is done using Transformation functions. Spark provides many transformation functions. You can see a comprehensive list &lt;a href="http://spark.apache.org/docs/latest/programming-guide.html#transformations"&gt;here&lt;/a&gt;. Some of the main ones that I use frequently are:&lt;/p&gt;
&lt;h5 id="map"&gt;1. Map:&lt;/h5&gt;
&lt;p&gt;Applies a given function to an RDD. Note that the syntax is a little bit different from python, but it necessarily does the same thing. Don't worry about collet yet. For now just think of it as a function that collects the data in squared_rdd back to a list.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;data = [1,2,3,4,5,6,7,8,9,10]
rdd = sc.parallelize(data,4)
squared_rdd = rdd.map(lambda x:x**2)
squared_rdd.collect()

    &lt;span style="background-color: #FFFFFF; color:#000000"&gt;[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h5 id="filter"&gt;2. Filter:&lt;/h5&gt;
&lt;p&gt;Again no surprises here. Takes as input a condition and keeps only those elements that fulfill that condition.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;data = [1,2,3,4,5,6,7,8,9,10]
rdd = sc.parallelize(data,4)
filtered_rdd = rdd.filter(lambda x:x%2==0)
filtered_rdd.collect()

    &lt;span style="background-color: #FFFFFF; color:#000000"&gt;[2, 4, 6, 8, 10]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h5 id="distinct"&gt;3. Distinct:&lt;/h5&gt;
&lt;p&gt;Returns only distinct elements in an RDD&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;data = [1,2,2,2,2,3,3,3,3,4,5,6,7,7,7,8,8,8,9,10]
rdd = sc.parallelize(data,4)
distinct_rdd = rdd.distinct()
distinct_rdd.collect()

    &lt;span style="background-color: #FFFFFF; color:#000000"&gt;[8, 4, 1, 5, 9, 2, 10, 6, 3, 7]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h5 id="flatmap"&gt;4. Flatmap:&lt;/h5&gt;
&lt;p&gt;Similar to map, but each input item can be mapped to 0 or more output items&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;data = [1,2,3,4]
rdd = sc.parallelize(data,4)
flat_rdd = rdd.flatMap(lambda x:[x,x**3])
flat_rdd.collect()

    &lt;span style="background-color: #FFFFFF; color:#000000"&gt;[1, 1, 2, 8, 3, 27, 4, 64]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h5 id="reduce-by-key"&gt;5. Reduce By Key:&lt;/h5&gt;
&lt;p&gt;The analogue to the reduce in Hadoop Mapreduce. Now Spark cannot provide the value if it just worked with Lists. In Spark there is a concept of pair RDDs that makes it a lot more flexible. Lets assume we have a data in which we have product, its category and its selling price. We can still parallelize the data.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;data = [('Apple','Fruit',200),('Banana','Fruit',24),('Tomato','Fruit',56),('Potato','Vegetable',103),('Carrot','Vegetable',34)]
rdd = sc.parallelize(data,4)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Right now our RDD rdd holds tuples. Now we want to find out the total sum of revenue that we got from each category. To do that we have to transform our rdd to a pair rdd so that it only contatins key-value pairs/tuples.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;category_price_rdd = rdd.map(lambda x: (x[1],x[2]))
category_price_rdd.collect()
    
     &lt;span style="background-color: #FFFFFF; color:#000000"&gt;[('Fruit', 200), ('Fruit', 24), ('Fruit', 56), ('Vegetable', 103), ('Vegetable', 34)]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Here we used the map function to get it in the format we wanted. When working with textfile, the rdd that gets formed has got a lot of strings. We use map to convert it into a format that we want.&lt;/p&gt;
&lt;p&gt;So now our category_price_rdd contains the product category and the price at which the prouct sold. Now we want to reduce on the key and sum the prices. We can do this by:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;category_total_price_rdd = category_price_rdd.reduceByKey(lambda x,y:x+y)
category_total_price_rdd.collect()
    
    &lt;span style="background-color: #FFFFFF; color:#000000"&gt;[('Vegetable', 137), ('Fruit', 280)]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h5 id="group-by-key"&gt;6. Group By Key:&lt;/h5&gt;
&lt;p&gt;Similar to reduce by key but does not reduce just puts all the elements in an iterator. For example if we wanted to keep as key the category and as the value all the products we would use this function.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;data = [('Apple','Fruit',200),('Banana','Fruit',24),('Tomato','Fruit',56),('Potato','Vegetable',103),('Carrot','Vegetable',34)]
rdd = sc.parallelize(data,4)
category_product_rdd = rdd.map(lambda x: (x[1],x[0]))
category_product_rdd.collect()
    
    &lt;span style="background-color: #FFFFFF; color:#000000"&gt;[('Fruit','Apple'),('Fruit','Banana'),('Fruit','Tomato'),('Vegetable','Potato'),('Vegetable','Carrot')]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;grouped_products_by_category_rdd = category_product_rdd.groupByKey()
findata = grouped_products_by_category_rdd.collect()
for data in findata:
    print data[0],list(data[1])

    &lt;span style="background-color: #FFFFFF; color:#000000"&gt;Vegetable ['Potato', 'Carrot']&lt;/span&gt;
    &lt;span style="background-color: #FFFFFF; color:#000000"&gt;Fruit ['Apple', 'Banana', 'Tomato']&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Here the grouped by function worked and it returned the category and the list of products in that category.&lt;/p&gt;
&lt;h2 id="understanding-actions"&gt;Understanding Actions&lt;/h2&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Now you have filtered your data, mapped some functions on it. Done your computation. Now you want to get the data on your local machine or save it to a file. You will have to use actions for that. A comprehensive list of actions is providede &lt;a href="http://spark.apache.org/docs/latest/programming-guide.html#actions"&gt;HERE&lt;/a&gt; Some of the most common actions that I tend to use are:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h5 id="collect"&gt;1. Collect:&lt;/h5&gt;
&lt;p&gt;We have already used this actio many times. It takes the whole rdd and brings it back to the driver program.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h5 id="reduce"&gt;2. Reduce:&lt;/h5&gt;
&lt;p&gt;Aggregate the elements of the dataset using a function func (which takes two arguments and returns one). The function should be commutative and associative so that it can be computed correctly in parallel.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;rdd = sc.parallelize([1,2,3,4,5])
rdd.reduce(lambda x,y : x+y)

    &lt;span style="background-color: #FFFFFF; color:#000000"&gt;15&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h5 id="take"&gt;3.take:&lt;/h5&gt;
&lt;p&gt;Return an list with the first n elements of the dataset.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;rdd = sc.parallelize([1,2,3,4,5])
rdd.take(3)

    &lt;span style="background-color: #FFFFFF; color:#000000"&gt;[1, 2, 3]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h5 id="takeordered"&gt;4. takeOrdered:&lt;/h5&gt;
&lt;p&gt;Return the first n elements of the RDD using either their natural order or a custom comparator.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;rdd = sc.parallelize([5,3,12,23])
rdd.takeOrdered(3,lambda s:-1*s)      # descending order

    &lt;span style="background-color: #FFFFFF; color:#000000"&gt;[23, 12, 5]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;rdd = sc.parallelize([(5,23),(3,34),(12,344),(23,29)])
rdd.takeOrdered(3,lambda s:-1*s[1])      # descending order

    &lt;span style="background-color: #FFFFFF; color:#000000"&gt;[(12, 344), (3, 34), (23, 29)]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;So now lets take a look at the Wordcount Again&lt;/p&gt;
&lt;h2 id="understanding-the-wordcount-example"&gt;Understanding The WordCount Example&lt;/h2&gt;
&lt;p&gt;Now we sort of understand the transformations and the actions provided to us by Spark. It should not be difficult to understand the work count program now. Lets go through the program niw line by line.&lt;/p&gt;
&lt;p&gt;The first lines creates a RDD and distributeds to the workers.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lines = sc.textFile(&amp;quot;data/cs100/lab1/shakespeare.txt&amp;quot;)  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This RDD lines contains a list of strings that are actually the line in file. This RDD is of the form:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;['word1 word2 word3','word4 word3 word2']&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This next line is actually the workhorse function in the whole script.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;counts = (lines.flatMap(lambda x: x.split(&amp;#39; &amp;#39;))          
                  .map(lambda x: (x, 1))                 
                  .reduceByKey(lambda x,y : x + y))      &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It contains a series of transformations that we do to the lines RDD. First of all we do a flatmap transformation. The flatmap transformation takes as input the lines and gives words as output. So after the flatmap transformation the RDD is of the form:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;['word1','word2','word3','word4','word3','word2']&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Next we do a map transformation on the flatmap output which converts the rdd to :&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;[('word1',1),('word2',1),('word3',1),('word4',1),('word3',1),('word2',1)]&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Finally we do a reduceByKey transformation which counts the number of time each word appeared. After which the rdd approaches the final desirable form.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;[('word1',1),('word2',2),('word3',2),('word4',1)]&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This next line is an action that takes the first 10 elements of the resulting RDD locally.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;output = counts.take(10)                                 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This line just prints the output&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for (word, count) in output:                 
    print(&amp;quot;%s: %i&amp;quot; % (word, count))&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="getting-serious"&gt;Getting Serious&lt;/h2&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;So till now we have talked about the Wordcount example and the basic transformations and actions that you could use in Spark. But we don't do wordcount in real life. We have to work on bigger problems which are much more complex. Worry not! whatever we have learned till now will let us do that and more.&lt;/p&gt;
&lt;p&gt;Lets work with a concrete example: I will work on an example in which Greg Rada Worked on &lt;a href="http://grouplens.org/datasets/movielens/"&gt;Movielens&lt;/a&gt; Data with &lt;a href="http://www.gregreda.com/2013/10/26/using-pandas-on-the-movielens-dataset/"&gt;Pandas&lt;/a&gt; (BTW a great resource to learn Pandas). This example takes care of every sort of transformation that you may like to do with this data.&lt;/p&gt;
&lt;p&gt;So lets first talk about the dataset. The movielens dataset contains a lot of files but we are going to be working with 3 files only:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;p&gt;Users: This file name is kept as &amp;quot;u.user&amp;quot;, The columns in this file are:&lt;/p&gt;
&lt;p&gt;['user_id', 'age', 'sex', 'occupation', 'zip_code']&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ratings: This file name is kept as &amp;quot;u.data&amp;quot;, The columns in this file are:&lt;/p&gt;
&lt;p&gt;['user_id', 'movie_id', 'rating', 'unix_timestamp']&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Movies: This file name is kept as &amp;quot;u.item&amp;quot;, The columns in this file are:&lt;/p&gt;
&lt;p&gt;['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url', and 18 more columns.....]&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="what-are-the-25-most-rated-movies"&gt;What are the 25 most rated movies?&lt;/h2&gt;
&lt;p&gt;First of all lets load the data in different rdds. And see what the data contains.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;userRDD = sc.textFile("/vagrant/ml-100k/u.user") 
ratingRDD = sc.textFile("/vagrant/ml-100k/u.data") 
movieRDD = sc.textFile("/vagrant/ml-100k/u.item") 
print "userRDD:",userRDD.take(1)
print "ratingRDD:",ratingRDD.take(1)
print "movieRDD:",movieRDD.take(1)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/data_def.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Seeing the data we note that to answer this question we will need to use the ratingRdd. But the ratingRDD does not have movie name. So we would have to merge movieRDD and ratingRDD. So lets see how we would do that in Spark. Lets first do it step by step.Read the comments.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;# Create a RDD from RatingRDD that only contains the two columns of interest i.e. movie_id,rating.
RDD_movid_rating = ratingRDD.map(lambda x : (x.split("\t")[1],x.split("\t")[2]))
print "RDD_movid_rating:",RDD_movid_rating.take(4)

# Create a RDD from MovieRDD that only contains the two columns of interest i.e. movie_id,title.
RDD_movid_title = movieRDD.map(lambda x : (x.split("|")[0],x.split("|")[1]))
print "RDD_movid_title:",RDD_movid_title.take(2)

# merge these two pair RDDs based on movie_id. For this we will use the transformation leftOuterJoin()
rdd_movid_title_rating = RDD_movid_rating.leftOuterJoin(RDD_movid_title)
print "rdd_movid_title_rating:",rdd_movid_title_rating.take(1)

# use the RDD in previous step to create (movie,1) tuple pair RDD
rdd_title_rating = rdd_movid_title_rating.map(lambda x: (x[1][1],1 ))
print "rdd_title_rating:",rdd_title_rating.take(2)

# Use the reduceByKey transformation to reduce on the basis of movie_title
rdd_title_ratingcnt = rdd_title_rating.reduceByKey(lambda x,y: x+y)
print "rdd_title_ratingcnt:",rdd_title_ratingcnt.take(2)

# Get the final answer by using takeOrdered Transformation
print "#####################################"
print "25 most rated movies:",rdd_title_ratingcnt.takeOrdered(25,lambda x:-x[1])
print "#####################################"
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/result_rating_cnt_25.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;We could have done all this in a single command using the below command but the code is a little messy now. I did this to show that you can do things sequentially with Spark and you could bypass the process of variable creation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;print (((ratingRDD.map(lambda x : (x.split("\t")[1],x.split("\t")[2]))).
     leftOuterJoin(movieRDD.map(lambda x : (x.split("|")[0],x.split("|")[1])))).
     map(lambda x: (x[1][1],1)).
     reduceByKey(lambda x,y: x+y).
     takeOrdered(25,lambda x:-x[1]))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/result_rating_cnt_25_2.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;h2 id="which-movies-are-most-highly-rated"&gt;Which movies are most highly rated?&lt;/h2&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Now we want to find the most highly rated 25 movvies using the same dataset. We actually want only those movies which have been rated atleast 100 times. Lets do this using Spark:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;# We already have the RDD rdd_movid_title_rating: [(u'429', (u'5', u'Day the Earth Stood Still, The (1951)'))]
# We create an RDD that contains sum of all the ratings for a particular movie

rdd_title_ratingsum = (rdd_movid_title_rating.
                        map(lambda x: (x[1][1],int(x[1][0]))).
                        reduceByKey(lambda x,y:x+y))
                        
print "rdd_title_ratingsum:",rdd_title_ratingsum.take(2)

# Merge this data with the RDD rdd_title_ratingcnt we created in the last step 
# And use Map function to divide ratingsum by rating count.

rdd_title_ratingmean_rating_count = (rdd_title_ratingsum.
                                    leftOuterJoin(rdd_title_ratingcnt).
                                    map(lambda x:(x[0],(float(x[1][0])/x[1][1],x[1][1]))))
                                    
print "rdd_title_ratingmean_rating_count:",rdd_title_ratingmean_rating_count.take(1)

# We could use take ordered here only but we want to only get the movies which have count
# of ratings more than or equal to 100 so lets filter the data RDD.
rdd_title_rating_rating_count_gt_100 = (rdd_title_ratingmean_rating_count.
                                        filter(lambda x: x[1][1]&gt;=100))
                                        
print "rdd_title_rating_rating_count_gt_100:",rdd_title_rating_rating_count_gt_100.take(1)

# Get the final answer by using takeOrdered Transformation
print "#####################################"
print "25 highly rated movies:",
print rdd_title_rating_rating_count_gt_100.takeOrdered(25,lambda x:-x[1][0])
print "#####################################"
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/result_top25_rating.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;So Spark has Already provided an interface where we could apply transformations sequentially much easily than Hadoop. And it is fast. While in hadoop things are a pain to do sequentially, the infrastructure that Spark provides seem to fit naturally into the analytics use case.&lt;/p&gt;
&lt;p&gt;Hopefully I've covered the basics well enough to pique your interest and help you get started with Spark. If I've missed something critical, feel free to let me know on Twitter or in the comments - I'd love constructive feedback.&lt;/p&gt;
&lt;p&gt;You can find the Jupyter notebook &lt;a href="http://nbviewer.ipython.org/github/MLWhiz/Spark_blog/blob/master/Spark_Part1.ipynb"&gt;HERE&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Look out for these two books to learn more about Spark.&lt;/p&gt;
&lt;div style="margin-left:1em ; text-align: center;"&gt;
&lt;a target="_blank"  href="https://www.amazon.com/gp/product/1491912766/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1491912766&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=916f1678fb802e13211b4b1c648be75e"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1491912766&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1491912766" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/t&gt;&lt;/t&gt;
&lt;a target="_blank"  href="https://www.amazon.com/gp/product/1617292605/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1617292605&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=89da1866198268847438c42ef14c4380"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1617292605&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1617292605" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;

&lt;p&gt;The first one of these is a bestseller. It presents 9 case studies of data analysis applications in various domains. The topics are diverse and the authors always use real world datasets. Beside learning Spark and a data science you will also have the opportunity to gain insight about topics like taxi traffic in NYC, deforestation or neuroscience. The second one is more of a reference that takes the reader on a tour of the Spark fundamentals, explaining the RDD data model in detail, after which it dives into the main functionality of Spark: Spark SQL, Spark Streaming, MLLib, SparkML, and GraphX. Later on, it covers the operational aspects of setting up a standalone Spark cluster, as well as running it on YARN and Mesos.&lt;/p&gt;
&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;</summary><category term="Big Data"></category><category term="Hadoop"></category><category term="Apache Spark"></category></entry><entry><title>Behold the power of MCMC</title><link href="http://mlwhiz.github.io/blog/2015/08/21/MCMC_Algorithms_Cryptography/" rel="alternate"></link><updated>2015-08-21T04:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2015-08-21:blog/2015/08/21/MCMC_Algorithms_Cryptography/</id><summary type="html">&lt;p&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/mcmc.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;Last time I wrote an article on MCMC and how they could be useful. We learned how MCMC chains could be used to simulate from a random variable whose distribution is partially known i.e. we don't know the normalizing constant.&lt;/p&gt;
&lt;p&gt;So MCMC Methods may sound interesting to some (for these what follows is a treat) and for those who don't really appreciate MCMC till now, I hope I will be able to pique your interest by the end of this blog post.&lt;/p&gt;
&lt;p&gt;So here goes. This time we will cover some applications of MCMC in various areas of Computer Science using Python. If you feel the problems difficult to follow with, I would advice you to go back and read the &lt;a href="http://mlwhiz.com/blog/2015/08/19/MCMC_Algorithms_Beta_Distribution/"&gt;previous post&lt;/a&gt;, which tries to explain MCMC Methods. We Will try to solve the following two problems:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Breaking the Code&lt;/strong&gt; - This problem has got somewhat of a great pedigree as this method was suggested by Persi Diaconis- The Mathemagician. So Someone comes to you with the below text. This text looks like gibberish but this is a code, Could you decrypyt it?&lt;br&gt;&lt;br&gt; &lt;em&gt;XZ STAVRK HXVR MYAZ OAKZM JKSSO SO MYR OKRR XDP JKSJRK XBMASD SO YAZ TWDHZ MYR JXMBYNSKF BSVRKTRM NYABY NXZ BXKRTRZZTQ OTWDH SVRK MYR AKSD ERPZMRXP KWZMTRP MYR JXTR OXBR SO X QSWDH NSIXD NXZ KXAZRP ORRETQ OKSI MYR JATTSN XDP X OXADM VSABR AIJRKORBMTQ XKMABWTXMRP MYR NSKPZ TRM IR ZRR MYR BYATP XDP PAR MYR ZWKHRSD YXP ERRD ZAMMADH NAMY YAZ OXBR MWKDRP MSNXKPZ MYR OAKR HAVADH MYR JXTIZ SO YAZ YXDPZ X NXKI XDP X KWE XTMRKDXMRTQ XZ MYR QSWDH NSIXD ZJSFR YR KSZR XDP XPVXDBADH MS MYR ERP Z YRXP ZXAP NAMY ISKR FADPDRZZ MYXD IAHYM YXVR ERRD RGJRBMRP SO YAI&lt;/em&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;The Knapsack Problem&lt;/strong&gt; - This problem comes from &lt;a href="http://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science-ebook/dp/B00MMOJ19I"&gt;Introduction to probability&lt;/a&gt; by Joseph Blitzstein. You should check out his courses (&lt;a href="http://projects.iq.harvard.edu/stat110/handouts"&gt;STAT110&lt;/a&gt; And &lt;a href="http://cm.dce.harvard.edu/2014/01/14328/publicationListing.shtml"&gt;CS109&lt;/a&gt;) as they are awesome. Also as it turns out Diaconis was the advisor of Joseph. So you have Bilbo a Thief who goes to Smaug's Lair. He finds M treasures. Each treasure has some Weight and some Gold value. But Bilbo cannot really take all of that. He could only carry a certain Maximum Weight. But being a smart hobbit, he wants to Maximize the value of the treasures he takes. Given the values for weights and value of the treasures and the maximum weight that Bilbo could carry, could you find a good solution? This is known as the Knapsack Problem in Computer Science.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="breaking-the-code"&gt;Breaking the Code&lt;/h2&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/security.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;So we look at the data and form a hypothesis that the data has been scrambled using a Substitution Cipher. We don't know the encryption key, and we would like to know the Decryption Key so that we can decrypt the data and read the code.&lt;/p&gt;
&lt;p&gt;To create this example, this data has actually been taken from Oliver Twist. We scrambled the data using a random encryption key, which we forgot after encrypting and we would like to decrypt this encrypted text using MCMC Chains. The real decryption key actually is &amp;quot;ICZNBKXGMPRQTWFDYEOLJVUAHS&amp;quot;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;So lets think about this problem for a little bit. The decryption key could be any 26 letter string with all alphabets appearing exactly once. How many string permutations are there like that? That number would come out to be &lt;span class="math inline"&gt;\(26! \approx 10^{26}\)&lt;/span&gt; permutations. That is a pretty large number. If we go for using a brute force approach we are screwed. So what could we do? MCMC Chains come to rescue.&lt;/p&gt;
&lt;p&gt;We will devise a Chain whose states theoritically could be any of these permutations. Then we will:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Start by picking up a random current state.&lt;/li&gt;
&lt;li&gt;Create a proposal for a new state by swapping two random letters in the current state.&lt;/li&gt;
&lt;li&gt;Use a Scoring Function which calculates the score of the current state &lt;span class="math inline"&gt;\(Score_C\)&lt;/span&gt; and the proposed State &lt;span class="math inline"&gt;\(Score_P\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;If the score of the proposed state is more than current state, Move to Proposed State.&lt;/li&gt;
&lt;li&gt;Else flip a coin which has a probability of Heads &lt;span class="math inline"&gt;\(Score_P/Score_C\)&lt;/span&gt;. If it comes heads move to proposed State.&lt;/li&gt;
&lt;li&gt;Repeat from 2nd State.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If we get lucky we may reach a steady state where the chain has the stationary distribution of the needed states and the state that the chain is at could be used as a solution.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;So the Question is what is the scoring function that we will want to use. We want to use a scoring function for each state(Decryption key) which assigns a positive score to each decryption key. This score intuitively should be more if the encrypted text looks more like actual english if decrypted using this decryption key.&lt;/p&gt;
&lt;p&gt;So how can we quantify such a function. We will check a long text and calculate some statistics. See how many times one alphabet comes after another in a legitimate long text like War and Peace. For example we want to find out how many times does 'BA' appears in the text or how many times 'TH' occurs in the text.&lt;/p&gt;
&lt;p&gt;For each pair of characters &lt;span class="math inline"&gt;\(\beta_1\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(\beta_2\)&lt;/span&gt; (e.g. &lt;span class="math inline"&gt;\(\beta_1\)&lt;/span&gt; = T and &lt;span class="math inline"&gt;\(\beta_2\)&lt;/span&gt; =H), we let &lt;span class="math inline"&gt;\(R(\beta_1,\beta_2)\)&lt;/span&gt; record the number of times that specific pair(e.g. &amp;quot;TH&amp;quot;) appears consecutively in the reference text.&lt;/p&gt;
&lt;p&gt;Similarly, for a putative decryption key x, we let &lt;span class="math inline"&gt;\(F_x(\beta_1,\beta_2)\)&lt;/span&gt; record the number of times that pair appears when the cipher text is decrypted using the decryption key x.&lt;/p&gt;
&lt;p&gt;We then Score a particular decryption key x using:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[Score(x) = \prod R(\beta_1,\beta_2)^{F_x(\beta_1,\beta_2)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This function can be thought of as multiplying, for each consecutive pair of letters in the decrypted text, the number of times that pair occurred in the reference text. Intuitively, the score function is higher when the pair frequencies in the decrypted text most closely match those of the reference text, and the decryption key is thus most likely to be correct.&lt;/p&gt;
&lt;p&gt;To make life easier with calculations we will calculate &lt;span class="math inline"&gt;\(log(Score(x))\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;So lets start working through the problem step by step.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;
# AIM: To Decrypt a text using MCMC approach. i.e. find decryption key which we will call cipher from now on.
import string
import math
import random

# This function takes as input a decryption key and creates a dict for key where each letter in the decryption key
# maps to a alphabet For example if the decryption key is "DGHJKL...." this function will create a dict like {D:A,G:B,H:C....} 
def create_cipher_dict(cipher):
    cipher_dict = {}
    alphabet_list = list(string.ascii_uppercase)
    for i in range(len(cipher)):
        cipher_dict[alphabet_list[i]] = cipher[i]
    return cipher_dict

# This function takes a text and applies the cipher/key on the text and returns text.
def apply_cipher_on_text(text,cipher):
    cipher_dict = create_cipher_dict(cipher) 
    text = list(text)
    newtext = ""
    for elem in text:
        if elem.upper() in cipher_dict:
            newtext+=cipher_dict[elem.upper()]
        else:
            newtext+=" "
    return newtext

# This function takes as input a path to a long text and creates scoring_params dict which contains the 
# number of time each pair of alphabet appears together
# Ex. {'AB':234,'TH':2343,'CD':23 ..}
def create_scoring_params_dict(longtext_path):
    scoring_params = {}
    alphabet_list = list(string.ascii_uppercase)
    with open(longtext_path) as fp:
        for line in fp:
            data = list(line.strip())
            for i in range(len(data)-1):
                alpha_i = data[i].upper()
                alpha_j = data[i+1].upper()
                if alpha_i not in alphabet_list and alpha_i != " ":
                    alpha_i = " "
                if alpha_j not in alphabet_list and alpha_j != " ":
                    alpha_j = " "
                key = alpha_i+alpha_j
                if key in scoring_params:
                    scoring_params[key]+=1
                else:
                    scoring_params[key]=1
    return scoring_params

# This function takes as input a text and creates scoring_params dict which contains the 
# number of time each pair of alphabet appears together
# Ex. {'AB':234,'TH':2343,'CD':23 ..}

def score_params_on_cipher(text):
    scoring_params = {}
    alphabet_list = list(string.ascii_uppercase)
    data = list(text.strip())
    for i in range(len(data)-1):
        alpha_i =data[i].upper()
        alpha_j = data[i+1].upper()
        if alpha_i not in alphabet_list and alpha_i != " ":
            alpha_i = " "
        if alpha_j not in alphabet_list and alpha_j != " ":
            alpha_j = " "
        key = alpha_i+alpha_j
        if key in scoring_params:
            scoring_params[key]+=1
        else:
            scoring_params[key]=1
    return scoring_params

# This function takes the text to be decrypted and a cipher to score the cipher.
# This function returns the log(score) metric

def get_cipher_score(text,cipher,scoring_params):
    cipher_dict = create_cipher_dict(cipher)
    decrypted_text = apply_cipher_on_text(text,cipher)
    scored_f = score_params_on_cipher(decrypted_text)
    cipher_score = 0
    for k,v in scored_f.iteritems():
        if k in scoring_params:
            cipher_score += v*math.log(scoring_params[k])
    return cipher_score

# Generate a proposal cipher by swapping letters at two random location
def generate_cipher(cipher):
    pos1 = random.randint(0, len(list(cipher))-1)
    pos2 = random.randint(0, len(list(cipher))-1)
    if pos1 == pos2:
        return generate_cipher(cipher)
    else:
        cipher = list(cipher)
        pos1_alpha = cipher[pos1]
        pos2_alpha = cipher[pos2]
        cipher[pos1] = pos2_alpha
        cipher[pos2] = pos1_alpha
        return "".join(cipher)

# Toss a random coin with robability of head p. If coin comes head return true else false.
def random_coin(p):
    unif = random.uniform(0,1)
    if unif&gt;=p:
        return False
    else:
        return True
    
# Takes as input a text to decrypt and runs a MCMC algorithm for n_iter. Returns the state having maximum score and also
# the last few states 
def MCMC_decrypt(n_iter,cipher_text,scoring_params):
    current_cipher = string.ascii_uppercase # Generate a random cipher to start
    state_keeper = set()
    best_state = ''
    score = 0
    for i in range(n_iter):
        state_keeper.add(current_cipher)
        proposed_cipher = generate_cipher(current_cipher)
        score_current_cipher = get_cipher_score(cipher_text,current_cipher,scoring_params)
        score_proposed_cipher = get_cipher_score(cipher_text,proposed_cipher,scoring_params)
        acceptance_probability = min(1,math.exp(score_proposed_cipher-score_current_cipher))
        if score_current_cipher&gt;score:
            best_state = current_cipher
        if random_coin(acceptance_probability):
            current_cipher = proposed_cipher
        if i%500==0:
            print "iter",i,":",apply_cipher_on_text(cipher_text,current_cipher)[0:99]
    return state_keeper,best_state

## Run the Main Program:

scoring_params = create_scoring_params_dict('war_and_peace.txt')

plain_text = "As Oliver gave this first proof of the free and proper action of his lungs, \
the patchwork coverlet which was carelessly flung over the iron bedstead, rustled; \
the pale face of a young woman was raised feebly from the pillow; and a faint voice imperfectly \
articulated the words, Let me see the child, and die. \
The surgeon had been sitting with his face turned towards the fire: giving the palms of his hands a warm \
and a rub alternately. As the young woman spoke, he rose, and advancing to the bed's head, said, with more kindness \
than might have been expected of him: "

encryption_key = "XEBPROHYAUFTIDSJLKZMWVNGQC"
cipher_text = apply_cipher_on_text(plain_text,encryption_key)
decryption_key = "ICZNBKXGMPRQTWFDYEOLJVUAHS"

print"Text To Decode:", cipher_text
print "\n"
states,best_state = MCMC_decrypt(10000,cipher_text,scoring_params)
print "\n"
print "Decoded Text:",apply_cipher_on_text(cipher_text,best_state)
print "\n"
print "MCMC KEY FOUND:",best_state
print "ACTUAL DECRYPTION KEY:",decryption_key
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/result1_MCMC.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This chain converges around the 2000th iteration and we are able to unscramble the code. That's awesome!!! Now as you see the MCMC Key found is not exactly the encryption key. So the solution is not a deterministic one, but we can see that it does not actually decrease any of the value that the MCMC Methods provide. Now Lets Help Bilbo :)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="the-knapsack-problem"&gt;The Knapsack Problem&lt;/h1&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Restating, we have Bilbo a Thief who goes to Smaug's Lair. He finds M treasures. Each treasure has some Weight and some Gold value. But Bilbo cannot really take all of that. He could only carry a certain Maximum Weight. But being a smart hobbit, he wants to Maximize the value of the treasures he takes. Given the values for weights and value of the treasures and the maximum weight that Bilbo could carry, could you find a good solution?&lt;/p&gt;
&lt;p&gt;So in this problem we have an &lt;span class="math inline"&gt;\(1\)&lt;/span&gt;x&lt;span class="math inline"&gt;\(M\)&lt;/span&gt; array of Weight Values W, Gold Values G and a value for the maximum weight &lt;span class="math inline"&gt;\(w_{MAX}\)&lt;/span&gt; that Bilbo can carry. We want to find out an &lt;span class="math inline"&gt;\(1\)&lt;/span&gt;x&lt;span class="math inline"&gt;\(M\)&lt;/span&gt; array &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; of 1's and 0's, which holds weather Bilbo Carries a particular treasure or not. This array needs to follow the constraint &lt;span class="math inline"&gt;\(WX^T &amp;lt; w_{MAX}\)&lt;/span&gt; and we want to maximize &lt;span class="math inline"&gt;\(GX^T\)&lt;/span&gt; for a particular state X.(Here the T means transpose)&lt;/p&gt;
&lt;p&gt;So lets first discuss as to how we will create a proposal from a previous state.&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Pick a random index from the state and toggle the index value.&lt;/li&gt;
&lt;li&gt;Check if we satisfy our constraint. If yes this state is the proposal state.&lt;/li&gt;
&lt;li&gt;Else pick up another random index and repeat.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We also need to think about the Scoring Function. We need to give high values to states with high gold value. We will use: &lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[Score(X)=e^{\beta GX^T}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We give exponentially more value to higher score. The Beta here is a +ve constant. But how to choose it? If &lt;span class="math inline"&gt;\(\beta\)&lt;/span&gt; is big we will give very high score to good solutions and the chain will not be able to try new solutions as it can get stuck in local optimas. If we give a small value the chain will not converge to very good solutions. So weuse an Optimization Technique called &lt;strong&gt;&lt;a href="https://en.wikipedia.org/wiki/Simulated_annealing"&gt;Simulated Annealing&lt;/a&gt;&lt;/strong&gt; i.e. we will start with a small value of &lt;span class="math inline"&gt;\(\beta\)&lt;/span&gt; and increase as no of iterations go up. That way the chain will explore in the starting stages and stay at the best solution in the later stages.&lt;/p&gt;
&lt;p&gt;So now we have everything we need to get started&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;
import numpy as np

W = [20,40,60,12,34,45,67,33,23,12,34,56,23,56]
G = [120,420,610,112,341,435,657,363,273,812,534,356,223,516]
W_max = 150

# This function takes a state X , The gold vector G and a Beta Value and return the Log of score
def score_state_log(X,G,Beta):
    return Beta*np.dot(X,G)

# This function takes as input a state X and the number of treasures M, The weight vector W and the maximum weight W_max
# and returns a proposal state
def create_proposal(X,W,W_max):
    M = len(W)
    random_index = random.randint(0,M-1)
    #print random_index
    proposal = list(X)
    proposal[random_index] = 1 - proposal[random_index]  #Toggle
    #print proposal
    if np.dot(proposal,W)&lt;=W_max:
        return proposal
    else:
        return create_proposal(X,W,W_max)
    
# Takes as input a text to decrypt and runs a MCMC algorithm for n_iter. Returns the state having maximum score and also
# the last few states 
def MCMC_Golddigger(n_iter,W,G,W_max, Beta_start = 0.05, Beta_increments=.02):
    M = len(W)
    Beta = Beta_start
    current_X = [0]*M # We start with all 0's
    state_keeper = []
    best_state = ''
    score = 0
    
    for i in range(n_iter):
        state_keeper.append(current_X)
        proposed_X = create_proposal(current_X,W,W_max)

        score_current_X = score_state_log(current_X,G,Beta)
        score_proposed_X = score_state_log(proposed_X,G,Beta)
        acceptance_probability = min(1,math.exp(score_proposed_X-score_current_X))
        if score_current_X&gt;score:
            best_state = current_X
        if random_coin(acceptance_probability):
            current_X = proposed_X
        if i%500==0:
            Beta += Beta_increments 
        # You can use these below two lines to tune value of Beta
        #if i%20==0:
        #    print "iter:",i," |Beta=",Beta," |Gold Value=",np.dot(current_X,G)
            
    return state_keeper,best_state
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Running the Main program:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;
max_state_value =0 
Solution_MCMC = [0]
for i in range(10):
    state_keeper,best_state = MCMC_Golddigger(50000,W,G,W_max,0.0005, .0005)
    state_value=np.dot(best_state,G)
    if state_value&gt;max_state_value:
        max_state_value = state_value
        Solution_MCMC = best_state

print "MCMC Solution is :" , str(Solution_MCMC) , "with Gold Value:", str(max_state_value)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;pre&gt;&lt;code&gt;MCMC Solution is : [0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0] with Gold Value: 2435&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I won't say that this is the best solution. The deterministic solution using DP will be the best for such use case but sometimes when the problems gets large, having such techniques at disposal becomes invaluable.&lt;/p&gt;
&lt;p&gt;So tell me What do you think about MCMC Methods?&lt;/p&gt;
&lt;p&gt;Also, If you find any good applications or would like to apply these techniques to some area, I would really be glad to know about them and help if possible.&lt;/p&gt;
&lt;p&gt;The codes for both examples are sourced at &lt;a href="https://github.com/MLWhiz/MCMC_Project"&gt;Github&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="references-and-sources"&gt;References and Sources:&lt;/h2&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;a href="http://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science-ebook/dp/B00MMOJ19I"&gt;Introduction to Probability Joseph K Blitzstein, Jessica Hwang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://statweb.stanford.edu/~cgates/PERSI/papers/MCMCRev.pdf"&gt;The Markov Chain Monte Carlo Revolution, Persi Diaconis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.utstat.toronto.edu/wordpress/WSFiles/technicalreports/1005.pdf"&gt;Decrypting Classical Cipher Text Using Markov Chain Monte Carlo, Jian Chen and Jeffrey S. Rosenthal&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Look out for these two books to learn more about MCMC. I have not yet read them whole but still I liked whatever I read:&lt;/p&gt;
&lt;div style="margin-left:1em ; text-align: center;"&gt;

&lt;a target="_blank"  href="https://www.amazon.com/gp/product/1439840954/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1439840954&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=d55979088adc0aabeaed88f4f14b48b6"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1439840954&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1439840954" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/t&gt;&lt;/t&gt;
&lt;a target="_blank"  href="https://www.amazon.com/gp/product/1584885874/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1584885874&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=ee3e2a0bc99359d6c5db0463ab1abb13"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1584885874&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1584885874" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;

&lt;p&gt;Both these books are pretty high level and hard on math. But these are the best texts out there too. :)&lt;/p&gt;
&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;</summary><category term="Statistics"></category><category term="python"></category></entry><entry><title>My Tryst With MCMC Algorithms</title><link href="http://mlwhiz.github.io/blog/2015/08/19/MCMC_Algorithms_Beta_Distribution/" rel="alternate"></link><updated>2015-08-19T13:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2015-08-19:blog/2015/08/19/MCMC_Algorithms_Beta_Distribution/</id><summary type="html">&lt;p&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
The things that I find hard to understand push me to my limits. One of the things that I have always found hard is &lt;strong&gt;Markov Chain Monte Carlo Methods&lt;/strong&gt;. When I first encountered them, I read a lot about them but mostly it ended like this.
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/flabbergasted.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;The meaning is normally hidden in deep layers of Mathematical noise and not easy to decipher. This blog post is intended to clear up the confusion around MCMC methods, Know what they are actually useful for and Get hands on with some applications.&lt;/p&gt;
&lt;h2 id="so-what-really-are-mcmc-methods"&gt;&lt;strong&gt;So what really are MCMC Methods?&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;First of all we have to understand what are &lt;strong&gt;&lt;em&gt;Monte Carlo&lt;/em&gt;&lt;/strong&gt; Methods!!!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Monte_Carlo_method"&gt;Monte Carlo&lt;/a&gt; methods derive their name from Monte Carlo Casino in Monaco. There are many card games that need probability of winning against the dealer. Sometimes calculating this probability can be mathematically complex or highly intractable. But we can always run a computer simulation to simulate the whole game many times and see the probability as the number of wins divided by the number of games played.&lt;/p&gt;
&lt;p&gt;So that is all you need to know about Monte carlo Methods. Yes it is just a simple simulation technique with a Fancy Name.&lt;/p&gt;
&lt;p&gt;So as we have got the first part of MCMC, we also need to understand what are &lt;strong&gt;&lt;em&gt;&lt;a href="https://en.wikipedia.org/wiki/Markov_chain"&gt;Markov Chains&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;. Before Jumping onto Markov Chains let us learn a little bit about &lt;strong&gt;Markov Property&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Suppose you have a system of &lt;span class="math inline"&gt;\(M\)&lt;/span&gt; possible states, and you are hopping from one state to another. &lt;em&gt;Markov Property&lt;/em&gt; says that given a process which is at a state &lt;span class="math inline"&gt;\(X_n\)&lt;/span&gt; at a particular point of time, the probability of &lt;span class="math inline"&gt;\(X_{n+1} = k\)&lt;/span&gt;, where &lt;span class="math inline"&gt;\(k\)&lt;/span&gt; is any of the &lt;span class="math inline"&gt;\(M\)&lt;/span&gt; states the process can hop to, will only be dependent on which state it is at the given moment of time. And not on how it reached the current state.&lt;/p&gt;
&lt;p&gt;Mathematically speaking:&lt;/p&gt;
&lt;center&gt;
&lt;span class="math display"&gt;\[ P(X_{n+1}=k | X_n=k_n,X_{n-1}=k_{n-1},....,X_1=k_1) = P(X_{n+1}=k|X_n=k_n)\]&lt;/span&gt;
&lt;/center&gt;
&lt;p&gt;If a process exhibits the Markov Property than it is known as a Markov Process.&lt;/p&gt;
&lt;p&gt;Now Why is a Markov Chain important? It is important because of its &lt;strong&gt;stationary distribution&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;So what is a &lt;strong&gt;Stationary Distribution&lt;/strong&gt;?&lt;/p&gt;
&lt;p&gt;Assume you have a markov process like below. You start from any state &lt;span class="math inline"&gt;\(X_i\)&lt;/span&gt; and want to find out the state Probability distribution at &lt;span class="math inline"&gt;\(X_{i+1}\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div style="margin-top: 10px; margin-bottom: -10px;"&gt;
&lt;center&gt;
&lt;img src="/images/Finance_Markov_chain_example_state_space.svg"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
You have a matrix of transition probability
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/transition_matrix.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;which defines the probability of going from a state &lt;span class="math inline"&gt;\(X_i\)&lt;/span&gt; to &lt;span class="math inline"&gt;\(X_j\)&lt;/span&gt;. You start calculating the Probability distribution for the next state. If you are at Bull Market State at time &lt;span class="math inline"&gt;\(i\)&lt;/span&gt; , you have a state Probability distribution as [0,1,0]&lt;/p&gt;
&lt;p&gt;you want to get the state pdf at &lt;span class="math inline"&gt;\(X_{i+1}\)&lt;/span&gt;. That is given by&lt;/p&gt;
&lt;div&gt;
&lt;center&gt;
&lt;span class="math display"&gt;\[s_{i+1} = s_{i}Q\]&lt;/span&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;center&gt;
&lt;span class="math display"&gt;\[ s_{i+1}=\left[ {\begin{array}{cc}   .15 &amp;amp; .8 &amp;amp; .05      \end{array} } \right]\]&lt;/span&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;And the next state distribution could be found out by&lt;/p&gt;
&lt;center&gt;
&lt;span class="math display"&gt;\[s_{i+1} = s_iQ^2\]&lt;/span&gt;
&lt;/center&gt;
and so on. Eventually you will reach a stationary state s where:
&lt;center&gt;
&lt;span class="math display"&gt;\[sQ=s\]&lt;/span&gt;
&lt;/center&gt;
For this transition matrix Q the Stationary distribution &lt;span class="math inline"&gt;\(s\)&lt;/span&gt; is
&lt;center&gt;
&lt;span class="math display"&gt;\[ s_{i+1}=\left[ {\begin{array}{cc}   .625 &amp;amp; .3125 &amp;amp; .0625      \end{array} } \right]\]&lt;/span&gt;
&lt;/center&gt;
&lt;p&gt;The stationary state distribution is important because it lets you define the probability for every state of a system at a random time. That is for this particular example we can say that 62.5% of the times market will be in a bull market state, 31.25% of weeks it will be a bear market and 6.25% of weeks it will be stagnant&lt;/p&gt;
&lt;p&gt;Intuitively you can think of it as an random walk on a chain. You might visit some nodes more often than others based on node probabilities. In the &lt;em&gt;Google Pagerank&lt;/em&gt; problem you might think of a node as a page, and the probability of a page in the stationary distribution as its relative importance.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Woah!&lt;/em&gt;&lt;/strong&gt; That was a lot of information and we have yet not started talking about the MCMC Methods. Well if you are with me till now, we can now get on to the real topic now.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="so-what-is-mcmc"&gt;So What is MCMC?&lt;/h2&gt;
According to &lt;a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo"&gt;Wikipedia&lt;/a&gt;:
&lt;blockquote&gt;
&lt;strong&gt;Markov Chain Monte Carlo&lt;/strong&gt; (MCMC) methods are a class of algorithms for &lt;strong&gt;sampling from a probability distribution&lt;/strong&gt; based on constructing a Markov chain that has the desired distribution as its stationary distribution. The state of the chain after a number of steps is then used as a sample of the desired distribution. The quality of the sample improves as a function of the number of steps.
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;So let's explain this with an example: Assume that &lt;strong&gt;we want to sample from a &lt;a href="https://en.wikipedia.org/wiki/Beta_distribution"&gt;Beta distribution&lt;/a&gt;&lt;/strong&gt;. The &lt;em&gt;PDF&lt;/em&gt; is:&lt;/p&gt;
&lt;center&gt;
&lt;span class="math display"&gt;\[f(x) = Cx^{\alpha -1}(1-x)^{\beta -1}\]&lt;/span&gt;
&lt;/center&gt;
&lt;p&gt;where &lt;span class="math inline"&gt;\(C\)&lt;/span&gt; is the normalizing constant &lt;em&gt;(which we actually don't need to Sample from the distribution as we will see later)&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This is a &lt;strong&gt;fairly difficult problem&lt;/strong&gt; with the Beta Distribution if not intractable. In reality you might need to work with a lot harder Distribution Functions and sometimes you won't actually know the normalizing constants.&lt;/p&gt;
&lt;p&gt;MCMC methods make life easier for us by providing us with algorithms that could create a Markov Chain which has the Beta distribution as its &lt;strong&gt;stationary distribution&lt;/strong&gt; given that we can sample from a uniform distribution(which is &lt;em&gt;fairly&lt;/em&gt; easy).&lt;/p&gt;
&lt;p&gt;If we start from a random state and traverse to the next state based on some algorithm repeatedly, we will end up creating a Markov Chain which has the Beta distribution as its &lt;strong&gt;stationary distribution&lt;/strong&gt; and the states we are at after a long time could be used as sample from the Beta Distribution.&lt;/p&gt;
&lt;p&gt;One such MCMC Algorithm is the &lt;strong&gt;&lt;a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm"&gt;Metropolis Hastings Algorithm&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id="metropolis-hastings-algorithm"&gt;Metropolis Hastings Algorithm&lt;/h2&gt;
&lt;p&gt;Let &lt;span class="math inline"&gt;\(s=(s_1,s_2,....,s_M)\)&lt;/span&gt; be the desired stationary distribution. We want to create a Markov Chain that has this stationary distribution. We start with an arbitrary Markov Chain &lt;span class="math inline"&gt;\(P\)&lt;/span&gt; with &lt;span class="math inline"&gt;\(M\)&lt;/span&gt; states with transition matrix &lt;span class="math inline"&gt;\(Q\)&lt;/span&gt;, so that &lt;span class="math inline"&gt;\(Q_{ij}\)&lt;/span&gt; represents the probability of going from state &lt;span class="math inline"&gt;\(i\)&lt;/span&gt; to &lt;span class="math inline"&gt;\(j\)&lt;/span&gt;. Intuitively we know how to wander around this Markov Chain but this Markov Chain does not have the required Stationary Distribution. This chain does have some stationary distribution(which is not of our use)&lt;/p&gt;
&lt;p&gt;Our Goal is to change the way we wander on the this Markov Chain &lt;span class="math inline"&gt;\(P\)&lt;/span&gt; so that this chain has the desired Stationary distribution.&lt;/p&gt;
&lt;p&gt;To do this we:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Start at a random initial State &lt;span class="math inline"&gt;\(i\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Randomly pick a new &lt;em&gt;Proposal State&lt;/em&gt; by looking at the transition probabilities in the ith row of the transition matrix Q.&lt;/li&gt;
&lt;li&gt;Compute an measure called the &lt;em&gt;Acceptance Probability&lt;/em&gt; which is defined as:
&lt;center&gt;
&lt;span class="math display"&gt;\[a_{ij} = min(s_jp_{ji}/s_{i}p_{ij},1)\]&lt;/span&gt;
&lt;/center&gt;&lt;/li&gt;
&lt;li&gt;Now Flip a coin that lands head with probability &lt;span class="math inline"&gt;\(a_{ij}\)&lt;/span&gt;. If the coin comes up heads, accept the proposal i.e move to next state else reject the proposal i.e. stay at the current state.&lt;/li&gt;
&lt;li&gt;Repeat for a long time&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After a long time this chain will converge and will have a stationary distribution &lt;span class="math inline"&gt;\(s\)&lt;/span&gt;. &lt;strong&gt;We can then use the states of the chain as the sample from any distribution.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;While doing this to sample the Beta Distribution, the only time we are using the PDF is to find the acceptance probability and in that we divide &lt;span class="math inline"&gt;\(s_j\)&lt;/span&gt; by &lt;span class="math inline"&gt;\(s_i\)&lt;/span&gt;, i.e. the &lt;strong&gt;normalizing constant &lt;span class="math inline"&gt;\(C\)&lt;/span&gt; gets cancelled&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
Now Let's Talk about the intuition. For the Intuition I am quoting an &lt;a href="http://stats.stackexchange.com/a/12657"&gt;Answer&lt;/a&gt; from the site Stack Exchange,as this was the best intuitive explanation that I could find:
&lt;blockquote&gt;
I think there's a nice and simple intuition to be gained from the (independence-chain) Metropolis-Hastings algorithm. &lt;br&gt; &lt;br&gt; First, what's the goal? The goal of MCMC is to &lt;strong&gt;draw samples from some probability distribution&lt;/strong&gt; without having to know its exact height at any point(We don't need to know C). The way MCMC achieves this is to &lt;strong&gt;&amp;quot;wander around&amp;quot; on that distribution in such a way that the amount of time spent in each location is proportional to the height of the distribution&lt;/strong&gt;. If the &amp;quot;wandering around&amp;quot; process is set up correctly, you can make sure that this proportionality (between time spent and height of the distribution) is achieved. &lt;br&gt; &lt;br&gt; Intuitively, what we want to do is to to walk around on some (lumpy) surface in such a way that the amount of time we spend (or # samples drawn) in each location is proportional to the height of the surface at that location. So, e.g., we'd like to spend twice as much time on a hilltop that's at an altitude of 100m as we do on a nearby hill that's at an altitude of 50m. The nice thing is that we can do this even if we don't know the absolute heights of points on the surface: all we have to know are the relative heights. e.g., if one hilltop A is twice as high as hilltop B, then we'd like to spend twice as much time at A as we spend at B. &lt;br&gt; &lt;br&gt; The simplest variant of the Metropolis-Hastings algorithm (independence chain sampling) achieves this as follows: assume that in every (discrete) time-step, we pick a random new &amp;quot;proposed&amp;quot; location (selected uniformly across the entire surface). If the proposed location is higher than where we're standing now, move to it. If the proposed location is lower, then move to the new location with probability p, where p is the ratio of the height of that point to the height of the current location. (i.e., flip a coin with a probability p of getting heads; if it comes up heads, move to the new location; if it comes up tails, stay where we are). Keep a list of the locations you've been at on every time step, and that list will (asyptotically) have the right proportion of time spent in each part of the surface. (And for the A and B hills described above, you'll end up with twice the probability of moving from B to A as you have of moving from A to B). &lt;br&gt; &lt;br&gt; There are more complicated schemes for proposing new locations and the rules for accepting them, but the basic idea is still: &lt;strong&gt;(1) pick a new &amp;quot;proposed&amp;quot; location; (2) figure out how much higher or lower that location is compared to your current location; (3) probabilistically stay put or move to that location in a way that respects the overall goal of spending time proportional to height of the location. &amp;quot;&amp;quot;&amp;quot;&lt;/strong&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="sampling-from-beta-distribution"&gt;Sampling from Beta Distribution&lt;/h2&gt;
&lt;p&gt;Now Let's Move on to the problem of Simulating from Beta Distribution. Now Beta Distribution is a continuous Distribution on [0,1] and it can have infinite states on [0,1].&lt;/p&gt;
&lt;p&gt;Lets Assume an arbitrary Markov Chain P with infinite states on [0,1] having transition Matrix Q such that &lt;span class="math inline"&gt;\(Q_{ij} = Q_{ji} =\)&lt;/span&gt; All entries in Matrix. We don't really need the Matrix Q as we will see later, But I want to keep the problem description as close to the algorihm we suggested.&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Start at a random &lt;strong&gt;initial State &lt;span class="math inline"&gt;\(i\)&lt;/span&gt;&lt;/strong&gt; given by Unif(0,1).&lt;/li&gt;
&lt;li&gt;Randomly pick a new &lt;strong&gt;Proposal State&lt;/strong&gt; by looking at the transition probabilities in the ith row of the transition matrix Q. Lets say we pick up another Unif(0,1) state as a proposal state &lt;span class="math inline"&gt;\(j\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Compute an measure called the &lt;strong&gt;Acceptance Probability&lt;/strong&gt; :
&lt;center&gt;
&lt;span class="math display"&gt;\[a_{ij} = min(s_jp_{ji}/s_{i}p_{ij},1)\]&lt;/span&gt;
&lt;/center&gt;
which is,
&lt;center&gt;
&lt;span class="math display"&gt;\[a_{ij} = min(s_j/s_i,1)\]&lt;/span&gt;
&lt;/center&gt;
where,
&lt;center&gt;
&lt;span class="math display"&gt;\[s_i = Ci^{\alpha -1}(1-i)^{\beta -1}\]&lt;/span&gt;
&lt;/center&gt;
and,
&lt;center&gt;
&lt;span class="math display"&gt;\[s_j = Cj^{\alpha -1}(1-j)^{\beta -1}\]&lt;/span&gt;
&lt;/center&gt;&lt;/li&gt;
&lt;li&gt;Now Flip a coin that lands head with probability &lt;span class="math inline"&gt;\(a_{ij}\)&lt;/span&gt;. If the coin comes up heads, accept the proposal i.e move to next state else reject the proposal i.e. stay at the current state.&lt;/li&gt;
&lt;li&gt;Repeat for a long time&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So enough with theory, Let's Move on to python to create our Beta Simulations Now....&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;import random
# Lets define our Beta Function to generate s for any particular state. We don't care for the normalizing constant here.
def beta_s(w,a,b):
    return w**(a-1)*(1-w)**(b-1)

# This Function returns True if the coin with probability P of heads comes heads when flipped.
def random_coin(p):
    unif = random.uniform(0,1)
    if unif&gt;=p:
        return False
    else:
        return True

# This Function runs the MCMC chain for Beta Distribution.
def beta_mcmc(N_hops,a,b):
    states = []
    cur = random.uniform(0,1)
    for i in range(0,N_hops):
        states.append(cur)
        next = random.uniform(0,1)
        ap = min(beta_s(next,a,b)/beta_s(cur,a,b),1) # Calculate the acceptance probability
        if random_coin(ap):
            cur = next
    return states[-1000:] # Returns the last 100 states of the chain
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Let us check our results of the MCMC Sampled Beta distribution against the actual beta distribution.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;
import numpy as np
import pylab as pl
import scipy.special as ss
%matplotlib inline
pl.rcParams['figure.figsize'] = (17.0, 4.0)

# Actual Beta PDF.
def beta(a, b, i):
    e1 = ss.gamma(a + b)
    e2 = ss.gamma(a)
    e3 = ss.gamma(b)
    e4 = i ** (a - 1)
    e5 = (1 - i) ** (b - 1)
    return (e1/(e2*e3)) * e4 * e5

# Create a function to plot Actual Beta PDF with the Beta Sampled from MCMC Chain.
def plot_beta(a, b):
    Ly = []
    Lx = []
    i_list = np.mgrid[0:1:100j]
    for i in i_list:
        Lx.append(i)
        Ly.append(beta(a, b, i))
    pl.plot(Lx, Ly, label="Real Distribution: a="+str(a)+", b="+str(b))
    pl.hist(beta_mcmc(100000,a,b),normed=True,bins =25, histtype='step',label="Simulated_MCMC: a="+str(a)+", b="+str(b))
    pl.legend()
    pl.show()
    
plot_beta(0.1, 0.1)
plot_beta(1, 1)
plot_beta(2, 3)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div style="margin-top: -9px; margin-bottom: 30px;"&gt;
&lt;p&gt;&lt;img src="/images/graphs.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;As we can see our sampled beta values closely resemble the beta distribution.&lt;/p&gt;
&lt;p&gt;So MCMC Methods are useful for the following basic problems.&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Simulating from a Random Variable PDF. Example: Simulate from a Beta(0.5,0.5) or from a Normal(0,1).&lt;/li&gt;
&lt;li&gt;Solve problems with a large state space.For Example: Knapsack Problem, Encrytion Cipher etc. We will work on this in the &lt;a href="http://mlwhiz.com/blog/2015/08/21/MCMC_Algorithms_Cryptography/"&gt;Next Blog Post&lt;/a&gt; as this one has already gotten bigger than what I expected.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Till Then Ciao!!!!!!&lt;/p&gt;
&lt;h2 id="references-and-sources"&gt;References and Sources:&lt;/h2&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;a href="http://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science-ebook/dp/B00MMOJ19I"&gt;Introduction to Probability Joseph K Blitzstein, Jessica Hwang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stats.stackexchange.com/a/12657"&gt;StackExchange&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Look out for these two books to learn more about MCMC. I have not yet read them whole but still I liked whatever I read:&lt;/p&gt;
&lt;div style="margin-left:1em ; text-align: center;"&gt;

&lt;a target="_blank"  href="https://www.amazon.com/gp/product/1439840954/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1439840954&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=d55979088adc0aabeaed88f4f14b48b6"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1439840954&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1439840954" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/t&gt;&lt;/t&gt;
&lt;a target="_blank"  href="https://www.amazon.com/gp/product/1584885874/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1584885874&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=ee3e2a0bc99359d6c5db0463ab1abb13"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1584885874&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1584885874" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;

&lt;p&gt;Both these books are pretty high level and hard on math. But these are the best texts out there too. :)&lt;/p&gt;
&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;</summary><category term="Statistics"></category><category term="python"></category></entry><entry><title>Hadoop Mapreduce Streaming Tricks and Techniques</title><link href="http://mlwhiz.github.io/blog/2015/05/09/Hadoop_Mapreduce_Streaming_Tricks_and_Techniques/" rel="alternate"></link><updated>2015-05-09T13:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2015-05-09:blog/2015/05/09/Hadoop_Mapreduce_Streaming_Tricks_and_Techniques/</id><summary type="html">&lt;p&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I have been using Hadoop a lot now a days and thought about writing some of the novel techniques that a user could use to get the most out of the Hadoop Ecosystem.&lt;/p&gt;
&lt;h3 id="using-shell-scripts-to-run-your-programs"&gt;Using Shell Scripts to run your Programs&lt;/h3&gt;
&lt;div style="margin-top: -9px; margin-bottom: -30px;"&gt;
&lt;p&gt;&lt;img src="/images/I-love-bash-1024x220.png" &gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br&gt; I am not a fan of large bash commands. The ones where you have to specify the whole path of the jar files and the such. &lt;em&gt;You can effectively organize your workflow by using shell scripts.&lt;/em&gt; Now Shell scripts are not as formidable as they sound. We wont be doing programming perse using these shell scripts(Though they are pretty good at that too), we will just use them to store commands that we need to use sequentially.&lt;/p&gt;
&lt;p&gt;Below is a sample of the shell script I use to run my Mapreduce Codes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="bash" style="background-color:#000000; color:#FFFFFF"&gt;#!/bin/bash
#Defining program variables
IP="/data/input"
OP="/data/output"
HADOOP_JAR_PATH="/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/contrib/streaming/hadoop-streaming-2.0.0-mr1-cdh4.5.0.jar"
MAPPER="test_m.py"
REDUCER="test_r.py"

hadoop fs -rmr -skipTrash&amp;nbsp;$OP
hadoop jar&amp;nbsp;$HADOOP_JAR_PATH \
-file&amp;nbsp;$MAPPER -mapper "python test_m.py" \
-file&amp;nbsp;$REDUCER -reducer "python test_r.py" \
-input&amp;nbsp;$IP -output&amp;nbsp;$OP
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
I generally save them as test_s.sh and whenever i need to run them i simply type &lt;code&gt;sh test_s.sh&lt;/code&gt;. This helps in three ways.
&lt;ul&gt;
&lt;li&gt;
It helps me to store hadoop commands in a manageable way.
&lt;/li&gt;
&lt;li&gt;
It is easy to run the mapreduce code using the shell script.
&lt;/li&gt;
&lt;li&gt;
&lt;em&gt;&lt;strong&gt;If the code fails, I do not have to manually delete the output directory&lt;/strong&gt;&lt;/em&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;em&gt; The simplification of anything is always sensational. &lt;br&gt;&lt;/em&gt; &lt;small&gt;Gilbert K. Chesterton&lt;/small&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="using-distributed-cache-to-provide-mapper-with-a-dictionary"&gt;Using Distributed Cache to provide mapper with a dictionary&lt;/h3&gt;
&lt;div style="margin-top: -9px; margin-bottom: -30px;"&gt;
&lt;p&gt;&lt;img src="/images/Game-Of-Thrones-Wallpaper-House-Sigils-1.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;br&gt; Often times it happens that you want that your Hadoop Mapreduce program is able to access some static file. This static file could be a dictionary, could be parameters for the program or could be anything. What distributed cache does is that it provides this file to all the mapper nodes so that you can use that file in any way across all your mappers. Now this concept although simple would help you to think about Mapreduce in a whole new light. Lets start with an example. Supppose you have to create a sample Mapreduce program that reads a big file containing the information about all the characters in &lt;a href="http://www.hbo.com/game-of-thrones"&gt;Game of Thrones&lt;/a&gt; stored as &lt;strong&gt;&lt;code&gt;&amp;quot;/data/characters/&amp;quot;&lt;/code&gt;&lt;/strong&gt;:
&lt;div style="width: 50%; margin: 0 auto;"&gt;
&lt;table class="table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;
Cust_ID
&lt;/th&gt;
&lt;th&gt;
User_Name
&lt;/th&gt;
&lt;th&gt;
House
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
1
&lt;/td&gt;
&lt;td&gt;
Daenerys Targaryen
&lt;/td&gt;
&lt;td&gt;
Targaryen
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
2
&lt;/td&gt;
&lt;td&gt;
Tyrion Lannister
&lt;/td&gt;
&lt;td&gt;
Lannister
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
3
&lt;/td&gt;
&lt;td&gt;
Cersei Lannister
&lt;/td&gt;
&lt;td&gt;
Lannister
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class="warning"&gt;
&lt;td&gt;
4
&lt;/td&gt;
&lt;td&gt;
Robert Baratheon
&lt;/td&gt;
&lt;td&gt;
Baratheon
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class="warning"&gt;
&lt;td&gt;
5
&lt;/td&gt;
&lt;td&gt;
Robb Stark
&lt;/td&gt;
&lt;td&gt;
Stark
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;But you dont want to use the dead characters in the file for the analysis you want to do. &lt;em&gt;You want to count the number of living characters in Game of Thrones grouped by their House&lt;/em&gt;. (I know its easy!!!!!) One thing you could do is include an if statement in your Mapper Code which checks if the persons ID is 4 then exclude it from the mapper and such. But the problem is that you would have to do it again and again for the same analysis as characters die like flies when it comes to George RR Martin.(Also where is the fun in that) So you create a file which contains the Ids of all the dead characters at &lt;strong&gt;&lt;code&gt;&amp;quot;/data/dead_characters.txt&amp;quot;&lt;/code&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;div style="width: 50%; margin: 0 auto;"&gt;
&lt;table class="table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;
Died
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
4
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
5
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;Whenever you have to run the analysis you can just add to this file and you wont have to change anything in the code. Also sometimes this file would be long and you would not want to clutter your code with IDs and such.&lt;/p&gt;
&lt;p&gt;So How Would we do it. Let's go in a step by step way around this. We will create a shell script, a mapper script and a reducer script for this task.&lt;/p&gt;
&lt;h5 id="shell-script"&gt;1) Shell Script&lt;/h5&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="bash" style="background-color:#000000; color:#FFFFFF"&gt;#!/bin/bash
#Defining program variables
DC="/data/dead_characters.txt"
IP="/data/characters"
OP="/data/output"
HADOOP_JAR_PATH="/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/contrib/streaming/hadoop-streaming-2.0.0-mr1-cdh4.5.0.jar"
MAPPER="got_living_m.py"
REDUCER="got_living_r.py"

hadoop jar&amp;nbsp;$HADOOP_JAR_PATH \
-file&amp;nbsp;$MAPPER -mapper "python got_living_m.py" \
-file&amp;nbsp;$REDUCER -reducer "python got_living_r.py" \
-cacheFile&amp;nbsp;$DC#ref \
-input&amp;nbsp;$IP -output&amp;nbsp;$OP
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Note how we use the &lt;code&gt;&amp;quot;-cacheFile&amp;quot;&lt;/code&gt; option here. We have specified that we will refer to the file that has been provided in the Distributed cache as &lt;code&gt;#ref&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Next is our Mapper Script.&lt;/p&gt;
&lt;h5 id="mapper-script"&gt;2) Mapper Script&lt;/h5&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;import sys
dead_ids = set()

def read_cache():
    for line in open('ref'):
        id = line.strip()
        dead_ids.add(id)

read_cache()

for line in sys.stdin:
    rec = line.strip().split("|") # Split using Delimiter "|"
    id = rec[0]
    house = rec[2]
    if id not in dead_ids:
        print "%s\t%s" % (house,1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And our Reducer Script.&lt;/p&gt;
&lt;h5 id="reducer-script"&gt;3) Reducer Script&lt;/h5&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/darkula.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;import sys
current_key = None
key = None
count = 0

for line in sys.stdin:
    line = line.strip()
    rec = line.split('\t')
    key = rec[0]    
    value = int(rec[1])
    
    if current_key == key:
        count += value
    else:
        if current_key:
            print "%s:%s" %(key,str(count))     
        current_key = key
        count = value

if current_key == key:
    print "%s:%s" %(key,str(count)) 
&lt;/code&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This was a simple program and the output will be just what you expected and not very exciting. &lt;em&gt;&lt;strong&gt;But the Technique itself solves a variety of common problems. You can use it to pass any big dictionary to your Mapreduce Program&lt;/strong&gt;&lt;/em&gt;. Atleast thats what I use this feature mostly for. Hope You liked it. Will try to expand this post with more tricks.&lt;/p&gt;
&lt;p&gt;The codes for this post are posted at github &lt;a href="https://github.com/MLWhiz/Hadoop-Mapreduce-Tricks"&gt;here&lt;/a&gt;.&lt;/p&gt;
Other Great Learning Resources For Hadoop:
&lt;ul&gt;
&lt;li&gt;
&lt;a href="http://www.google.co.in/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0CB0QFjAA&amp;url=http%3A%2F%2Fwww.michael-noll.com%2Ftutorials%2Fwriting-an-hadoop-mapreduce-program-in-python%2F&amp;ei=8RRVVdP2IMe0uQShsYDYBg&amp;usg=AFQjCNH3DqrlSIG8D-K8jgQWTALic1no5A&amp;sig2=BivwTW6mdJs5c9w9VaSK2Q&amp;bvm=bv.93112503,d.c2E"&gt;Michael Noll's Hadoop Mapreduce Tutorial&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="http://www.google.co.in/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0CCMQFjAB&amp;url=http%3A%2F%2Fhadoop.apache.org%2Fdocs%2Fr1.2.1%2Fstreaming.html&amp;ei=8RRVVdP2IMe0uQShsYDYBg&amp;usg=AFQjCNEIB4jmqcBs-GepHdn7DRxqTI9zXA&amp;sig2=nYkAnDjjjaum5YVlYuMUJQ&amp;bvm=bv.93112503,d.c2E"&gt;Apache's Hadoop Streaming Documentation&lt;/a&gt;
&lt;/li&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Also I like these books a lot. Must have for a Hadooper....&lt;/p&gt;
&lt;div style="margin-left:1em ; text-align: center;"&gt;
&lt;a target="_blank"  href="https://www.amazon.com/gp/product/1785887211/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1785887211&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=a0e7b4f0b2ea4a5146042890e1c04f7e"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1785887211&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1785887211" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/t&gt;&lt;/t&gt;
&lt;a target="_blank"  href="https://www.amazon.com/gp/product/1491901632/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1491901632&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=4122280e94f7bbd0ceebc9d13e60d103"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1491901632&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1491901632" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;

&lt;p&gt;The first book is a guide for using Hadoop as well as spark with Python. While the second one contains a detailed overview of all the things in Hadoop. Its the definitive guide.&lt;/p&gt;

&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;</summary><category term="hadoop"></category><category term="python"></category></entry><entry><title>Exploring Vowpal Wabbit with the Avazu Clickthrough Prediction Challenge</title><link href="http://mlwhiz.github.io/blog/2014/12/01/Exploring_Vowpal_Wabbit_with_Avazu/" rel="alternate"></link><updated>2014-12-01T13:43:00-02:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2014-12-01:blog/2014/12/01/Exploring_Vowpal_Wabbit_with_Avazu/</id><summary type="html">&lt;p&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In online advertising, click-through rate (CTR) is a very important metric for evaluating ad performance. As a result, click prediction systems are essential and widely used for sponsored search and real-time bidding.&lt;/p&gt;
&lt;p&gt;For this competition, we have provided 11 days worth of Avazu data to build and test prediction models. Can you find a strategy that beats standard classification algorithms? The winning models from this competition will be released under an open-source license.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="data-fields"&gt;Data Fields&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;id: ad identifier
click: 0/1 for non-click/click
hour: format is YYMMDDHH, so 14091123 means 23:00 on Sept. 11, 2014 UTC.
C1 -- anonymized categorical variable
banner_pos
site_id
site_domain
site_category
app_id
app_domain
app_category
device_id
device_ip
device_model
device_type
device_conn_type
C14-C21 -- anonymized categorical variables&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="loading-data"&gt;Loading Data&lt;/h4&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[9]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="c"&gt;## Loading the data &lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;string&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;stri&lt;/span&gt;

&lt;span class="c"&gt;#too large data not keeping it in memory.&lt;/span&gt;
&lt;span class="c"&gt;# will be using line by line scripting.&lt;/span&gt;
&lt;span class="c"&gt;#data = pd.read_csv(&amp;quot;/Users/RahulAgarwal/kaggle_cpr/train&amp;quot;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Since the data istoo large around 6 gb , we will proceed by doing line by line analysis of data. We will try to use vowpal wabbit first of all as it is an online model and it also gives us the option of minimizing log loss as a default. It is also very fast to run and will give us quite an intuition as to how good our prediction can be. - I will use all the variables in the first implementation and we will rediscover things as we move on&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="running-vowpal-wabbit"&gt;Running Vowpal Wabbit&lt;/h4&gt;
&lt;h4 id="creating-data-in-vowpal-format-one-time-only"&gt;Creating data in vowpal format (One Time Only)&lt;/h4&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[15]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;datetime&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;csv_to_vw&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loc_csv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loc_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;now&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;Turning &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt; into &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;. Is_train_set? &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loc_csv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;loc_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loc_csv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;r&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loc_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;wb&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;counter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;infile&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;line_count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;infile&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="c"&gt;# to counter the header&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;line_count&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;line_count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
                &lt;span class="k"&gt;continue&lt;/span&gt;
            &lt;span class="c"&gt;# The data has all categorical features&lt;/span&gt;
            &lt;span class="c"&gt;#numerical_features = &amp;quot;&amp;quot;&lt;/span&gt;
            &lt;span class="n"&gt;categorical_features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
            &lt;span class="n"&gt;counter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;counter&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="c"&gt;#print counter&lt;/span&gt;
            &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;,&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="c"&gt;#working on the date column. We will take day , hour&lt;/span&gt;
                &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="n"&gt;new_date&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;20&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
                &lt;span class="n"&gt;day&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new_date&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strftime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;%A&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;hour&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="n"&gt;categorical_features&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot; |hr &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;hour&lt;/span&gt;
                &lt;span class="n"&gt;categorical_features&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot; |day &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;day&lt;/span&gt;
                &lt;span class="c"&gt;# 24 columns in data    &lt;/span&gt;
                &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                        &lt;span class="n"&gt;categorical_features&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;|c&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="n"&gt;new_date&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;20&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
                &lt;span class="n"&gt;day&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;new_date&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strftime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;%A&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;hour&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="n"&gt;categorical_features&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot; |hr &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;hour&lt;/span&gt;
                &lt;span class="n"&gt;categorical_features&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot; |day &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;day&lt;/span&gt;
                &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                        &lt;span class="n"&gt;categorical_features&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot; |c&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  &lt;span class="c"&gt;#Creating the labels&lt;/span&gt;
            &lt;span class="c"&gt;#print &amp;quot;a&amp;quot;&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c"&gt;#we care about labels&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
                &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="c"&gt;#we set negative label to -1&lt;/span&gt;
                &lt;span class="c"&gt;#print (numerical_features)&lt;/span&gt;
                &lt;span class="c"&gt;#print categorical_features&lt;/span&gt;
                &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt; &amp;#39;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;categorical_features&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c"&gt;#we dont care about labels&lt;/span&gt;
                &lt;span class="c"&gt;#print ( &amp;quot;1 &amp;#39;%s |i%s |c%s\n&amp;quot; % (line[0],numerical_features,categorical_features) )&lt;/span&gt;
                &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;1 &amp;#39;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;categorical_features&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c"&gt;#Reporting progress&lt;/span&gt;
            &lt;span class="c"&gt;#print counter&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;counter&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;1000000&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;counter&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;now&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt; Task execution time:&lt;/span&gt;&lt;span class="se"&gt;\n\t&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;counter&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;now&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="c"&gt;#csv_to_vw(&amp;quot;/Users/RahulAgarwal/kaggle_cpr/train&amp;quot;, &amp;quot;/Users/RahulAgarwal/kaggle_cpr/click.train_original_data.vw&amp;quot;,train=True)&lt;/span&gt;
&lt;span class="c"&gt;#csv_to_vw(&amp;quot;/Users/RahulAgarwal/kaggle_cpr/test&amp;quot;, &amp;quot;/Users/RahulAgarwal/kaggle_cpr/click.test_original_data.vw&amp;quot;,train=False)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="running-vowpal-wabbit-on-the-data"&gt;Running Vowpal Wabbit on the data&lt;/h4&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The Vowpal Wabbit will be run on the command line itself.&lt;/p&gt;
&lt;p&gt;Training VW:&lt;/p&gt;
&lt;p&gt;vw click.train_original_data.vw -f click.model.vw --loss_function logistic&lt;/p&gt;
&lt;p&gt;Testing VW:&lt;/p&gt;
&lt;p&gt;vw click.test_original_data.vw -t -i click.model.vw -p click.preds.txt&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="creating-kaggle-submission-file"&gt;Creating Kaggle Submission File&lt;/h4&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[17]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;math&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;zygmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;kaggle.click.submission.csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;wb&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;outfile&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;outfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;id,click&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;click.preds.txt&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        
        &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;outfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;,&lt;/span&gt;&lt;span class="si"&gt;%f&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;zygmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))))&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This solution ranked 211/371 submissions at the time and the leaderboard score was 0.4031825 while the best leaderboard score was 0.3901120&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="next-steps"&gt;Next Steps&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Create a better VW model
&lt;ul&gt;
&lt;li&gt;Shuffle the data before making the model as the VW algorithm is an online learner and might have given more preference to the latest data&lt;/li&gt;
&lt;li&gt;provide high weights for clicks as data is skewed. How Much?&lt;/li&gt;
&lt;li&gt;tune VW algorithm using vw-hypersearch. What should be tuned?&lt;/li&gt;
&lt;li&gt;Use categorical features like |C1 &amp;quot;C1&amp;quot;&amp;amp;&amp;quot;1&amp;quot;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Create a XGBoost Model.&lt;/li&gt;
&lt;li&gt;Create a Sofia-ML Model and see how it works on this data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;</summary><category term="ctr"></category><category term="vw"></category></entry><entry><title>Data Science 101 : Playing with Scraping in Python</title><link href="http://mlwhiz.github.io/blog/2014/10/02/data_science_101_python_pattern/" rel="alternate"></link><updated>2014-10-02T13:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2014-10-02:blog/2014/10/02/data_science_101_python_pattern/</id><summary type="html">&lt;p&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This is a simple illustration of using Pattern Module to scrape web data using Python. We will be scraping the data from imdb for the top TV Series along with their ratings&lt;/p&gt;
&lt;p&gt;We will be using this link for this:&lt;/p&gt;
&lt;p&gt;http://www.imdb.com/search/title?count=100&amp;amp;num_votes=5000,&amp;amp;ref_=gnr_tv_hr&amp;amp;sort=user_rating,desc&amp;amp;start=1&amp;amp;title_type=tv_series,mini_series&lt;/p&gt;
&lt;p&gt;This URL gives a list of top Rated TV Series which have number of votes atleast 5000. The Thing to note in this URL is the &amp;quot;&amp;amp;start=&amp;quot; parameter where we can specify which review should the list begin with. If we specify 1 we will get reviews starting from 1-100, if we specify 101 we get reviews from 101-200 and so on.&lt;/p&gt;
&lt;p&gt;Lets Start by importing some Python Modules that will be needed for Scraping Data:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[1]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;                     &lt;span class="c"&gt;# This is a module that is used for getting html data from a webpage in the text format&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pattern&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;web&lt;/span&gt;             &lt;span class="c"&gt;# We use this module to parse through the dtaa that we loaded using requests&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="loading-the-data-using-requests-and-pattern"&gt;Loading the data using requests and pattern&lt;/h3&gt;
&lt;p&gt;So the modules are loaded at this point, next we will try to catch the url using python and put this into a dict in python. We will start with a single URL and then try to parse it using pattern module&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[7]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;http://www.imdb.com/search/title?count=100&amp;amp;num_votes=5000,&amp;amp;ref_=gnr_tv_hr&amp;amp;sort=user_rating,desc&amp;amp;start=1&amp;amp;title_type=tv_series,mini_series&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;html_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; 
&lt;span class="n"&gt;dom&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;web&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Element&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;html_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="parsing-the-data"&gt;Parsing the data&lt;/h3&gt;
&lt;p&gt;This is the data of Interest found out after some nspection of the html code. This is for a single TV Series Band of brothers, but if you are able to parse this you just have to move hrough a loop.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;td&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;title&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;wlb_wrapper&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tconst&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;tt0185906&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;small&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;caller&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;search&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/title/tt0185906/&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;Band&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;Brothers&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;year_type&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2001&lt;/span&gt; &lt;span class="n"&gt;Mini&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;br&lt;/span&gt; &lt;span class="o"&gt;/&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;div&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;user_rating&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;div&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;rating rating-list&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;auth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;BCYm-Mk2Ros7BTxsLNL2XJX_icfZVahNr1bE9-5Ajb2N3381yxcaNN4ZQqyrX7KgEFGqHWmwv10lv7lAnXyC8CCkh9hPqQfzwVTumCeRzjpnndW4_ft97qQkBYLUvFxYnFgR&amp;quot;&lt;/span&gt; &lt;span class="nb"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;tt0185906|imdb|9.6|9.6|advsearch&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ga&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;identifier&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;advsearch&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Users rated this 9.6/10 (156,073 votes) - click stars to rate&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;rating-bg&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;nbsp&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;rating-imdb&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;width: 134px&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;nbsp&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;rating-stars&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/register/login?why=vote&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Register or login to rate this title&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;nofollow&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/register/login?why=vote&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Register or login to rate this title&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;nofollow&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/register/login?why=vote&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Register or login to rate this title&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;nofollow&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/register/login?why=vote&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Register or login to rate this title&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;nofollow&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/register/login?why=vote&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Register or login to rate this title&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;nofollow&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/register/login?why=vote&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Register or login to rate this title&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;nofollow&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/register/login?why=vote&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Register or login to rate this title&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;nofollow&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/register/login?why=vote&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Register or login to rate this title&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;nofollow&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/register/login?why=vote&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Register or login to rate this title&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;nofollow&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/register/login?why=vote&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Register or login to rate this title&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;nofollow&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;rating-rating&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;value&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mf"&gt;9.6&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;grey&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;/&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;grey&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;rating-cancel&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/title/tt0185906/vote?v=X;k=BCYm-Mk2Ros7BTxsLNL2XJX_icfZVahNr1bE9-5Ajb2N3381yxcaNN4ZQqyrX7KgEFGqHWmwv10lv7lAnXyC8CCkh9hPqQfzwVTumCeRzjpnndW4_ft97qQkBYLUvFxYnFgR&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Delete&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;nofollow&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;nbsp&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;div&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;div&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;outline&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;story&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;Easy&lt;/span&gt; &lt;span class="n"&gt;Company&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;US&lt;/span&gt; &lt;span class="n"&gt;Army&lt;/span&gt; &lt;span class="mi"&gt;101&lt;/span&gt;&lt;span class="n"&gt;st&lt;/span&gt; &lt;span class="n"&gt;Airborne&lt;/span&gt; &lt;span class="n"&gt;division&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;their&lt;/span&gt; &lt;span class="n"&gt;mission&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;WWII&lt;/span&gt; &lt;span class="n"&gt;Europe&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;Operation&lt;/span&gt; &lt;span class="nn"&gt;Overlord&lt;/span&gt; &lt;span class="nn"&gt;through&lt;/span&gt; &lt;span class="nn"&gt;V&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;J&lt;/span&gt; &lt;span class="n"&gt;Day&lt;/span&gt;&lt;span class="o"&gt;.&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;credit&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="n"&gt;With&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/name/nm0342241/&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;Scott&lt;/span&gt; &lt;span class="n"&gt;Grimes&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/name/nm0500614/&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;Matthew&lt;/span&gt; &lt;span class="n"&gt;Leitch&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/name/nm0507073/&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;Damian&lt;/span&gt; &lt;span class="n"&gt;Lewis&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;genre&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/genre/action&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;Action&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/genre/drama&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;Drama&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/genre/history&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;History&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/genre/war&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;War&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;certificate&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;TV_MA&amp;quot;&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;us_tv_ma titlePageSprite&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;runtime&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;705&lt;/span&gt; &lt;span class="n"&gt;mins&lt;/span&gt;&lt;span class="o"&gt;.&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;td&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Now we have loaded the data we need to parse it using the functions from pattern module. The main function in pattern module is the by_tag() function which lets you get all the elements with that particular tagname. For us the main interest is this &amp;quot;td&amp;quot; tag with class as &amp;quot;title&amp;quot;. This &amp;quot;td&amp;quot; tag contains: 1. Title in the &amp;quot;a&amp;quot; tag 2. Rating in the &amp;quot;span&amp;quot; tag with class &amp;quot;value&amp;quot; 3. Genres in the &amp;quot;span&amp;quot; tag with class &amp;quot;genre&amp;quot; and then looping through the &amp;quot;a&amp;quot; tags 4. Runtime in &amp;quot;span&amp;quot; tag with class &amp;quot;runtime&amp;quot; 5. Artists in &amp;quot;span&amp;quot; tag with class &amp;quot;credit&amp;quot; loop through &amp;quot;a&amp;quot; tags&lt;/p&gt;
&lt;p&gt;Now lets write some code to parse this data.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;tv_series&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;dom&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;td.title&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;    
    &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tv_series&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;
    &lt;span class="n"&gt;genres&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tv_series&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;span.genre&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;genres&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;genres&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;runtime&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tv_series&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;span.runtime&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;runtime&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;NA&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;rating&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tv_series&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;span.value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;
    &lt;span class="n"&gt;artists&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tv_series&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;span.credit&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;artists&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;artists&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;genres&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;runtime&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rating&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;artists&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Band of Brothers [u'Action', u'Drama', u'History', u'War'] 705 mins. 9.6 [u'Scott Grimes', u'Matthew Leitch', u'Damian Lewis']&lt;/p&gt;
&lt;p&gt;Breaking Bad [u'Crime', u'Drama', u'Thriller'] 45 mins. 9.6 [u'Bryan Cranston', u'Aaron Paul', u'Anna Gunn']&lt;/p&gt;
&lt;p&gt;Game of Thrones [u'Adventure', u'Drama', u'Fantasy'] 55 mins. 9.5 [u'Lena Headey', u'Peter Dinklage', u'Maisie Williams']&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;So finally we are OK with parsing. We have understood the structure of the webpage, the tags and classes we will need to use and how to use pattern module to find data for a single page. Now lets use the power of for loops to get all the data.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="getting-whole-data"&gt;Getting Whole Data&lt;/h3&gt;
&lt;p&gt;Lets Go through it the pythonic way. We will create functions and try to execute small chunks of code rather than doing it all at once. Lets first create a funcion that takes a start_val(for the start parameter) and returns a dom element.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[64]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_dom&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;start_val&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;http://www.imdb.com/search/title?count=100&amp;amp;num_votes=5000,&amp;amp;ref_=gnr_tv_hr&amp;amp;sort=user_rating,desc&amp;amp;start=&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;start_val&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&amp;amp;title_type=tv_series,mini_series&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;html_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; 
    &lt;span class="n"&gt;dom&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;web&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Element&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;html_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;dom&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Now lets create a function parse_dom that takes as input dom an throws out a list containing all the data. The list is like this :&lt;/p&gt;
&lt;p&gt;[&lt;/p&gt;
&lt;p&gt;['Band of Brothers','Action|Drama|History|War','705 mins.','9.6','Scott Grimes|Matthew Leitch|Damian Lewis'],&lt;/p&gt;
&lt;p&gt;['Breaking Bad','Crime|Drama|Thriller','45 mins.', '9.6' ,'Bryan Cranston|Aaron Paul|Anna Gunn'],.....&lt;/p&gt;
&lt;p&gt;]&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[54]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse_dom&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dom&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;tv_series&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;dom&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;td.title&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;    
        &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tv_series&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;
        &lt;span class="n"&gt;genres&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tv_series&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;span.genre&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;genres&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;|&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;genres&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;runtime&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tv_series&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;span.runtime&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;runtime&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;NA&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;rating&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tv_series&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;span.value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;
        &lt;span class="n"&gt;artists&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tv_series&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;span.credit&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;artists&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;|&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;artists&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;temp_res&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="n"&gt;temp_res&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extend&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;genres&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;runtime&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rating&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;artists&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;temp_res&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;
    
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Now Lets Use these functions and a simple while loop to scrap all the pages&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[55]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;all_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;dom&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_dom&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;datalist&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;parse_dom&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dom&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;datalist&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;break&lt;/span&gt;
    &lt;span class="n"&gt;all_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;all_data&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;parse_dom&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dom&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[63]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Total Elements:&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;all_data&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;First Five Elements :&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;all_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;div class="vbox output_wrapper"&gt;
&lt;div class="output vbox"&gt;


&lt;div class="hbox output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="box-flex1 output_subarea output_stream output_stdout"&gt;
&lt;pre&gt;
Total Elements:898
First Five Elements :[[u&amp;apos;Breaking Bad&amp;apos;, u&amp;apos;Crime|Drama|Thriller&amp;apos;, u&amp;apos;45 mins.&amp;apos;, u&amp;apos;9.6&amp;apos;, u&amp;apos;Bryan Cranston|Aaron Paul|Anna Gunn&amp;apos;], [u&amp;apos;Game of Thrones&amp;apos;, u&amp;apos;Adventure|Drama|Fantasy&amp;apos;, u&amp;apos;55 mins.&amp;apos;, u&amp;apos;9.5&amp;apos;, u&amp;apos;Lena Headey|Peter Dinklage|Maisie Williams&amp;apos;], [u&amp;apos;Planet Earth&amp;apos;, u&amp;apos;Documentary&amp;apos;, u&amp;apos;570 mins.&amp;apos;, u&amp;apos;9.5&amp;apos;, u&amp;apos;David Attenborough|Sigourney Weaver|Huw Cordey&amp;apos;], [u&amp;apos;Cosmos: A SpaceTime Odyssey&amp;apos;, u&amp;apos;Documentary&amp;apos;, u&amp;apos;60 mins.&amp;apos;, u&amp;apos;9.5&amp;apos;, u&amp;apos;Neil deGrasse Tyson|Stoney Emshwiller|Piotr Michael&amp;apos;]]

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Voila!!! The number of elements we had to scrap were 898 and We got all of them. And to tell you, IMDB is one of the worst written HTML's. So that's Great.&lt;/p&gt;
&lt;p&gt;In the next part of the tutorial we will run exploratory data analysis on this data using pandas and maplotlib. Till then keep learning.&lt;/p&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;</summary><category term="web scraping"></category></entry><entry><title>Download CS109 Lectures using RTMPDump</title><link href="http://mlwhiz.github.io/blog/2014/10/02/data_science_cs_109_download_rtmdump/" rel="alternate"></link><updated>2014-10-02T13:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2014-10-02:blog/2014/10/02/data_science_cs_109_download_rtmdump/</id><summary type="html">&lt;p&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Right Now I am working on CS109 from Harvard. It is a great course but its not easy to download, that is if you dont have this script. :)&lt;/p&gt;
&lt;p&gt;PS: You will have to install rtmpdump in your machine for this to work&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[34]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pattern&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;web&lt;/span&gt; 
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;subprocess&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[35]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;firsturl&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;http://cm.dce.harvard.edu/2014/01/14328/publicationListing.shtml&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;firsturl&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[36]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;dom&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;web&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Element&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[37]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;dom&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;div class="vbox output_wrapper"&gt;
&lt;div class="output vbox"&gt;


&lt;div class="hbox output_area"&gt;&lt;div class="prompt output_prompt"&gt;
    Out[37]:&lt;/div&gt;
&lt;div class="box-flex1 output_subarea output_pyout"&gt;


&lt;pre&gt;
Element(tag=u&amp;apos;[document]&amp;apos;)
&lt;/pre&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[38]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="c"&gt;#[elem.by_tag(&amp;#39;li.list-type&amp;#39;)[0].content for elem in dom.by_tag(&amp;#39;ul.list-publication&amp;#39;)]&lt;/span&gt;
&lt;span class="n"&gt;mdict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;NOV&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;11&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;OCT&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;10&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;SEP&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;09&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;DEC&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;12&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;elem&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;elem&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;dom&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;div.list-date  list-lecture&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;day&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;elem&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;span&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;elem&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;dom&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;div.list-date  list-lecture&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;datedict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;day&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[39]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;mmdd_dict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mdict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;elem&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;elem&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;elem&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;datedict&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[40]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;dictlnames&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L23&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L21&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L22&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L19&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L20&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L17&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L18&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L15&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L16&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L13&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L14&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L11&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L12&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L09&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L10&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L07&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L08&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L05&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L06&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L03&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L04&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L01&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;L02&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;fdict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dictlnames&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;mmdd_dict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[41]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;ffdict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{}&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;elem&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;fdict&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;mmdd&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;elem&lt;/span&gt;
    &lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;L&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;rtmpdump -r rtmp://flash.dce.harvard.edu/bounce -C B:0 -C Z: -C S:/2014/01/14328/L&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/14328-2013&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;mmdd&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;-L&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;-1-h264-av1248-16x9-852x480.mp4 -C S:BounceAPI3.0 -C N:0.000000 -C S:mp4  -y mp4:2014/01/14328/L&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/14328-2013&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;mmdd&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;-L&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;-1-h264-av1248-16x9-852x480.mp4  -o lecture&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;.mp4&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;ffdict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;You should change range in the code below, if some of the lectures were downloaded and you dont want to script it all over again. I am downloading lectures from 13 to 23 as i have already downloaded the previous ones. The lectures are roughly 1 GB in length and if your internet connection is slow you might face a problem with break downloads.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ffdict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;subprocess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Popen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;subprocess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PIPE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Lets do it for labs:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[31]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="c"&gt;#[elem.by_tag(&amp;#39;li.list-type&amp;#39;)[0].content for elem in dom.by_tag(&amp;#39;ul.list-publication&amp;#39;)]&lt;/span&gt;

&lt;span class="n"&gt;mdict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;NOV&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;11&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;OCT&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;10&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;SEP&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;09&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;DEC&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;12&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;elem&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;elem&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;dom&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;div.list-date  list-section&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;day&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;elem&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;span&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;elem&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;dom&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;by_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;div.list-date  list-section&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;datedict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;day&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c"&gt;#print datedict&lt;/span&gt;
&lt;span class="n"&gt;mmdd_dict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mdict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;elem&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;elem&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;elem&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;datedict&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="c"&gt;#print mmdd_dict&lt;/span&gt;
&lt;span class="n"&gt;dictlnames&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;S10&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;S09&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;S08&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;S06&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;S05&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;S04&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;S03&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;S02&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;S01&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;fdict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dictlnames&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;mmdd_dict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c"&gt;#print fdict&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[32]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;ffdict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{}&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;elem&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;fdict&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;mmdd&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;elem&lt;/span&gt;
    &lt;span class="c"&gt;#lec_num=lec_num.replace(&amp;quot;S&amp;quot;,&amp;quot;&amp;quot;)&lt;/span&gt;
    &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;rtmpdump -r rtmp://flash.dce.harvard.edu/bounce -C B:0 -C Z: -C S:/2014/01/14328/&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/14328-2013&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;mmdd&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;-&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;-1-h264-av1248-16x9-852x480.mp4 -C S:BounceAPI3.0 -C N:0.000000 -C S:mp4  -y mp4:2014/01/14328/&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/14328-2013&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;mmdd&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;-&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;-1-h264-av1248-16x9-852x480.mp4  -o lab&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;.mp4&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;S&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ffdict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lec_num&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;
&lt;span class="c"&gt;#print ffdict&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[33]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ffdict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;subprocess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Popen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;subprocess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PIPE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;pass&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;div class="vbox output_wrapper"&gt;
&lt;div class="output vbox"&gt;


&lt;div class="hbox output_area"&gt;&lt;div class="prompt"&gt;&lt;/div&gt;
&lt;div class="box-flex1 output_subarea output_stream output_stdout"&gt;
&lt;pre&gt;




&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The results of the downloads are displayed in the terminal window where you have opened the ipython notebook&lt;/p&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;</summary><category term="learning"></category><category term="cs109"></category></entry><entry><title>DICTVECTORIZER FOR ONE HOT ENCODING OF CATEGORICAL DATA</title><link href="http://mlwhiz.github.io/blog/2014/09/30/dictvectorizer_one_hot_encoding/" rel="alternate"></link><updated>2014-09-30T13:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2014-09-30:blog/2014/09/30/dictvectorizer_one_hot_encoding/</id><summary type="html">&lt;p&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="the-problem"&gt;THE PROBLEM:&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Recently I was working on the Criteo Advertising Competition on Kaggle. The competition was a classification problem which basically involved predicting the click through rates based on several features provided in the train data. Seeing the size of the data (11 GB Train), I felt that going with Vowpal Wabbit might be a better option But after getting to an CV error of .47 on the Kaggle LB and being stuck there , I felt the need to go back to Scikit learn. While SciKit learn seemed to have a partial_fit method in SGDClassifier, I still could not find a partial_fit method in the OneHotEncoder or DictVectorizer class which made me look to the internet again. Now while I could find many advices on how to use OneHotEncoding and DictVectorizer on small data, I cannot find something relate to data too big to store in the memory. How do I OneHotEncode such a large data file?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="dictvectorizer"&gt;DICTVECTORIZER&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;How does a DictVectorizer works. There is a lot of stuff around the net for this but I dint get to understand much around it. This blog from Zygmuntz of Fastml came to rescue then. Although still it didn’t resolve how to apply that to such large amount of data.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.feature_extraction&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DictVectorizer&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;DV&lt;/span&gt;
&lt;span class="c"&gt;# Create Vectorizer&lt;/span&gt;
&lt;span class="n"&gt;vectorizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;sparse&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c"&gt;# Read the whole Data&lt;/span&gt;
&lt;span class="n"&gt;traindata&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;header&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;names&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;colnames&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c"&gt;# Retain the categorical Columns&lt;/span&gt;
&lt;span class="n"&gt;train_df&lt;/span&gt;   &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;traindata&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;cat_col&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="c"&gt;# Convert Panda Data frame to Dict&lt;/span&gt;
&lt;span class="n"&gt;train_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_dict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c"&gt;# Create Fit&lt;/span&gt;
&lt;span class="n"&gt;vectorizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_dict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="the-data"&gt;THE DATA&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The data was basically comprised of 40 Features with: 1. First two Columns as ID, Label 2. Next 13 columns Continuous columns labelled I1-I13 3. Next 26 Columns Categorical labelled C1-C26 Further the categorical columns were very sparse and some of the categorical variables could take more than a million different values.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="the-workarounds"&gt;THE WORKAROUNDS&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The main problem that I faced was that I could not fit that much data in a DataFrame, even when I have a machine of 16GB, and that lead me to think that do I have a need for such a large data frame. And that lead me to the first part of the solution. I don’t need to load the whole data at once. I just needed to create another dictionary with all the possible combinations and then fit my dictvectorizer on it. I know that it is a lot to take in, so let’s take an example to understand it: Let’s say we have a data of infinite size, which has 3 categorical variables: C1 could take values 1-100 C2 could take values 1-3 C3 could take values 1-1000 Then we just have to find which category could take the maximum number of values (i.e. C3 in the above case) and make a dict which contains other categories replicated to contain as many values In other words, we need to make a dict like: {C1 : [1,2,3,……,97,98,99,100]&lt;em&gt;10 , C2 : [1,2,3]&lt;/em&gt;333+[1] , C3: [1….1000]} Notice the star sign at the last of the list. That means that for every key in the dict the number of values is now 1000(i.e. the maximum number of features). And so that is what I did. After we have the Vectorizer Fit, the next task was to transform the data. I took the data transformed it and sent it to my model line by line. P.S. Don’t store the transformed data as around a 100000 records takes ~ 10GB of Hard Disk Space due to the high number of features. Hope you find it Informative and happy learning.&lt;/p&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;</summary><category term="machine learning"></category><category term="categorical data"></category></entry><entry><title>Learning pyspark – Installation – Part 1</title><link href="http://mlwhiz.github.io/blog/2014/09/28/learning_pyspark/" rel="alternate"></link><updated>2014-09-28T13:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2014-09-28:blog/2014/09/28/learning_pyspark/</id><summary type="html">&lt;p&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This is part one of a learning series of pyspark, which is a python binding to the spark program written in Scala.&lt;/p&gt;
&lt;p&gt;The installation is pretty simple. These steps were done on Mac OS Mavericks but should work for Linux too. Here are the steps for the installation:&lt;/p&gt;
&lt;h3 id="download-the-binaries"&gt;1. Download the Binaries:&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;Spark&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;spark&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apache&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;org&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;downloads&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;
&lt;span class="n"&gt;Scala&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;www&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scala&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;lang&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;org&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;

&lt;span class="n"&gt;Dont&lt;/span&gt; &lt;span class="n"&gt;use&lt;/span&gt; &lt;span class="n"&gt;Latest&lt;/span&gt; &lt;span class="n"&gt;Version&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;Scala&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Use&lt;/span&gt; &lt;span class="n"&gt;Scala&lt;/span&gt; &lt;span class="mf"&gt;2.10&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="add-these-lines-to-your-.bash_profile"&gt;2. Add these lines to your .bash_profile:&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;export&lt;/span&gt; &lt;span class="n"&gt;SCALA_HOME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;your_path_to_scala&lt;/span&gt;
&lt;span class="n"&gt;export&lt;/span&gt; &lt;span class="n"&gt;SPARK_HOME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;your_path_to_spark&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="build-sparkthis-will-take-time"&gt;3. Build Spark(This will take time):&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;brew&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;sbt&lt;/span&gt;
&lt;span class="n"&gt;cd&lt;/span&gt; &lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;SPARK_HOME&lt;/span&gt;
&lt;span class="n"&gt;sbt&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sbt&lt;/span&gt; &lt;span class="n"&gt;assembly&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="start-the-pyspark-shell"&gt;4. Start the Pyspark Shell:&lt;/h3&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;SPARK_HOME&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;bin&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;pyspark&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;And Voila. You are running pyspark on your Machine&lt;/p&gt;
&lt;p&gt;To check that everything is properly installed, Lets run a simple program:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parallelize&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This should return 3.&lt;/p&gt;
&lt;p&gt;So Now Just Run Hadoop On your Machine and then run pyspark Using:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;cd&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;local&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;hadoop&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;
&lt;span class="nb"&gt;bin&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nb"&gt;all&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sh&lt;/span&gt;
&lt;span class="n"&gt;jps&lt;/span&gt;
&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;SPARK_HOME&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;bin&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;pyspark&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;&lt;/p&gt;
&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;</summary><category term="pyspark"></category><category term="learning"></category></entry><entry><title>Hadoop, Mapreduce and More – Part 1</title><link href="http://mlwhiz.github.io/blog/2014/09/27/hadoop_mapreduce/" rel="alternate"></link><updated>2014-09-27T13:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2014-09-27:blog/2014/09/27/hadoop_mapreduce/</id><summary type="html">&lt;p&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;It has been some time since I was stalling learning Hadoop. Finally got some free time and realized that Hadoop may not be so difficult after all. What I understood finally is that Hadoop is basically comprised of 3 elements:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;A File System&lt;/li&gt;
&lt;li&gt;Map – Reduce&lt;/li&gt;
&lt;li&gt;Its many individual Components. Let’s go through each of them one by one.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="hadoop-as-a-file-system"&gt;1. Hadoop as a File System:&lt;/h3&gt;
&lt;p&gt;One of the main things that Hadoop provides is cheap data storage. What happens intrinsically is that the Hadoop system takes a file, cuts it into chunks and keeps those chunks at different places in a cluster. Suppose you have a big big file in your local system and you want that file to be:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;On the cloud for easy access&lt;/li&gt;
&lt;li&gt;Processable in human time&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The one thing you can look forward to is Hadoop.&lt;/p&gt;
&lt;p&gt;Assuming that you have got hadoop instaled on the amazon cluster you are working on.(If you don’t know how to setup a hadoop cluster, go to this guy)&lt;/p&gt;
&lt;h4 id="start-the-hadoop-cluster"&gt;Start the Hadoop Cluster:&lt;/h4&gt;
&lt;p&gt;You need to run the following commands to start the hadoop cluster(Based on location of hadoop installation directory):&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;cd&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;local&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;hadoop&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;
&lt;span class="nb"&gt;bin&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nb"&gt;all&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sh&lt;/span&gt;
&lt;span class="n"&gt;jps&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Adding File to HDFS: Every command in Hadoop starts with hadoop fs and the rest of it works like the UNIX syntax. To add a file “purchases.txt” to the hdfs system:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;hadoop&lt;/span&gt; &lt;span class="n"&gt;fs&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;put&lt;/span&gt; &lt;span class="n"&gt;purchases&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;purchases&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="hadoop-for-map-reduce"&gt;2. Hadoop for Map-Reduce:&lt;/h3&gt;
&lt;p&gt;MapReduce is a programming model and an associated implementation for processing and generating large data sets with a parallel, distributed algorithm on a cluster.&lt;/p&gt;
&lt;p&gt;While Hadoop is implemented in Java, you can use almost any language to do map-reduce in hadoop using hadoop streaming. Suppose you have a big file containing the Name of store and sales of store each hour. And you want to find out the sales per store using map-reduce. Lets Write a sample code for that:&lt;/p&gt;
&lt;p&gt;InputFile&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;300&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;
&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;234&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;
&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;234&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;
&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;123&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;
&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;123&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;
&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;346&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Mapper.py&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;mapper&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="c"&gt;# The Mapper takes inputs from stdin and prints out store name and value&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdin&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;,&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;storeName&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;{0},{1}&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;storeName&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Reducer.py&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;reducer&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="c"&gt;# The reducer takes inputs from mapper and prints out aggregated store name and value&lt;/span&gt;
    &lt;span class="n"&gt;salesTotal&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="n"&gt;oldKey&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdin&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;,&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c"&gt;#Adding a little bit of Defensive programming&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;continue&lt;/span&gt;
        &lt;span class="n"&gt;curKey&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;curVal&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;oldKey&lt;/span&gt; &lt;span class="n"&gt;adn&lt;/span&gt; &lt;span class="n"&gt;oldKey&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;curKey&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;{0},{1}&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;oldKey&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;salesTotal&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;salesTotal&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="n"&gt;oldKey&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;curKey&lt;/span&gt;
        &lt;span class="n"&gt;salesTotal&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;curVal&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;oldkey&lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;{0},{1}&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;oldKey&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;salesTotal&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Running the program on shell using pipes&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;textfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="o"&gt;./&lt;/span&gt;&lt;span class="n"&gt;mapper&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;sort&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="o"&gt;./&lt;/span&gt;&lt;span class="n"&gt;reducer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Running the program on mapreduce using Hadoop Streaming&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;hadoop&lt;/span&gt; &lt;span class="n"&gt;jar&lt;/span&gt; &lt;span class="n"&gt;contrib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;streaming&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;hadoop&lt;/span&gt;&lt;span class="o"&gt;-*&lt;/span&gt;&lt;span class="n"&gt;streaming&lt;/span&gt;&lt;span class="o"&gt;*.&lt;/span&gt;&lt;span class="n"&gt;jar&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nb"&gt;file&lt;/span&gt; &lt;span class="n"&gt;mapper&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;mapper&lt;/span&gt; &lt;span class="n"&gt;mapper&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nb"&gt;file&lt;/span&gt; &lt;span class="n"&gt;reducer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;reducer&lt;/span&gt; &lt;span class="n"&gt;reducer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nb"&gt;input&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;inputfile&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;outputfile&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="hadoop-components"&gt;3. Hadoop Components:&lt;/h3&gt;
&lt;p&gt;Now if you have been following Hadoop you might have heard about Apache, Cloudera, HortonWorks etc. All of these are Hadoop vendors who provide Hadoop Along with its components. I will talk about the main component of Hadoop here – Hive. So what exactly is Hive: Hive is a SQL like interface to map-reduce queries. So if you don’t understand all the hocus-pocus of map-reduce but know SQL, you can do map-reduce via Hive. Seems Promising? It is. While the syntax is mainly SQL, it is still a little different and there are some quirks that we need to understand to work with Hive. First of all lets open hive command prompt: For that you just have to type “hive”, and voila you are in. Here are some general commands&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;show&lt;/span&gt; &lt;span class="n"&gt;databases&lt;/span&gt;  &lt;span class="c"&gt;#   -- See all Databases&lt;/span&gt;
&lt;span class="n"&gt;use&lt;/span&gt; &lt;span class="n"&gt;database&lt;/span&gt;     &lt;span class="c"&gt;#     -- Use a particular Database&lt;/span&gt;
&lt;span class="n"&gt;show&lt;/span&gt; &lt;span class="n"&gt;tables&lt;/span&gt;       &lt;span class="c"&gt;#     -- See all tables in a particular Database&lt;/span&gt;
&lt;span class="n"&gt;describe&lt;/span&gt; &lt;span class="n"&gt;table&lt;/span&gt;    
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Creating an external table:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell vbox"&gt;
&lt;div class="input hbox"&gt;
&lt;div class="prompt input_prompt"&gt;
In&amp;nbsp;[]:
&lt;/div&gt;
&lt;div class="input_area box-flex1"&gt;
&lt;div class="highlight-ipynb"&gt;&lt;pre class="ipynb"&gt;&lt;span class="n"&gt;CREATE&lt;/span&gt; &lt;span class="n"&gt;EXTERNAL&lt;/span&gt; &lt;span class="n"&gt;TABLE&lt;/span&gt; &lt;span class="n"&gt;IF&lt;/span&gt; &lt;span class="n"&gt;NOT&lt;/span&gt; &lt;span class="n"&gt;EXISTS&lt;/span&gt; &lt;span class="n"&gt;BXDataSet&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ISBN&lt;/span&gt; &lt;span class="n"&gt;STRING&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;BookTitle&lt;/span&gt; &lt;span class="n"&gt;STRING&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ImageURLL&lt;/span&gt; &lt;span class="n"&gt;STRING&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ROW&lt;/span&gt; &lt;span class="n"&gt;FORMAT&lt;/span&gt; &lt;span class="n"&gt;DELIMITED&lt;/span&gt;  &lt;span class="n"&gt;FIELDS&lt;/span&gt; &lt;span class="n"&gt;TERMINATED&lt;/span&gt; &lt;span class="n"&gt;BY&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="n"&gt;STORED&lt;/span&gt; &lt;span class="n"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;TEXTFILE&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="n"&gt;LOAD&lt;/span&gt; &lt;span class="n"&gt;DATA&lt;/span&gt; &lt;span class="n"&gt;INPATH&lt;/span&gt; &lt;span class="err"&gt;‘&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;user&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;book&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="err"&gt;’&lt;/span&gt; &lt;span class="n"&gt;OVERWRITE&lt;/span&gt; &lt;span class="n"&gt;INTO&lt;/span&gt; &lt;span class="n"&gt;TABLE&lt;/span&gt; &lt;span class="n"&gt;BXDataSet&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The query commands work the same way as in SQL. You can do all the group by and hive will automatically convert it in map-reduce:&lt;/p&gt;
&lt;p&gt;select * from tablename;&lt;/p&gt;
&lt;p&gt;Stay Tuned for Part 2 – Where we will talk about another components of Hadoop – PIG&lt;/p&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;To learn more about hadoop in th meantime these are the books I recommend:&lt;/p&gt;
&lt;div style="text-align: center;"&gt;
&lt;a target="_blank"  href="https://www.amazon.com/gp/product/1491901632/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1491901632&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=4122280e94f7bbd0ceebc9d13e60d103"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1491901632&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1491901632" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;

&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;</summary><category term="hadoop"></category><category term="mapreduce"></category></entry></feed>