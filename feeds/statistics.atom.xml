<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>mlwhiz</title><link href="http://mlwhiz.com/" rel="alternate"></link><link href="http://mlwhiz.com/feeds/statistics.atom.xml" rel="self"></link><id>http://mlwhiz.com/</id><updated>2016-12-24T04:43:00-02:00</updated><entry><title>Things to see while buying a Mutual Fund</title><link href="http://mlwhiz.com/blog/2016/12/24/mutual_fund_ratios/" rel="alternate"></link><updated>2016-12-24T04:43:00-02:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.com,2016-12-24:blog/2016/12/24/mutual_fund_ratios/</id><summary type="html">&lt;p&gt;This is a post which deviates from my pattern fo blogs that I have wrote till now but I found that Finance also uses up a lot of Statistics. So it won't be a far cry to put this on my blog here. I recently started investing in Mutual funds so thought of rersearching the area before going all in. Here is the result of some of my research.&lt;/p&gt;
&lt;h2&gt;1. Load/No-Load:&lt;/h2&gt;
&lt;p&gt;Always Buy No Load Mutual Funds&lt;/p&gt;
&lt;h2&gt;2. Regular/Direct:&lt;/h2&gt;
&lt;p&gt;There are many differenct sites from where you can buy Mutual funds. Most of these sites take a commision to let you the investor buy and sell from their platform. To overcome this commision you can buy direct Mutual funds from the fund houses themselves. But that would be difficult as their are a lot of fund houses and mmanaging all of that could be quite painful. But with the advent of MFUtility you can buy direct plans from the same platform.&lt;/p&gt;
&lt;h2&gt;3. Expense Ratios:&lt;/h2&gt;
&lt;p&gt;The expense ratio is a measure of what it costs an investment company to operate a mutual fund.
To see how expense ratios can affect your investments over time, let’s compare the returns of several hypothetical investments that differ only in expense ratio. The following table depicts the returns on a 10,000 initial investment, assuming an average annualized gain of 10%, with different expense ratios (0.5%, 1%, 1.5%, 2% and 2.5%):&lt;/p&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/fund_expense_ratio.jpg"  height="400" width="500" &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;As the table illustrates, even a small difference in expense ratio can cost you a lot of money in the long run. If you had invested 10,000 in the fund with a 2.5% expense ratio, the value of your fund would be 46,022 after 20 years. Had you instead invested your 10,000 in the fund with a lower, 0.5% expense ratio, your investment would be worth $61,159 after two decades, a 0.33% improvement over the more expensive fund. Keep in mind, this hypothetical example examines funds whose only differences are the expense ratios: all other variables, including initial investment and annualized gains, remain constant (for the example, we must assume identical taxation as well). While two funds are not likely to have the exact same performance over a 20-year period, the table illustrates the effects that small changes in expense ratio can have on your long-term returns.&lt;/p&gt;
&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;

&lt;h2&gt;4. Avoid Mutual Funds With High Turnover Ratios:&lt;/h2&gt;
&lt;p&gt;Mutual fund turnover is calculated as the value of all transactions (buying, selling) divided by two, then divided by a fund's total holdings. In simpler terms, mutual fund turnover typically measures the replacement of holdings in a mutual fund, and is commonly presented to investors as a percentage over a one year period. If a fund has 100% turnover, the fund replaces all of its holdings over a 12-month period and that bears cost to the investment company in terms of brokerage etc.&lt;/p&gt;
&lt;h2&gt;5. Look for Ample Diversification of Assets:&lt;/h2&gt;
&lt;p&gt;Simply owning four different mutual funds specializing in the financial sector (shares of banks, insurance companies, etc.) is not diversification. Don’t own funds that make heavy sector or industry bets. If you choose to despite this warning, make sure that you don’t have a huge portion of your funds invested in them. If it’s a bond fund, you typically want to avoid bets on the direction of interest rates as this is rank speculation.&lt;/p&gt;
&lt;h2&gt;6. Not Same Fund Family:&lt;/h2&gt;
&lt;p&gt;Don’t keep all of your funds within the same fund family. Witness the mutual fund scandal of a few years ago where portfolio management at many firms allowed big traders to market time the funds, essentially stealing money from smaller investors. By spreading your assets out at different companies, you can mitigate the risk of internal turmoil, ethics breaches, and other localized problems.&lt;/p&gt;
&lt;h2&gt;7. Keep Track of various Risk Ratios:&lt;/h2&gt;
&lt;h3&gt;a. &lt;strong&gt;&lt;strong&gt;Standard deviation:&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Standard deviation (SD) measures the volatility the fund's returns in relation to its average. It tells
you how much the fund's return can deviate from the historical mean return of the scheme. If a fund
has a 12% average rate of return and a standard deviation of 4%, its return will range from 8-16%&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Computation:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Standard Deviation (SD) = Square root of Variance (V)&lt;/p&gt;
&lt;p&gt;Variance = (Sum of squared difference between each monthly return and its mean / number of monthly return data – 1)
&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;b. &lt;strong&gt;&lt;strong&gt;R-Squared:&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;R-Squared measures the relationship between a portfolio and its benchmark. It can be thought of as a percentage from 1 to 100. R-squared is not a measure of the performance of a portfolio. A great portfolio can have a very low R-squared. It is simply a measure of the correlation of the portfolio's returns to the benchmark's returns.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Computation:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;R-Squared = Square of Correlation&lt;/p&gt;
&lt;p&gt;Correlation(xy)= Covariance between index and portfolio/(Standard deviation of portfolio * standard deviation of index)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Significance:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If you want a portfolio that moves like the benchmark, you'd want a portfolio with a high Rsquared.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you want a portfolio that doesn't move at all like the benchmark, you'd want a low R-squared.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;General Range for R-Squared:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;70-100% = good correlation between the portfolio's returns and the benchmark's returns&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;40-70% = average correlation between the portfolio's returns and the benchmark's returns&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;1-40% = low correlation between the portfolio's returns and the benchmark's returns&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Index funds will have an R-squared very close to 100.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;R-squared can be used to ascertain the significance of a particular beta or alpha. Generally, a higher R-squared will indicate a more useful beta figure. If the R-squared is lower, then the beta is less relevant to the fund's performance&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Values range from 1 (returns are explained 100% by the market) to 0 (returns bear no association with the market)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;c. &lt;strong&gt;&lt;strong&gt;Beta:&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;A beta of 1.0 indicates that the investment's price will move in lock-step with the market.&lt;/p&gt;
&lt;p&gt;A beta of less than 1.0 indicates that the investment will be less volatile than the market, and, correspondingly, a beta of more than 1.0 indicates that the investment's price will be more volatile than the market.&lt;/p&gt;
&lt;p&gt;For example, if a fund portfolio's beta is 1.2, it's theoretically 20% more volatile than the market. Conservative investors looking to preserve capital should focus on securities and fund portfolios with low betas, whereas those investors willing to take on more risk in search of higher returns should look for high beta investments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Computation:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Beta = (Standard Deviation of Fund x R-Square) / Standard Deviation of Benchmark&lt;/p&gt;
&lt;p&gt;If a fund has a beta of 1.5, it means that for every 10% upside or downside, the fund's NAV would be 15% in the respective direction.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;d. &lt;strong&gt;&lt;strong&gt;Jensens Alpha:&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Alpha is a measure of an investment's performance on a risk-adjusted basis.&lt;/p&gt;
&lt;p&gt;Simply stated, alpha is often considered to represent the value that a portfolio manager adds or subtracts from a fund portfolio's return.&lt;/p&gt;
&lt;p&gt;A positive alpha of 1.0 means the fund has outperformed its benchmark index by 1%. Correspondingly, a similar negative alpha would indicate an underperformance of 1%.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Computation:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Alpha = {(Fund return-Risk free return) – (Funds beta) *(Benchmark return- risk free return)}&lt;/p&gt;
&lt;p&gt;For example, assume a mutual fund realized a return of 15% last year. The appropriate market index for this fund returned 12%. The beta of the fund versus that same index is 1.2 and the risk-free rate is 3%. The fund's alpha is calculated as:&lt;/p&gt;
&lt;p&gt;Alpha = {(15 -3) – (1.2) *(12- 3)} = 12 - 9 x 1.2 = 12-10.8 = 1.2&lt;/p&gt;
&lt;p&gt;Given a beta of 1.2, the mutual fund is expected to be riskier than the index, and thus earn more. A positive alpha in this example shows that the mutual fund manager earned more than enough return to be compensated for the risk he took over the course of the year. If the mutual fund only returned 13%, the calculated alpha would be -0.8. With a negative alpha, the mutual fund manager would not have earned enough return given the amount of risk he was taking.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;e. &lt;strong&gt;&lt;strong&gt;Sharpe Ratio:&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Sharpe Ratio measures how well the fund has performed vis-a vis the risk taken by it. It is the excess return over risk-free return (usually return from treasury bills or government securities) divided by the standard deviation. The higher the Sharpe Ratio, the better the fund has performed in proportion to the risk taken by it.
The Sharpe ratio is also known as Reward-to-Variability ratio and it is named after William Forsyth Sharpe.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Computation:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;SR = (Total Return – Risk Free Rate) / SD Of Fund&lt;/p&gt;
&lt;p&gt;For example: Your investor gets 7 per cent return on her investment in a scheme with a standard deviation/volatility of 0.5. We assume risk free rate is 5 per cent.
Sharpe Ratio is 7-5/0.5 = 4 in this case&lt;/p&gt;
&lt;h2&gt;8. And Finally Always Dollar-Cost Average:&lt;/h2&gt;
&lt;p&gt;Dollar cost averaging is a technique designed to reduce market risk through the systematic purchase of securities at predetermined intervals and set amounts.Instead of investing assets in a lump sum, the investor works his way into a position by slowly buying smaller amounts over a longer period of time. This spreads the cost basis out over several years, providing insulation against changes in market price.&lt;/p&gt;
&lt;p&gt;Every investor investment strategy differs. These are just some common guidelines to work your way through the market and making informed decisions while buying Mutual Funds.
Normally I work through points 1-6 and get my list to a few mutual funds after which I generally use risk ratios to determine which of the funds I selected might be a winner.
I have a bias towards long term investing when it comes to investing so whatever I wrote here must be taken with a grain of salt just as everything related to investment must be.  Some of you who are doing this for a longer time than I can also tell me about the various other things I can do.
I will try to include those ideas in this post as well.&lt;/p&gt;
&lt;p&gt;To Learn more about Mutual funds and investing in general, take a look at the following two gems:&lt;/p&gt;
&lt;div style="margin-left:1em ; text-align: center;"&gt;
&lt;a target="_blank"  href="https://www.amazon.com/gp/product/0060555661/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0060555661&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=59d5b0af035ad4ba7eda55548194a638"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=0060555661&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=0060555661" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/t&gt;&lt;/t&gt;
&lt;a target="_blank"  href="https://www.amazon.com/gp/product/0470138130/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0470138130&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=2f78b02ff1a38e3383c5a8cff52f2a9a"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=0470138130&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=0470138130" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;

&lt;p&gt;The Editorial review of The intelligent Investor says "Among the library of investment books promising no-fail strategies for riches, Benjamin Graham's classic, The Intelligent Investor, offers no guarantees or gimmicks but overflows with the wisdom at the core of all good portfolio management" and it rings true in every sense. A must read for everyone looking to invest seriously.&lt;/p&gt;
&lt;p&gt;Common Sense on Mutual Funds focusses on Mutual funds exclusively. Lets you understand that investing is not difficult. For the not so involved reader.&lt;/p&gt;
&lt;p&gt;Till than Ciao!!!&lt;/p&gt;
&lt;h2&gt;References:&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;https://www.thebalance.com/picking-winning-mutual-funds-357957&lt;/li&gt;
&lt;li&gt;http://www.miraeassetmf.co.in/uploads/TermofWeek/Sharpe_Ratio.pdf&lt;/li&gt;
&lt;li&gt;http://www.miraeassetmf.co.in/uploads/TermofWeek/Beta_SD_RSquared.pdf&lt;/li&gt;
&lt;li&gt;http://www.investopedia.com&lt;/li&gt;
&lt;/ol&gt;</summary><category term="statistics"></category></entry><entry><title>Donald Trump : Two new Survey Biases</title><link href="http://mlwhiz.com/blog/2016/11/10/trump_really/" rel="alternate"></link><updated>2016-11-10T04:43:00-02:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.com,2016-11-10:blog/2016/11/10/trump_really/</id><summary type="html">&lt;p&gt;The US elections have got everyone startled. &lt;strong&gt;Trump&lt;/strong&gt;. Seriously. The most powerful man on the entire earth is Donald Trump. Just think about it for a second. The most coveted post in all world and America could not find a better person to fill it? Now to tell you the truth I was not at all surprised to see it happen. I don’t know if America has ever seen this brand of politics, we indians have seen this brand of politics many a times and have suffered a lot because of it.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;To put my case forward we have many a examples in our country like &lt;strong&gt;Bal Thackeray&lt;/strong&gt; whose slogan was “Uthao lungi aur bajao pungi” which basically meant send away the south indians back from Mumbai. He was worshipped in Mumbai by the local People for the same and around 1.5 Million people came to attend his funeral. His son Raj Thackeray has the same brand of politics but he wants to send away North Indians. Wow!&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Then there are issues of Caste based politics where people like Mulayam Singh and Mayawati would use reservations in India to their advantage to pull the caste vote bank.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Trump Brand of politics was pretty much the same — &lt;strong&gt;Divisive&lt;/strong&gt;. Get people against each other. Now that I think of it Hitler had the same formula.
The way this formula works is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Target a minority community by telling other community how its presence is badly effecting them.&lt;/li&gt;
&lt;li&gt;Promise to eliminate them.&lt;/li&gt;
&lt;li&gt;Win.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;This election could be posed as a study in psyche of a developed nation such as America. America as a nation may call itself inclusive, non sexist, and secular but a Trump win tells that people are two-faced. The one face that they want the world to see and the other they know they are.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;The pre election polls all had Hillary in the lead, but surveys forget the one element of Human Nature- the human psyche. How many people that supported trump would openly admit that they would vote for him? They don’t want to be branded sexist, misogynist, racist. But they picked a president which is all three.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;This election essentially provided us with two different types of bias that could occur in surveys.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;

&lt;h3&gt;Lie Bias:&lt;/h3&gt;
&lt;p&gt;People lied in the surveys. That much is certain. To say that they would support Trump was shameful to a lot of people. This bias could be linked to the response Bias in a way but here the people did not lie because they wanted to appease the questioner, they lied to appease themselves.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;Undecideds Bias:&lt;/h3&gt;
&lt;p&gt;The night before the elections the polls stood at 42% Trump, 46% Hillary, 12% Undecided. I would focus on the 12 % here. Where do you think these 12% votes went. This is just a speculation but there is a high chance that the undecideds were not undecideds at all. Most of them wanted to support Trump while keeping it under wraps and not lying. The undecided group proportion was high as compared to other election years. In 2008 and 2012 the undecideds were 4% and 3% respectively. so there is a ~8% increase in number of undecideds, and to what can we attribute that? The only thing that comes to my mind is that the people who were gonna vote trump were calling themselves undecided.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Now I would sincerely thank Mr Trump who put us in such a diabolical situation that provides us with such twisted biases and thereby close my rant.&lt;/p&gt;</summary><category term=""></category></entry><entry><title>Behold the power of MCMC</title><link href="http://mlwhiz.com/blog/2015/08/21/MCMC_Algorithms_Cryptography/" rel="alternate"></link><updated>2015-08-21T04:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.com,2015-08-21:blog/2015/08/21/MCMC_Algorithms_Cryptography/</id><summary type="html">&lt;p&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/mcmc.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;Last time I wrote an article on MCMC and how they could be useful. We learned how MCMC chains could be used to simulate from a random variable whose distribution is partially known i.e. we don't know the normalizing constant.&lt;/p&gt;
&lt;p&gt;So MCMC Methods may sound interesting to some (for these what follows is a treat) and for those who don't really appreciate MCMC till now, I hope I will be able to pique your interest by the end of this blog post.&lt;/p&gt;
&lt;p&gt;So here goes. This time we will cover some applications of MCMC in various areas of Computer Science using Python. If you feel the problems difficult to follow with, I would advice you to go back and read the &lt;a href="http://mlwhiz.com/blog/2015/08/19/MCMC_Algorithms_Beta_Distribution/"&gt;previous post&lt;/a&gt;, which tries to explain MCMC Methods. We Will try to solve the following two problems:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Breaking the Code&lt;/strong&gt; - This problem has got somewhat of a great pedigree as this method was suggested by Persi Diaconis- The Mathemagician. So Someone comes to you with the below text. This text looks like gibberish but this is a code, Could you decrypyt it?&lt;br&gt;&lt;br&gt; &lt;em&gt;XZ STAVRK HXVR MYAZ OAKZM JKSSO SO MYR OKRR XDP JKSJRK XBMASD SO YAZ TWDHZ MYR JXMBYNSKF BSVRKTRM NYABY NXZ BXKRTRZZTQ OTWDH SVRK MYR AKSD ERPZMRXP KWZMTRP MYR JXTR OXBR SO X QSWDH NSIXD NXZ KXAZRP ORRETQ OKSI MYR JATTSN XDP X OXADM VSABR AIJRKORBMTQ XKMABWTXMRP MYR NSKPZ TRM IR ZRR MYR BYATP XDP PAR MYR ZWKHRSD YXP ERRD ZAMMADH NAMY YAZ OXBR MWKDRP MSNXKPZ MYR OAKR HAVADH MYR JXTIZ SO YAZ YXDPZ X NXKI XDP X KWE XTMRKDXMRTQ XZ MYR QSWDH NSIXD ZJSFR YR KSZR XDP XPVXDBADH MS MYR ERP Z YRXP ZXAP NAMY ISKR FADPDRZZ MYXD IAHYM YXVR ERRD RGJRBMRP SO YAI&lt;/em&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;The Knapsack Problem&lt;/strong&gt; - This problem comes from &lt;a href="http://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science-ebook/dp/B00MMOJ19I"&gt;Introduction to probability&lt;/a&gt; by Joseph Blitzstein. You should check out his courses (&lt;a href="http://projects.iq.harvard.edu/stat110/handouts"&gt;STAT110&lt;/a&gt; And &lt;a href="http://cm.dce.harvard.edu/2014/01/14328/publicationListing.shtml"&gt;CS109&lt;/a&gt;) as they are awesome. Also as it turns out Diaconis was the advisor of Joseph. So you have Bilbo a Thief who goes to Smaug's Lair. He finds M treasures. Each treasure has some Weight and some Gold value. But Bilbo cannot really take all of that. He could only carry a certain Maximum Weight. But being a smart hobbit, he wants to Maximize the value of the treasures he takes. Given the values for weights and value of the treasures and the maximum weight that Bilbo could carry, could you find a good solution? This is known as the Knapsack Problem in Computer Science.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="breaking-the-code"&gt;Breaking the Code&lt;/h2&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/security.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;So we look at the data and form a hypothesis that the data has been scrambled using a Substitution Cipher. We don't know the encryption key, and we would like to know the Decryption Key so that we can decrypt the data and read the code.&lt;/p&gt;
&lt;p&gt;To create this example, this data has actually been taken from Oliver Twist. We scrambled the data using a random encryption key, which we forgot after encrypting and we would like to decrypt this encrypted text using MCMC Chains. The real decryption key actually is &amp;quot;ICZNBKXGMPRQTWFDYEOLJVUAHS&amp;quot;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;So lets think about this problem for a little bit. The decryption key could be any 26 letter string with all alphabets appearing exactly once. How many string permutations are there like that? That number would come out to be &lt;span class="math inline"&gt;\(26! \approx 10^{26}\)&lt;/span&gt; permutations. That is a pretty large number. If we go for using a brute force approach we are screwed. So what could we do? MCMC Chains come to rescue.&lt;/p&gt;
&lt;p&gt;We will devise a Chain whose states theoritically could be any of these permutations. Then we will:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Start by picking up a random current state.&lt;/li&gt;
&lt;li&gt;Create a proposal for a new state by swapping two random letters in the current state.&lt;/li&gt;
&lt;li&gt;Use a Scoring Function which calculates the score of the current state &lt;span class="math inline"&gt;\(Score_C\)&lt;/span&gt; and the proposed State &lt;span class="math inline"&gt;\(Score_P\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;If the score of the proposed state is more than current state, Move to Proposed State.&lt;/li&gt;
&lt;li&gt;Else flip a coin which has a probability of Heads &lt;span class="math inline"&gt;\(Score_P/Score_C\)&lt;/span&gt;. If it comes heads move to proposed State.&lt;/li&gt;
&lt;li&gt;Repeat from 2nd State.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If we get lucky we may reach a steady state where the chain has the stationary distribution of the needed states and the state that the chain is at could be used as a solution.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;So the Question is what is the scoring function that we will want to use. We want to use a scoring function for each state(Decryption key) which assigns a positive score to each decryption key. This score intuitively should be more if the encrypted text looks more like actual english if decrypted using this decryption key.&lt;/p&gt;
&lt;p&gt;So how can we quantify such a function. We will check a long text and calculate some statistics. See how many times one alphabet comes after another in a legitimate long text like War and Peace. For example we want to find out how many times does 'BA' appears in the text or how many times 'TH' occurs in the text.&lt;/p&gt;
&lt;p&gt;For each pair of characters &lt;span class="math inline"&gt;\(\beta_1\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(\beta_2\)&lt;/span&gt; (e.g. &lt;span class="math inline"&gt;\(\beta_1\)&lt;/span&gt; = T and &lt;span class="math inline"&gt;\(\beta_2\)&lt;/span&gt; =H), we let &lt;span class="math inline"&gt;\(R(\beta_1,\beta_2)\)&lt;/span&gt; record the number of times that specific pair(e.g. &amp;quot;TH&amp;quot;) appears consecutively in the reference text.&lt;/p&gt;
&lt;p&gt;Similarly, for a putative decryption key x, we let &lt;span class="math inline"&gt;\(F_x(\beta_1,\beta_2)\)&lt;/span&gt; record the number of times that pair appears when the cipher text is decrypted using the decryption key x.&lt;/p&gt;
&lt;p&gt;We then Score a particular decryption key x using:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[Score(x) = \prod R(\beta_1,\beta_2)^{F_x(\beta_1,\beta_2)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This function can be thought of as multiplying, for each consecutive pair of letters in the decrypted text, the number of times that pair occurred in the reference text. Intuitively, the score function is higher when the pair frequencies in the decrypted text most closely match those of the reference text, and the decryption key is thus most likely to be correct.&lt;/p&gt;
&lt;p&gt;To make life easier with calculations we will calculate &lt;span class="math inline"&gt;\(log(Score(x))\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;So lets start working through the problem step by step.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;
# AIM: To Decrypt a text using MCMC approach. i.e. find decryption key which we will call cipher from now on.
import string
import math
import random

# This function takes as input a decryption key and creates a dict for key where each letter in the decryption key
# maps to a alphabet For example if the decryption key is "DGHJKL...." this function will create a dict like {D:A,G:B,H:C....} 
def create_cipher_dict(cipher):
    cipher_dict = {}
    alphabet_list = list(string.ascii_uppercase)
    for i in range(len(cipher)):
        cipher_dict[alphabet_list[i]] = cipher[i]
    return cipher_dict

# This function takes a text and applies the cipher/key on the text and returns text.
def apply_cipher_on_text(text,cipher):
    cipher_dict = create_cipher_dict(cipher) 
    text = list(text)
    newtext = ""
    for elem in text:
        if elem.upper() in cipher_dict:
            newtext+=cipher_dict[elem.upper()]
        else:
            newtext+=" "
    return newtext

# This function takes as input a path to a long text and creates scoring_params dict which contains the 
# number of time each pair of alphabet appears together
# Ex. {'AB':234,'TH':2343,'CD':23 ..}
def create_scoring_params_dict(longtext_path):
    scoring_params = {}
    alphabet_list = list(string.ascii_uppercase)
    with open(longtext_path) as fp:
        for line in fp:
            data = list(line.strip())
            for i in range(len(data)-1):
                alpha_i = data[i].upper()
                alpha_j = data[i+1].upper()
                if alpha_i not in alphabet_list and alpha_i != " ":
                    alpha_i = " "
                if alpha_j not in alphabet_list and alpha_j != " ":
                    alpha_j = " "
                key = alpha_i+alpha_j
                if key in scoring_params:
                    scoring_params[key]+=1
                else:
                    scoring_params[key]=1
    return scoring_params

# This function takes as input a text and creates scoring_params dict which contains the 
# number of time each pair of alphabet appears together
# Ex. {'AB':234,'TH':2343,'CD':23 ..}

def score_params_on_cipher(text):
    scoring_params = {}
    alphabet_list = list(string.ascii_uppercase)
    data = list(text.strip())
    for i in range(len(data)-1):
        alpha_i =data[i].upper()
        alpha_j = data[i+1].upper()
        if alpha_i not in alphabet_list and alpha_i != " ":
            alpha_i = " "
        if alpha_j not in alphabet_list and alpha_j != " ":
            alpha_j = " "
        key = alpha_i+alpha_j
        if key in scoring_params:
            scoring_params[key]+=1
        else:
            scoring_params[key]=1
    return scoring_params

# This function takes the text to be decrypted and a cipher to score the cipher.
# This function returns the log(score) metric

def get_cipher_score(text,cipher,scoring_params):
    cipher_dict = create_cipher_dict(cipher)
    decrypted_text = apply_cipher_on_text(text,cipher)
    scored_f = score_params_on_cipher(decrypted_text)
    cipher_score = 0
    for k,v in scored_f.iteritems():
        if k in scoring_params:
            cipher_score += v*math.log(scoring_params[k])
    return cipher_score

# Generate a proposal cipher by swapping letters at two random location
def generate_cipher(cipher):
    pos1 = random.randint(0, len(list(cipher))-1)
    pos2 = random.randint(0, len(list(cipher))-1)
    if pos1 == pos2:
        return generate_cipher(cipher)
    else:
        cipher = list(cipher)
        pos1_alpha = cipher[pos1]
        pos2_alpha = cipher[pos2]
        cipher[pos1] = pos2_alpha
        cipher[pos2] = pos1_alpha
        return "".join(cipher)

# Toss a random coin with robability of head p. If coin comes head return true else false.
def random_coin(p):
    unif = random.uniform(0,1)
    if unif&gt;=p:
        return False
    else:
        return True
    
# Takes as input a text to decrypt and runs a MCMC algorithm for n_iter. Returns the state having maximum score and also
# the last few states 
def MCMC_decrypt(n_iter,cipher_text,scoring_params):
    current_cipher = string.ascii_uppercase # Generate a random cipher to start
    state_keeper = set()
    best_state = ''
    score = 0
    for i in range(n_iter):
        state_keeper.add(current_cipher)
        proposed_cipher = generate_cipher(current_cipher)
        score_current_cipher = get_cipher_score(cipher_text,current_cipher,scoring_params)
        score_proposed_cipher = get_cipher_score(cipher_text,proposed_cipher,scoring_params)
        acceptance_probability = min(1,math.exp(score_proposed_cipher-score_current_cipher))
        if score_current_cipher&gt;score:
            best_state = current_cipher
        if random_coin(acceptance_probability):
            current_cipher = proposed_cipher
        if i%500==0:
            print "iter",i,":",apply_cipher_on_text(cipher_text,current_cipher)[0:99]
    return state_keeper,best_state

## Run the Main Program:

scoring_params = create_scoring_params_dict('war_and_peace.txt')

plain_text = "As Oliver gave this first proof of the free and proper action of his lungs, \
the patchwork coverlet which was carelessly flung over the iron bedstead, rustled; \
the pale face of a young woman was raised feebly from the pillow; and a faint voice imperfectly \
articulated the words, Let me see the child, and die. \
The surgeon had been sitting with his face turned towards the fire: giving the palms of his hands a warm \
and a rub alternately. As the young woman spoke, he rose, and advancing to the bed's head, said, with more kindness \
than might have been expected of him: "

encryption_key = "XEBPROHYAUFTIDSJLKZMWVNGQC"
cipher_text = apply_cipher_on_text(plain_text,encryption_key)
decryption_key = "ICZNBKXGMPRQTWFDYEOLJVUAHS"

print"Text To Decode:", cipher_text
print "\n"
states,best_state = MCMC_decrypt(10000,cipher_text,scoring_params)
print "\n"
print "Decoded Text:",apply_cipher_on_text(cipher_text,best_state)
print "\n"
print "MCMC KEY FOUND:",best_state
print "ACTUAL DECRYPTION KEY:",decryption_key
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/result1_MCMC.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This chain converges around the 2000th iteration and we are able to unscramble the code. That's awesome!!! Now as you see the MCMC Key found is not exactly the encryption key. So the solution is not a deterministic one, but we can see that it does not actually decrease any of the value that the MCMC Methods provide. Now Lets Help Bilbo :)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="the-knapsack-problem"&gt;The Knapsack Problem&lt;/h1&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Restating, we have Bilbo a Thief who goes to Smaug's Lair. He finds M treasures. Each treasure has some Weight and some Gold value. But Bilbo cannot really take all of that. He could only carry a certain Maximum Weight. But being a smart hobbit, he wants to Maximize the value of the treasures he takes. Given the values for weights and value of the treasures and the maximum weight that Bilbo could carry, could you find a good solution?&lt;/p&gt;
&lt;p&gt;So in this problem we have an &lt;span class="math inline"&gt;\(1\)&lt;/span&gt;x&lt;span class="math inline"&gt;\(M\)&lt;/span&gt; array of Weight Values W, Gold Values G and a value for the maximum weight &lt;span class="math inline"&gt;\(w_{MAX}\)&lt;/span&gt; that Bilbo can carry. We want to find out an &lt;span class="math inline"&gt;\(1\)&lt;/span&gt;x&lt;span class="math inline"&gt;\(M\)&lt;/span&gt; array &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; of 1's and 0's, which holds weather Bilbo Carries a particular treasure or not. This array needs to follow the constraint &lt;span class="math inline"&gt;\(WX^T &amp;lt; w_{MAX}\)&lt;/span&gt; and we want to maximize &lt;span class="math inline"&gt;\(GX^T\)&lt;/span&gt; for a particular state X.(Here the T means transpose)&lt;/p&gt;
&lt;p&gt;So lets first discuss as to how we will create a proposal from a previous state.&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Pick a random index from the state and toggle the index value.&lt;/li&gt;
&lt;li&gt;Check if we satisfy our constraint. If yes this state is the proposal state.&lt;/li&gt;
&lt;li&gt;Else pick up another random index and repeat.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We also need to think about the Scoring Function. We need to give high values to states with high gold value. We will use: &lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[Score(X)=e^{\beta GX^T}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We give exponentially more value to higher score. The Beta here is a +ve constant. But how to choose it? If &lt;span class="math inline"&gt;\(\beta\)&lt;/span&gt; is big we will give very high score to good solutions and the chain will not be able to try new solutions as it can get stuck in local optimas. If we give a small value the chain will not converge to very good solutions. So weuse an Optimization Technique called &lt;strong&gt;&lt;a href="https://en.wikipedia.org/wiki/Simulated_annealing"&gt;Simulated Annealing&lt;/a&gt;&lt;/strong&gt; i.e. we will start with a small value of &lt;span class="math inline"&gt;\(\beta\)&lt;/span&gt; and increase as no of iterations go up. That way the chain will explore in the starting stages and stay at the best solution in the later stages.&lt;/p&gt;
&lt;p&gt;So now we have everything we need to get started&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;
import numpy as np

W = [20,40,60,12,34,45,67,33,23,12,34,56,23,56]
G = [120,420,610,112,341,435,657,363,273,812,534,356,223,516]
W_max = 150

# This function takes a state X , The gold vector G and a Beta Value and return the Log of score
def score_state_log(X,G,Beta):
    return Beta*np.dot(X,G)

# This function takes as input a state X and the number of treasures M, The weight vector W and the maximum weight W_max
# and returns a proposal state
def create_proposal(X,W,W_max):
    M = len(W)
    random_index = random.randint(0,M-1)
    #print random_index
    proposal = list(X)
    proposal[random_index] = 1 - proposal[random_index]  #Toggle
    #print proposal
    if np.dot(proposal,W)&lt;=W_max:
        return proposal
    else:
        return create_proposal(X,W,W_max)
    
# Takes as input a text to decrypt and runs a MCMC algorithm for n_iter. Returns the state having maximum score and also
# the last few states 
def MCMC_Golddigger(n_iter,W,G,W_max, Beta_start = 0.05, Beta_increments=.02):
    M = len(W)
    Beta = Beta_start
    current_X = [0]*M # We start with all 0's
    state_keeper = []
    best_state = ''
    score = 0
    
    for i in range(n_iter):
        state_keeper.append(current_X)
        proposed_X = create_proposal(current_X,W,W_max)

        score_current_X = score_state_log(current_X,G,Beta)
        score_proposed_X = score_state_log(proposed_X,G,Beta)
        acceptance_probability = min(1,math.exp(score_proposed_X-score_current_X))
        if score_current_X&gt;score:
            best_state = current_X
        if random_coin(acceptance_probability):
            current_X = proposed_X
        if i%500==0:
            Beta += Beta_increments 
        # You can use these below two lines to tune value of Beta
        #if i%20==0:
        #    print "iter:",i," |Beta=",Beta," |Gold Value=",np.dot(current_X,G)
            
    return state_keeper,best_state
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Running the Main program:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;
max_state_value =0 
Solution_MCMC = [0]
for i in range(10):
    state_keeper,best_state = MCMC_Golddigger(50000,W,G,W_max,0.0005, .0005)
    state_value=np.dot(best_state,G)
    if state_value&gt;max_state_value:
        max_state_value = state_value
        Solution_MCMC = best_state

print "MCMC Solution is :" , str(Solution_MCMC) , "with Gold Value:", str(max_state_value)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;pre&gt;&lt;code&gt;MCMC Solution is : [0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0] with Gold Value: 2435&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I won't say that this is the best solution. The deterministic solution using DP will be the best for such use case but sometimes when the problems gets large, having such techniques at disposal becomes invaluable.&lt;/p&gt;
&lt;p&gt;So tell me What do you think about MCMC Methods?&lt;/p&gt;
&lt;p&gt;Also, If you find any good applications or would like to apply these techniques to some area, I would really be glad to know about them and help if possible.&lt;/p&gt;
&lt;p&gt;The codes for both examples are sourced at &lt;a href="https://github.com/MLWhiz/MCMC_Project"&gt;Github&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="references-and-sources"&gt;References and Sources:&lt;/h2&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;a href="http://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science-ebook/dp/B00MMOJ19I"&gt;Introduction to Probability Joseph K Blitzstein, Jessica Hwang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://statweb.stanford.edu/~cgates/PERSI/papers/MCMCRev.pdf"&gt;The Markov Chain Monte Carlo Revolution, Persi Diaconis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.utstat.toronto.edu/wordpress/WSFiles/technicalreports/1005.pdf"&gt;Decrypting Classical Cipher Text Using Markov Chain Monte Carlo, Jian Chen and Jeffrey S. Rosenthal&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;One of the newest and best resources that you can keep an eye on is the &lt;a href="https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0"&gt;Bayesian Methods for Machine Learning&lt;/a&gt; course in the &lt;a href="https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0"&gt;Advanced machine learning specialization&lt;/a&gt; created jointly by Kazanova(Number 3 Kaggler at the time of writing)&lt;/p&gt;
&lt;p&gt;Apart from that I also found a course on &lt;strong&gt;&lt;a href="https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;amp;offerid=495576.8910375858&amp;amp;type=2&amp;amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Fbayesian"&gt;Bayesian Statistics on Coursera&lt;/a&gt;&lt;/strong&gt;. In the process of doing it right now so couldn't really comment on it. But since I had done an course on &lt;strong&gt;&lt;a href="https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;amp;offerid=495576.8839843074&amp;amp;type=2&amp;amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Finferential-statistics-intro"&gt;Inferential Statistics&lt;/a&gt;&lt;/strong&gt; taught by the same professor before(Mine Çetinkaya-Rundel), I am very hopeful for this course. Let's see.&lt;/p&gt;
&lt;p&gt;Also look out for these two books to learn more about MCMC. I have not yet read them whole but still I liked whatever I read:&lt;/p&gt;
&lt;div style="margin-left:1em ; text-align: center;"&gt;

&lt;a target="_blank"  href="https://www.amazon.com/gp/product/1439840954/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1439840954&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=d55979088adc0aabeaed88f4f14b48b6"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1439840954&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1439840954" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/t&gt;&lt;/t&gt;
&lt;a target="_blank"  href="https://www.amazon.com/gp/product/1584885874/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1584885874&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=ee3e2a0bc99359d6c5db0463ab1abb13"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1584885874&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1584885874" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;

&lt;p&gt;Both these books are pretty high level and hard on math. But these are the best texts out there too. :)&lt;/p&gt;</summary><category term="Statistics"></category><category term="python"></category></entry><entry><title>My Tryst With MCMC Algorithms</title><link href="http://mlwhiz.com/blog/2015/08/19/MCMC_Algorithms_Beta_Distribution/" rel="alternate"></link><updated>2015-08-19T13:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.com,2015-08-19:blog/2015/08/19/MCMC_Algorithms_Beta_Distribution/</id><summary type="html">&lt;p&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
The things that I find hard to understand push me to my limits. One of the things that I have always found hard is &lt;strong&gt;Markov Chain Monte Carlo Methods&lt;/strong&gt;. When I first encountered them, I read a lot about them but mostly it ended like this.
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/flabbergasted.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;The meaning is normally hidden in deep layers of Mathematical noise and not easy to decipher. This blog post is intended to clear up the confusion around MCMC methods, Know what they are actually useful for and Get hands on with some applications.&lt;/p&gt;
&lt;h2 id="so-what-really-are-mcmc-methods"&gt;&lt;strong&gt;So what really are MCMC Methods?&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;First of all we have to understand what are &lt;strong&gt;&lt;em&gt;Monte Carlo&lt;/em&gt;&lt;/strong&gt; Methods!!!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Monte_Carlo_method"&gt;Monte Carlo&lt;/a&gt; methods derive their name from Monte Carlo Casino in Monaco. There are many card games that need probability of winning against the dealer. Sometimes calculating this probability can be mathematically complex or highly intractable. But we can always run a computer simulation to simulate the whole game many times and see the probability as the number of wins divided by the number of games played.&lt;/p&gt;
&lt;p&gt;So that is all you need to know about Monte carlo Methods. Yes it is just a simple simulation technique with a Fancy Name.&lt;/p&gt;
&lt;p&gt;So as we have got the first part of MCMC, we also need to understand what are &lt;strong&gt;&lt;em&gt;&lt;a href="https://en.wikipedia.org/wiki/Markov_chain"&gt;Markov Chains&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;. Before Jumping onto Markov Chains let us learn a little bit about &lt;strong&gt;Markov Property&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Suppose you have a system of &lt;span class="math inline"&gt;\(M\)&lt;/span&gt; possible states, and you are hopping from one state to another. &lt;em&gt;Markov Property&lt;/em&gt; says that given a process which is at a state &lt;span class="math inline"&gt;\(X_n\)&lt;/span&gt; at a particular point of time, the probability of &lt;span class="math inline"&gt;\(X_{n+1} = k\)&lt;/span&gt;, where &lt;span class="math inline"&gt;\(k\)&lt;/span&gt; is any of the &lt;span class="math inline"&gt;\(M\)&lt;/span&gt; states the process can hop to, will only be dependent on which state it is at the given moment of time. And not on how it reached the current state.&lt;/p&gt;
&lt;p&gt;Mathematically speaking:&lt;/p&gt;
&lt;center&gt;
&lt;span class="math display"&gt;\[ P(X_{n+1}=k | X_n=k_n,X_{n-1}=k_{n-1},....,X_1=k_1) = P(X_{n+1}=k|X_n=k_n)\]&lt;/span&gt;
&lt;/center&gt;
&lt;p&gt;If a process exhibits the Markov Property than it is known as a Markov Process.&lt;/p&gt;
&lt;p&gt;Now Why is a Markov Chain important? It is important because of its &lt;strong&gt;stationary distribution&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;So what is a &lt;strong&gt;Stationary Distribution&lt;/strong&gt;?&lt;/p&gt;
&lt;p&gt;Assume you have a markov process like below. You start from any state &lt;span class="math inline"&gt;\(X_i\)&lt;/span&gt; and want to find out the state Probability distribution at &lt;span class="math inline"&gt;\(X_{i+1}\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div style="margin-top: 10px; margin-bottom: -10px;"&gt;
&lt;center&gt;
&lt;img src="/images/Finance_Markov_chain_example_state_space.svg"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
You have a matrix of transition probability
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/transition_matrix.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;which defines the probability of going from a state &lt;span class="math inline"&gt;\(X_i\)&lt;/span&gt; to &lt;span class="math inline"&gt;\(X_j\)&lt;/span&gt;. You start calculating the Probability distribution for the next state. If you are at Bull Market State at time &lt;span class="math inline"&gt;\(i\)&lt;/span&gt; , you have a state Probability distribution as [0,1,0]&lt;/p&gt;
&lt;p&gt;you want to get the state pdf at &lt;span class="math inline"&gt;\(X_{i+1}\)&lt;/span&gt;. That is given by&lt;/p&gt;
&lt;div&gt;
&lt;center&gt;
&lt;span class="math display"&gt;\[s_{i+1} = s_{i}Q\]&lt;/span&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;center&gt;
&lt;span class="math display"&gt;\[ s_{i+1}=\left[ {\begin{array}{cc}   .15 &amp;amp; .8 &amp;amp; .05      \end{array} } \right]\]&lt;/span&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;And the next state distribution could be found out by&lt;/p&gt;
&lt;center&gt;
&lt;span class="math display"&gt;\[s_{i+1} = s_iQ^2\]&lt;/span&gt;
&lt;/center&gt;
and so on. Eventually you will reach a stationary state s where:
&lt;center&gt;
&lt;span class="math display"&gt;\[sQ=s\]&lt;/span&gt;
&lt;/center&gt;
For this transition matrix Q the Stationary distribution &lt;span class="math inline"&gt;\(s\)&lt;/span&gt; is
&lt;center&gt;
&lt;span class="math display"&gt;\[ s_{i+1}=\left[ {\begin{array}{cc}   .625 &amp;amp; .3125 &amp;amp; .0625      \end{array} } \right]\]&lt;/span&gt;
&lt;/center&gt;
&lt;p&gt;The stationary state distribution is important because it lets you define the probability for every state of a system at a random time. That is for this particular example we can say that 62.5% of the times market will be in a bull market state, 31.25% of weeks it will be a bear market and 6.25% of weeks it will be stagnant&lt;/p&gt;
&lt;p&gt;Intuitively you can think of it as an random walk on a chain. You might visit some nodes more often than others based on node probabilities. In the &lt;em&gt;Google Pagerank&lt;/em&gt; problem you might think of a node as a page, and the probability of a page in the stationary distribution as its relative importance.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Woah!&lt;/em&gt;&lt;/strong&gt; That was a lot of information and we have yet not started talking about the MCMC Methods. Well if you are with me till now, we can now get on to the real topic now.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="so-what-is-mcmc"&gt;So What is MCMC?&lt;/h2&gt;
According to &lt;a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo"&gt;Wikipedia&lt;/a&gt;:
&lt;blockquote&gt;
&lt;strong&gt;Markov Chain Monte Carlo&lt;/strong&gt; (MCMC) methods are a class of algorithms for &lt;strong&gt;sampling from a probability distribution&lt;/strong&gt; based on constructing a Markov chain that has the desired distribution as its stationary distribution. The state of the chain after a number of steps is then used as a sample of the desired distribution. The quality of the sample improves as a function of the number of steps.
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;So let's explain this with an example: Assume that &lt;strong&gt;we want to sample from a &lt;a href="https://en.wikipedia.org/wiki/Beta_distribution"&gt;Beta distribution&lt;/a&gt;&lt;/strong&gt;. The &lt;em&gt;PDF&lt;/em&gt; is:&lt;/p&gt;
&lt;center&gt;
&lt;span class="math display"&gt;\[f(x) = Cx^{\alpha -1}(1-x)^{\beta -1}\]&lt;/span&gt;
&lt;/center&gt;
&lt;p&gt;where &lt;span class="math inline"&gt;\(C\)&lt;/span&gt; is the normalizing constant &lt;em&gt;(which we actually don't need to Sample from the distribution as we will see later)&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This is a &lt;strong&gt;fairly difficult problem&lt;/strong&gt; with the Beta Distribution if not intractable. In reality you might need to work with a lot harder Distribution Functions and sometimes you won't actually know the normalizing constants.&lt;/p&gt;
&lt;p&gt;MCMC methods make life easier for us by providing us with algorithms that could create a Markov Chain which has the Beta distribution as its &lt;strong&gt;stationary distribution&lt;/strong&gt; given that we can sample from a uniform distribution(which is &lt;em&gt;fairly&lt;/em&gt; easy).&lt;/p&gt;
&lt;p&gt;If we start from a random state and traverse to the next state based on some algorithm repeatedly, we will end up creating a Markov Chain which has the Beta distribution as its &lt;strong&gt;stationary distribution&lt;/strong&gt; and the states we are at after a long time could be used as sample from the Beta Distribution.&lt;/p&gt;
&lt;p&gt;One such MCMC Algorithm is the &lt;strong&gt;&lt;a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm"&gt;Metropolis Hastings Algorithm&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id="metropolis-hastings-algorithm"&gt;Metropolis Hastings Algorithm&lt;/h2&gt;
&lt;p&gt;Let &lt;span class="math inline"&gt;\(s=(s_1,s_2,....,s_M)\)&lt;/span&gt; be the desired stationary distribution. We want to create a Markov Chain that has this stationary distribution. We start with an arbitrary Markov Chain &lt;span class="math inline"&gt;\(P\)&lt;/span&gt; with &lt;span class="math inline"&gt;\(M\)&lt;/span&gt; states with transition matrix &lt;span class="math inline"&gt;\(Q\)&lt;/span&gt;, so that &lt;span class="math inline"&gt;\(Q_{ij}\)&lt;/span&gt; represents the probability of going from state &lt;span class="math inline"&gt;\(i\)&lt;/span&gt; to &lt;span class="math inline"&gt;\(j\)&lt;/span&gt;. Intuitively we know how to wander around this Markov Chain but this Markov Chain does not have the required Stationary Distribution. This chain does have some stationary distribution(which is not of our use)&lt;/p&gt;
&lt;p&gt;Our Goal is to change the way we wander on the this Markov Chain &lt;span class="math inline"&gt;\(P\)&lt;/span&gt; so that this chain has the desired Stationary distribution.&lt;/p&gt;
&lt;p&gt;To do this we:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Start at a random initial State &lt;span class="math inline"&gt;\(i\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Randomly pick a new &lt;em&gt;Proposal State&lt;/em&gt; by looking at the transition probabilities in the ith row of the transition matrix Q.&lt;/li&gt;
&lt;li&gt;Compute an measure called the &lt;em&gt;Acceptance Probability&lt;/em&gt; which is defined as:
&lt;center&gt;
&lt;span class="math display"&gt;\[a_{ij} = min(s_jp_{ji}/s_{i}p_{ij},1)\]&lt;/span&gt;
&lt;/center&gt;&lt;/li&gt;
&lt;li&gt;Now Flip a coin that lands head with probability &lt;span class="math inline"&gt;\(a_{ij}\)&lt;/span&gt;. If the coin comes up heads, accept the proposal i.e move to next state else reject the proposal i.e. stay at the current state.&lt;/li&gt;
&lt;li&gt;Repeat for a long time&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After a long time this chain will converge and will have a stationary distribution &lt;span class="math inline"&gt;\(s\)&lt;/span&gt;. &lt;strong&gt;We can then use the states of the chain as the sample from any distribution.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;While doing this to sample the Beta Distribution, the only time we are using the PDF is to find the acceptance probability and in that we divide &lt;span class="math inline"&gt;\(s_j\)&lt;/span&gt; by &lt;span class="math inline"&gt;\(s_i\)&lt;/span&gt;, i.e. the &lt;strong&gt;normalizing constant &lt;span class="math inline"&gt;\(C\)&lt;/span&gt; gets cancelled&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
Now Let's Talk about the intuition. For the Intuition I am quoting an &lt;a href="http://stats.stackexchange.com/a/12657"&gt;Answer&lt;/a&gt; from the site Stack Exchange,as this was the best intuitive explanation that I could find:
&lt;blockquote&gt;
I think there's a nice and simple intuition to be gained from the (independence-chain) Metropolis-Hastings algorithm. &lt;br&gt; &lt;br&gt; First, what's the goal? The goal of MCMC is to &lt;strong&gt;draw samples from some probability distribution&lt;/strong&gt; without having to know its exact height at any point(We don't need to know C). The way MCMC achieves this is to &lt;strong&gt;&amp;quot;wander around&amp;quot; on that distribution in such a way that the amount of time spent in each location is proportional to the height of the distribution&lt;/strong&gt;. If the &amp;quot;wandering around&amp;quot; process is set up correctly, you can make sure that this proportionality (between time spent and height of the distribution) is achieved. &lt;br&gt; &lt;br&gt; Intuitively, what we want to do is to to walk around on some (lumpy) surface in such a way that the amount of time we spend (or # samples drawn) in each location is proportional to the height of the surface at that location. So, e.g., we'd like to spend twice as much time on a hilltop that's at an altitude of 100m as we do on a nearby hill that's at an altitude of 50m. The nice thing is that we can do this even if we don't know the absolute heights of points on the surface: all we have to know are the relative heights. e.g., if one hilltop A is twice as high as hilltop B, then we'd like to spend twice as much time at A as we spend at B. &lt;br&gt; &lt;br&gt; The simplest variant of the Metropolis-Hastings algorithm (independence chain sampling) achieves this as follows: assume that in every (discrete) time-step, we pick a random new &amp;quot;proposed&amp;quot; location (selected uniformly across the entire surface). If the proposed location is higher than where we're standing now, move to it. If the proposed location is lower, then move to the new location with probability p, where p is the ratio of the height of that point to the height of the current location. (i.e., flip a coin with a probability p of getting heads; if it comes up heads, move to the new location; if it comes up tails, stay where we are). Keep a list of the locations you've been at on every time step, and that list will (asyptotically) have the right proportion of time spent in each part of the surface. (And for the A and B hills described above, you'll end up with twice the probability of moving from B to A as you have of moving from A to B). &lt;br&gt; &lt;br&gt; There are more complicated schemes for proposing new locations and the rules for accepting them, but the basic idea is still: &lt;strong&gt;(1) pick a new &amp;quot;proposed&amp;quot; location; (2) figure out how much higher or lower that location is compared to your current location; (3) probabilistically stay put or move to that location in a way that respects the overall goal of spending time proportional to height of the location. &amp;quot;&amp;quot;&amp;quot;&lt;/strong&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="sampling-from-beta-distribution"&gt;Sampling from Beta Distribution&lt;/h2&gt;
&lt;p&gt;Now Let's Move on to the problem of Simulating from Beta Distribution. Now Beta Distribution is a continuous Distribution on [0,1] and it can have infinite states on [0,1].&lt;/p&gt;
&lt;p&gt;Lets Assume an arbitrary Markov Chain P with infinite states on [0,1] having transition Matrix Q such that &lt;span class="math inline"&gt;\(Q_{ij} = Q_{ji} =\)&lt;/span&gt; All entries in Matrix. We don't really need the Matrix Q as we will see later, But I want to keep the problem description as close to the algorihm we suggested.&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Start at a random &lt;strong&gt;initial State &lt;span class="math inline"&gt;\(i\)&lt;/span&gt;&lt;/strong&gt; given by Unif(0,1).&lt;/li&gt;
&lt;li&gt;Randomly pick a new &lt;strong&gt;Proposal State&lt;/strong&gt; by looking at the transition probabilities in the ith row of the transition matrix Q. Lets say we pick up another Unif(0,1) state as a proposal state &lt;span class="math inline"&gt;\(j\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Compute an measure called the &lt;strong&gt;Acceptance Probability&lt;/strong&gt; :
&lt;center&gt;
&lt;span class="math display"&gt;\[a_{ij} = min(s_jp_{ji}/s_{i}p_{ij},1)\]&lt;/span&gt;
&lt;/center&gt;
which is,
&lt;center&gt;
&lt;span class="math display"&gt;\[a_{ij} = min(s_j/s_i,1)\]&lt;/span&gt;
&lt;/center&gt;
where,
&lt;center&gt;
&lt;span class="math display"&gt;\[s_i = Ci^{\alpha -1}(1-i)^{\beta -1}\]&lt;/span&gt;
&lt;/center&gt;
and,
&lt;center&gt;
&lt;span class="math display"&gt;\[s_j = Cj^{\alpha -1}(1-j)^{\beta -1}\]&lt;/span&gt;
&lt;/center&gt;&lt;/li&gt;
&lt;li&gt;Now Flip a coin that lands head with probability &lt;span class="math inline"&gt;\(a_{ij}\)&lt;/span&gt;. If the coin comes up heads, accept the proposal i.e move to next state else reject the proposal i.e. stay at the current state.&lt;/li&gt;
&lt;li&gt;Repeat for a long time&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So enough with theory, Let's Move on to python to create our Beta Simulations Now....&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;import random
# Lets define our Beta Function to generate s for any particular state. We don't care for the normalizing constant here.
def beta_s(w,a,b):
    return w**(a-1)*(1-w)**(b-1)

# This Function returns True if the coin with probability P of heads comes heads when flipped.
def random_coin(p):
    unif = random.uniform(0,1)
    if unif&gt;=p:
        return False
    else:
        return True

# This Function runs the MCMC chain for Beta Distribution.
def beta_mcmc(N_hops,a,b):
    states = []
    cur = random.uniform(0,1)
    for i in range(0,N_hops):
        states.append(cur)
        next = random.uniform(0,1)
        ap = min(beta_s(next,a,b)/beta_s(cur,a,b),1) # Calculate the acceptance probability
        if random_coin(ap):
            cur = next
    return states[-1000:] # Returns the last 100 states of the chain
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Let us check our results of the MCMC Sampled Beta distribution against the actual beta distribution.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;
import numpy as np
import pylab as pl
import scipy.special as ss
%matplotlib inline
pl.rcParams['figure.figsize'] = (17.0, 4.0)

# Actual Beta PDF.
def beta(a, b, i):
    e1 = ss.gamma(a + b)
    e2 = ss.gamma(a)
    e3 = ss.gamma(b)
    e4 = i ** (a - 1)
    e5 = (1 - i) ** (b - 1)
    return (e1/(e2*e3)) * e4 * e5

# Create a function to plot Actual Beta PDF with the Beta Sampled from MCMC Chain.
def plot_beta(a, b):
    Ly = []
    Lx = []
    i_list = np.mgrid[0:1:100j]
    for i in i_list:
        Lx.append(i)
        Ly.append(beta(a, b, i))
    pl.plot(Lx, Ly, label="Real Distribution: a="+str(a)+", b="+str(b))
    pl.hist(beta_mcmc(100000,a,b),normed=True,bins =25, histtype='step',label="Simulated_MCMC: a="+str(a)+", b="+str(b))
    pl.legend()
    pl.show()
    
plot_beta(0.1, 0.1)
plot_beta(1, 1)
plot_beta(2, 3)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div style="margin-top: -9px; margin-bottom: 30px;"&gt;
&lt;p&gt;&lt;img src="/images/graphs.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;As we can see our sampled beta values closely resemble the beta distribution.&lt;/p&gt;
&lt;p&gt;So MCMC Methods are useful for the following basic problems.&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Simulating from a Random Variable PDF. Example: Simulate from a Beta(0.5,0.5) or from a Normal(0,1).&lt;/li&gt;
&lt;li&gt;Solve problems with a large state space.For Example: Knapsack Problem, Encrytion Cipher etc. We will work on this in the &lt;a href="http://mlwhiz.com/blog/2015/08/21/MCMC_Algorithms_Cryptography/"&gt;Next Blog Post&lt;/a&gt; as this one has already gotten bigger than what I expected.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Till Then Ciao!!!!!!&lt;/p&gt;
&lt;h2 id="references-and-sources"&gt;References and Sources:&lt;/h2&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;a href="http://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science-ebook/dp/B00MMOJ19I"&gt;Introduction to Probability Joseph K Blitzstein, Jessica Hwang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stats.stackexchange.com/a/12657"&gt;StackExchange&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;One of the newest and best resources that you can keep an eye on is the &lt;a href="https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0"&gt;Bayesian Methods for Machine Learning&lt;/a&gt; course in the &lt;a href="https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0"&gt;Advanced machine learning specialization&lt;/a&gt; created jointly by Kazanova(Number 3 Kaggler at the time of writing)&lt;/p&gt;
&lt;p&gt;Apart from that I also found a course on &lt;strong&gt;&lt;a href="https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;amp;offerid=495576.8910375858&amp;amp;type=2&amp;amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Fbayesian"&gt;Bayesian Statistics on Coursera&lt;/a&gt;&lt;/strong&gt;. In the process of doing it right now so couldn't really comment on it. But since I had done an course on &lt;strong&gt;&lt;a href="https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;amp;offerid=495576.8839843074&amp;amp;type=2&amp;amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Finferential-statistics-intro"&gt;Inferential Statistics&lt;/a&gt;&lt;/strong&gt; taught by the same professor before(Mine Çetinkaya-Rundel), I am very hopeful for this course. Let's see.&lt;/p&gt;
&lt;p&gt;Also look out for these two books to learn more about MCMC. I have not yet read them whole but still I liked whatever I read:&lt;/p&gt;
&lt;div style="margin-left:1em ; text-align: center;"&gt;

&lt;a target="_blank"  href="https://www.amazon.com/gp/product/1439840954/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1439840954&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=d55979088adc0aabeaed88f4f14b48b6"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1439840954&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1439840954" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/t&gt;&lt;/t&gt;
&lt;a target="_blank"  href="https://www.amazon.com/gp/product/1584885874/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1584885874&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=ee3e2a0bc99359d6c5db0463ab1abb13"&gt;&lt;img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1584885874&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=am2&amp;o=1&amp;a=1584885874" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;

&lt;p&gt;Both these books are pretty high level and hard on math. But these are the best texts out there too. :)&lt;/p&gt;</summary><category term="Statistics"></category><category term="python"></category></entry></feed>