<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>mlwhiz</title><link href="https://mlwhiz.com/" rel="alternate"></link><link href="http://mlwhiz.github.io/feeds/python-statistics.atom.xml" rel="self"></link><id>https://mlwhiz.com/</id><updated>2016-10-27T04:43:00-02:00</updated><entry><title>Pandas For All - Some Basic Pandas Functions</title><link href="https://mlwhiz.com/blog/2016/10/27/baby_panda/" rel="alternate"></link><updated>2016-10-27T04:43:00-02:00</updated><author><name>Rahul Agarwal</name></author><id>tag:https://mlwhiz.com,2016-10-27:blog/2016/10/27/baby_panda/</id><summary type="html">&lt;p&gt;It has been quite a few days I have been working with Pandas and apparently I feel I have gotten quite good at it. (Quite a Braggard I know)
So thought about adding a post about Pandas usage here. I intend to make this post quite practical and since I find the pandas syntax quite self explanatory, I won't be explaining much of the codes. Just the use cases and the code to achieve them.&lt;/p&gt;
&lt;h2&gt;1. Import Pandas&lt;/h2&gt;
&lt;p&gt;We Start by importing the libraries that we will need to use.&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;import pandas as pd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;2. Read a Datasource:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# Read from csv data files

# With Header
df = pd.read_csv("/Users/ragarw5/Downloads/SalesJan2009.csv")

# Without Header. sep param to provide the delimiter
df = pd.read_csv("/Users/ragarw5/Downloads/SalesJan2009.csv", header=None, sep= ",")

# Reading from SQL Datasource

import MySQLdb
from pandas import DataFrame
from pandas.io.sql import read_sql

db = MySQLdb.connect(host="localhost",    # your host, usually localhost
                     user="root",         # your username
                     passwd="password",   # your password
                     db="dbname")         # name of the data base

query = "SELECT * FROM tablename"

data = read_sql(query, db)

# Reading from ExcelFile
data = pd.read_excel(filename)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
For now, we will be working with the file at http://samplecsvs.s3.amazonaws.com/SalesJan2009.csv. The Sales Jan 2009 file contains some “sanitized” sales transactions during the month of January. If you want to work along you can download this file from that location.&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;df = pd.read_csv("/Users/ragarw5/Downloads/SalesJan2009.csv")
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;3. See few rows of data:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# top 5 rows
df.head()

# top 50 rows
df.head(50)

# last 5 rows
df.tail()

# last 50 rows
df.tail(50)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;4. Getting Column Names in a list:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;columnnames = df.columns
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;5. Specifying user defined Column Names:&lt;/h2&gt;
&lt;p&gt;Sometimes you want to change the column names:&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;df.columns = ['Transdate', 'Product', 'Price', 'PaymentType', 'Name',
       'City', 'State', 'Country', 'AccountCreated', 'LastLogin',
       'Latitude', 'Longitude']
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;6. Subsetting specific columns:&lt;/h2&gt;
&lt;p&gt;Sometimes you only need to work with specific columns in a dataframe only. You can subset the columns in the dataframe using&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;newDf = df[['Product', 'Price', 'PaymentType', 'Name', 'City', 'State', 'Country']]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;7. Seeing column types:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;newDf.dtypes&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;8. Change type of a column&lt;/h2&gt;
&lt;p&gt;First thing i try is this.
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;newDf['Price'] = newDf['Price'].astype('int')&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;It gives error : ValueError: invalid literal for long() with base 10: '13,000'. That is you cannot cast a string with "," to an int. To do that we first have to get rid of the comma. For that we use a particular lambda-apply functionality which lets us apply functions to each row in the data.&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;newDf['Price'] = newDf.apply(lambda x: int(x['Price'].replace(',', '')),axis=1)&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"&gt;&lt;/script&gt;

&lt;h2&gt;9. Simple Dataframe Statistics:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# To get statistics of numerical columns
newDf.describe()

# To get maximum value of a column. When you take a single column you can think of it as a list and apply functions you would apply to a list
max(newDf['Price'])

# no of rows in dataframe
len(newDf)

# Shape of Dataframe
newDf.shape&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;10. Creating a new column:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# Create a column Address containing City,State and Country. Simply concat the columns.
newDf['Address'] = newDf['City'] +","+ newDf['State'] +","+ newDf['Country']

# I like to use a function defined approach with lambda-apply as it gives me more flexibility and more options. Like if i want to create a column which is 1 if the price is greater than 1200 and 0 otherwise.

def gt(x):
    if x&gt;1200:
        return 1
    else:
        return 0

newDf['Pricegt1200'] = newDf.apply(lambda x: gt(x['Price']),axis=1)&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;11. Subset a DataFrame:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# Single condition: dataframe with all entries priced greater than 1500

df_gt_1500 = newDf[newDf['Price']&gt;1500]

# Multiple conditions: AND - dataframe with all entries priced greater than 1500 and from London

And_df = newDf[(newDf['Price']&gt;1500) &amp; (newDf['City']=='London')]

# Multiple conditions: OR - dataframe with all entries priced greater than 1500 or from London

Or_df = newDf[(newDf['Price']&gt;1500) | (newDf['City']=='London')]

# Multiple conditions: NOT - dataframe with all entries priced greater than 1500 or from London have to be excluded

Not_df = newDf[~((newDf['Price']&gt;1500) | (newDf['City']=='London'))]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;12. Change the Column at particular places or impute:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# In the state column the state is abbreviated as 'TX'. We want the whole name 'Texas' in there
newDf.loc[newDf['State']=='TX','State'] = 'Texas'

# When City is Monaco State is not given. You want to impute 'Monaco State' as state also.
newDf.loc[newDf['City']=='Monaco','State'] = 'Monaco State'
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;13. GroupBy:&lt;/h2&gt;
&lt;p&gt;One of the most used functionality. One simple example&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# Find out the sum of transactions by a state. reset_index() is a function that resets the index of a dataframe. I apply this function ALWAYS whenever I do a groupby and you might think of it as a default syntax for groupby operations
import numpy as np
newDf.groupby(['State']).aggregate(np.sum).reset_index()

# You might get a few extra columns that you dont need. Just subset the columns in the dataframe. You could just chain the commands to subset for the columns you need.
newDf.groupby(['State']).aggregate(np.sum).reset_index()[['State','Price']]

# Find minimum transaction in each state
newDf.groupby(['State']).aggregate(np.min).reset_index()[['State','Price']]

# You might want to groupby more than one column

newDf.groupby(['State','City']).aggregate(np.sum).reset_index()[['State','City','Price']]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;14. Concat:&lt;/h2&gt;
&lt;p&gt;You have two datarames df1 and df2 you need to concat. Means append one below the other you can do it using:&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;pd.concat([df1,df2])&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;15. Merge:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;#Suppose in the start, you had two dataframes. One which contains city and price information:
City_Price = newwDf[['City','Price']]

#And another which contains 'City' and 'State' insformation
City_State = newDf[['City','State']].drop_duplicates(keep=False).reset_index()

#You need to merge these datatframes on basis of city. You need to do:
City_Price_State_df = pd.merge(City_Price,City_State,on=['City'],how='left')
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;16. Save a Dataframe to external File:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# To Csv file
newDf.to_csv("NewDfData.csv",index=False)

# To Excel File
from pandas import ExcelWriter
writer =  ExcelWriter('NewDfData.xlsx')
newDf.to_excel(writer,'Sheet1')
writer.save()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;17. Pushing Pandas Df to a sql database:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;from pandas.io import sql
import MySQLdb

db = MySQLdb.connect(host="localhost",    # your host, usually localhost
                     user="root",         # your username
                     passwd="password",  # your password
                     db="dbname")        # name of the data base

newDf.to_sql(con = db, name='tablename',if_exists='append',flavor='mysql', chunksize=10000,index=False)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Hope you found this post useful and worth your time. I tried to make this as simple as possible but You may always &lt;strong&gt;ask me&lt;/strong&gt; or see the documentation for doubts.&lt;/p&gt;
&lt;p&gt;If you have &lt;strong&gt;any more ideas&lt;/strong&gt; on how to use Pandas or &lt;strong&gt;other usecases&lt;/strong&gt;, please suggest in the &lt;strong&gt;comments&lt;/strong&gt; section.&lt;/p&gt;
&lt;p&gt;Till then ciao!!&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://www.gregreda.com/2013/10/26/intro-to-pandas-data-structures/"&gt;Intro to Pandas By Greg Rada&lt;/a&gt; What I have written is in a condensed form, If you want to get a detailed description visit Greg Rada's 3 posts series.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pandas.pydata.org/pandas-docs/stable/"&gt;Pandas Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</summary><category term="Python"></category><category term="dataframe"></category><category term="data munging"></category><category term="pandas"></category></entry></feed>