<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kaggle on Helping You Learn Data Science!</title><link>https://mlwhiz.com/tags/kaggle/</link><description>Recent content in Kaggle on Helping You Learn Data Science!</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 30 Mar 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://mlwhiz.com/tags/kaggle/index.xml" rel="self" type="application/rss+xml"/><item><title>NLP Learning Series: Part 4 - Transfer Learning Intuition for Text Classification</title><link>https://mlwhiz.com/blog/2019/03/30/transfer_learning_text_classification/</link><pubDate>Sat, 30 Mar 2019 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2019/03/30/transfer_learning_text_classification/</guid><description>This post is the fourth post of the NLP Text classification series.</description></item><item><title>NLP Learning Series: Part 3 - Attention, CNN and what not for Text Classification</title><link>https://mlwhiz.com/blog/2019/03/09/deeplearning_architectures_text_classification/</link><pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2019/03/09/deeplearning_architectures_text_classification/</guid><description>This post is the third post of the NLP Text classification series.</description></item><item><title>What my first Silver Medal taught me about Text Classification and Kaggle in general?</title><link>https://mlwhiz.com/blog/2019/02/19/siver_medal_kaggle_learnings/</link><pubDate>Tue, 19 Feb 2019 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2019/02/19/siver_medal_kaggle_learnings/</guid><description>Kaggle is an excellent place for learning. And I learned a lot of things from the recently concluded competition on Quora Insincere questions classification in which I got a rank of 182/4037.</description></item><item><title>NLP Learning Series: Part 2 - Conventional Methods for Text Classification</title><link>https://mlwhiz.com/blog/2019/02/08/deeplearning_nlp_conventional_methods/</link><pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2019/02/08/deeplearning_nlp_conventional_methods/</guid><description>This is the second post of the NLP Text classification series.</description></item><item><title>NLP Learning Series: Part 1 - Text Preprocessing Methods for Deep Learning</title><link>https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/</link><pubDate>Thu, 17 Jan 2019 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/</guid><description>Recently, I started up with an NLP competition on Kaggle called Quora Question insincerity challenge.</description></item><item><title>A Layman guide to moving from Keras to Pytorch</title><link>https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/</link><pubDate>Sun, 06 Jan 2019 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/</guid><description>Recently I started up with a competition on kaggle on text classification, and as a part of the competition, I had to somehow move to Pytorch to get deterministic results.</description></item><item><title>What Kagglers are using for Text Classification</title><link>https://mlwhiz.com/blog/2018/12/17/text_classification/</link><pubDate>Mon, 17 Dec 2018 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2018/12/17/text_classification/</guid><description>With the problem of Image Classification is more or less solved by Deep learning, Text Classification is the next new developing theme in deep learning.</description></item><item><title>Using XGBoost for time series prediction tasks</title><link>https://mlwhiz.com/blog/2017/12/26/win_a_data_science_competition/</link><pubDate>Tue, 26 Dec 2017 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2017/12/26/win_a_data_science_competition/</guid><description>Recently Kaggle master Kazanova along with some of his friends released a &amp;amp;ldquo;How to win a data science competition&amp;amp;rdquo; Coursera course.</description></item><item><title>Good Feature Building Techniques - Tricks for Kaggle - My Kaggle Code Repository</title><link>https://mlwhiz.com/blog/2017/09/14/kaggle_tricks/</link><pubDate>Thu, 14 Sep 2017 00:00:00 +0000</pubDate><guid>https://mlwhiz.com/blog/2017/09/14/kaggle_tricks/</guid><description>Often times it happens that we fall short of creativity. And creativity is one of the basic ingredients of what we do.</description></item></channel></rss>