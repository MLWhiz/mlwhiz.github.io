<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nlp on MLWhiz</title>
    <link>https://mlwhiz.com/tags/nlp/</link>
    <description>Recent content in Nlp on MLWhiz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 06 Jan 2019 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://mlwhiz.com/tags/nlp/atom.xml" rel="self" type="application/rss" />
    
    
    <item>
      <title>A Layman guide to moving from Keras to Pytorch</title>
      <link>https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/</link>
      <pubDate>Sun, 06 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/</guid>
      <description>

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/artificial-neural-network.png&#34;  height=&#34;350&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Recently I started up with a competition on kaggle on text classification, and as a part of the competition, I had to somehow move to Pytorch to get deterministic results. Now I have always worked with Keras in the past and it has given me pretty good results, but somehow I got to know that the &lt;strong&gt;CuDNNGRU/CuDNNLSTM layers in keras are not deterministic&lt;/strong&gt;, even after setting the seeds. So Pytorch did come to rescue. And am  I  glad that I moved.&lt;/p&gt;

&lt;p&gt;As a &lt;strong&gt;side note&lt;/strong&gt;: if you want to know more about &lt;strong&gt;NLP&lt;/strong&gt;, I would like to recommend this awesome course on &lt;strong&gt;&lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Natural Language Processing&lt;/a&gt;&lt;/strong&gt; in the &lt;strong&gt;&lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Advanced machine learning specialization&lt;/a&gt;&lt;/strong&gt;. You can start for free with the 7-day Free Trial. This course covers a wide range of tasks in Natural Language Processing from basic to advanced: Sentiment Analysis, summarization, dialogue state tracking, to name a few.&lt;/p&gt;

&lt;p&gt;Also take a look at my other post: &lt;a href=&#34;https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/&#34;&gt;Text Preprocessing Methods for Deep Learning&lt;/a&gt;, which talks about different preprocessing techniques you can use for your NLP task and &lt;a href=&#34;https://mlwhiz.com/blog/2018/12/17/text_classification/&#34;&gt;What Kagglers are using for Text Classification&lt;/a&gt;, which talks about various deep learning models in use in NLP.&lt;/p&gt;

&lt;p&gt;Ok back to the task at hand. &lt;em&gt;While Keras is great to start with deep learning, with time you are going to resent some of its limitations.&lt;/em&gt; I sort of thought about moving to Tensorflow. It seemed like a good transition as TF is the backend of Keras. But was it hard? With the whole &lt;code&gt;session.run&lt;/code&gt; commands and tensorflow sessions, I was sort of confused. It was not Pythonic at all.&lt;/p&gt;

&lt;p&gt;Pytorch helps in that since it seems like the &lt;strong&gt;python way to do things&lt;/strong&gt;. You have things under your control and you are not losing anything on the performance front. In the words of Andrej Karpathy:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;en&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;I&amp;#39;ve been using PyTorch a few months now and I&amp;#39;ve never felt better. I have more energy. My skin is clearer. My eye sight has improved.&lt;/p&gt;&amp;mdash; Andrej Karpathy (@karpathy) &lt;a href=&#34;https://twitter.com/karpathy/status/868178954032513024?ref_src=twsrc%5Etfw&#34;&gt;May 26, 2017&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;So without further ado let me translate Keras to Pytorch for you.&lt;/p&gt;

&lt;h2 id=&#34;the-classy-way-to-write-your-network&#34;&gt;The Classy way to write your network?&lt;/h2&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/structured.jpeg&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Ok, let us create an example network in keras first which we will try to port into Pytorch. Here I would like to give a piece of advice too. When you try to move from Keras to Pytorch &lt;strong&gt;take any network you have and try porting it to Pytorch&lt;/strong&gt;. It will make you understand Pytorch in a much better way. Here I am trying to write one of the networks that gave pretty good results in the Quora Insincere questions classification challenge for me. This model has all the bells and whistles which at least any Text Classification deep learning network could contain with its GRU, LSTM and embedding layers and also a meta input layer. And thus would serve as a good example. Also if you want to read up more on how the BiLSTM/GRU and Attention model work do visit my post &lt;a href=&#34;https://mlwhiz.com/blog/2018/12/17/text_classification/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_model&lt;/span&gt;(features,clipvalue&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt;,num_filters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;40&lt;/span&gt;,dropout&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;,embed_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;501&lt;/span&gt;):
    features_input &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],))
    inp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(maxlen, ))
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 1: Word2Vec Embeddings.&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Embedding(max_features, embed_size, weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[embedding_matrix], trainable&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)(inp)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 2: SpatialDropout1D(0.1)&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; SpatialDropout1D(dropout)(x)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 3: Bidirectional CuDNNLSTM&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Bidirectional(LSTM(num_filters, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True))(x)

    &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 4: Bidirectional CuDNNGRU&lt;/span&gt;
    x, x_h, x_c &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Bidirectional(GRU(num_filters, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, return_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; True))(x)  
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 5: some pooling operations&lt;/span&gt;
    avg_pool &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GlobalAveragePooling1D()(x)
    max_pool &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GlobalMaxPooling1D()(x)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 6: A concatenation of the last state, maximum pool, average pool and &lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# additional features&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; concatenate([avg_pool, x_h, max_pool,features_input])
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 7: A dense layer&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;)(x)

    &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 8: A dropout layer&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dropout(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)(x)
    
    &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 9: Output dense layer with one output for our Binary Classification problem.&lt;/span&gt;
    outp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sigmoid&amp;#34;&lt;/span&gt;)(x)

    &lt;span style=&#34;color:#75715e&#34;&gt;# Some keras model creation and compiling&lt;/span&gt;
    model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[inp,features_input], outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;outp)
    adam &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;adam(clipvalue&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;clipvalue)
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;binary_crossentropy&amp;#39;&lt;/span&gt;,
                  optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;adam,
                  metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So a model in pytorch is defined as a class(therefore a little more classy) which inherits from &lt;code&gt;nn.module&lt;/code&gt; . Every class necessarily contains an &lt;code&gt;__init__&lt;/code&gt; procedure block and a block for the &lt;code&gt;forward&lt;/code&gt; pass.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;In the &lt;code&gt;__init__&lt;/code&gt; part the user defines all the layers the network is going to have but doesn&amp;rsquo;t yet define how those layers would be connected to each other&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;In the forward pass block, the user defines how data flows from one layer to another inside the network.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;why-is-this-classy&#34;&gt;Why is this Classy?&lt;/h4&gt;

&lt;p&gt;Obviously classy because of Classes. Duh! But jokes apart, I found it beneficial due to a couple of reasons:&lt;/p&gt;

&lt;p&gt;1) It gives you a &lt;strong&gt;lot of control&lt;/strong&gt; on how your network is built.&lt;/p&gt;

&lt;p&gt;2) You understand a lot about the network when you are building it since you have to specify input and output dimensions. So ** fewer chances of error**. (Although this one is really up to the skill level)&lt;/p&gt;

&lt;p&gt;3) &lt;strong&gt;Easy to debug&lt;/strong&gt; networks. Any time you find any problem with the network just use something like &lt;code&gt;print(&amp;quot;avg_pool&amp;quot;, avg_pool.size())&lt;/code&gt; in the forward pass to check the sizes of the layer and you will debug the network easily&lt;/p&gt;

&lt;p&gt;4) You can &lt;strong&gt;return multiple outputs&lt;/strong&gt; from the forward layer. This is pretty helpful in the Encoder-Decoder architecture where you can return both the encoder and decoder output. Or in the case of autoencoder where you can return the output of the model and the hidden layer embedding for the data.&lt;/p&gt;

&lt;p&gt;5) &lt;strong&gt;Pytorch tensors work in a very similar manner to numpy arrays&lt;/strong&gt;. For example, I could have used Pytorch Maxpool function to write the maxpool layer but &lt;code&gt;max_pool, _ = torch.max(h_gru, 1)&lt;/code&gt; will also work.&lt;/p&gt;

&lt;p&gt;6) You can set up &lt;strong&gt;different layers with different initialization schemes&lt;/strong&gt;. Something you won&amp;rsquo;t be able to do in Keras. For example, in the below network I have changed the initialization scheme of my LSTM layer. The LSTM layer has different initializations for biases, input layer weights, and hidden layer weights.&lt;/p&gt;

&lt;p&gt;7) Wait until you see the &lt;strong&gt;training loop in Pytorch&lt;/strong&gt; You will be amazed at the sort of &lt;strong&gt;control&lt;/strong&gt; it provides.&lt;/p&gt;

&lt;p&gt;Now the same model in Pytorch will look like something like this. Do go through the code comments to understand more on how to port.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Alex_NeuralNet_Meta&lt;/span&gt;(nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Module):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; __init__(self,hidden_size,lin_size, embedding_matrix&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;embedding_matrix):
        super(Alex_NeuralNet_Meta, self)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__init__()

        &lt;span style=&#34;color:#75715e&#34;&gt;# Initialize some parameters for your model&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hidden_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; hidden_size
        drp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;

        &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 1: Word2Vec Embeddings.&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Embedding(max_features, embed_size)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;weight &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Parameter(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(embedding_matrix, dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32))
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;weight&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;requires_grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False

        &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 2: Dropout1D(0.1)&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding_dropout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout2d(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)

        &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 3: Bidirectional CuDNNLSTM&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lstm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LSTM(embed_size, hidden_size, bidirectional&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, batch_first&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)

        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; name, param &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lstm&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;named_parameters():
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bias&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; name:
                 nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;constant_(param, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;weight_ih&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; name:
                 nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;kaiming_normal_(param)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;weight_hh&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; name:
                 nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;orthogonal_(param)

        &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 4: Bidirectional CuDNNGRU&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gru &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GRU(hidden_size&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, hidden_size, bidirectional&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, batch_first&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)

        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; name, param &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gru&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;named_parameters():
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bias&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; name:
                 nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;constant_(param, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;weight_ih&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; name:
                 nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;kaiming_normal_(param)
            &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;weight_hh&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; name:
                 nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;orthogonal_(param)

        &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 7: A dense layer&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linear &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Linear(hidden_size&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; features&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], lin_size)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;relu &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ReLU()
        
        &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 8: A dropout layer &lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dropout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dropout(drp)

        &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 9: Output dense layer with one output for our Binary Classification problem.&lt;/span&gt;
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;out &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Linear(lin_size, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;forward&lt;/span&gt;(self, x):
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        here x[0] represents the first element of the input that is going to be passed. 
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        We are going to pass a tuple where first one contains the sequences(x[0])
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        and the second one is a additional feature vector(x[1])
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
        h_embedding &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding(x[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
        &lt;span style=&#34;color:#75715e&#34;&gt;# Based on comment by Ivank to integrate spatial dropout. &lt;/span&gt;
        embeddings &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; h_embedding&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unsqueeze(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)    &lt;span style=&#34;color:#75715e&#34;&gt;# (N, T, 1, K)&lt;/span&gt;
        embeddings &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;permute(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# (N, K, 1, T)&lt;/span&gt;
        embeddings &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embedding_dropout(embeddings)  &lt;span style=&#34;color:#75715e&#34;&gt;# (N, K, 1, T), some features are masked&lt;/span&gt;
        embeddings &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;permute(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# (N, T, 1, K)&lt;/span&gt;
        h_embedding &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; embeddings&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# (N, T, K)&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;#h_embedding = torch.squeeze(self.embedding_dropout(torch.unsqueeze(h_embedding, 0)))&lt;/span&gt;
        
        &lt;span style=&#34;color:#75715e&#34;&gt;#print(&amp;#34;emb&amp;#34;, h_embedding.size())&lt;/span&gt;
        h_lstm, _ &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;lstm(h_embedding)
        &lt;span style=&#34;color:#75715e&#34;&gt;#print(&amp;#34;lst&amp;#34;,h_lstm.size())&lt;/span&gt;
        h_gru, hh_gru &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gru(h_lstm)
        hh_gru &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; hh_gru&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;view(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hidden_size )
        &lt;span style=&#34;color:#75715e&#34;&gt;#print(&amp;#34;gru&amp;#34;, h_gru.size())&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;#print(&amp;#34;h_gru&amp;#34;, hh_gru.size())&lt;/span&gt;

        &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 5: is defined dynamically as an operation on tensors.&lt;/span&gt;
        avg_pool &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(h_gru, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
        max_pool, _ &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max(h_gru, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
        &lt;span style=&#34;color:#75715e&#34;&gt;#print(&amp;#34;avg_pool&amp;#34;, avg_pool.size())&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;#print(&amp;#34;max_pool&amp;#34;, max_pool.size())&lt;/span&gt;
        
        &lt;span style=&#34;color:#75715e&#34;&gt;# the extra features you want to give to the model&lt;/span&gt;
        f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cuda()
        &lt;span style=&#34;color:#75715e&#34;&gt;#print(&amp;#34;f&amp;#34;, f.size())&lt;/span&gt;

        &lt;span style=&#34;color:#75715e&#34;&gt;# Layer 6: A concatenation of the last state, maximum pool, average pool and &lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# additional features&lt;/span&gt;
        conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cat(( hh_gru, avg_pool, max_pool,f), &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
        &lt;span style=&#34;color:#75715e&#34;&gt;#print(&amp;#34;conc&amp;#34;, conc.size())&lt;/span&gt;

        &lt;span style=&#34;color:#75715e&#34;&gt;# passing conc through linear and relu ops&lt;/span&gt;
        conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;relu(self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linear(conc))
        conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dropout(conc)
        out &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;out(conc)
        &lt;span style=&#34;color:#75715e&#34;&gt;# return the final output&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; out&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Hope you are still there with me. One thing I would like to emphasize here is that you need to code something up in Pytorch to really understand how it works. And know that once you do that you would be glad that you put in the effort. On to the next section.&lt;/p&gt;

&lt;h2 id=&#34;tailored-or-readymade-the-best-fit-with-a-highly-customizable-training-loop&#34;&gt;Tailored or Readymade: The Best Fit with a highly customizable Training Loop&lt;/h2&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/sewing-machine.jpg&#34;  height=&#34;300&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;In the above section I wrote that you will be amazed once you saw the training loop. That was an exaggeration. On the first try you will be a little baffled/confused. But as soon as you read through the loop more than once it will make a lot of intuituve sense. Once again read up the comments and the code to gain a better understanding.&lt;/p&gt;

&lt;p&gt;This training loop does k-fold cross-validation on your training data and outputs Out-of-fold train_preds and test_preds averaged over the runs on the test data. I apologize if the flow looks something straight out of a kaggle competition, but if you understand this you would be able to create a training loop for your own workflow. And that is the beauty of Pytorch.&lt;/p&gt;

&lt;p&gt;So a brief summary of this loop are as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Create stratified splits using train data&lt;/li&gt;
&lt;li&gt;Loop through the splits.

&lt;ul&gt;
&lt;li&gt;Convert your train and CV data to tensor and load your data to the GPU using the
&lt;code&gt;X_train_fold = torch.tensor(x_train[train_idx.astype(int)], dtype=torch.long).cuda()&lt;/code&gt; command&lt;/li&gt;
&lt;li&gt;Load the model onto the GPU using the &lt;code&gt;model.cuda()&lt;/code&gt; command&lt;/li&gt;
&lt;li&gt;Define Loss function, Scheduler and Optimizer&lt;/li&gt;
&lt;li&gt;create &lt;code&gt;train_loader&lt;/code&gt;    and     valid_loader` to iterate through batches.&lt;/li&gt;
&lt;li&gt;Start running epochs. In each epoch

&lt;ul&gt;
&lt;li&gt;Set the model mode to train using &lt;code&gt;model.train()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Go through the batches in &lt;code&gt;train_loader&lt;/code&gt; and run the forward pass&lt;/li&gt;
&lt;li&gt;Run a scheduler step to change the learning rate&lt;/li&gt;
&lt;li&gt;Compute loss&lt;/li&gt;
&lt;li&gt;Set the existing gradients in the optimizer to zero&lt;/li&gt;
&lt;li&gt;Backpropagate the losses through the network&lt;/li&gt;
&lt;li&gt;Clip the gradients&lt;/li&gt;
&lt;li&gt;Take an optimizer step to change the weights in the whole network&lt;/li&gt;
&lt;li&gt;Set the model mode to eval using &lt;code&gt;model.eval()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Get predictions for the validation data using &lt;code&gt;valid_loader&lt;/code&gt; and store in variable &lt;code&gt;valid_preds_fold&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Calculate Loss and print&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;After all epochs are done. Predict the test data and store the predictions. These predictions will be averaged at the end of the split loop to get the final &lt;code&gt;test_preds&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Get Out-of-fold(OOF) predictions for train set using &lt;code&gt;train_preds[valid_idx] = valid_preds_fold&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;These OOF predictions can then be used to calculate the Local CV score for your model.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;pytorch_model_run_cv&lt;/span&gt;(x_train,y_train,features,x_test, model_obj, feats &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False,clip &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; True):
    seed_everything()
    avg_losses_f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    avg_val_losses_f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    &lt;span style=&#34;color:#75715e&#34;&gt;# matrix for the out-of-fold predictions&lt;/span&gt;
    train_preds &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((len(x_train)))
    &lt;span style=&#34;color:#75715e&#34;&gt;# matrix for the predictions on the test set&lt;/span&gt;
    test_preds &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((len(x_test)))
    splits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(StratifiedKFold(n_splits&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;n_splits, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;SEED)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(x_train, y_train))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, (train_idx, valid_idx) &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(splits):
        seed_everything(i&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;i)
        x_train &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(x_train)
        y_train &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(y_train)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; feats:
            features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(features)
        x_train_fold &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(x_train[train_idx&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(int)], dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;long)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cuda()
        y_train_fold &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(y_train[train_idx&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(int), np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis], dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cuda()
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; feats:
            kfold_X_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; features[train_idx&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(int)]
            kfold_X_valid_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; features[valid_idx&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(int)]
        x_val_fold &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(x_train[valid_idx&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(int)], dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;long)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cuda()
        y_val_fold &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(y_train[valid_idx&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(int), np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;newaxis], dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float32)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cuda()
        
        model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; copy&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;deepcopy(model_obj)

        model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cuda()

        loss_fn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;BCEWithLogitsLoss(reduction&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sum&amp;#39;&lt;/span&gt;)

        step_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;
        base_lr, max_lr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.001&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.003&lt;/span&gt;   
        optimizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optim&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Adam(filter(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; p: p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;requires_grad, model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parameters()), 
                                 lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;max_lr)
        
        &lt;span style=&#34;color:#75715e&#34;&gt;################################################################################################&lt;/span&gt;
        scheduler &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; CyclicLR(optimizer, base_lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;base_lr, max_lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;max_lr,
                   step_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;step_size, mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;exp_range&amp;#39;&lt;/span&gt;,
                   gamma&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.99994&lt;/span&gt;)
        &lt;span style=&#34;color:#75715e&#34;&gt;###############################################################################################&lt;/span&gt;

        train &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MyDataset(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;TensorDataset(x_train_fold, y_train_fold))
        valid &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MyDataset(torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;TensorDataset(x_val_fold, y_val_fold))
        
        train_loader &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataLoader(train, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;batch_size, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
        valid_loader &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataLoader(valid, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;batch_size, shuffle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)

        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Fold {i + 1}&amp;#39;&lt;/span&gt;)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; epoch &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(n_epochs):
            start_time &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()
            model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;train()

            avg_loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.&lt;/span&gt;  
            &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, (x_batch, y_batch, index) &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(train_loader):
                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; feats:       
                    f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; kfold_X_features[index]
                    y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model([x_batch,f])
                &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
                    y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(x_batch)

                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; scheduler:
                    scheduler&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;batch_step()

                &lt;span style=&#34;color:#75715e&#34;&gt;# Compute and print loss.&lt;/span&gt;
                loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; loss_fn(y_pred, y_batch)
                optimizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zero_grad()
                loss&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;backward()
                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; clip:
                    nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip_grad_norm_(model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parameters(),&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
                optimizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;step()
                avg_loss &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; loss&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item() &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; len(train_loader)
                
            model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eval()
            
            valid_preds_fold &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((x_val_fold&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;size(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)))
            test_preds_fold &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((len(x_test)))
            
            avg_val_loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.&lt;/span&gt;
            &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, (x_batch, y_batch,index) &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(valid_loader):
                &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; feats:
                    f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; kfold_X_valid_features[index]            
                    y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model([x_batch,f])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;detach()
                &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
                    y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(x_batch)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;detach()
                
                avg_val_loss &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; loss_fn(y_pred, y_batch)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item() &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; len(valid_loader)
                valid_preds_fold[index] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sigmoid(y_pred&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
            
            elapsed_time &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time() &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; start_time 
            &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Epoch {}/{} &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; loss={:.4f} &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; val_loss={:.4f} &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; time={:.2f}s&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(
                epoch &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, n_epochs, avg_loss, avg_val_loss, elapsed_time))
        avg_losses_f&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(avg_loss)
        avg_val_losses_f&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(avg_val_loss) 
        &lt;span style=&#34;color:#75715e&#34;&gt;# predict all samples in the test set batch per batch&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, (x_batch,) &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(test_loader):
            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; feats:
                f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; test_features[i &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; batch_size:(i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; batch_size]
                y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model([x_batch,f])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;detach()
            &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
                y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(x_batch)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;detach()

            test_preds_fold[i &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; batch_size:(i&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; batch_size] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sigmoid(y_pred&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
            
        train_preds[valid_idx] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; valid_preds_fold
        test_preds &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; test_preds_fold &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; len(splits)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;All &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; loss={:.4f} &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; val_loss={:.4f} &lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\t&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; &amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;average(avg_losses_f),np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;average(avg_val_losses_f)))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; train_preds, test_preds&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&#34;but-why-why-so-much-code&#34;&gt;But Why? Why so much code?&lt;/h4&gt;

&lt;p&gt;Okay. I get it. That was probably a handful. What you could have done with a simple&lt;code&gt;.fit&lt;/code&gt; in keras, takes a lot of code to accomplish in Pytorch. But understand that you get a lot of power too. Some use cases for you to understand:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;While in Keras you have prespecified schedulers like &lt;code&gt;ReduceLROnPlateau&lt;/code&gt; (and it is a task to write them), in Pytorch you can experiment like crazy. &lt;strong&gt;If you know how to write Python you are going to get along just fine&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Want to change the structure of your model between the epochs. Yeah you can do it. Changing the input size for convolution networks on the fly.&lt;/li&gt;
&lt;li&gt;And much more. It is only your imagination that will stop you.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;wanna-run-it-yourself&#34;&gt;Wanna Run it Yourself?&lt;/h2&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/tools.jpg&#34; alt=&#34;You have all the tools it seems&#34; height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;So another small confession here. The code above will not run as is as there are some code artifacts which I have not shown here. I did this in favor of making the post more readable. Like you see the &lt;code&gt;seed_everything&lt;/code&gt;, &lt;code&gt;MyDataset&lt;/code&gt; and &lt;code&gt;CyclicLR&lt;/code&gt; (From Jeremy Howard Course) functions and classes in the code above which are not really included with Pytorch. But fret not my friend. I have tried to write a &lt;a href=&#34;https://www.kaggle.com/mlwhiz/third-place-model-for-toxic-comments-in-pytorch/edit&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Kaggle Kernel&lt;/a&gt; with the whole running code. You can see the code here and include it in your projects.&lt;/p&gt;

&lt;p&gt;If you liked this post, &lt;strong&gt;please don&amp;rsquo;t forget to upvote the &lt;a href=&#34;https://www.kaggle.com/mlwhiz/third-place-model-for-toxic-comments-in-pytorch/edit&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Kernel&lt;/a&gt; too.&lt;/strong&gt; I will be obliged.&lt;/p&gt;

&lt;h2 id=&#34;endnotes-and-references&#34;&gt;Endnotes and References&lt;/h2&gt;

&lt;p&gt;This post is a result of an effort of a lot of excellent Kagglers and I will try to reference them in this section. If I leave out someone, do understand that it was not my intention to do so.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52644&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Discussion on 3rd Place winner model in Toxic comment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/larryfreeman/toxic-comments-code-for-alexander-s-9872-model&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;3rd Place model in Keras by Larry Freeman&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/spirosrap/bilstm-attention-kfold-clr-extra-features-capsule&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Pytorch starter Capsule model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;How to: Preprocessing when using embeddings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Improve your Score with some Text Preprocessing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Pytorch baseline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/hengzheng/pytorch-starter&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Pytorch starter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What Kagglers are using for Text Classification</title>
      <link>https://mlwhiz.com/blog/2018/12/17/text_classification/</link>
      <pubDate>Mon, 17 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2018/12/17/text_classification/</guid>
      <description>

&lt;p&gt;With the problem of Image Classification is more or less solved by Deep learning, &lt;em&gt;Text Classification is the next new developing theme in deep learning&lt;/em&gt;. For those who don&amp;rsquo;t know, Text classification is a common task in natural language processing, which transforms a sequence
of text of indefinite length into a category of text. How could you use that?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;To find sentiment of a review.&lt;/li&gt;
&lt;li&gt;Find toxic comments in a platform like Facebook&lt;/li&gt;
&lt;li&gt;Find Insincere questions on Quora. A current ongoing competition on kaggle&lt;/li&gt;
&lt;li&gt;Find fake reviews on websites&lt;/li&gt;
&lt;li&gt;Will a text advert get clicked or not&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And much more. The whole internet is filled with text and to categorise that information algorithmically will only give us incremental benefits to say the least in the field of AI.&lt;/p&gt;

&lt;p&gt;Here I am going to use the data from Quora&amp;rsquo;s Insincere questions to talk about the different models that people are building and sharing to perform this task. Obviously these standalone models are not going to put you on the top of the leaderboard, yet I hope that this ensuing discussion would be helpful for people who want to learn more about text classification. This is going to be a long post in that regard.&lt;/p&gt;

&lt;p&gt;As a side note: if you want to know more about NLP, I would like to recommend this awesome course on &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Natural Language Processing&lt;/a&gt; in the &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Advanced machine learning specialization&lt;/a&gt;. You can start for free with the 7-day Free Trial. This course covers a wide range of tasks in Natural Language Processing from basic to advanced: sentiment analysis, summarization, dialogue state tracking, to name a few.&lt;/p&gt;

&lt;p&gt;Also take a look at my other post: &lt;a href=&#34;https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/&#34;&gt;Text Preprocessing Methods for Deep Learning&lt;/a&gt;, which talks about different preprocessing techniques you can use for your NLP task and &lt;a href=&#34;https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/&#34;&gt;how to switch from Keras to Pytorch&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So let me try to go through some of the models which people are using to perform text classification and try to provide a brief intuition for them.&lt;/p&gt;

&lt;h2 id=&#34;1-textcnn&#34;&gt;1. TextCNN:&lt;/h2&gt;

&lt;p&gt;The idea of using a CNN to classify text was first presented in the paper &lt;a href=&#34;https://www.aclweb.org/anthology/D14-1181&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Convolutional Neural Networks for Sentence Classification&lt;/a&gt; by Yoon Kim. Instead of image pixels, the input to the tasks are sentences or documents represented as a matrix. Each row of the matrix corresponds to one word vector. That is, each row is word-vector that represents a word. Thus a sequence of max length 70 gives us a image of 70(max sequence length)x300(embedding size)&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/text_convolution.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Now for some intuition. While for a image we move our conv filter horizontally also since here we have fixed our kernel size to filter_size x embed_size i.e. (3,300) we are just going to move down for the convolution taking look at three words at once since our filter size is 3 in this case.Also one can think of filter sizes as unigrams, bigrams, trigrams etc. Since we are looking at a context window of 1,2,3, and 5 words respectively. Here is the text classification network coded in Keras:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# https://www.kaggle.com/yekenot/2dcnn-textclassifier&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model_cnn&lt;/span&gt;(embedding_matrix):
    filter_sizes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;]
    num_filters &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;36&lt;/span&gt;

    inp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(maxlen,))
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Embedding(max_features, embed_size, weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[embedding_matrix])(inp)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Reshape((maxlen, embed_size, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))(x)

    maxpool_pool &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(len(filter_sizes)):
        conv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Conv2D(num_filters, kernel_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(filter_sizes[i], embed_size),
                                     kernel_initializer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;he_normal&amp;#39;&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;elu&amp;#39;&lt;/span&gt;)(x)
        maxpool_pool&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(MaxPool2D(pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(maxlen &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; filter_sizes[i] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))(conv))

    z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Concatenate(axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)(maxpool_pool)   
    z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Flatten()(z)
    z &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dropout(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)(z)

    outp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sigmoid&amp;#34;&lt;/span&gt;)(z)

    model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inp, outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;outp)
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;binary_crossentropy&amp;#39;&lt;/span&gt;, optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
    
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I have written a simplified and well commented code to run this network(taking input from a lot of other kernels) on a &lt;a href=&#34;https://www.kaggle.com/mlwhiz/learning-text-classification-textcnn&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;kaggle kernel&lt;/a&gt; for this competition. Do take a look there to learn the preprocessing steps, and the word to vec embeddings usage in this model. You will learn something. Please do upvote the kernel if you find it helpful. This kernel scored around 0.661 on the public leaderboard.&lt;/p&gt;

&lt;h2 id=&#34;2-bidirectional-rnn-lstm-gru&#34;&gt;2. BiDirectional RNN(LSTM/GRU):&lt;/h2&gt;

&lt;p&gt;TextCNN takes care of a lot of things. For example it takes care of words in close range. It is able to see &amp;ldquo;new york&amp;rdquo; together. But it still can&amp;rsquo;t take care of all the context provided in a particular text sequence. It still does not learn the seem to learn the sequential structure of the data, where every word is dependednt on the previous word. Or a word in the previous sentence.&lt;/p&gt;

&lt;p&gt;RNN help us with that. &lt;em&gt;They are able to remember previous information using hidden states and connect it to the current task.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Long Short Term Memory networks (LSTM) are a subclass of RNN, specialized in remembering information for a long period of time. More over the Bidirectional LSTM keeps the contextual information in both directions which is pretty useful in text classification task (But won&amp;rsquo;t work for a time sweries prediction task).&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/birnn.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;For a most simplistic explanation of Bidirectional RNN, think of RNN cell as taking as input a hidden state(a vector) and the word vector and giving out an output vector and the next hidden state.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        Hidden state, Word vector -&amp;gt;(RNN Cell) -&amp;gt; Output Vector , Next Hidden state
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For a sequence of length 4 like &amp;lsquo;you will never believe&amp;rsquo;, The RNN cell will give 4 output vectors. Which can be concatenated and then used as part of a dense feedforward architecture.&lt;/p&gt;

&lt;p&gt;In the Bidirectional RNN the only change is that we read the text in the normal fashion as well in reverse. So we stack two RNNs in parallel and hence we get 8 output vectors to append.&lt;/p&gt;

&lt;p&gt;Once we get the output vectors we send them through a series of dense layers and finally a softmax layer to build a text classifier.&lt;/p&gt;

&lt;p&gt;Due to the limitations of RNNs like not remembering long term dependencies, in practice we almost always use LSTM/GRU to model long term dependencies. In such a case you can just think of the RNN cell being replaced by a LSTM cell or a GRU cell in the above figure. An example model is provided below. You can use CuDNNGRU interchangably with CuDNNLSTM, when you build models.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# BiDirectional LSTM&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model_lstm_du&lt;/span&gt;(embedding_matrix):
    inp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(maxlen,))
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Embedding(max_features, embed_size, weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[embedding_matrix])(inp)
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Here 64 is the size(dim) of the hidden state vector as well as the output vector. Keeping return_sequence we want the output for the entire sequence. So what is the dimension of output for this layer?
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        64*70(maxlen)*2(bidirection concat)
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    CuDNNLSTM is fast implementation of LSTM layer in Keras which only runs on GPU
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Bidirectional(CuDNNLSTM(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True))(x)
    avg_pool &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GlobalAveragePooling1D()(x)
    max_pool &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GlobalMaxPooling1D()(x)
    conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; concatenate([avg_pool, max_pool])
    conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;)(conc)
    conc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dropout(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)(conc)
    outp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sigmoid&amp;#34;&lt;/span&gt;)(conc)
    model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inp, outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;outp)
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;binary_crossentropy&amp;#39;&lt;/span&gt;, optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I have written a simplified and well commented code to run this network(taking input from a lot of other kernels) on a &lt;a href=&#34;https://www.kaggle.com/mlwhiz/learning-text-classification-bidirectionalrnn&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;kaggle kernel&lt;/a&gt; for this competition. Do take a look there to learn the preprocessing steps, and the word to vec embeddings usage in this model. You will learn something. Please do upvote the kernel if you find it helpful. This kernel scored around 0.671 on the public leaderboard.&lt;/p&gt;

&lt;h2 id=&#34;3-attention-models&#34;&gt;3. Attention Models&lt;/h2&gt;

&lt;p&gt;The concept of Attention is relatively new as it comes from &lt;a href=&#34;https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Hierarchical Attention Networks for Document Classification&lt;/a&gt; paper written jointly by CMU and Microsoft guys in 2016.&lt;/p&gt;

&lt;p&gt;So in the past we used to find features from text by doing a keyword extraction. Some word are more helpful in determining the category of a text than others. But in this method we sort of lost the sequential structure of text. With LSTM and deep learning methods while we are able to take case of the sequence structure we lose the ability to give higher weightage to more important words.
Can we have the best of both worlds?&lt;/p&gt;

&lt;p&gt;And that is attention for you. In the author&amp;rsquo;s words:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Not all words contribute equally to the representation of the sentence meaning. Hence, we introduce attention mechanism to extract
such words that are important to the meaning of the sentence and aggregate the representation of those informative words to form a sentence vector&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/birnn attention.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;In essense we want to create scores for every word in the text, which are the attention similarity score for a word.&lt;/p&gt;

&lt;p&gt;To do this we start with a weight matrix(W), a bias vector(b) and a context vector u. All of them will be learned by the optimmization algorithm.&lt;/p&gt;

&lt;p&gt;Then there are a series of mathematical operations. See the figure for more clarification. We can think of u1 as non linearity on RNN word output. After that v1 is a dot product of u1 with a context vector u raised to an exponentiation. From an intuition viewpoint, the value of v1 will be high if u and u1 are similar. Since we want the sum of scores to be 1, we divide v by the sum of v’s to get the Final Scores,s&lt;/p&gt;

&lt;p&gt;These final scores are then multiplied by RNN output for words to weight them according to their importance. After which the outputs are summed and sent through dense layers and softmax for the task of text classification.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dot_product&lt;/span&gt;(x, kernel):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Wrapper for dot product operation, in order to be compatible with both
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Theano and Tensorflow
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Args:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        x (): input
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        kernel (): weights
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Returns:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;backend() &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;tensorflow&amp;#39;&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;squeeze(K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(x, K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(kernel)), axis&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(x, kernel)
    

&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;AttentionWithContext&lt;/span&gt;(Layer):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Attention operation, with a context/query vector, for temporal data.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Supports Masking.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;Hierarchical Attention Networks for Document Classification&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    by using a context vector to assist the attention
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    # Input shape
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        3D tensor with shape: `(samples, steps, features)`.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    # Output shape
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        2D tensor with shape: `(samples, features)`.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    How to use:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    The dimensions are inferred based on the output shape of the RNN.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Note: The layer has been tested with Keras 2.0.6
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Example:
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        model.add(LSTM(64, return_sequences=True))
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        model.add(AttentionWithContext())
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        # next add a Dense layer (for classification/regression) or whatever...
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; __init__(self,
                 W_regularizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, u_regularizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, b_regularizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None,
                 W_constraint&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, u_constraint&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, b_constraint&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None,
                 bias&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;kwargs):

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;supports_masking &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; True
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; initializers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;glorot_uniform&amp;#39;&lt;/span&gt;)

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_regularizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; regularizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(W_regularizer)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;u_regularizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; regularizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(u_regularizer)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_regularizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; regularizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(b_regularizer)

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_constraint &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; constraints&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(W_constraint)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;u_constraint &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; constraints&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(u_constraint)
        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_constraint &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; constraints&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(b_constraint)

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bias &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; bias
        super(AttentionWithContext, self)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__init__(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;kwargs)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;build&lt;/span&gt;(self, input_shape):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;assert&lt;/span&gt; len(input_shape) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_weight((input_shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], input_shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],),
                                 initializer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init,
                                 name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{}_W&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name),
                                 regularizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_regularizer,
                                 constraint&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_constraint)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bias:
            self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_weight((input_shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],),
                                     initializer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;zero&amp;#39;&lt;/span&gt;,
                                     name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{}_b&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name),
                                     regularizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_regularizer,
                                     constraint&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_constraint)

        self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;u &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_weight((input_shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],),
                                 initializer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init,
                                 name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{}_u&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name),
                                 regularizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;u_regularizer,
                                 constraint&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;u_constraint)

        super(AttentionWithContext, self)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;build(input_shape)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;compute_mask&lt;/span&gt;(self, input, input_mask&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None):
        &lt;span style=&#34;color:#75715e&#34;&gt;# do not pass the mask to the next layers&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; None

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;call&lt;/span&gt;(self, x, mask&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None):
        uit &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dot_product(x, self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W)

        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bias:
            uit &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b

        uit &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tanh(uit)
        ait &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dot_product(uit, self&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;u)

        a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(ait)

        &lt;span style=&#34;color:#75715e&#34;&gt;# apply mask after the exp. will be re-normalized next&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; mask &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
            &lt;span style=&#34;color:#75715e&#34;&gt;# Cast the mask to floatX to avoid float64 upcasting in theano&lt;/span&gt;
            a &lt;span style=&#34;color:#f92672&#34;&gt;*=&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(mask, K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;floatx())

        &lt;span style=&#34;color:#75715e&#34;&gt;# in some cases especially in the early stages of training the sum may be almost zero&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# and this results in NaN&amp;#39;s. A workaround is to add a very small positive number ε to the sum.&lt;/span&gt;
        &lt;span style=&#34;color:#75715e&#34;&gt;# a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())&lt;/span&gt;
        a &lt;span style=&#34;color:#f92672&#34;&gt;/=&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cast(K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(a, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, keepdims&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;epsilon(), K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;floatx())

        a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;expand_dims(a)
        weighted_input &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; a
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; K&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(weighted_input, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;compute_output_shape&lt;/span&gt;(self, input_shape):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; input_shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], input_shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]


&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;model_lstm_atten&lt;/span&gt;(embedding_matrix):
    inp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Input(shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(maxlen,))
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Embedding(max_features, embed_size, weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[embedding_matrix], trainable&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)(inp)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Bidirectional(CuDNNLSTM(&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True))(x)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Bidirectional(CuDNNLSTM(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, return_sequences&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True))(x)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AttentionWithContext()(x)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;)(x)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sigmoid&amp;#34;&lt;/span&gt;)(x)
    model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;inp, outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;x)
    model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;binary_crossentropy&amp;#39;&lt;/span&gt;, optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I have written a simplified and well commented code to run this network(taking input from a lot of other kernels) on a &lt;a href=&#34;https://www.kaggle.com/mlwhiz/learning-text-classification-attention&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;kaggle kernel&lt;/a&gt; for this competition. Do take a look there to learn the preprocessing steps, and the word to vec embeddings usage in this model. You will learn something. Please do upvote the kernel if you find it helpful. This kernel scored around 0.682 on the public leaderboard.&lt;/p&gt;

&lt;p&gt;Hope that Helps! Do checkout the kernels for all the networks and see the comments too. I will try to write a part 2 of this post where I would like to talk about capsule networks and more techniques as they get used in this competition.&lt;/p&gt;

&lt;p&gt;Here are the kernel links again: &lt;a href=&#34;https://www.kaggle.com/mlwhiz/learning-text-classification-textcnn&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;TextCNN&lt;/a&gt;,&lt;a href=&#34;https://www.kaggle.com/mlwhiz/learning-text-classification-bidirectionalrnn&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;BiLSTM/GRU&lt;/a&gt;,&lt;a href=&#34;https://www.kaggle.com/mlwhiz/learning-text-classification-attention&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Attention&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Do upvote the kenels if you find them helpful.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;CNN for NLP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.diveintodeeplearning.org/d2l-en.pdf&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;https://en.diveintodeeplearning.org/d2l-en.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gist.github.com/cbaziotis/7ef97ccf71cbc14366835198c09809d2&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;https://gist.github.com/cbaziotis/7ef97ccf71cbc14366835198c09809d2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://univagora.ro/jour/index.php/ijccc/article/view/3142&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;http://univagora.ro/jour/index.php/ijccc/article/view/3142&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/shujian/fork-of-mix-of-nn-models&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Shujian&amp;rsquo;s kernel on Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Using XGBoost for time series prediction tasks</title>
      <link>https://mlwhiz.com/blog/2017/12/26/win_a_data_science_competition/</link>
      <pubDate>Tue, 26 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2017/12/26/win_a_data_science_competition/</guid>
      <description>

&lt;p&gt;Recently Kaggle master Kazanova along with some of his friends released a &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-BShznKdc3CUauhfsM7_8xw&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;How to win a data science competition&amp;rdquo;&lt;/a&gt; Coursera course. You can start for free with the 7-day Free Trial. The Course involved a final project which itself was a time series prediction problem. Here I will describe how I got a top 10 position as of writing this article.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/lboard.png&#34;  height=&#34;800&#34; width=&#34;600&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h2 id=&#34;description-of-the-problem&#34;&gt;Description of the Problem:&lt;/h2&gt;

&lt;p&gt;In this competition we were given a challenging time-series dataset consisting of daily sales data, kindly provided by one of the largest Russian software firms - 1C Company.&lt;/p&gt;

&lt;p&gt;We were asked you to predict total sales for every product and store in the next month.&lt;/p&gt;

&lt;p&gt;The evaluation metric was RMSE where True target values are clipped into [0,20] range. This target range will be a lot important in understanding the submissions that I will prepare.&lt;/p&gt;

&lt;p&gt;The main thing that I noticed was that the data preparation aspect of this competition was by far the most important thing. I creted a variety of features. Here are the steps I took and the features I created.&lt;/p&gt;

&lt;h2 id=&#34;1-created-a-dataframe-of-all-date-block-num-store-and-item-combinations&#34;&gt;1. Created a dataframe of all Date_block_num, Store and  Item combinations:&lt;/h2&gt;

&lt;p&gt;This is important because in the months we don&amp;rsquo;t have a data for an item store combination, the machine learning algorithm needs to be specifically told that the sales is zero.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; itertools &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; product
&lt;span style=&#34;color:#75715e&#34;&gt;# Create &amp;#34;grid&amp;#34; with columns&lt;/span&gt;
index_cols &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;shop_id&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_id&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;]

&lt;span style=&#34;color:#75715e&#34;&gt;# For every month we create a grid from all shops/items combinations from that month&lt;/span&gt;
grid &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; block_num &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sales[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unique():
    cur_shops &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[sales[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; block_num, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;shop_id&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unique()
    cur_items &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[sales[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; block_num, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_id&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unique()
    grid&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(list(product(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;[cur_shops, cur_items, [block_num]])),dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;int32&amp;#39;&lt;/span&gt;))
grid &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;vstack(grid), columns &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; index_cols,dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;2-cleaned-up-a-little-of-sales-data-after-some-basic-eda&#34;&gt;2. Cleaned up a little of sales data after some basic EDA:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;sales &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales[sales&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item_price&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100000&lt;/span&gt;]
sales &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales[sales&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item_cnt_day&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;3-created-mean-encodings&#34;&gt;3. Created Mean Encodings:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;sales_m &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;shop_id&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_id&amp;#39;&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;agg({&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_cnt_day&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sum&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_price&amp;#39;&lt;/span&gt;: np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean})&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reset_index()
sales_m &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;merge(grid,sales_m,on&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;shop_id&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_id&amp;#39;&lt;/span&gt;],how&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;left&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fillna(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# adding the category id too&lt;/span&gt;
sales_m &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;merge(sales_m,items,on&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_id&amp;#39;&lt;/span&gt;],how&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;left&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; type_id &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_id&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;shop_id&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_category_id&amp;#39;&lt;/span&gt;]:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; column_id,aggregator,aggtype &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; [(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_price&amp;#39;&lt;/span&gt;,np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;avg&amp;#39;&lt;/span&gt;),(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_cnt_day&amp;#39;&lt;/span&gt;,np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sum&amp;#39;&lt;/span&gt;),(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_cnt_day&amp;#39;&lt;/span&gt;,np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;avg&amp;#39;&lt;/span&gt;)]:

        mean_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby([type_id,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;aggregate(aggregator)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reset_index()[[column_id,type_id,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;]]
        mean_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [type_id&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;_&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;aggtype&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;_&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;column_id,type_id,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;]

        sales_m &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;merge(sales_m,mean_df,on&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;,type_id],how&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;left&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;These above lines add the following 9 features :&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;lsquo;item_id_avg_item_price&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_id_sum_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_id_avg_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;shop_id_avg_item_price&amp;rsquo;,&lt;/li&gt;
&lt;li&gt;&amp;lsquo;shop_id_sum_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;shop_id_avg_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_category_id_avg_item_price&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_category_id_sum_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_category_id_avg_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;4-create-lag-features&#34;&gt;4. Create Lag Features:&lt;/h2&gt;

&lt;p&gt;Next we create lag features with diferent lag periods on the following features:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;lsquo;item_id_avg_item_price&amp;rsquo;,&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_id_sum_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_id_avg_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;shop_id_avg_item_price&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;shop_id_sum_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;shop_id_avg_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_category_id_avg_item_price&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_category_id_sum_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_category_id_avg_item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;li&gt;&amp;lsquo;item_cnt_day&amp;rsquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;lag_variables  &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(sales_m&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns[&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;:])&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_cnt_day&amp;#39;&lt;/span&gt;]
lags &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; ,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; ,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; ,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;]
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; lag &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; lags:
    sales_new_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales_m&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;copy()
    sales_new_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;date_block_num&lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt;lag
    sales_new_df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales_new_df[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;shop_id&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_id&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;lag_variables]
    sales_new_df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;shop_id&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_id&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; [lag_feat&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;_lag_&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;str(lag) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; lag_feat &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; lag_variables]
    sales_means &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;merge(sales_means, sales_new_df,on&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;shop_id&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_id&amp;#39;&lt;/span&gt;] ,how&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;left&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;5-fill-na-with-zeros&#34;&gt;5. Fill NA with zeros:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; feat &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sales_means&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns:
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_cnt&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; feat:
        sales_means[feat]&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sales_means[feat]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fillna(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_price&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; feat:
        sales_means[feat]&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sales_means[feat]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fillna(sales_means[feat]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;median())&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;6-drop-the-columns-that-we-are-not-going-to-use-in-training&#34;&gt;6. Drop the columns that we are not going to use in training:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;cols_to_drop &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lag_variables[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_name&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_price&amp;#39;&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;7-take-a-recent-bit-of-data-only&#34;&gt;7. Take a recent bit of data only:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;sales_means &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales_means[sales_means[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;8-split-in-train-and-cv&#34;&gt;8. Split in train and CV :&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;X_train &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sales_means[sales_means[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;33&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(cols_to_drop, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
X_cv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  sales_means[sales_means[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;date_block_num&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;33&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(cols_to_drop, axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;9-the-magic-sauce&#34;&gt;9. THE MAGIC SAUCE:&lt;/h2&gt;

&lt;p&gt;In the start I told that the clipping aspect of [0,20] will be important.
In the next few lines I clipped the days to range[0,40]. You might ask me why 40. An intuitive answer is if I had clipped to range [0,20] there would be very few tree nodes that could give 20 as an answer. While if I increase it to 40 having a 20 becomes much more easier. Please note that We will clip our predictions in the [0,20] range in the end.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;clip&lt;/span&gt;(x):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;40&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;40&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; x
train[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_cnt_day&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: clip(x[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_cnt_day&amp;#39;&lt;/span&gt;]),axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
cv[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_cnt_day&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: clip(x[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;item_cnt_day&amp;#39;&lt;/span&gt;]),axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;10-modelling&#34;&gt;10: Modelling:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Created a XGBoost model to get the most important features(Top 42 features)&lt;/li&gt;
&lt;li&gt;Use hyperopt to tune xgboost&lt;/li&gt;
&lt;li&gt;Used top 10 models from tuned XGBoosts to generate predictions.&lt;/li&gt;
&lt;li&gt;clipped the predictions to [0,20] range&lt;/li&gt;
&lt;li&gt;Final solution was the average of these 10 predictions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Learned a lot of new things from this &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-BShznKdc3CUauhfsM7_8xw&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;awesome course&lt;/a&gt;. Most recommended.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Good Feature Building Techniques - Tricks for Kaggle -  My Kaggle Code Repository</title>
      <link>https://mlwhiz.com/blog/2017/09/14/kaggle_tricks/</link>
      <pubDate>Thu, 14 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2017/09/14/kaggle_tricks/</guid>
      <description>

&lt;p&gt;Often times it happens that we fall short of creativity. And creativity is one of the basic ingredients of what we do. Creating features needs creativity. So here is the list of ideas I gather in day to day life, where people have used creativity to get great results on Kaggle leaderboards.&lt;/p&gt;

&lt;p&gt;Take a look at the &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;How to Win a Data Science Competition: Learn from Top Kagglers&lt;/a&gt; course in the &lt;a href=&#34;https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Advanced machine learning specialization&lt;/a&gt; by Kazanova(Number 3 Kaggler at the time of writing). You can start for free with the 7-day Free Trial.&lt;/p&gt;

&lt;p&gt;This post is inspired by a &lt;a href=&#34;https://www.kaggle.com/gaborfodor/from-eda-to-the-top-lb-0-368&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Kernel&lt;/a&gt; on Kaggle written by Beluga, one of the top Kagglers, for a knowledge based &lt;a href=&#34;https://www.kaggle.com/c/nyc-taxi-trip-duration&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;competition&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Some of the techniques/tricks I am sharing have been taken directly from that kernel so you could take a look yourself.
Otherwise stay here and read on.&lt;/p&gt;

&lt;h2 id=&#34;1-don-t-try-predicting-the-future-when-you-don-t-have-to&#34;&gt;1. Don&amp;rsquo;t try predicting the future when you don&amp;rsquo;t have to:&lt;/h2&gt;

&lt;p&gt;If both training/test comes from the same timeline, we can get really crafty with features. Although this is a case with Kaggle only, we can use this to our advantage. For example: In the Taxi Trip duration challenge the test data is randomly sampled from the train data. In this case we can use the target variable averaged over different categorical variable as a feature. Like in this case Beluga actually used the averaged the target variable over different weekdays. He then mapped the same averaged value as a variable by mapping it to test data too.&lt;/p&gt;

&lt;h2 id=&#34;2-logloss-clipping-technique&#34;&gt;2. logloss clipping Technique:&lt;/h2&gt;

&lt;p&gt;Something that I learned in the Neural Network course by Jeremy Howard. Its based on a very simple Idea. Logloss penalises a lot if we are very confident and wrong. So in case of Classification problems where we have to predict probabilities, it would be much better to clip our probabilities between 0.05-0.95 so that we are never very sure about our prediction.&lt;/p&gt;

&lt;h2 id=&#34;3-kaggle-submission-in-gzip-format&#34;&gt;3. kaggle submission in gzip format:&lt;/h2&gt;

&lt;p&gt;A small piece of code that will help you save countless hours of uploading. Enjoy.
df.to_csv(&amp;lsquo;submission.csv.gz&amp;rsquo;, index=False, compression=&amp;lsquo;gzip&amp;rsquo;)&lt;/p&gt;

&lt;h2 id=&#34;4-how-best-to-use-latitude-and-longitude-features-part-1&#34;&gt;4. How best to use Latitude and Longitude features - Part 1:&lt;/h2&gt;

&lt;p&gt;One of the best things that I liked about the Beluga Kernel is how he used the Lat/Lon Data. So in the example we had pickup Lat/Lon and Dropoff Lat/Lon. We created features like:&lt;/p&gt;

&lt;h4 id=&#34;a-haversine-distance-between-the-two-lat-lons&#34;&gt;A. Haversine Distance Between the Two Lat/Lons:&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;haversine_array&lt;/span&gt;(lat1, lng1, lat2, lng2):
    lat1, lng1, lat2, lng2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; map(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;radians, (lat1, lng1, lat2, lng2))
    AVG_EARTH_RADIUS &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6371&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# in km&lt;/span&gt;
    lat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lat2 &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; lat1
    lng &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lng2 &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; lng1
    d &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(lat &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos(lat1) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos(lat2) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(lng &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
    h &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; AVG_EARTH_RADIUS &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arcsin(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(d))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; h&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&#34;b-manhattan-distance-between-the-two-lat-lons&#34;&gt;B. Manhattan Distance Between the two Lat/Lons:&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dummy_manhattan_distance&lt;/span&gt;(lat1, lng1, lat2, lng2):
    a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; haversine_array(lat1, lng1, lat1, lng2)
    b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; haversine_array(lat1, lng1, lat2, lng1)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&#34;c-bearing-between-the-two-lat-lons&#34;&gt;C. Bearing Between the two Lat/Lons:&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;bearing_array&lt;/span&gt;(lat1, lng1, lat2, lng2):
    AVG_EARTH_RADIUS &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6371&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# in km&lt;/span&gt;
    lng_delta_rad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;radians(lng2 &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; lng1)
    lat1, lng1, lat2, lng2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; map(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;radians, (lat1, lng1, lat2, lng2))
    y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(lng_delta_rad) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos(lat2)
    x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos(lat1) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(lat2) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(lat1) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos(lat2) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos(lng_delta_rad)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;degrees(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arctan2(y, x))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&#34;d-center-latitude-and-longitude-between-pickup-and-dropoff&#34;&gt;D. Center Latitude and Longitude between Pickup and Dropoff:&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[:, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;center_latitude&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (train[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_latitude&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; train[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_latitude&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[:, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;center_longitude&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (train[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_longitude&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; train[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_longitude&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;5-how-best-to-use-latitude-and-longitude-features-part-2&#34;&gt;5. How best to use Latitude and Longitude features - Part 2:&lt;/h2&gt;

&lt;p&gt;The Second way he used the Lat/Lon Feats was to create clusters for Pickup and Dropoff Lat/Lons. The way it worked was it created sort of Boroughs in the data by design.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.cluster &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; MiniBatchKMeans
coords &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;vstack((train[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_longitude&amp;#39;&lt;/span&gt;]]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values,
                    train[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_longitude&amp;#39;&lt;/span&gt;]]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values,
                    test[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_longitude&amp;#39;&lt;/span&gt;]]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values,
                    test[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_longitude&amp;#39;&lt;/span&gt;]]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values))

sample_ind &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;permutation(len(coords))[:&lt;span style=&#34;color:#ae81ff&#34;&gt;500000&lt;/span&gt;]
kmeans &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MiniBatchKMeans(n_clusters&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10000&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(coords[sample_ind])

train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[:, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_cluster&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; kmeans&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(train[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_longitude&amp;#39;&lt;/span&gt;]])
train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[:, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_cluster&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; kmeans&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(train[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_longitude&amp;#39;&lt;/span&gt;]])
test&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[:, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_cluster&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; kmeans&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(test[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_longitude&amp;#39;&lt;/span&gt;]])
test&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[:, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_cluster&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; kmeans&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(test[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_longitude&amp;#39;&lt;/span&gt;]])&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;He then used these Clusters to create features like counting no of trips going out and coming in on a particular day.&lt;/p&gt;

&lt;h2 id=&#34;6-how-best-to-use-latitude-and-longitude-features-part-3&#34;&gt;6. How best to use Latitude and Longitude features - Part 3&lt;/h2&gt;

&lt;p&gt;He used PCA to transform longitude and latitude coordinates. In this case it is not about dimension reduction since he transformed 2D-&amp;gt; 2D. The rotation could help for decision tree splits, and it did actually.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;pca &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; PCA()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(coords)
train[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_pca0&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pca&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(train[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_longitude&amp;#39;&lt;/span&gt;]])[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
train[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_pca1&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pca&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(train[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_longitude&amp;#39;&lt;/span&gt;]])[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
train[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_pca0&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pca&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(train[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_longitude&amp;#39;&lt;/span&gt;]])[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
train[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_pca1&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pca&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(train[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_longitude&amp;#39;&lt;/span&gt;]])[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
test[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_pca0&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pca&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(test[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_longitude&amp;#39;&lt;/span&gt;]])[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
test[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_pca1&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pca&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(test[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pickup_longitude&amp;#39;&lt;/span&gt;]])[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
test[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_pca0&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pca&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(test[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_longitude&amp;#39;&lt;/span&gt;]])[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
test[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_pca1&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pca&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(test[[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_latitude&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dropoff_longitude&amp;#39;&lt;/span&gt;]])[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;7-lets-not-forget-the-normal-things-you-can-do-with-your-features&#34;&gt;7. Lets not forget the Normal Things you can do with your features:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Scaling by Max-Min&lt;/li&gt;
&lt;li&gt;Normalization using Standard Deviation&lt;/li&gt;
&lt;li&gt;Log based feature/Target: use log based features or log based target function.&lt;/li&gt;
&lt;li&gt;One Hot Encoding&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;8-creating-intuitive-additional-features&#34;&gt;8. Creating Intuitive Additional Features:&lt;/h2&gt;

&lt;p&gt;A) Date time Features: Time based Features like &amp;ldquo;Evening&amp;rdquo;, &amp;ldquo;Noon&amp;rdquo;, &amp;ldquo;Night&amp;rdquo;, &amp;ldquo;Purchases_last_month&amp;rdquo;, &amp;ldquo;Purchases_last_week&amp;rdquo; etc.&lt;/p&gt;

&lt;p&gt;B) Thought Features: Suppose you have shopping cart data and you want to categorize TripType (See Walmart Recruiting: Trip Type Classification on &lt;a href=&#34;https://www.kaggle.com/c/walmart-recruiting-trip-type-classification/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Kaggle&lt;/a&gt; for some background).&lt;/p&gt;

&lt;p&gt;You could think of creating a feature like &amp;ldquo;Stylish&amp;rdquo; where you create this variable by adding together number of items that belong to category Men&amp;rsquo;s Fashion, Women&amp;rsquo;s Fashion, Teens Fashion.&lt;/p&gt;

&lt;p&gt;You could create a feature like &amp;ldquo;Rare&amp;rdquo; which is created by tagging some items as rare, based on the data we have and then counting the number of those rare items in the shopping cart. Such features might work or might not work. From what I have observed they normally provide a lot of value.&lt;/p&gt;

&lt;p&gt;I feel this is the way that Target&amp;rsquo;s &amp;ldquo;Pregnant Teen model&amp;rdquo; was made. They would have had a variable in which they kept all the items that a pregnant teen could buy and put it into a classification algorithm.&lt;/p&gt;

&lt;h2 id=&#34;9-the-not-so-normal-things-which-people-do&#34;&gt;9 . The not so Normal Things which people do:&lt;/h2&gt;

&lt;p&gt;These features are highly unintuitive and should not be created where the machine learning model needs to be interpretable.&lt;/p&gt;

&lt;p&gt;A) Interaction Features: If you have features A and B create features A*B, A+B, A/B, A-B. This explodes the feature space. If you have 10 features and you are creating two variable interactions you will be adding 10C2 * 4  features = 180 features to your model. And most of us have a lot more than 10 features.&lt;/p&gt;

&lt;p&gt;B) Bucket Feature Using Hashing: Suppose you have a lot of features. In the order of Thousands but you don&amp;rsquo;t want to use all the thousand features because of the training times of algorithms involved. People bucket their features using some hashing algorithm to achieve this.Mostly done for text classification tasks.
For example:
If we have 6 features A,B,C,D,E,F.
And the row of data is:
A:1,B:1,C:1,D:0,E:1,F:0
I may decide to use a hashing function so that these 6 features correspond to 3 buckets and create the data using this feature hashing vector.
After processing my data might look like:
Bucket1:2,Bucket2:2,Bucket3:0
Which happened because A and B fell in bucket1, C and E fell in bucket2 and D and F fell in bucket 3. I summed up the observations here, but you could substitute addition with any math function you like.
Now i would use Bucket1,Bucket2,Bucket3 as my variables for machine learning.&lt;/p&gt;

&lt;p&gt;Will try to keep on expanding. Wait for more&amp;hellip;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Today I Learned This Part I: What are word2vec Embeddings?</title>
      <link>https://mlwhiz.com/blog/2017/04/09/word_vec_embeddings_examples_understanding/</link>
      <pubDate>Sun, 09 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2017/04/09/word_vec_embeddings_examples_understanding/</guid>
      <description>

&lt;p&gt;Recently Quora put out a &lt;a href=&#34;https://www.kaggle.com/c/quora-question-pairs&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Question similarity&lt;/a&gt; competition on Kaggle. This is the first time I was attempting an NLP problem so a lot to learn. The one thing that blew my mind away was the word2vec embeddings.&lt;/p&gt;

&lt;p&gt;Till now whenever I heard the term word2vec I visualized it as a way to create a bag of words vector for a sentence.&lt;/p&gt;

&lt;p&gt;For those who don&amp;rsquo;t know &lt;em&gt;bag of words&lt;/em&gt;:
If we have a series of sentences(documents)&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;This is good       - [1,1,1,0,0]&lt;/li&gt;
&lt;li&gt;This is bad        - [1,1,0,1,0]&lt;/li&gt;
&lt;li&gt;This is awesome    - [1,1,0,0,1]&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Bag of words would encode it using &lt;em&gt;0:This 1:is 2:good 3:bad 4:awesome&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;But it is much more powerful than that.&lt;/p&gt;

&lt;p&gt;What word2vec does is that it creates vectors for words.
What I mean by that is that we have a 300 dimensional vector for every word(common bigrams too) in a dictionary.&lt;/p&gt;

&lt;h2 id=&#34;how-does-that-help&#34;&gt;How does that help?&lt;/h2&gt;

&lt;p&gt;We can use this for multiple scenarios but the most common are:&lt;/p&gt;

&lt;p&gt;A. &lt;em&gt;Using word2vec embeddings we can find out similarity between words&lt;/em&gt;.
Assume you have to answer if these two statements signify the same thing:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;President greets press in Chicago&lt;/li&gt;
&lt;li&gt;Obama speaks to media in Illinois.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If we do a sentence similarity metric or a bag of words approach to compare these two sentences we will get a pretty low score.&lt;/p&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/word2vecembed.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;But with a word encoding we can say that&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;President is similar to Obama&lt;/li&gt;
&lt;li&gt;greets is similar to speaks&lt;/li&gt;
&lt;li&gt;press is similar to media&lt;/li&gt;
&lt;li&gt;Chicago is similar to Illinois&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;B. &lt;em&gt;Encode Sentences&lt;/em&gt;: I read a &lt;a href=&#34;https://www.linkedin.com/pulse/duplicate-quora-question-abhishek-thakur&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;post&lt;/a&gt; from Abhishek Thakur a prominent kaggler.(Must Read). What he did was he used these word embeddings to create a 300 dimensional vector for every sentence.&lt;/p&gt;

&lt;p&gt;His Approach: Lets say the sentence is &amp;ldquo;What is this&amp;rdquo;
And lets say the embedding for every word is given in 4 dimension(normally 300 dimensional encoding is given)&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;what : [.25 ,.25 ,.25 ,.25]&lt;/li&gt;
&lt;li&gt;is   : [  1 ,  0 ,  0 ,  0]&lt;/li&gt;
&lt;li&gt;this : [ .5 ,  0 ,  0 , .5]&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Then the vector for the sentence is normalized elementwise addition of the vectors. i.e.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Elementwise addition : [.25+1+0.5, 0.25+0+0 , 0.25+0+0, .25+0+.5] = [1.75, .25, .25, .75]
divided by
math.sqrt(1.25^2 + .25^2 + .25^2 + .75^2) = 1.5
gives:[1.16, .17, .17, 0.5]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Thus I can convert any sentence to a vector  of a fixed dimension(decided by the embedding). To find similarity between two sentences I can use a variety of distance/similarity metrics.&lt;/p&gt;

&lt;p&gt;C. Also It enables us to do algebraic manipulations on words which was not possible before. For example: What is king - man + woman ?&lt;/p&gt;

&lt;p&gt;Guess what it comes out to be : &lt;em&gt;Queen&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;application-coding&#34;&gt;Application/Coding:&lt;/h2&gt;

&lt;p&gt;Now lets get down to the coding part as we know a little bit of fundamentals.&lt;/p&gt;

&lt;p&gt;First of all we download a custom word embedding from Google. There are many other embeddings too.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;wget https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The above file is pretty big. Might take some time. Then moving on to coding.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; gensim.models &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; word2vec
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; gensim&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;models&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;KeyedVectors&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_word2vec_format(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;data/GoogleNews-vectors-negative300.bin.gz&amp;#39;&lt;/span&gt;, binary&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&#34;1-starting-simple-lets-find-out-similar-words-want-to-find-similar-words-to-python&#34;&gt;1. Starting simple, lets find out similar words. Want to find similar words to python?&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;most_similar(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;python&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;font-size:80%;color:black;font-family: helvetica;line-height:18px;margin-top:8px;margin-left:20px&#34;&gt;
[(u&#39;pythons&#39;, 0.6688377261161804),&lt;br&gt;
 (u&#39;Burmese_python&#39;, 0.6680364608764648),&lt;br&gt;
 (u&#39;snake&#39;, 0.6606293320655823),&lt;br&gt;
 (u&#39;crocodile&#39;, 0.6591362953186035),&lt;br&gt;
 (u&#39;boa_constrictor&#39;, 0.6443519592285156),&lt;br&gt;
 (u&#39;alligator&#39;, 0.6421656608581543),&lt;br&gt;
 (u&#39;reptile&#39;, 0.6387745141983032),&lt;br&gt;
 (u&#39;albino_python&#39;, 0.6158879995346069),&lt;br&gt;
 (u&#39;croc&#39;, 0.6083582639694214),&lt;br&gt;
 (u&#39;lizard&#39;, 0.601341724395752)]&lt;br&gt;
 &lt;/div&gt;

&lt;h3 id=&#34;2-now-we-can-use-this-model-to-find-the-solution-to-the-equation&#34;&gt;2. Now we can use this model to find the solution to the equation:&lt;/h3&gt;

&lt;p&gt;What is king - man + woman?&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;most_similar(positive &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;king&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;woman&amp;#39;&lt;/span&gt;],negative &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;man&amp;#39;&lt;/span&gt;])&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;font-size:80%;color:black;font-family: helvetica;line-height:18px;margin-top:8px;margin-left:20px&#34;&gt;
[(u&#39;queen&#39;, 0.7118192315101624),&lt;br&gt;
 (u&#39;monarch&#39;, 0.6189674139022827),&lt;br&gt;
 (u&#39;princess&#39;, 0.5902431011199951),&lt;br&gt;
 (u&#39;crown_prince&#39;, 0.5499460697174072),&lt;br&gt;
 (u&#39;prince&#39;, 0.5377321839332581),&lt;br&gt;
 (u&#39;kings&#39;, 0.5236844420433044),&lt;br&gt;
 (u&#39;Queen_Consort&#39;, 0.5235946178436279),&lt;br&gt;
 (u&#39;queens&#39;, 0.5181134343147278),&lt;br&gt;
 (u&#39;sultan&#39;, 0.5098593235015869),&lt;br&gt;
 (u&#39;monarchy&#39;, 0.5087412595748901)]&lt;br&gt;
&lt;/div&gt;

&lt;p&gt;You can do plenty of freaky/cool things using this:&lt;/p&gt;

&lt;h3 id=&#34;3-lets-say-you-wanted-a-girl-and-had-a-girl-name-like-emma-in-mind-but-you-got-a-boy-so-what-is-the-male-version-for-emma&#34;&gt;3. Lets say you wanted a girl and had a girl name like emma in mind but you got a boy. So what is the male version for emma?&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;most_similar(positive &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;emma&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;he&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;male&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mr&amp;#39;&lt;/span&gt;],negative &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;she&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mrs&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;female&amp;#39;&lt;/span&gt;])&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;font-size:80%;color:black;font-family: helvetica;line-height:18px;margin-top:8px;margin-left:20px&#34;&gt;
[(u&#39;sanchez&#39;, 0.4920658469200134),&lt;br&gt;
 (u&#39;kenny&#39;, 0.48300960659980774),&lt;br&gt;
 (u&#39;alves&#39;, 0.4684845209121704),&lt;br&gt;
 (u&#39;gareth&#39;, 0.4530612826347351),&lt;br&gt;
 (u&#39;bellamy&#39;, 0.44884198904037476),&lt;br&gt;
 (u&#39;gibbs&#39;, 0.445194810628891),&lt;br&gt;
 (u&#39;dos_santos&#39;, 0.44508373737335205),&lt;br&gt;
 (u&#39;gasol&#39;, 0.44387346506118774),&lt;br&gt;
 (u&#39;silva&#39;, 0.4424275755882263),&lt;br&gt;
 (u&#39;shaun&#39;, 0.44144102931022644)]&lt;br&gt;&lt;br&gt;
&lt;/div&gt;

&lt;h3 id=&#34;4-find-which-word-doesn-t-belong-to-a-list-https-github-com-dhammack-word2vecexample-blob-master-main-py&#34;&gt;4. Find which word doesn&amp;rsquo;t belong to a &lt;a href=&#34;https://github.com/dhammack/Word2VecExample/blob/master/main.py&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;list&lt;/a&gt;?&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;doesnt_match(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;math shopping reading science&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I think staple doesn&amp;rsquo;t belong in this list!&lt;/p&gt;

&lt;h2 id=&#34;other-cool-things&#34;&gt;Other Cool Things&lt;/h2&gt;

&lt;h3 id=&#34;1-recommendations&#34;&gt;1. Recommendations:&lt;/h3&gt;

&lt;div style=&#34;margin-top: 4px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/recommendationpaper.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;In this &lt;a href=&#34;https://arxiv.org/abs/1603.04259&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt;, the authors have shown that itembased CF can be cast in the same framework of word embedding.&lt;/p&gt;

&lt;h3 id=&#34;2-some-other-examples-http-byterot-blogspot-in-2015-06-five-crazy-abstractions-my-deep-learning-word2doc-model-just-did-nlp-gensim-html-that-people-have-seen-after-using-their-own-embeddings&#34;&gt;2. Some other &lt;a href=&#34;http://byterot.blogspot.in/2015/06/five-crazy-abstractions-my-deep-learning-word2doc-model-just-did-NLP-gensim.html&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;examples&lt;/a&gt; that people have seen after using their own embeddings:&lt;/h3&gt;

&lt;p&gt;Library - Books = Hall&lt;br&gt;
Obama + Russia - USA = Putin&lt;br&gt;
Iraq - Violence = Jordan&lt;br&gt;
President - Power = Prime Minister (Not in India Though)&lt;br&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-seeing-the-above-i-started-playing-with-it-a-little&#34;&gt;3.Seeing the above I started playing with it a little.&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Is this model sexist?&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;most_similar(positive &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;donald_trump&amp;#34;&lt;/span&gt;],negative &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;brain&amp;#39;&lt;/span&gt;])&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;font-size:80%;color:black;font-family: helvetica;line-height:18px;margin-top:8px;margin-left:20px&#34;&gt;
[(u&#39;novak&#39;, 0.40405112504959106),&lt;br&gt;
 (u&#39;ozzie&#39;, 0.39440611004829407),&lt;br&gt;
 (u&#39;democrate&#39;, 0.39187556505203247),&lt;br&gt;
 (u&#39;clinton&#39;, 0.390536367893219),&lt;br&gt;
 (u&#39;hillary_clinton&#39;, 0.3862358033657074),&lt;br&gt;
 (u&#39;bnp&#39;, 0.38295692205429077),&lt;br&gt;
 (u&#39;klaar&#39;, 0.38228923082351685),&lt;br&gt;
 (u&#39;geithner&#39;, 0.380607008934021),&lt;br&gt;
 (u&#39;bafana_bafana&#39;, 0.3801495432853699),&lt;br&gt;
 (u&#39;whitman&#39;, 0.3790769875049591)]&lt;br&gt;
&lt;/div&gt;

&lt;p&gt;Whatever it is doing it surely feels like magic. Next time I will try to write more on how it works once I understand it fully.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>