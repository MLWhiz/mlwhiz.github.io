<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>
    Probability on 
    MLWhiz
    </title>
    <link>https://mlwhiz.com/tags/probability/</link>
    <description>Recent content in Probability 
    on MLWhiz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
    
    <lastBuildDate>Thu, 14 Sep 2017 00:00:00 +0000</lastBuildDate>
    
    
        <atom:link href="https://mlwhiz.com/tags/probability/atom.xml" rel="self" type="application/rss" />
    
    
    <item>
      <title>The story of every distribution - Discrete Distributions</title>
      <link>https://mlwhiz.com/blog/2017/09/14/discrete_distributions/</link>
      <pubDate>Thu, 14 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2017/09/14/discrete_distributions/</guid>
      <description>

&lt;p&gt;Distributions play an important role in the life of every Statistician. I coming from a non-statistic background am not so well versed in these and keep forgetting about the properties of these famous distributions. That is why I chose to write my own understanding in an intuitive way to keep a track.
One of the most helpful way to learn more about these is the &lt;a href=&#34;https://projects.iq.harvard.edu/stat110/home&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;STAT110&lt;/a&gt; course by Joe Blitzstein and his &lt;a href=&#34;http://amzn.to/2xAsYzE&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;book&lt;/a&gt;. You can check out this &lt;a href=&#34;https://www.coursera.org/specializations/statistics?siteID=lVarvwc5BD0-1nQtJg8.ENATqSUIufAaaw&amp;amp;utm_content=2&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=lVarvwc5BD0&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Coursera&lt;/a&gt; course too. Hope it could be useful to someone else too. So here goes:&lt;/p&gt;

&lt;h2 id=&#34;1-bernoulli-distribution&#34;&gt;1. Bernoulli Distribution:&lt;/h2&gt;

&lt;p&gt;Perhaps the most simple discrete distribution of all.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Story:&lt;/strong&gt; A Coin is tossed with probability p of heads.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF of Bernoulli Distribution is given by:&lt;/strong&gt;&lt;/p&gt;

&lt;div&gt;$$P(X=k) = \begin{cases}1-p &amp; k = 0\\p &amp; k = 1\end{cases}$$&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;CDF of Bernoulli Distribution is given by:&lt;/strong&gt;&lt;/p&gt;

&lt;div&gt;$$P(X \leq k) = \begin{cases}0 &amp; k \lt 0\\1-p &amp; 0 \leq k \lt 1 \\1 &amp; k \geq 1\end{cases}$$&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Expected Value:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$E[X] = \sum kP(X=k)$$
$$E[X] = 0*P(X=0)+1*P(X=1) = p$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$Var[X] = E[X^2] - E[X]^2$$
Now we find,
$$E[X]^2 = p^2$$
and
$$E[X^2] = \sum k^2P(X=k)$$
$$E[X^2] =  0^2P(X=0) + 1^2P(X=1) = p $$
Thus,
$$Var[X] = p(1-p)$$&lt;/p&gt;

&lt;h2 id=&#34;2-binomial-distribution&#34;&gt;2. Binomial Distribution:&lt;/h2&gt;

&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/maxresdefault.jpg&#34;  height=&#34;400&#34; width=&#34;500&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;One of the most basic distribution in the Statistician toolkit. The parameters of this distribution is n(number of trials) and p(probability of success).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Story:&lt;/strong&gt;
Probability of getting exactly k successes in n trials&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF of binomial Distribution is given by:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$P(X=k) = \left(\begin{array}{c}n\ k\end{array}\right) p^{k}(1-p)^{n-k}$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;CDF of binomial Distribution is given by:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$ P(X\leq k) = \sum_{i=0}^k  \left(\begin{array}{c}n\ i\end{array}\right)  p^i(1-p)^{n-i} $$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Expected Value:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$E[X] = \sum kP(X=k)$$
$$E[X] = \sum_{k=0}^n k \left(\begin{array}{c}n\ k\end{array}\right) * p^{k}(1-p)^{n-k} = np $$&lt;/p&gt;

&lt;p&gt;A better way to solve this:&lt;/p&gt;

&lt;div&gt;$$ X = I_{1} + I_{2} + ....+ I_{n-1}+ I_{n} $$&lt;/div&gt;

&lt;p&gt;X is the sum on n Indicator Bernoulli random variables.&lt;/p&gt;

&lt;p&gt;Thus,&lt;/p&gt;

&lt;div&gt;
$$E[X] = E[I_{1} + I_{2} + ....+ I_{n-1}+ I_{n}]$$&lt;/div&gt;

&lt;div&gt;$$E[X] = E[I_{1}] + E[I_{2}] + ....+ E[I_{n-1}]+ E[I_{n}]$$&lt;/div&gt;

&lt;div&gt;$$E[X] = \underbrace{p + p + ....+ p + p}_{n} = np$$&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Variance:&lt;/strong&gt;&lt;/p&gt;

&lt;div&gt;$$ X = I_{1} + I_{2} + ....+ I_{n-1}+ I_{n} $$&lt;/div&gt;
X is the sum on n Indicator Bernoulli random variables.
&lt;div&gt;$$Var[X] = Var[I_{1} + I_{2} + ....+ I_{n-1}+ I_{n}]$$&lt;/div&gt;
&lt;div&gt;$$Var[X] = Var[I_{1}] + Var[I_{2}] + ....+ Var[I_{n-1}]+ Var[I_{n}]$$&lt;/div&gt;
&lt;div&gt;$$Var[X] = \underbrace{p(1-p) + p(1-p) + ....+ p(1-p) + p(1-p)}_{n} = np(1-p)$$&lt;/div&gt;

&lt;h2 id=&#34;3-geometric-distribution&#34;&gt;3. Geometric Distribution:&lt;/h2&gt;

&lt;p&gt;The parameters of this distribution is p(probability of success).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Story:&lt;/strong&gt;
The number of failures before the first success(Heads) when a coin with probability p is tossed&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF of Geometric Distribution is given by:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$P(X=k) = (1-p)^kp$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;CDF of Geometric Distribution is given by:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$ P(X\leq k) = \sum_{i=0}^k (1-p)^{i}p$$
$$ P(X\leq k) = p(1+q+q^2&amp;hellip;+q^k)= p(1-q^k)/(1-q) = 1-(1-p)^k $$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Expected Value:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$E[X] = \sum kP(X=k)$$
$$E[X] = \sum_{k=0}^{inf} k (1-p)^kp$$
$$E[X] = qp +2q^2p +3q^3p +4q^4p &amp;hellip;. $$
$$E[X] = qp(1+2q+3q^2+4q^3+&amp;hellip;.)$$
$$E[X] = qp/(1-q)^2 = q/p $$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$Var[X] = E[X^2] - E[X]^2$$
Now we find,
$$E[X]^2 = q^2/p^2$$
and
$$E[X^2] = \sum_0^k k^2q^kp= qp + 4q^2p + 9q^3p +16q^4p &amp;hellip; = qp(1+4q+9q^2+16q^3&amp;hellip;.)$$
$$E[X^2] = qp^{-2}(1+q)$$&lt;/p&gt;

&lt;p&gt;Thus,
$$Var[X] =q/p^2$$&lt;/p&gt;

&lt;p&gt;Check Math appendix at bottom of this post for Geometric Series Proofs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Q. A doctor is seeking an anti-depressant for a newly diagnosed patient. Suppose that, of the available anti-depressant drugs, the probability that any particular drug will be effective for a particular patient is p=0.6. What is the probability that the first drug found to be effective for this patient is the first drug tried, the second drug tried, and so on? What is the expected number of drugs that will be tried to find one that is effective?&lt;/p&gt;

&lt;p&gt;A. Expected number of drugs that will be tried to find one that is effective = q/p = .4/.6 =.67&lt;/p&gt;

&lt;h2 id=&#34;4-negative-binomial-distribution&#34;&gt;4. Negative Binomial Distribution:&lt;/h2&gt;

&lt;p&gt;The parameters of this distribution is p(probability of success) and r(number of success).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Story:&lt;/strong&gt;
The &lt;strong&gt;number of failures&lt;/strong&gt; of independent Bernoulli(p) trials before the rth success.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF of Negative Binomial Distribution is given by:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;r successes , k failures , last attempt needs to be a success:
$$P(X=k) = \left(\begin{array}{c}k+r-1\ k\end{array}\right) p^r(1-p)^k$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Expected Value:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The negative binomial RV could be stated as the sum of r Geometric RVs
$$X = X^1+X^2&amp;hellip;. X^{r-1} +X^r$$
Thus,
$$E[X] = E[X^1]+E[X^2]&amp;hellip;. E[X^{r-1}] +E[X^r]$$&lt;/p&gt;

&lt;p&gt;$$E[X] = rq/p$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The negative binomial RV could be stated as the sum of r independent Geometric RVs
$$X = X^1+X^2&amp;hellip;. X^{r-1} +X^r$$
Thus,
$$Var[X] = Var[X^1]+Var[X^2]&amp;hellip;. Var[X^{r-1}] +Var[X^r]$$&lt;/p&gt;

&lt;p&gt;$$E[X] = rq/p^2$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Q. Pat is required to sell candy bars to raise money for the 6th grade field trip. There are thirty houses in the neighborhood, and Pat is not supposed to return home until five candy bars have been sold. So the child goes door to door, selling candy bars. At each house, there is a 0.4 probability of selling one candy bar and a 0.6 probability of selling nothing.
What&amp;rsquo;s the probability of selling the last candy bar at the nth house?&lt;/p&gt;

&lt;p&gt;A. r = 5 ; k = n - r&lt;/p&gt;

&lt;p&gt;Probability of selling the last candy bar at the nth house =
$$P(X=k) = \left(\begin{array}{c}k+r-1\ k\end{array}\right) p^r(1-p)^k$$
$$P(X=k) = \left(\begin{array}{c}n-1\ n-5\end{array}\right) .4^5(.6)^{n-5}$$&lt;/p&gt;

&lt;h2 id=&#34;5-poisson-distribution&#34;&gt;5. Poisson Distribution:&lt;/h2&gt;

&lt;p&gt;The parameters of this distribution is $\lambda$ the rate parameter.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Motivation:&lt;/strong&gt;
There is as such no story to this distribution but only motivation for using this distribution. The Poisson distribution is often used for applications where we count the successes of a large number of trials where the per-trial success rate is small. For example, the Poisson distribution is a good starting point for counting the number of people who email you over the course of an hour.The number of chocolate chips in a chocolate chip cookie is another good candidate for a Poisson distribution, or the number of earthquakes in a year in some particular region&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF of Poisson Distribution is given by:&lt;/strong&gt;
$$ P(X=k) = \frac{e^{-\lambda}\lambda^k} {k!}$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Expected Value:&lt;/strong&gt;&lt;/p&gt;

&lt;div&gt;$$E[X] = \sum kP(X=k)$$&lt;/div&gt;

&lt;div&gt;$$ E[X] = \sum_{k=0}^{inf} k \frac{e^{-\lambda}\lambda^k} {k!}$$&lt;/div&gt;
&lt;div&gt;$$ E[X] = \lambda e^{-\lambda}\sum_{k=0}^{inf}  \frac{\lambda^{k-1}} {(k-1)!}$$&lt;/div&gt;
&lt;div&gt;$$ E[X] = \lambda e^{-\lambda} e^{\lambda} = \lambda $$&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Variance:&lt;/strong&gt;&lt;/p&gt;

&lt;div&gt;$$Var[X] = E[X^2] - E[X]^2$$&lt;/div&gt;

&lt;p&gt;Now we find,
&lt;div&gt;$$E[X]^2 = \lambda + \lambda^2$$&lt;/div&gt;
Thus,
$$Var[X] = \lambda$$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Q. If electricity power failures occur according to a Poisson distribution with an average of 3 failures every twenty weeks, calculate the probability that there will not be more than one failure during a particular week?&lt;/p&gt;

&lt;p&gt;A. Probability = P(X=0)+P(X=1) =&lt;/p&gt;

&lt;div&gt;$$e^{-3/20} + e^{-3/20}3/20 = 23/20*e^{-3/20} $$&lt;/div&gt;

&lt;p&gt;Probability of selling the last candy bar at the nth house =
$$P(X=k) = \left(\begin{array}{c}k+r-1\ k\end{array}\right) p^r(1-p)^k$$
$$P(X=k) = \left(\begin{array}{c}n-1\ n-5\end{array}\right) .4^5(.6)^{n-5}$$&lt;/p&gt;

&lt;h2 id=&#34;math-appendix&#34;&gt;Math Appendix:&lt;/h2&gt;

&lt;p&gt;Some Math (For Geometric Distribution) :&lt;/p&gt;

&lt;p&gt;$$a+ar+ar^2+ar^3+⋯=a/(1−r)=a(1−r)^{−1}$$
Taking the derivatives of both sides, the first derivative with respect to r must be:
$$a+2ar+3ar^2+4ar^3⋯=a(1−r)^{−2}$$
Multiplying above with r:
$$ar+2ar^2+3ar^3+4ar^4⋯=ar(1−r)^{−2}$$
Taking the derivatives of both sides, the first derivative with respect to r must be:
$$a+4ar+9ar^2+16ar^3⋯=a(1−r)^{-3}(1+r)$$&lt;/p&gt;

&lt;h2 id=&#34;bonus-python-graphs-and-functions&#34;&gt;Bonus - Python Graphs and Functions:&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Useful Function to create graph&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;chart_creator&lt;/span&gt;(x,y,title):
    &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt  &lt;span style=&#34;color:#75715e&#34;&gt;#sets up plotting under plt&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; sns           &lt;span style=&#34;color:#75715e&#34;&gt;#sets up styles and gives us more plotting options&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd             &lt;span style=&#34;color:#75715e&#34;&gt;#lets us handle data as dataframes&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;matplotlib inline
    &lt;span style=&#34;color:#75715e&#34;&gt;# Create a list of 100 Normal RVs&lt;/span&gt;
    data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(zip(x,y))
    data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;x&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;y&amp;#39;&lt;/span&gt;]
    &lt;span style=&#34;color:#75715e&#34;&gt;# We dont Probably need the Gridlines. Do we? If yes comment this line&lt;/span&gt;
    sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set(style&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ticks&amp;#34;&lt;/span&gt;)

    &lt;span style=&#34;color:#75715e&#34;&gt;# Here we create a matplotlib axes object. The extra parameters we use&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#34;ci&amp;#34; to remove confidence interval&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#34;marker&amp;#34; to have a x as marker.&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#34;scatter_kws&amp;#34; to provide style info for the points.[s for size]&lt;/span&gt;
    &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#34;line_kws&amp;#34; to provide style info for the line.[lw for line width]&lt;/span&gt;

    g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;regplot(x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;x&amp;#39;&lt;/span&gt;, y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;y&amp;#39;&lt;/span&gt;, data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;data, ci &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False,
        scatter_kws&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;color&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;darkred&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;alpha&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;s&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;90&lt;/span&gt;},
        line_kws&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;color&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;g&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;alpha&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;lw&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;},marker&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;x&amp;#34;&lt;/span&gt;)

    &lt;span style=&#34;color:#75715e&#34;&gt;# remove the top and right line in graph&lt;/span&gt;
    sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;despine()

    &lt;span style=&#34;color:#75715e&#34;&gt;# Set the size of the graph from here&lt;/span&gt;
    g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_size_inches(&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;)
    &lt;span style=&#34;color:#75715e&#34;&gt;# Set the Title of the graph from here&lt;/span&gt;
    g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axes&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_title(title, fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;34&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
    &lt;span style=&#34;color:#75715e&#34;&gt;# Set the xlabel of the graph from here&lt;/span&gt;
    g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;k&amp;#34;&lt;/span&gt;,size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;67&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
    &lt;span style=&#34;color:#75715e&#34;&gt;# Set the ylabel of the graph from here&lt;/span&gt;
    g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;pmf&amp;#34;&lt;/span&gt;,size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;67&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
    &lt;span style=&#34;color:#75715e&#34;&gt;# Set the ticklabel size and color of the graph from here&lt;/span&gt;
    g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tick_params(labelsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;14&lt;/span&gt;,labelcolor&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;black&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And here I will generate the PMFs of the discrete distributions we just discussed above using Pythons built in functions. For more details on the upper function, please see my previous post - &lt;a href=&#34;http://mlwhiz.com/blog/2015/09/13/seaborn_visualizations/&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Create basic graph visualizations with SeaBorn&lt;/a&gt;. Also take a look at the &lt;a href=&#34;https://docs.scipy.org/doc/scipy/reference/stats.html&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;documentation&lt;/a&gt; guide for the below functions&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Binomial :&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; scipy.stats &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; binom
n&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;
p&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;
k &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,n)
pmf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; binom&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pmf(k, n, p)
chart_creator(k,pmf,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Binomial PMF&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/output_12_0.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Geometric :&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; scipy.stats &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; geom
n&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;
p&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;
k &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,n)
&lt;span style=&#34;color:#75715e&#34;&gt;# -1 here is the location parameter for generating the PMF we want.&lt;/span&gt;
pmf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; geom&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pmf(k, p,&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
chart_creator(k,pmf,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Geometric PMF&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/output_13_0.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Negative Binomial :&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; scipy.stats &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; nbinom
r&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# number of successes&lt;/span&gt;
p&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# probability of Success&lt;/span&gt;
k &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;# number of failures&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# -1 here is the location parameter for generating the PMF we want.&lt;/span&gt;
pmf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; nbinom&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pmf(k, r, p)
chart_creator(k,pmf,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Nbinom PMF&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/output_14_0.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#Poisson&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; scipy.stats &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; poisson
lamb &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# Rate&lt;/span&gt;
k &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;)
pmf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; poisson&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pmf(k, lamb)
chart_creator(k,pmf,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Poisson PMF&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/output_15_0.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h2 id=&#34;references&#34;&gt;References:&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://amzn.to/2xAsYzE&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Introduction to Probability by Joe Blitzstein&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Negative_binomial_distribution&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Next thing I want to come up with is a same sort of post for continuous distributions too. Keep checking for the same. Till then Ciao.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Maths Beats Intuition probably every damn time</title>
      <link>https://mlwhiz.com/blog/2017/04/16/maths_beats_intuition/</link>
      <pubDate>Sun, 16 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2017/04/16/maths_beats_intuition/</guid>
      <description>

&lt;p&gt;Newton once said that &lt;strong&gt;&amp;ldquo;God does not play dice with the universe&amp;rdquo;&lt;/strong&gt;. But actually he does. Everything happening around us could be explained in terms of probabilities. We repeatedly watch things around us happen due to chances, yet we never learn. We always get dumbfounded by the playfulness of nature.&lt;/p&gt;

&lt;p&gt;One of such ways intuition plays with us is with the Birthday problem.&lt;/p&gt;

&lt;h2 id=&#34;problem-statement&#34;&gt;Problem Statement:&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;In a room full of N people, what is the probability that 2 or more people share the same birthday(Assumption: 365 days in year)?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;By the &lt;a href=&#34;https://en.wikipedia.org/wiki/Pigeonhole_principle&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;pigeonhole principle&lt;/a&gt;, the probability reaches 100% when the number of people reaches 366 (since there are only 365 possible birthdays).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;However, the paradox is that 99.9% probability is reached with just 70 people, and 50% probability is reached with just 23 people.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;mathematical-proof&#34;&gt;Mathematical Proof:&lt;/h2&gt;

&lt;p&gt;Sometimes a good strategy when trying to find out probability of an event is to look at the probability of the complement event.Here it is easier to find the probability of the complement event.
We just need to count the number of cases in which no person has the same birthday.(Sampling without replacement)
Since there are k ways in which birthdays can be chosen with replacement.&lt;/p&gt;

&lt;p&gt;$P(birthday Match) = 1 - \dfrac{(365).364&amp;hellip;(365−k+1)}{365^k}$&lt;/p&gt;

&lt;h2 id=&#34;simulation&#34;&gt;Simulation:&lt;/h2&gt;

&lt;p&gt;Lets try to build around this result some more by trying to simulate this result:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;matplotlib inline
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt  &lt;span style=&#34;color:#75715e&#34;&gt;#sets up plotting under plt&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; sns           &lt;span style=&#34;color:#75715e&#34;&gt;#sets up styles and gives us more plotting options&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; pd             &lt;span style=&#34;color:#75715e&#34;&gt;#lets us handle data as dataframes&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sim_bithday_problem&lt;/span&gt;(num_people_room, trials &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;):
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;This function takes as input the number of people in the room.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Runs 1000 trials by default and returns
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    (number of times same brthday found)/(no of trials)
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    same_birthdays_found &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(trials):
        &lt;span style=&#34;color:#75715e&#34;&gt;# randomly sample from the birthday space which could be any of a number from 1 to 365&lt;/span&gt;
        birthdays &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randint(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;365&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_people_room)]
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; len(birthdays) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; len(set(birthdays))&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
            same_birthdays_found&lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; same_birthdays_found&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;float(trials)

num_people &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;)
probs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [sim_bithday_problem(i) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; num_people]
data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame()
data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;num_peeps&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; num_people
data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;probs&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; probs
sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set(style&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ticks&amp;#34;&lt;/span&gt;)

g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;regplot(x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;num_peeps&amp;#34;&lt;/span&gt;, y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;probs&amp;#34;&lt;/span&gt;, data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;data, ci &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; False,
    scatter_kws&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;color&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;darkred&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;alpha&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;0.3&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;s&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;90&lt;/span&gt;},
    marker&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;x&amp;#34;&lt;/span&gt;,fit_reg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)

sns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;despine()
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_size_inches(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;axes&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;As the Number of people in room reaches 23 the probability reaches ~0.5&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;At more than 50 people the probability is reaching 1&amp;#39;&lt;/span&gt;, fontsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;g&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;# of people in room&amp;#34;&lt;/span&gt;,size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Probability&amp;#34;&lt;/span&gt;,size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;,color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;r&amp;#34;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;)
g&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tick_params(labelsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;14&lt;/span&gt;,labelcolor&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;black&amp;#34;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div style=&#34;margin-top: 9px; margin-bottom: 10px;&#34;&gt;
&lt;center&gt;&lt;img src=&#34;https://mlwhiz.com/images/bithdayproblem.png&#34;  height=&#34;400&#34; width=&#34;700&#34; &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;We can see from the &lt;a href=&#34;https://mlwhiz.com/blog/2015/09/13/seaborn_visualizations/&#34;&gt;graph&lt;/a&gt; that as the Number of people in room reaches 23 the probability reaches ~ 0.5. So we have proved this fact Mathematically as well as with simulation.&lt;/p&gt;

&lt;h2 id=&#34;intuition&#34;&gt;Intuition:&lt;/h2&gt;

&lt;p&gt;To understand it we need to think of this problem in terms of pairs. There are ${{23}\choose{2}} = 253$ pairs of people in the room when only 23 people are present. Now with that big number you should not find the probability of 0.5 too much. In the case of 70 people we are looking at ${{70}\choose{2}} = 2450$ pairs.&lt;/p&gt;

&lt;p&gt;So thats it for now. To learn more about this go to &lt;a href=&#34;https://en.wikipedia.org/wiki/Birthday_problem&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Wikipedia&lt;/a&gt; which has an awesome page on this topic.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References:&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://amzn.to/2nIUkxq&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Introduction to Probability by Joseph K. Blitzstein&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Birthday_problem&#34; rel=&#34;nofollow&#34; target=&#34;_blank&#34;&gt;Birthday Problem on Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>