<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Artificial Intelligence on MLWhiz</title>
    <link>mlwhiz.com/tags/artificial-intelligence/</link>
    <description>Recent content in Artificial Intelligence on MLWhiz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 17 Jan 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="mlwhiz.com/tags/artificial-intelligence/atom.xml" rel="self" type="application/rss" />
    
    
    <item>
      <title>NLP  Learning Series: Text Preprocessing Methods for Deep Learning</title>
      <link>mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/</link>
      <pubDate>Thu, 17 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/</guid>
      <description>Recently, I started up with an NLP competition on Kaggle called Quora Question insincerity challenge. It is an NLP Challenge on text classification and as the problem has become more clear after working through the competition as well as by going through the invaluable kernels put up by the kaggle experts, I thought of sharing the knowledge.
Since we have a large amount of material to cover, I am splitting this post into a series of posts.</description>
    </item>
    
  </channel>
</rss>