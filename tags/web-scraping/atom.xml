<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1" xmlns:content="http://purl.org/rss/1.0/modules/content" xmlns:media="http://search.yahoo.com/mrss/" >

  
  <channel>
    <title>Web Scraping on MLWhiz</title>
    <link>https://mlwhiz.com/tags/web-scraping/</link>
    <description>Recent content in Web Scraping on MLWhiz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 Oct 2014 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://mlwhiz.com/tags/web-scraping/atom.xml" rel="self" type="application/rss+xml" />
    

    

    <item>
      <title>Data Science 101 : Playing with Scraping in Python</title>
      <link>https://mlwhiz.com/blog/2014/10/02/data_science_101_python_pattern/</link>
      <pubDate>Thu, 02 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2014/10/02/data_science_101_python_pattern/</guid>
      
      

      
      <description>This is a simple illustration of using Pattern Module to scrape web data using Python. We will be scraping the data from imdb for the top TV Series along with their ratings
We will be using this link for this:
This URL gives a list of top Rated TV Series which have number of votes atleast 5000. The Thing to note in this URL is the &amp;amp;ldquo;&amp;amp;amp;start=&amp;amp;rdquo; parameter where we can specify which review should the list begin with.</description>

      <content:encoded>  
        
        <![CDATA[ This is a simple illustration of using Pattern Module to scrape web data using Python. We will be scraping the data from imdb for the top TV Series along with their ratings
We will be using this link for this:
This URL gives a list of top Rated TV Series which have number of votes atleast 5000. The Thing to note in this URL is the &amp;ldquo;&amp;amp;start=&amp;rdquo; parameter where we can specify which review should the list begin with. If we specify 1 we will get reviews starting from 1-100, if we specify 101 we get reviews from 101-200 and so on.
Lets Start by importing some Python Modules that will be needed for Scraping Data:
import requests # This is a module that is used for getting html data from a webpage in the text format from pattern import web # We use this module to parse through the dtaa that we loaded using requests Loading the data using requests and pattern So the modules are loaded at this point, next we will try to catch the url using python and put this into a dict in python. We will start with a single URL and then try to parse it using pattern module
url= &amp;#34;http://www.imdb.com/search/title?count=100&amp;amp;num_votes=5000,&amp;amp;ref_=gnr_tv_hr&amp;amp;sort=user_rating,desc&amp;amp;start=1&amp;amp;title_type=tv_series,mini_series&amp;#34; html_data = requests.get(url).text dom=web.Element(html_data) Parsing the data This is the data of Interest found out after some nspection of the html code. This is for a single TV Series Band of brothers, but if you are able to parse this you just have to move hrough a loop.
&amp;lt;html&amp;gt; &amp;lt;td class=&amp;#34;title&amp;#34;&amp;gt; &amp;lt;span class=&amp;#34;wlb_wrapper&amp;#34; data-tconst=&amp;#34;tt0185906&amp;#34; data-size=&amp;#34;small&amp;#34; data-caller-name=&amp;#34;search&amp;#34;&amp;gt;&amp;lt;/span&amp;gt; &amp;lt;a href=&amp;#34;/title/tt0185906/&amp;#34;&amp;gt;Band of Brothers&amp;lt;/a&amp;gt; &amp;lt;span class=&amp;#34;year_type&amp;#34;&amp;gt;(2001 Mini-Series)&amp;lt;/span&amp;gt;&amp;lt;br /&amp;gt; &amp;lt;div class=&amp;#34;user_rating&amp;#34;&amp;gt; &amp;lt;div class=&amp;#34;rating rating-list&amp;#34; data-auth=&amp;#34;BCYm-Mk2Ros7BTxsLNL2XJX_icfZVahNr1bE9-5Ajb2N3381yxcaNN4ZQqyrX7KgEFGqHWmwv10lv7lAnXyC8CCkh9hPqQfzwVTumCeRzjpnndW4_ft97qQkBYLUvFxYnFgR&amp;#34; id=&amp;#34;tt0185906|imdb|9.6|9.6|advsearch&amp;#34; data-ga-identifier=&amp;#34;advsearch&amp;#34; title=&amp;#34;Users rated this 9.6/10 (156,073 votes) - click stars to rate&amp;#34;&amp;gt; &amp;lt;span class=&amp;#34;rating-bg&amp;#34;&amp;gt;&amp;amp;nbsp;&amp;lt;/span&amp;gt; &amp;lt;span class=&amp;#34;rating-imdb&amp;#34; style=&amp;#34;width: 134px&amp;#34;&amp;gt;&amp;amp;nbsp;&amp;lt;/span&amp;gt; &amp;lt;span class=&amp;#34;rating-stars&amp;#34;&amp;gt; &amp;lt;a href=&amp;#34;/register/login?why=vote&amp;#34; title=&amp;#34;Register or login to rate this title&amp;#34; rel=&amp;#34;nofollow&amp;#34;&amp;gt;&amp;lt;span&amp;gt;1&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt; &amp;lt;a href=&amp;#34;/register/login?why=vote&amp;#34; title=&amp;#34;Register or login to rate this title&amp;#34; rel=&amp;#34;nofollow&amp;#34;&amp;gt;&amp;lt;span&amp;gt;2&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt; &amp;lt;a href=&amp;#34;/register/login?why=vote&amp;#34; title=&amp;#34;Register or login to rate this title&amp;#34; rel=&amp;#34;nofollow&amp;#34;&amp;gt;&amp;lt;span&amp;gt;3&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt; &amp;lt;a href=&amp;#34;/register/login?why=vote&amp;#34; title=&amp;#34;Register or login to rate this title&amp;#34; rel=&amp;#34;nofollow&amp;#34;&amp;gt;&amp;lt;span&amp;gt;4&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt; &amp;lt;a href=&amp;#34;/register/login?why=vote&amp;#34; title=&amp;#34;Register or login to rate this title&amp;#34; rel=&amp;#34;nofollow&amp;#34;&amp;gt;&amp;lt;span&amp;gt;5&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt; &amp;lt;a href=&amp;#34;/register/login?why=vote&amp;#34; title=&amp;#34;Register or login to rate this title&amp;#34; rel=&amp;#34;nofollow&amp;#34;&amp;gt;&amp;lt;span&amp;gt;6&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt; &amp;lt;a href=&amp;#34;/register/login?why=vote&amp;#34; title=&amp;#34;Register or login to rate this title&amp;#34; rel=&amp;#34;nofollow&amp;#34;&amp;gt;&amp;lt;span&amp;gt;7&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt; &amp;lt;a href=&amp;#34;/register/login?why=vote&amp;#34; title=&amp;#34;Register or login to rate this title&amp;#34; rel=&amp;#34;nofollow&amp;#34;&amp;gt;&amp;lt;span&amp;gt;8&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt; &amp;lt;a href=&amp;#34;/register/login?why=vote&amp;#34; title=&amp;#34;Register or login to rate this title&amp;#34; rel=&amp;#34;nofollow&amp;#34;&amp;gt;&amp;lt;span&amp;gt;9&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt; &amp;lt;a href=&amp;#34;/register/login?why=vote&amp;#34; title=&amp;#34;Register or login to rate this title&amp;#34; rel=&amp;#34;nofollow&amp;#34;&amp;gt;&amp;lt;span&amp;gt;10&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt; &amp;lt;/span&amp;gt; &amp;lt;span class=&amp;#34;rating-rating&amp;#34;&amp;gt;&amp;lt;span class=&amp;#34;value&amp;#34;&amp;gt;9.6&amp;lt;/span&amp;gt;&amp;lt;span class=&amp;#34;grey&amp;#34;&amp;gt;/&amp;lt;/span&amp;gt;&amp;lt;span class=&amp;#34;grey&amp;#34;&amp;gt;10&amp;lt;/span&amp;gt;&amp;lt;/span&amp;gt; &amp;lt;span class=&amp;#34;rating-cancel&amp;#34;&amp;gt;&amp;lt;a href=&amp;#34;/title/tt0185906/vote?v=X;k=BCYm-Mk2Ros7BTxsLNL2XJX_icfZVahNr1bE9-5Ajb2N3381yxcaNN4ZQqyrX7KgEFGqHWmwv10lv7lAnXyC8CCkh9hPqQfzwVTumCeRzjpnndW4_ft97qQkBYLUvFxYnFgR&amp;#34; title=&amp;#34;Delete&amp;#34; rel=&amp;#34;nofollow&amp;#34;&amp;gt;&amp;lt;span&amp;gt;X&amp;lt;/span&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt; &amp;amp;nbsp;&amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;span class=&amp;#34;outline&amp;#34;&amp;gt;The story of Easy Company of the US Army 101st Airborne division and their mission in WWII Europe from Operation Overlord through V-J Day.&amp;lt;/span&amp;gt; &amp;lt;span class=&amp;#34;credit&amp;#34;&amp;gt; With: &amp;lt;a href=&amp;#34;/name/nm0342241/&amp;#34;&amp;gt;Scott Grimes&amp;lt;/a&amp;gt;, &amp;lt;a href=&amp;#34;/name/nm0500614/&amp;#34;&amp;gt;Matthew Leitch&amp;lt;/a&amp;gt;, &amp;lt;a href=&amp;#34;/name/nm0507073/&amp;#34;&amp;gt;Damian Lewis&amp;lt;/a&amp;gt; &amp;lt;/span&amp;gt; &amp;lt;span class=&amp;#34;genre&amp;#34;&amp;gt;&amp;lt;a href=&amp;#34;/genre/action&amp;#34;&amp;gt;Action&amp;lt;/a&amp;gt; | &amp;lt;a href=&amp;#34;/genre/drama&amp;#34;&amp;gt;Drama&amp;lt;/a&amp;gt; | &amp;lt;a href=&amp;#34;/genre/history&amp;#34;&amp;gt;History&amp;lt;/a&amp;gt; | &amp;lt;a href=&amp;#34;/genre/war&amp;#34;&amp;gt;War&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt; &amp;lt;span class=&amp;#34;certificate&amp;#34;&amp;gt;&amp;lt;span title=&amp;#34;TV_MA&amp;#34; class=&amp;#34;us_tv_ma titlePageSprite&amp;#34;&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;/span&amp;gt; &amp;lt;span class=&amp;#34;runtime&amp;#34;&amp;gt;705 mins.&amp;lt;/span&amp;gt; &amp;lt;/td&amp;gt; Now we have loaded the data we need to parse it using the functions from pattern module. The main function in pattern module is the by_tag() function which lets you get all the elements with that particular tagname. For us the main interest is this &amp;ldquo;td&amp;rdquo; tag with class as &amp;ldquo;title&amp;rdquo;. This &amp;ldquo;td&amp;rdquo; tag contains:
 Title in the &amp;ldquo;a&amp;rdquo; tag Rating in the &amp;ldquo;span&amp;rdquo; tag with class &amp;ldquo;value&amp;rdquo; Genres in the &amp;ldquo;span&amp;rdquo; tag with class &amp;ldquo;genre&amp;rdquo; and then looping through the &amp;ldquo;a&amp;rdquo; tags Runtime in &amp;ldquo;span&amp;rdquo; tag with class &amp;ldquo;runtime&amp;rdquo; Artists in &amp;ldquo;span&amp;rdquo; tag with class &amp;ldquo;credit&amp;rdquo; loop through &amp;ldquo;a&amp;rdquo; tags  Now lets write some code to parse this data.
for tv_series in dom.by_tag(&amp;#39;td.title&amp;#39;): title = tv_series.by_tag(&amp;#39;a&amp;#39;)[0].content genres = tv_series.by_tag(&amp;#39;span.genre&amp;#39;)[0].by_tag(&amp;#39;a&amp;#39;) genres = [g.content for g in genres] try: runtime = tv_series.by_tag(&amp;#39;span.runtime&amp;#39;)[0].content except: runtime = &amp;#34;NA&amp;#34; rating = tv_series.by_tag(&amp;#39;span.value&amp;#39;)[0].content artists = tv_series.by_tag(&amp;#39;span.credit&amp;#39;)[0].by_tag(&amp;#39;a&amp;#39;) artists = [a.content for a in artists] print title, genres, runtime, rating, artists So finally we are OK with parsing. We have understood the structure of the webpage, the tags and classes we will need to use and how to use pattern module to find data for a single page. Now lets use the power of for loops to get all the data.
Getting Whole Data Lets Go through it the pythonic way. We will create functions and try to execute small chunks of code rather than doing it all at once. Lets first create a funcion that takes a start_val(for the start parameter) and returns a dom element.
def get_dom(start_val): url= &amp;#34;http://www.imdb.com/search/title?count=100&amp;amp;num_votes=5000,&amp;amp;ref_=gnr_tv_hr&amp;amp;sort=user_rating,desc&amp;amp;start=&amp;#34;&#43;str(start_val)&#43;&amp;#34;&amp;amp;title_type=tv_series,mini_series&amp;#34; html_data = requests.get(url).text dom=web.Element(html_data) return dom Now lets create a function parse_dom that takes as input dom an throws out a list containing all the data. The list is like this :
def parse_dom(dom): result=[] for tv_series in dom.by_tag(&amp;#39;td.title&amp;#39;): title = tv_series.by_tag(&amp;#39;a&amp;#39;)[0].content genres = tv_series.by_tag(&amp;#39;span.genre&amp;#39;)[0].by_tag(&amp;#39;a&amp;#39;) genres = &amp;#34;|&amp;#34;.join([g.content for g in genres]) try: runtime = tv_series.by_tag(&amp;#39;span.runtime&amp;#39;)[0].content except: runtime = &amp;#34;NA&amp;#34; rating = tv_series.by_tag(&amp;#39;span.value&amp;#39;)[0].content artists = tv_series.by_tag(&amp;#39;span.credit&amp;#39;)[0].by_tag(&amp;#39;a&amp;#39;) artists = &amp;#34;|&amp;#34;.join([a.content for a in artists]) temp_res=[] temp_res.extend([title, genres, runtime, rating, artists]) result.append(temp_res) return result Now Lets Use these functions and a simple while loop to scrap all the pages
i=1 all_data = [] while True: dom = get_dom(i) datalist=parse_dom(dom) if len(datalist)==0: break all_data = all_data &#43; parse_dom(dom) i &#43;= 100 print &amp;#34;Total Elements:&amp;#34; &#43; str(len(all_data)) print &amp;#34;First Five Elements :&amp;#34; &#43; str(all_data[1:5]) Voila!!! The number of elements we had to scrap were 898 and We got all of them. And to tell you, IMDB is one of the worst written HTML&amp;rsquo;s. So that&amp;rsquo;s Great.
In the next part of the tutorial we will run exploratory data analysis on this data using pandas and maplotlib.
Till then keep learning.
]]>
        
      </content:encoded>
      
      
      
    </item>
    
  </channel>
</rss>