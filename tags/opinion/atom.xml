<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1" xmlns:content="http://purl.org/rss/1.0/modules/content" xmlns:media="http://search.yahoo.com/mrss/" >

  
  <channel>
    <title>Opinion on MLWhiz</title>
    <link>https://mlwhiz.com/tags/opinion/</link>
    <description>Recent content in Opinion on MLWhiz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 25 May 2020 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://mlwhiz.com/tags/opinion/atom.xml" rel="self" type="application/rss+xml" />
    

    

    <item>
      <title>5 Essential Business-Oriented Critical Thinking Skills For Data Scientists</title>
      <link>https://mlwhiz.com/blog/2020/08/12/ctskills/</link>
      <pubDate>Wed, 12 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2020/08/12/ctskills/</guid>
      
      
      <media:content type="image/png" medium="image" width="700" height="400"
      url="https://mlwhiz.com/images/ctskills/main.png"></media:content>
      

      
      <description>As Alexander Pope said, to err is human. By that metric, who is more human than us data scientists? We devise wrong hypotheses constantly and then spend time working on them just to find out how wrong we were.
When looking at mistakes from an experiment, a data scientist needs to be critical, always on the lookout for something that others may have missed. But sometimes, in our day-to-day routine, we can easily get lost in little details.</description>

      <content:encoded>  
        
        <![CDATA[  As Alexander Pope said, to err is human. By that metric, who is more human than us data scientists? We devise wrong hypotheses constantly and then spend time working on them just to find out how wrong we were.
When looking at mistakes from an experiment, a data scientist needs to be critical, always on the lookout for something that others may have missed. But sometimes, in our day-to-day routine, we can easily get lost in little details. When this happens, we often fail to look at the overall picture, ultimately failing to deliver what the business wants.
Our business partners have hired us to generate value. We won’t be able to generate that value unless we develop business-oriented critical thinking, including having a more holistic perspective of the business at hand. So here is some practical advice for your day-to-day work as a data scientist. These recommendations will help you to be more diligent and more impactful at the same time.
1. Beware of the Clean Data Syndrome Tell me how many times this has happened to you: You get a data set and start working on it straight away. You create neat visualizations and start building models. Maybe you even present automatically generated descriptive analytics to your business counterparts!
But do you ever ask, “Does this data actually make sense?” Incorrectly assuming that the data is clean could lead you toward very wrong hypotheses. Not only that, but you’re also missing an important analytical opportunity with this assumption.
You can actually discern a lot of important patterns by looking at discrepancies in the data. For example, if you notice that a particular column has more than 50 percent of values missing, you might think about dropping the column. But what if the missing column is because the data collection instrument has some error? By calling attention to this, you could have helped the business to improve its processes.
Or what if you’re given a distribution of customers that shows a ratio of 90 percent men versus 10 percent women, but the business is a cosmetics company that predominantly markets its products to women? You could assume you have clean data and show the results as is, or you can use common sense and ask the business partner if the labels are switched.
Such errors are widespread. Catching them not only helps the future data collection processes but also prevents the company from making wrong decisions by preventing various other teams from using bad data.
2. Be Aware of the business Source: Fab.com Beginnings
You probably know fab.com. If you don’t, it’s a website that sells selected health and fitness items. But the site’s origins weren’t in e-commerce. Fab.com started as Fabulis.com, a social networking site for gay men. One of the site’s most popular features was called the “Gay Deal of the Day.”
One day, the deal was for hamburgers. Half of the deal’s buyers were women, despite the fact that they weren’t the site’s target users. This fact caused the data team to realize that they had an untapped market for selling goods to women. So Fabulis.com changed its business model to serve this newfound market.
Be on the lookout for something out of the ordinary. Be ready to ask questions. If you see something in the data, you may have hit gold. Data can help a business to optimize revenue, but sometimes it has the power to change the direction of the company as well.
Source: Flickr Origins as “Game Neverending”
Another famous example of this is Flickr, which started out as a multiplayer game. Only when the founders noticed that people were using it as a photo upload service did the company pivot to the photo-sharing app we know it as today.
Try to see patterns that others would miss. Do you see a discrepancy in some buying patterns or maybe something you can’t seem to explain? That might be an opportunity in disguise when you look through a wider lens.
3. Focus on the right metrics What do we want to optimize for? Most businesses fail to answer this simple question.
Every business problem is a little different and should, therefore, be optimized differently. For example, a website owner might ask you to optimize for daily active users. Daily active users is a metric defined as the number of people who open a product on a given day. But is that the right metric? Probably not! In reality, it’s just a vanity metric, meaning one that makes you look good but doesn’t serve any purpose when it comes to actionability. This metric will always increase if you are spending marketing dollars across various channels to bring more and more customers to your site.
Instead, I would recommend optimizing the percentage of users that are active to get a better idea of how my product is performing. A big marketing campaign might bring a lot of users to my site, but if only a few of them convert to active, the marketing campaign was a failure and my site stickiness factor is very low. You can measure the stickiness by the second metric and not the first one. If the percentage of active users is increasing, that must mean that they like my website.
Another example of looking at the wrong metric happens when we create classification models. We often try to increase accuracy for such models. But do we really want accuracy as a metric of our model performance?
Imagine that we’re predicting the number of asteroids that will hit the Earth. If we want to optimize for accuracy, we can just say zero all the time, and we will be 99.99 percent accurate. That 0.01 percent error could be hugely impactful, though. What if that 0.01 percent is a planet-killing-sized asteroid? A model can be reasonably accurate but not at all valuable. A better metric would be the F score, which would be zero in this case, because the recall of such a model is zero as it never predicts an asteroid hitting the Earth.
When it comes to data science, designing a project and the metrics we want to use for evaluation is much more important than modeling itself. The metrics themselves need to specify the business goal and aiming for a wrong goal effectively destroys the whole purpose of modeling. For example, F1 or PRAUC is a better metric in terms of asteroid prediction as they take into consideration both the precision and recall of the model. If we optimize for accuracy, our whole modeling effort could just be in vain.
4. Statistics Lie sometimes Be skeptical of any statistics that get quoted to you. Statistics have been used to lie in advertisements, in workplaces, and in a lot of other arenas in the past. People will do anything to get sales or promotions.
For example, do you remember Colgate’s claim that 80 percent of dentists recommended their brand? This statistic seems pretty good at first. If so many dentists use Colgate, I should too, right? It turns out that during the survey, the dentists could choose multiple brands rather than just one. So other brands could be just as popular as Colgate.
Marketing departments are just myth creation machines. We often see such examples in our daily lives. Take, for example, this 1992 ad from Chevrolet. Just looking at just the graph and not at the axis labels, it looks like Nissan/Datsun must be dreadful truck manufacturers. In fact, the graph indicates that more than 95 percent of the Nissan and Datsun trucks sold in the previous 10 years were still running. And the small difference might just be due to sample sizes and the types of trucks sold by each of the companies. As a general rule, n*e*ver trust a chart that doesn’t label the Y-axis.
As a part of the ongoing pandemic, we’re seeing even more such examples with a lot of studies promoting cures for COVID-19. This past June in India, a man claimed to have made medicine for coronavirus that cured 100 percent of patients in seven days. This news predictably caused a big stir, but only after he was asked about the sample size did we understand what was actually happening here. With a sample size of 100, the claim was utterly ridiculous on its face. Worse, the way the sample was selected was hugely flawed. His organization selected asymptomatic and mildly symptomatic users with a mean age between 35 and 45 with no pre-existing conditions, I was dumbfounded — this was not even a random sample. So not only was the study useless, it was actually unethical.
When you see charts and statistics, remember to evaluate them carefully. Make sure the statistics were sampled correctly and are being used in an ethical, honest way.
5. Don’t Give in to Fallacies During the summer of 1913 in a casino in Monaco, gamblers watched in amazement as the roulette wheel landed on black an astonishing 26 times in a row. And since the probability of red versus black is precisely half, they were confident that red was “due.” It was a field day for the casino and a perfect example of gambler’s fallacy, a.k.a. the Monte Carlo fallacy.
This happens in everyday life outside of casinos too. People tend to avoid long strings of the same answer. Sometimes they do so while sacrificing accuracy of judgment for the sake of getting a pattern of decisions that look fairer or more probable. For example, an admissions office may reject the next application they see if they have approved three applications in a row, even if the application should have been accepted on merit.
The world works on probabilities. We are seven billion people, each doing an event every second of our lives. Because of that sheer volume, rare events are bound to happen. But we shouldn’t put our money on them.
Think also of the spurious correlations we end up seeing regularly. This particular graph shows that organic food sales cause autism. Or is it the opposite? Just because two variables move together in tandem doesn’t necessarily mean that one causes the other. Correlation does not imply causation and as data scientists, it is our job to be on a lookout for such fallacies, biases, and spurious correlations. We can’t allow oversimplified conclusions to cloud our work.
Data scientists have a big role to play in any organization. A good data scientist must be both technical as well as business-driven to perform the job’s requirements well. Thus, we need to make a conscious effort to understand the business’ needs while also polishing our technical skills.
Continue Learning If you want to learn more about how to apply Data Science in a business context, I would like to call out the AI for Everyone course by Andrew Ng which focusses on spotting opportunities to apply AI to problems in your own organization, working with an AI team and build an AI strategy in your company.
Thanks for the read. I am going to be writing more beginner-friendly posts in the future too. Follow me up at Medium or Subscribe to my blog.
This post was first published here
]]>
        
      </content:encoded>
      
      
      
    </item>
    

    <item>
      <title>Don’t Democratize Data Science</title>
      <link>https://mlwhiz.com/blog/2020/05/25/democratize/</link>
      <pubDate>Mon, 25 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2020/05/25/democratize/</guid>
      
      
      <media:content type="image/png" medium="image" width="700" height="400"
      url="https://mlwhiz.com/images/democratize/main.png"></media:content>
      

      
      <description>Every few years, some academic and professional field gets a lot of cachet in the popular imagination. Right now, that field is data science. As a result, a lot of people are looking to get into it. Add to that the news outlets calling data science sexy and various academic institutes promising to make a data scientist out of you in just a few months, and you’ve got the perfect recipe for disaster.</description>

      <content:encoded>  
        
        <![CDATA[  Every few years, some academic and professional field gets a lot of cachet in the popular imagination. Right now, that field is data science. As a result, a lot of people are looking to get into it. Add to that the news outlets calling data science sexy and various academic institutes promising to make a data scientist out of you in just a few months, and you’ve got the perfect recipe for disaster.
Of course, as a data scientist myself, I don’t think the problem lies in people choosing data science as a profession. If you’re interested in working with data, understanding business problems, grappling with math, and you love coding, you’re probably going to thrive in data science. You’ll get a lot of opportunities to use math and coding to develop innovative solutions to problems and will likely find the work rewarding. The main issue here is that the motivations people have for entering the field are often flawed.
For some, the appeal is money, while others like the way the title sounds. Even worse, some people are probably just responding to the herd mentality that our society has instilled. For instance, not long ago, every graduate aspired to do an MBA. And I myself am guilty of the same. It took me a GMAT test and a couple of rejections to realize that I didn’t really want the degree. Ultimately, those rejections were the best thing that happened to me because, after that, I finally looked at data science as an option. Once I got into it, I found that I love the math involved and all the different ways in which I get to use data science to help solve problems for businesses.
 Today, I see that data science has somehow acquired the same stature that the MBA once had.
 A lot of people want to do it, but they don’t know what the job really entails. And this has resulted in a lot of people calling themselves data scientists and a lot of bad decision making. In fact, a lot of people considering entering the profession probably don’t even know what data science is.
Today, the whole field has been democratized by the availability of so much material. A plethora of MOOCs from the best instructors cover concepts from basic to advanced, and you can easily find packages that let you create models with just a few lines of code.
I genuinely love the fact that there are so many resources to learn and practice data science. But this democratization has created a few problems of its own. In this piece, I want to briefly look at some of these problems and the adverse effect they could have on the field.
Automated Data Science? A lot of AutoML packages aim at democratizing data science. They provide a repository of models, automate the hyperparameter tuning process, and sometimes offer a way to put these models into production. The availability of such packages has led a lot of people to think that data science could be fully automated, eliminating the need for data scientists altogether. Or, if the processes can’t be automated, these tools will allow anyone to become a data scientist.
I sincerely disagree. I have found such codebases useful at times, but they look at data science purely from a coding perspective.
 In my view, data science involves a lot of work apart from modeling.
 The work of data science includes understanding and identifying the problem at hand and setting up the right evaluation metrics. You also have to analyze the profitability of the project: most businesses don’t want to spend money on projects that don’t positively affect the bottom line. You can work with existing data, but sometimes you might need to come up with ways to set up new data pipelines to gather data to solve the problem. This requires talking to the stakeholders and gaining a holistic understanding of the problem. A data scientist also needs to be able to carry out data munging and feature creation to churn more performance out of existing models. In the end, model testing and setting the feedback loop require endless hours of discussions with the business and are pretty specific to each project. Someone who just runs code might not be able to add value to such discussions as they don’t really understand what goes behind the models they have used in AutoML.
Then there comes the issue of domain knowledge. Processes that are acceptable in a retail domain are not applicable in the finance domain where a small change could result in your customers losing a lot of money. Some things just can’t be automated since they require domain knowledge and an understanding of the business you’re working with.
 More importantly, an automated pipeline can’t be held responsible if a project doesn’t work or if your model fails in production.
 A good data scientist will try to figure out ways to sort out production issues as they arise as well as creating a machine learning pipeline specific to the project to mitigate such issues.
The Code-Runner Mentality I have become skeptical of what I call the New Data Scientist. Almost every day, I seem to meet a person calling themselves a data scientist when they are just glorified code runners, which refers to a person who just runs the code without understanding what goes on behind it. With so many academies and institutes providing boot-camp-based courses, code runners are in abundance right now.
I get a lot of requests where someone asks me whether they should take a certified course from XYZ institute or a boot camp from ABC academy. My answer is neither. I find that these institutes that promise to make data scientists in droves are mainly just in the money-making business. Ultimately, going through a few notebooks and running somebody else’s code doesn’t truly make a person a data scientist.
Now, don’t get me wrong. If someone learns best through a top-down approach where they run some code first and then read in-depth about the principles behind it, that’s perfectly fine. Data science is about more than just running code, though. Until you really understand the math and theory behind all the code, you haven’t mastered data science.
The Dunning-Kruger Effect The Dunning-Kruger effect is a type of cognitive bias in which a person with a little bit of knowledge about some subject overestimates their abilities because they’re unaware of how little they actually know. I see this in action constantly in data science. In fact, it might be more pronounced in this field than any other!
I tend to think of this as a novice effect. It’s a problem that plagues people in the early stages of learning a new skill. In my view, there are three stages to a data scientist’s journey.
 The Dunning-Kruger Stage —You created your first model and think you know everything there is to know about data science.
 The “I Don’t Know Anything” Stage —You go to a conference or talk to your peers and suddenly realize that there is so much more to learn.
 The “Lifelong Learning” Stage — You give in to the fact that there are always going to be some things you won’t know that just got introduced and so there is lifelong learning involved in pursuing data science.
  Now, the Dunning-Kruger effect is something that most of the beginners will face. The joy of running your first program and executing it perfectly really takes you to the top of the world. And it’s totally fine to be at this stage. The problem comes when newcomers are incapable of leaving this stage and moving on to the next ones in a timely fashion. I have seen a few people who get stuck at this stage because they got into data science with the wrong expectations, thinking that it’s sexy and exciting, without understanding the field’s depth. These types of people tend to think they can just use existing models to solve problems and that they get by without understanding the math.
For instance, I recently interviewed a guy who had two years of experience in the field. He seemed confident. He had used data science in his job and had worked on a couple of Kaggle projects. The first few minutes of the interview went really well. He explained the higher-level concepts well enough that I decided to dig a little deeper into his mathematical understanding of the techniques he had applied in his projects. And that was where things changed. I asked him to tell me about the log loss function. When he said, “But we have packages for doing all this,” I realized that this guy had never left the first stage.
Conclusion The availability of ready-made packages and courses is democratizing the field of data science. But there is just so much more to the job that comes from hands-on experience, communicating with people, and being able to listen to different perspectives.
So, while some people may think of data science as a pure coding job, it’s not just about becoming a coding superstar.
It’s about finding the right problems that are useful for the business and coming up with best ways to solve them. To do that, you need domain knowledge, humility, a little bit of math, and, most importantly, a lifelong desire to learn.
If you want to learn about Data Science, I would like to call out this excellent course by Andrew Ng. This was the one that got me started.
Thanks for the read. I am going to be writing more beginner-friendly posts in the future too. Follow me up at Medium or Subscribe to my blog.
Also, a small disclaimer — There might be some affiliate links in this post to relevant resources, as sharing knowledge is never a bad idea.
This story was first published here. s
]]>
        
      </content:encoded>
      
      
      
    </item>
    

    <item>
      <title>Five Cognitive Biases In Data Science (And how to avoid them)</title>
      <link>https://mlwhiz.com/blog/2020/05/25/cogbias/</link>
      <pubDate>Mon, 25 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2020/05/25/cogbias/</guid>
      
      
      <media:content type="image/png" medium="image" width="700" height="400"
      url="https://mlwhiz.com/images/cogbias/main.png"></media:content>
      

      
      <description>Recently, I was reading Rolf Dobell’s The Art of Thinking Clearly, which made me think about cognitive biases in a way I never had before. I realized how deeply seated some cognitive biases are. In fact, we often don’t even consciously realize when our thinking is being affected by one. For data scientists, these biases can really change the way we work with data and make our day-to-day decisions, and generally not for the better.</description>

      <content:encoded>  
        
        <![CDATA[  Recently, I was reading Rolf Dobell’s The Art of Thinking Clearly, which made me think about cognitive biases in a way I never had before. I realized how deeply seated some cognitive biases are. In fact, we often don’t even consciously realize when our thinking is being affected by one. For data scientists, these biases can really change the way we work with data and make our day-to-day decisions, and generally not for the better.
 Data science is, despite the seeming objectivity of all the facts we work with, surprisingly subjective in its processes.
 As data scientists, our job is to make sense of the facts. In carrying out this analysis, we have to make subjective decisions though. So even though we work with hard facts and data, there’s a strong interpretive component to data science.
As a result, we data scientists need to be extremely careful, because all humans are very much susceptible to cognitive biases. We’re no exception. In fact, I have seen many instances where data scientists ended up making decisions based on pre-existing beliefs, limited data or just irrational preferences.
In this piece, I want to point out five of the most common types of cognitive biases. I will also offer some suggestions on how data scientists can work to avoid them and make better, more reasoned decisions.
1. Survivorship Bias During World War II, researchers from the non-profit research group the Center for Naval Analyses were tasked with a problem. They needed to reinforce the military’s fighter planes at their weakest spots. To accomplish this, they turned to data. They examined every plane that came back from a combat mission and made note of where bullets had hit the aircraft. Based on that information, they recommended that the planes be reinforced at those precise spots.
Do you see any problems with this approach?
The problem, of course, was that they only looked at the planes that returned and not at the planes that didn’t. Of course, data from the planes that had been shot down would almost certainly have been much more useful in determining where fatal damage to a plane was likely to have occurred, as those were the ones that suffered catastrophic damage.
The research team suffered from survivorship bias: they just looked at the data that was available to them without analyzing the larger situation. This is a form of selection bias in which we implicitly filter data based on some arbitrary criteria and then try to make sense out of it without realizing or acknowledging that we’re working with incomplete data.
Let’s think about how this might apply to our work in data science. Say you begin working on a data set. You have created your features and reached a decent accuracy on your modelling task. But maybe you should ask yourself if that is the best result you can achieve. Have you tried looking for more data? Maybe adding weather forecast data to the regular sales variables that you use in your ARIMA models would help you to forecast your sales better. Or perhaps some features around holidays can tell your model why your buyers are behaving in a particular fashion around Thanksgiving or Christmas.
Recommendation to Overcome: One way to mitigate this bias is by thinking in a rigorous, scientific way about the problem at hand and then brainstorming about any type of data that could help to solve it (rather than just starting with the data). These approaches may seem similar, but the second method restricts your vision because you don’t know what’s missing from your work. By using the first approach, you will know what data you were not able to get, and you will end up factoring that into your conclusions.
2. Sunk Cost Fallacy We all have seen the sunk cost fallacy in action at some point, whether it be sitting through that bad movie because we have already paid for it or finishing that awful book because we were already halfway through. Everyone has been in a situation where they ended up wasting more time because they were trying to salvage the time they had already invested.
A sunk cost, also known as a retrospective cost, is one that has already been incurred and cannot be recovered by any additional action. The sunk cost fallacy refers to the tendency of human beings to make decisions based on how much of an investment they have already made, which leads to even more investment but no returns whatsoever.
 Sometimes, hard as it is, the best thing to do is to let go.
 This happens often with data science projects. A project might run for more than two years without results but an investigator continues running it because so much time, money and effort have already been invested. Or a data scientist might defend her project wholeheartedly because she has invested so much in it, failing to realize that putting in more work won’t help her or the company in the long run and that it is best if the project is scrapped.
Recommendation to Overcome: A way to save yourself from this cognitive bias is by focusing on future benefits and costs rather than the already lost past costs. You have to develop the habit, hard as it is, of ignoring the previous cost information. Of course, it is never easy for us data scientists to just disregard data. For myself, I have found that a methodical way works best in this case. I take a pen and paper to get away from all the distractions and try to come up with all the additional costs required to do a project along with the benefits I might get in the future. If the cost part of the task seems overly significant, then it is time to move on.
3. False Causality As data scientists, we are always in search of patterns. The tendency means that sometimes we even find patterns where none really even exist. Our brains are so trained in this way that we will even make sense of chaos to the extent that we can.
Because our training wires us to seek out patterns, it’s crucial to remember the simple maxim that correlation does not imply causation. Those five words are like the hammer of the data science toolbox without which you can’t accomplish anything. Just because two variables move in tandem doesn’t necessarily mean that one causes the other.
This principle has been hilariously demonstrated by numerous examples. For instance,
 by looking at fire department data, you notice that, as more firemen are dispatched to a fire, the more damage is ultimately done to a property. Thus, you might infer that more firemen are causing more damage.
 In another famous example, an academic who was investigating the cause of crime in New York City in the 1980s found a strong correlation between the number of serious crimes committed and the amount of ice cream sold by street vendors. But should we conclude that eating ice cream drives people to crime? Since this makes little sense, we should obviously suspect that there was an unobserved variable causing both. During the summer, crime rates are the highest, and this is also when most ice cream is sold. Ice cream sales don’t cause crime, nor does crime increase ice cream sales.
  In both of these instances, looking at the data too superficially leads to incorrect assumptions.
Recommendation to Overcome: As data scientists, we need to be mindful of this bias when we present findings. Often, variables that might seem causal might not be on closer inspection. We should also take special care to avoid this type of mistake when creating variables of our models. At each step of the process, it’s important to ask ourselves if our independent variable is possibly just correlated to the dependent variable.
4. Availability Bias Have you ever said something like, “I know that [insert a generic statement here] because [insert one single example].” For example, someone might say, “You can’t get fat from drinking beer, because Bob drinks a lot of it, and he’s thin.” If you have, then you’ve suffered from availability bias. You are trying to make sense of the world with limited data.
People naturally tend to base decisions on information that is already available to us or things we hear about often without looking at alternatives that might be useful.As a result, we limit ourselves to a very specific subset of information.
This happens often in the data science world. Data scientists tend to get and work on data that’s easier to obtain rather than looking for data that is harder to gather but might be more useful. We make do with models that we understand and that are available to us in a neat package rather than something more suitable for the problem at hand but much more difficult to come by.
Recommendation to Overcome: A way to overcome availability bias in data science is to broaden our horizons. Commit to lifelong learning. Read. A lot. About everything. Then read some more. Meet new people. Discuss your work with other data scientists at work or in online forums. Be more open to suggestions about changes that you may have to take in your approach. By opening yourself up to new information and ideas, you can make sure that you’re less likely to work with incomplete information.
5. Confirmation Bias An old joke says that if you torture the data long enough, it will confess. With enough work, you can distort data to make it say what you want it to say.
We all hold some beliefs, and that’s fine. It’s all part of being human. What’s not OK, though, is when we let those beliefs inadvertently come into the way we form our hypotheses.
We can see this tendency in our everyday lives. We often interpret new information in such a way that it becomes compatible with our own beliefs. We read the news on the site that conforms most closely to our beliefs. We talk to people who are like us and hold similar views. We don’t want to get disconcerting evidence because that might lead us to change our worldview, which we might be afraid to do.
For example, I have seen confirmation bias in action in data science during the cost-benefit analysis stage of a project. I’ve seen people clinging to the data that confirms their hypothesis while ignoring all the contradictory evidence. Obviously, doing this could have a negative impact on the benefits section of the project.
Recommendation to Overcome: One way to fight this bias is to critically examine all your beliefs and try to find disconcerting evidence about each of your theories. By that, I mean actively seeking out evidence by going to places where you don’t normally go, talking to people you don’t normally talk to, and generally keeping an open mind.
Conclusion  In our age of information overload, we are surrounded by so much data that our brains try desperately to make sense of the noise.
 Sometimes it is useful to be able to make some sense out of the world based on limited information. In fact, we make most of our decisions without thinking much, going with our gut feelings. The potential harm of most of our day-to-day actions is pretty small. Allowing our biases to influence our work, though, can leave us in an unfortunate situation. We may end up losing money or credibility if we make a vital decision that turns out to be wrong.
Knowing how our brain works will help us avoid these mistakes.
If you want to learn more about Data Science, I would like to call out this excellent course by Andrew Ng. This was the one that got me started. Do check it out.
Thanks for the read. I am going to be writing more beginner-friendly posts in the future too. Follow me up at Medium or Subscribe to my blog.
This story was first published here.
]]>
        
      </content:encoded>
      
      
      
    </item>
    

    <item>
      <title>5 tips for getting your first Data Science job in 2020</title>
      <link>https://mlwhiz.com/blog/2020/02/24/job/</link>
      <pubDate>Mon, 24 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2020/02/24/job/</guid>
      
      
      <media:content type="image/png" medium="image" width="700" height="400"
      url="https://mlwhiz.com/images/job/main.png"></media:content>
      

      
      <description>Many of my followers ask me — How difficult is it to get a job in the Data Science field? Or what should they study? Or what path they should take?
Now the answer is not one everyone would like — Getting into Data Science is pretty difficult, and you have to toil hard.
I mean you have to devote time to learn data science, understand algorithms, upgrade your skills as the market progresses, keep track of old conventional skills, and, of course, search for a job in the meantime and prepare for interviews.</description>

      <content:encoded>  
        
        <![CDATA[  Many of my followers ask me — How difficult is it to get a job in the Data Science field? Or what should they study? Or what path they should take?
Now the answer is not one everyone would like — Getting into Data Science is pretty difficult, and you have to toil hard.
I mean you have to devote time to learn data science, understand algorithms, upgrade your skills as the market progresses, keep track of old conventional skills, and, of course, search for a job in the meantime and prepare for interviews.
You also have to understand business problems and develop the acumen to frame business problems as data science problems. Remember, there are no fixed algorithms.
It gets really exerting for some and almost impossible for others.
To tell you about myself, I get bored quickly if I am not learning new things. I like Data Science as it gives me that opportunity.
So first of all, I would like to ask if you are like that?
If you are, and you are interested in solving new problems almost every day, then you would love data science as a field to make your career in.
And here are some tips for you brave ones.
1. Start Small  It is better to take many small steps in the right direction than to make a great leap forward only to stumble backward — Old Chinese Proverb
 Now, as far as beginning a career in Data Science goes, the above fits pretty nicely. More so if you are coming from a different stream(read not Computer Science, Statistics) or if you want to make a lateral switch.
I would advise against targeting big companies like Amazon, Google, etc. This is not to discourage you; it is more on the lines of practical thinking. I have observed their interview process, and I can assure you that it’s pretty rare, if not impossible, to get these jobs without some experience.
But, let me also tell you that there is no shortage of opportunities. You could easily get into a startup if you know your stuff. That is how I started myself.
2. Keep Learning I made it my goal to move into the data science space somewhere around in 2013. From then on, it has taken me a lot of failures and a lot of effort to shift jobs. Here is my story if you are interested.
In college, I spent a lot of my time gaming. From 2013 onwards, I spent whatever time I could find to study new technologies and learning about data science.
 Nothing will work unless You do — Maya Angelou
 Here is the way that I took to learn about data science, and any aspiring person could choose to become a self-trained data scientist.
How did I learn Data Science?
I hope that you don’t lose hope after seeing the long list. I already told you it wouldn’t be easy.
You have to start with one or two courses. The rest will follow with time. Just remember that time is a luxury you can afford.
3. Create your Portfolio Having a grasp of the theory is excellent, but you really don’t add value as a data scientist if you can’t write code.
So work on creating stuff. Try out new toy projects. Go to kaggle for inspiration. Participate in the discussion forums. But don’t stop there.
 Think creatively. Build your GitHub profile. Try to solve different problems.
 For example, in the starting phase, I created a simple graph visualization to discover interesting posts in DataScience Subreddit using d3.js and deployed it using Flask, and Heroku. I also created a Blackjack Simulator apart from solving the usual data science problems. I also implemented a code-breaking solution using MCMC.
I also took part in various kaggle competitions, and though I don’t have much of a rank to show for it, but I ended up learning a lot.
4. Blogging? This is something that comes from a personal bias of mine.
 When you blog, you end up creating high quality content for others to learn, document your learnings, understand concepts better by explaining them and maybe gain some extra recognition. What else would you want?
 Honestly, I love to write, and this is not a pure requirement to become a data scientist, but it helps a lot. I noticed that I understood data science concepts much better when I explained them. And Blogging is a perfect tool for this.
Also, Data Science is pretty vast, and I tend to forget whatever I learned some time ago. Blogging solves this problem too. It was in 2013 that I started my blog and tried to update it with whatever I learned. And thus, I ended up documenting everything. I still consult my blogs whenever I feel stuck on some problem.
I feel that blogging also helped me with my communication skills as it forced me to explain difficult concepts in simpler words.
Anyway, if you don’t like to blog, you can achieve something similar by taking notes.
As I said, Blogging is a personal preference. And if you are interested and want to know how I started writing on medium, here is my story.
My Data Science Blogging Journey on Medium till now
5. Don’t be too choosy You have an offer from an analytics company, and you are thinking if, by joining it, you are saying goodbye to data science.
It is a reasonably good situation to be in. While it is relatively hard to get a data science job, it might be easier to get a job as a business analyst or data analyst in an analytics company.
I would suggest taking any job relating to analysis or reporting or something related to data. I started the same way as I began to work with analytics and switched tracks when the data science opportunity presented itself.
 Being in the vicinity of data itself will open you to such opportunities inevitably. Treat your first job just as a stepping stone.
 Once you get such a job, you will have two options:
 Make an internal shift in the same company in the Data Science teams by creating good relationships and by showing interest, or
 Continue your learning in your spare time, and keep giving interviews.
  With time you would succeed. Good luck to you.
Thanks for the read. I am going to be writing more beginner-friendly posts in the future too. Follow me up at Medium or Subscribe to my blog.
]]>
        
      </content:encoded>
      
      
      
    </item>
    

    <item>
      <title>3 Mistakes you should not make in a Data Science Interview</title>
      <link>https://mlwhiz.com/blog/2019/12/24/mistakes/</link>
      <pubDate>Tue, 24 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2019/12/24/mistakes/</guid>
      
      
      <media:content type="image/png" medium="image" width="700" height="400"
      url="https://mlwhiz.com/images/mistakes/main.png"></media:content>
      

      
      <description>People ask me a lot about how to land a data science job? Or how to switch careers or how to study for a job interview?
Mostly my answer is to do some MOOCs, create some projects, participate in Kaggle, try to get in a startup and don’t give up.
But yet there are some things everyone should understand about data science jobs.
Data science jobs involve a lot of to and fro communication and involve a lot of people handling skills.</description>

      <content:encoded>  
        
        <![CDATA[  People ask me a lot about how to land a data science job? Or how to switch careers or how to study for a job interview?
Mostly my answer is to do some MOOCs, create some projects, participate in Kaggle, try to get in a startup and don’t give up.
But yet there are some things everyone should understand about data science jobs.
Data science jobs involve a lot of to and fro communication and involve a lot of people handling skills. And as such, even if you don’t realise you will be inadvertently tested on these skills.
Sometimes you may feel like — I am a coder and let me code in peace. Or how does my behaviour matter? The point is it does.
This post is about explaining some of the worst mistakes people do in a data science interview so that you don’t end up repeating them.
1. Lose your Entitlement This is what I often call the Survivorship Bias in Data Science.
So, you want to be a Rockstar Data Scientist. Maybe get a job in the booming sector. HBR did say that there is going to be a shortage of data scientists and you feel like you are just the right person for the job.
I do take interviews a lot right now, and I see a lot of people suffering from Survivorship Bias.
Just a while back, I interviewed a guy already having some experience in the field. Let’s call him Andy. I asked Andy a simple Math based question. This is a data science interview, so I guess he should have expected it. Right?
No. His answer was —
 We have packages for doing all this.
 I ignored that. Letting it go as a one-off.
Asked a different question, he said why am I asking Math questions?
The thing this told me about Andy is that he feels entitled. Just because Andy sees a lot of people getting into Data Science, he thinks he should also get in.
What Andy doesn’t understand is that for every successful Data Scientist, there are a lot of people who don’t make it.
All Andy sees are the survivors. And that is a mistake.
2. The Overconfidence Effect So, I recently also interviewed Chris for a Data Science role.
I started by asking about his projects and past work.
He confidently explained his projects. We talked about his various projects for the first 30 minutes, and I was pretty much convinced that he has a place in the team.
Till now I hadn’t asked much of technical questions and here is where I started getting sceptical. The thing was Chris would explain anything I asked pretty confidently, albeit wrongly. He would try to explain to me concepts he wouldn’t know.
 I felt as if he thought that maybe I didn’t know the answer to my own questions. And so he can luck out by saying anything.
 And this happened two or three times in the interview.
Now don’t get me wrong — Confidence is good. And a healthy bit of it is necessary. But be Confident and wrong, and you spell disaster.
Can I trust Chris to handle business? What would happen if he committed something wrongly to the business or made lofty claims and didn’t realise them afterwards?
 Overconfidence has been called the most “pervasive and potentially catastrophic” of all the cognitive biases to which human beings fall victim.It has been blamed for lawsuits, strikes, wars, and stock market bubbles and crashes. — Wikipedia
 In fact, I would prefer a non-confident and wrong person. At least then I would know to check my facts.
3. Keyword Stuffing Keyword stuffing is the practice of overloading one’s resume with skills they may not know.
The typical excuses to do this are — A lot of people do this. HR might not select me. The system works like that only.
 You might call it a necessary evil. I will call it you setting up yourself up for a failure.
 And you might get that occasional interview call when you do this; the odds are pretty much stacked against you as I will grill you on your resume. And I will expect you to know it well.
If Mark puts Decision Trees in his resume, Mark should expect a question around it.
Or if Mark says that he has implemented a Machine Learning algorithm from Scratch, I would not be wrong to expect Mark to explain the algorithm’s nitty-gritty details.
The point is that it is alright if you don’t know everything. Nobody ever does. But lie on your resume, and you have made my job easier as these kind of lies are pretty easy to capture.
Conclusion I thought a lot before writing this article as I might sound a little harsh in this one. But I guess it is necessary to let people know about their mistakes.
Some people will disagree with me here on how I can judge people from such small mistakes. &amp;gt; # I would say that an interview is about judging someone in a limited time frame.
Furthermore, a lot of companies now take behavioural rounds apart from the regular data science rounds and being ingenious, or entitled or overconfident will obviously not help you.
So, I would say that being respectful and nice goes a long way and you should aim for it in life and not just in the interview room.
That way, you also get a lot of practice, and you become a better person as well.
PS: All the names used are just placeholders and these are my own personal views.
]]>
        
      </content:encoded>
      
      
      
    </item>
    

    <item>
      <title>Top advice for a Data Scientist</title>
      <link>https://mlwhiz.com/blog/2017/03/05/think_like_a_data_scientist/</link>
      <pubDate>Sun, 05 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2017/03/05/think_like_a_data_scientist/</guid>
      
      

      
      <description>A data scientist needs to be Critical and always on a lookout of something that misses others. So here are some advices that one can include in day to day data science work to be better at their work:
1. Beware of the Clean Data Syndrome You need to ask yourself questions even before you start working on the data. Does this data make sense? Falsely assuming that the data is clean could lead you towards wrong Hypotheses.</description>

      <content:encoded>  
        
        <![CDATA[    A data scientist needs to be Critical and always on a lookout of something that misses others. So here are some advices that one can include in day to day data science work to be better at their work:
1. Beware of the Clean Data Syndrome You need to ask yourself questions even before you start working on the data. Does this data make sense? Falsely assuming that the data is clean could lead you towards wrong Hypotheses. Apart from that, you can discern a lot of important patterns by looking at discrepancies in the data. For example, if you notice that a particular column has more than 50% values missing, you might think about not using the column. Or you may think that some of the data collection instrument has some error.
Or let&amp;rsquo;s say you have a distribution of Male vs Female as 90:10 in a Female Cosmetic business. You may assume clean data and show the results as it is or you can use common sense and ask if the labels are switched.
2. Manage Outliers wisely Outliers can help you understand more about the people who are using your website/product 24 hours a day. But including them while building models will skew the models a lot.
3. Keep an eye out for the Abnormal Be on the lookout for something out of the obvious. If you find something you may have hit gold.
For example, Flickr started up as a Multiplayer game. Only when the founders noticed that people were using it as a photo upload service, did they pivot.
Another example: fab.com started up as fabulis.com, a site to help gay men meet people. One of the site&amp;rsquo;s popular features was the &amp;ldquo;Gay deal of the Day&amp;rdquo;. One day the deal was for Hamburgers - and half of the buyers were women. This caused the team to realize that there was a market for selling goods to women. So Fabulis pivoted to fab as a flash sale site for designer products.
4. Start Focussing on the right metrics  Beware of Vanity metrics For example, # of active users by itself doesn&amp;rsquo;t divulge a lot of information. I would rather say &amp;ldquo;5% MoM increase in active users&amp;rdquo; rather than saying &amp;ldquo; 10000 active users&amp;rdquo;. Even that is a vanity metric as active users would always increase. I would rather keep a track of percentage of users that are active to know how my product is performing. Try to find out a metric that ties with the business goal. For example, Average Sales/User for a particular month.   5. Statistics may lie too Be critical of everything that gets quoted to you. Statistics has been used to lie in advertisements, in workplaces and a lot of other marketing venues in the past. People will do anything to get sales or promotions.
For example: Do you remember Colgate’s claim that 80% of dentists recommended their brand?
This statistic seems pretty good at first. It turns out that at the time of surveying the dentists, they could choose several brands — not just one. So other brands could be just as popular as Colgate.
Another Example: &amp;ldquo;99 percent Accurate&amp;rdquo; doesn&amp;rsquo;t mean shit. Ask me to create a cancer prediction model and I could give you a 99 percent accurate model in a single line of code. How? Just predict &amp;ldquo;No Cancer&amp;rdquo; for each one. I will be accurate may be more than 99% of the time as Cancer is a pretty rare disease. Yet I have achieved nothing.
6. Understand how probability works It happened during the summer of 1913 in a Casino in Monaco. Gamblers watched in amazement as a casino&amp;rsquo;s roulette wheel landed on black 26 times in a row. And since the probability of a Red vs Black is exactly half, they were certain that red was &amp;ldquo;due&amp;rdquo;. It was a field day for the Casino. A perfect example of Gambler&amp;rsquo;s fallacy, aka the Monte Carlo fallacy.
And This happens in real life. People tend to avoid long strings of the same answer. Sometimes sacrificing accuracy of judgment for the sake of getting a pattern of decisions that looks fairer or probable.
For example, An admissions officer may reject the next application if he has approved three applications in a row, even if the application should have been accepted on merit.
7. Correlation Does Not Equal Causation   The Holy Grail of a Data scientist toolbox. To see something for what it is. Just because two variables move together in tandem doesn&amp;rsquo;t necessarily mean that one causes the another. There have been hilarious examples for this in the past. Some of my favorites are:
 Looking at the firehouse department data you infer that the more firemen are sent to a fire, the more damage is done.
 When investigating the cause of crime in New York City in the 80s, an academic found a strong correlation between the amount of serious crime committed and the amount of ice cream sold by street vendors! Obviously, there was an unobserved variable causing both. Summers are when the crime is the greatest and when the most ice cream is sold. So Ice cream sales don&amp;rsquo;t cause crime. Neither crime increases ice cream sales.
  8. More data may help Sometimes getting extra data may work wonders. You might be able to model the real world more closely by looking at the problem from all angles. Look for extra data sources.
For example, Crime data in a city might help banks provide a better credit line to a person living in a troubled neighborhood and in turn increase the bottom line.
]]>
        
      </content:encoded>
      
      
      
    </item>
    
  </channel>
</rss>