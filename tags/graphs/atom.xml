<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1" xmlns:content="http://purl.org/rss/1.0/modules/content" xmlns:media="http://search.yahoo.com/mrss/" >

  
  <channel>
    <title>Graphs on MLWhiz</title>
    <link>https://mlwhiz.com/tags/graphs/</link>
    <description>Recent content in Graphs on MLWhiz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 06 Nov 2019 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://mlwhiz.com/tags/graphs/atom.xml" rel="self" type="application/rss+xml" />
    

    

    <item>
      <title>4 Graph Algorithms on Steroids for data Scientists with cuGraph</title>
      <link>https://mlwhiz.com/blog/2019/10/20/cugraph/</link>
      <pubDate>Wed, 06 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2019/10/20/cugraph/</guid>
      
      
      <media:content type="image/jpeg" medium="image" width="700" height="400"
      url="https://mlwhiz.com/images/cugraph/1.jpg"></media:content>
      

      
      <description>We, as data scientists have gotten quite comfortable with Pandas or SQL or any other relational database.
We are used to seeing our users in rows with their attributes as columns. But does the real world behave like that?
In a connected world, users cannot be considered as independent entities. They have got certain relationships with each other, and we would sometimes like to include such relationships while building our machine learning models.</description>

      <content:encoded>  
        
        <![CDATA[  We, as data scientists have gotten quite comfortable with Pandas or SQL or any other relational database.
We are used to seeing our users in rows with their attributes as columns. But does the real world behave like that?
In a connected world, users cannot be considered as independent entities. They have got certain relationships with each other, and we would sometimes like to include such relationships while building our machine learning models.
Now while in a relational database, we cannot use such relations between different rows(users), in a graph database, it is relatively trivial to do that.
Now, as we know, Python has a great package called Networkx to do this. But the problem with that is that it is not scalable.
A GPU can help solve our scalability problems with its many cores and parallelization. And that is where RAPIDS.ai CuGraph comes in.
 The RAPIDS cuGraph library is a collection of graph analytics that process data found in GPU Dataframes — see cuDF. cuGraph aims to provide a NetworkX-like API that will be familiar to data scientists, so they can now build GPU-accelerated workflows more easily.
 In this post, I am going to be talking about some of the most essential graph algorithms you should know and how to implement them using Python with cuGraph.
Installation To install cuGraph you can just use the simple command that you can choose from rapids.ai based on your system and configuration.
The command I used is below and I used a nightly build(recommended):
conda install -c rapidsai-nightly -c nvidia -c numba -c conda-forge -c anaconda cudf=0.10 cuml=0.10 cugraph=0.10  1. Connected Components We all know how clustering works?
You can think of Connected Components in very layman’s terms as a sort of a hard clustering algorithm which finds clusters/islands in related/connected data.
As a concrete example: Say you have data about roads joining any two cities in the world. And you need to find out all the continents in the world and which city they contain.
How will you achieve that? Come on, give some thought.
The connected components algorithm that we use to do this is based on a special case of BFS/DFS. I won’t talk much about how it works here, but we will see how to get the code up and running using Networkx as well as cuGraph.
Applications From a Retail Perspective: Let us say, we have a lot of customers using a lot of accounts. One way in which we can use the Connected components algorithm is to find out distinct families in our dataset.
We can assume edges(roads) between CustomerIDs based on same credit card usage, or same address or same mobile number, etc. Once we have those connections, we can then run the connected component algorithm on the same to create individual clusters to which we can then assign a family ID.
We can then use these family IDs to provide personalized recommendations based on family needs. We can also use this family ID to fuel our classification algorithms by creating grouped features based on family.
From a Finance Perspective: Another use case would be to capture fraud using these family IDs. If an account has done fraud in the past, it is highly probable that the connected accounts are also susceptible to fraud.
The possibilities are only limited by your imagination.
Code We will be using the Networkx module in Python for creating and analyzing our graphs.
Let us start with an example graph which we are using for our purpose. Contains cities and distance information between them.
We first start by creating a list of edges along with the distances which we will add as the weight of the edge:
edgelist = [[&amp;#39;Mannheim&amp;#39;, &amp;#39;Frankfurt&amp;#39;, 85], [&amp;#39;Mannheim&amp;#39;, &amp;#39;Karlsruhe&amp;#39;, 80], [&amp;#39;Erfurt&amp;#39;, &amp;#39;Wurzburg&amp;#39;, 186], [&amp;#39;Munchen&amp;#39;, &amp;#39;Numberg&amp;#39;, 167], [&amp;#39;Munchen&amp;#39;, &amp;#39;Augsburg&amp;#39;, 84], [&amp;#39;Munchen&amp;#39;, &amp;#39;Kassel&amp;#39;, 502], [&amp;#39;Numberg&amp;#39;, &amp;#39;Stuttgart&amp;#39;, 183], [&amp;#39;Numberg&amp;#39;, &amp;#39;Wurzburg&amp;#39;, 103], [&amp;#39;Numberg&amp;#39;, &amp;#39;Munchen&amp;#39;, 167], [&amp;#39;Stuttgart&amp;#39;, &amp;#39;Numberg&amp;#39;, 183], [&amp;#39;Augsburg&amp;#39;, &amp;#39;Munchen&amp;#39;, 84], [&amp;#39;Augsburg&amp;#39;, &amp;#39;Karlsruhe&amp;#39;, 250], [&amp;#39;Kassel&amp;#39;, &amp;#39;Munchen&amp;#39;, 502], [&amp;#39;Kassel&amp;#39;, &amp;#39;Frankfurt&amp;#39;, 173], [&amp;#39;Frankfurt&amp;#39;, &amp;#39;Mannheim&amp;#39;, 85], [&amp;#39;Frankfurt&amp;#39;, &amp;#39;Wurzburg&amp;#39;, 217], [&amp;#39;Frankfurt&amp;#39;, &amp;#39;Kassel&amp;#39;, 173], [&amp;#39;Wurzburg&amp;#39;, &amp;#39;Numberg&amp;#39;, 103], [&amp;#39;Wurzburg&amp;#39;, &amp;#39;Erfurt&amp;#39;, 186], [&amp;#39;Wurzburg&amp;#39;, &amp;#39;Frankfurt&amp;#39;, 217], [&amp;#39;Karlsruhe&amp;#39;, &amp;#39;Mannheim&amp;#39;, 80], [&amp;#39;Karlsruhe&amp;#39;, &amp;#39;Augsburg&amp;#39;, 250],[&amp;#34;Mumbai&amp;#34;, &amp;#34;Delhi&amp;#34;,400],[&amp;#34;Delhi&amp;#34;, &amp;#34;Kolkata&amp;#34;,500],[&amp;#34;Kolkata&amp;#34;, &amp;#34;Bangalore&amp;#34;,600],[&amp;#34;TX&amp;#34;, &amp;#34;NY&amp;#34;,1200],[&amp;#34;ALB&amp;#34;, &amp;#34;NY&amp;#34;,800]] Now we want to find out distinct continents and their cities from this graph.
First, we will need to create a cudf dataframe with edges in it. Right now, I am creating a pandas dataframe and converting it to cudf dataframe, but in a real-life scenario, we will read from a csv file of edges.
import cugraph import cudf import pandas as pd # create a pandas dataframe of edges pandas_df = pd.DataFrame(edgelist) pandas_df.columns = [&amp;#39;src&amp;#39;,&amp;#39;dst&amp;#39;,&amp;#39;distance&amp;#39;] # create a pandas dataframe of reversed edges as we have a undirected graph rev_pandas_df = pandas_df.copy() rev_pandas_df.columns = [&amp;#39;dst&amp;#39;,&amp;#39;src&amp;#39;,&amp;#39;distance&amp;#39;] rev_pandas_df = rev_pandas_df[[&amp;#39;src&amp;#39;,&amp;#39;dst&amp;#39;,&amp;#39;distance&amp;#39;]] # concat all edges pandas_df = pd.concat([pandas_df,rev_pandas_df]) Now our pandas df contains edges in both directions. And our node names in src and dst columns are in str format. Apparently, cuGraph doesn&amp;rsquo;t like that and only works with integer node IDs.
# CuGraph works with only integer node IDs unique_destinations = set() for [src,dst,dis] in edgelist: unique_destinations.add(src) unique_destinations.add(dst) # create a map of city and a unique id city_id_dict = {} for i, city in enumerate(unique_destinations): city_id_dict[city]=i # create 2 columns that contain the integer IDs for src and dst pandas_df[&amp;#39;src_int&amp;#39;] = pandas_df[&amp;#39;src&amp;#39;].apply(lambda x : city_id_dict[x]) pandas_df[&amp;#39;dst_int&amp;#39;] = pandas_df[&amp;#39;dst&amp;#39;].apply(lambda x : city_id_dict[x]) Now comes the main part that we should focus on:
cuda_g = cudf.DataFrame.from_pandas(pandas_df) # cugraph needs node IDs to be int32 and weights to be float cuda_g[&amp;#39;src_int&amp;#39;] = cuda_g[&amp;#39;src_int&amp;#39;].astype(np.int32) cuda_g[&amp;#39;dst_int&amp;#39;] = cuda_g[&amp;#39;dst_int&amp;#39;].astype(np.int32) cuda_g[&amp;#39;distance&amp;#39;] = cuda_g[&amp;#39;distance&amp;#39;].astype(np.float) G = cugraph.Graph() G.add_edge_list(cuda_g[&amp;#34;src_int&amp;#34;],cuda_g[&amp;#34;dst_int&amp;#34;] , cuda_g[&amp;#39;distance&amp;#39;]) cugraph.weakly_connected_components(G) The output of the last call is a cudf dataframe.
As we can see, the labels correspond to Connected Components ID.
2. Shortest Path Continuing with the above example only, we are given a graph with the cities of Germany and the respective distance between them.
You want to find out how to go from Frankfurt (The starting node) to Munchen by covering the shortest distance.
The algorithm that we use for this problem is called Dijkstra. In Dijkstra’s own words:
 What is the shortest way to travel from Rotterdam to Groningen, in general: from given city to given city. It is the algorithm for the shortest path, which I designed in about twenty minutes. One morning I was shopping in Amsterdam with my young fiancée, and tired, we sat down on the café terrace to drink a cup of coffee and I was just thinking about whether I could do this, and I then designed the algorithm for the shortest path. As I said, it was a twenty-minute invention. In fact, it was published in ’59, three years later. The publication is still readable, it is, in fact, quite nice. One of the reasons that it is so nice was that I designed it without pencil and paper. I learned later that one of the advantages of designing without pencil and paper is that you are almost forced to avoid all avoidable complexities. Eventually that algorithm became, to my great amazement, one of the cornerstones of my fame. — Edsger Dijkstra, in an interview with Philip L. Frana, Communications of the ACM, 2001[3]
 Applications  Variations of the Dijkstra algorithm is used extensively in Google Maps to find the shortest routes.
 You are in a Walmart Store. You have different Aisles and distance between all the aisles. You want to provide the shortest pathway to the customer from Aisle A to Aisle D.
   You have seen how LinkedIn shows up 1st-degree connections, 2nd-degree connections. What goes on behind the scenes?  Code We already have our Graph as before. We can find the shortest distance from a source node to all nodes in the graph.
# get distances from source node 0 distances = cugraph.sssp(G, 0) # filter infinite distances distances = cugraph.traversal.filter_unreachable(distances) distances Now if we have to find the path between node 0 and 14 we can use the distances cudf.
# Getting the path is as simple as: path = [] dest = 14 while dest != 0: dest = distances[distances[&amp;#39;vertex&amp;#39;] == dest][&amp;#39;predecessor&amp;#39;].values[0] path.append(dest) # reverse the list and print print(path[::-1]) [0, 11, 9]  3. Pagerank This is the page sorting algorithm that powered google for a long time. It assigns scores to pages based on the number and quality of incoming and outgoing links.
Applications Pagerank can be used anywhere where we want to estimate node importance in any network.
 It has been used for finding the most influential papers using citations.
 Has been used by Google to rank pages
 It can be used to rank tweets- User and Tweets as nodes. Create Link between user if user A follows user B and Link between user and Tweets if user tweets/retweets a tweet.
 Recommendation engines
  Code For this exercise, we are going to be using Facebook social network data.
# Loading the file as cudf fb_cudf = cudf.read_csv(&amp;#34;facebook_combined.txt&amp;#34;, sep=&amp;#39; &amp;#39;, names=[&amp;#39;src&amp;#39;, &amp;#39;dst&amp;#39;],dtype =[&amp;#39;int32&amp;#39;,&amp;#39;int32&amp;#39;]) # adding reverse edges also rev_fb_cudf = fb_cudf[[&amp;#39;dst&amp;#39;,&amp;#39;src&amp;#39;]] rev_fb_cudf.columns = [&amp;#39;src&amp;#39;,&amp;#39;dst&amp;#39;] fb_cudf = cudf.concat([fb_cudf,rev_fb_cudf]) Creating the graph
# creating the graph fb_G = cugraph.Graph() fb_G.add_edge_list(fb_cudf[&amp;#34;src&amp;#34;],fb_cudf[&amp;#34;dst&amp;#34;]) Now we want to find the users having high influence capability.
Intuitively, the Pagerank algorithm will give a higher score to a user who has a lot of friends who in turn have a lot of FB Friends.
# Call cugraph.pagerank to get the pagerank scores fb_pagerank = cugraph.pagerank(fb_G) fb_pagerank.sort_values(by=&amp;#39;pagerank&amp;#39;,ascending=False).head() 4. Link Prediction Continuing along with our Facebook example. You might have seen recommended friends in your Facebook account. How can we create our small recommender?
Can we predict which edges will be connected in the future based on current edges?
A straightforward and fast approach to do this is by using the Jaccard Coefficient.
Applications There could be many applications of link predictions. We could predict
 Authors who are going to connect for co-authorships in a citation network
 Who will become friends in a social network?
  Idea We calculate the Jaccard coefficient between two nodes i and j as :
Where the numerator is the number of common neighbors of i and j, and the denominator is the total number of distinct neighbors of i and j.
So in the figure, the half red and green nodes are the common neighbors of both A and B. And they have a total of 5 distinct neighbors. So the JaccardCoeff(A, B) is 2&amp;frasl;5
Code We first create a cudf_nodes cudf with all possible node combinations.
max_vertex_id = fb_pagerank[&amp;#39;vertex&amp;#39;].max() data = [] for x in range(0,max_vertex_id&#43;1): for y in range(0,max_vertex_id&#43;1): data.append([x,y]) cudf_nodes =cudf.from_pandas(pd.DataFrame(data)) cudf_nodes.columns = [&amp;#39;src&amp;#39;,&amp;#39;dst&amp;#39;] cudf_nodes[&amp;#39;src&amp;#39;] = cudf_nodes[&amp;#39;src&amp;#39;].astype(np.int32) cudf_nodes[&amp;#39;dst&amp;#39;] = cudf_nodes[&amp;#39;dst&amp;#39;].astype(np.int32) We can then calculate the Jaccard coefficient between nodes as:
jaccard_coeff_between_nodes = cugraph.link_prediction.jaccard(fb_G,cudf_nodes[&amp;#34;src&amp;#34;],cudf_nodes[&amp;#34;dst&amp;#34;]) jaccard_coeff_between_nodes.head() But we are still not done. We need to remove the edges where the source==destination and the edges which are already present in the graph. We will do this using simple join and filter operations which work particularly similar to pandas.
jaccard_coeff_between_nodes=jaccard_coeff_between_nodes[jaccard_coeff_between_nodes[&amp;#39;source&amp;#39;]!=jaccard_coeff_between_nodes[&amp;#39;destination&amp;#39;]] fb_cudf.columns = [&amp;#39;source&amp;#39;, &amp;#39;destination&amp;#39;] fb_cudf[&amp;#39;edgeflag&amp;#39;]=1 jaccard_coeff_joined_with_edges = jaccard_coeff_between_nodes.merge(fb_cudf,on= [&amp;#39;source&amp;#39;, &amp;#39;destination&amp;#39;],how=&amp;#39;left&amp;#39;) # We just want to see the jaccard coeff of new edges new_edges_jaccard_coeff = jaccard_coeff_joined_with_edges[jaccard_coeff_joined_with_edges[&amp;#39;edgeflag&amp;#39;]!=1] This is our final sorted dataframe with the Jaccard coefficient between unconnected nodes. We know what friends to recommend to our platform users.
new_edges_jaccard_coeff.sort_values(by=&amp;#39;jaccard_coeff&amp;#39;,ascending=False) Basic Network Statistics There are a lot of basic measures which you want to know about your network.
Here is how you get them in your network
print(&amp;#34;Number of Nodes&amp;#34;,fb_G.number_of_nodes()) print(&amp;#34;Number of Edges&amp;#34;,fb_G.number_of_edges()) Number of Nodes 4039 Number of Edges 176468  You can also compute the indegree and outdegree for each node.
In a directed graph this corresponds to no of followers and no of follows.
fb_G.degrees().head() Performance Benchmarks I won’t do any justice to this post if I don’t add certain benchmarks for the different algorithms.
In my benchmark study, I use three datasets in increasing order of scale from the Stanford Large Network Dataset Collection.
 ego-Facebook: Undirected graph with 4 K nodes and 88 K edges from Facebook
 ego-Twitter: Directed graph with 81 K nodes and 1.7 M edges from Twitter
 ego-Gplus: Directed graph with 107 K nodes and 13.6 M edges from Google&#43;
  Here are the results of the experiments I performed on NVIDIA Tesla V100 32 GB GPU. Thanks to Josh Patterson from NVIDIA and Richard Ulrich at Walmart Labs for arranging that for me. All the times are given in milliseconds:
I didn’t add Jaccard coefficients in the results as it didn’t run even for facebook using networkX. For cuGraph it had millisecond-level latencies.
Let us visualize these results:
Caveats Rapids cuGraph is an excellent library for graph analysis, but I feel some things are still missing. Maybe we will get them in the next version.
 A little bit of inconvenience that we have to use numbered nodes with data type int32 only. Renumbering helps with that. See my notebook for the benchmark for the exact code. Check the function cugraph.symmetrize_df too for creating undirected graphs.
 Some algorithms are still not implemented. For instance, I could not find MST, Centrality measures, etc.
 More example notebooks are needed to document best practices. I might be going to be work on some of those.
 No visualization component in the library. I have to go to networkx to plot graphs.
  But despite that, I would also like to add that the idea to provide graph analysis with GPU is so great that I can live with these small problems. And the way they have made the API so similar to pandas and networkx adds to its value.
I remember how using GPU needed a lot of code in the past. RAPIDS has aimed to make GPU ubiquitous, and that is a fabulous initiative.
Conclusion In this post, I talked about some of the most powerful graph algorithms that have changed the way we live and how to scale them with GPUs.
I love the way Rapids AI has been working to make GPUs accessible to the typical developer/data scientist and to think that we hadn’t heard about it till a year back. They have come a long way.
Also, here are the newest version 0.9 documentation for cuDF and cuGraph.
You can get the running code in this Google Colab Notebook, and the code with benchmarks on my Github repository as Google Colab fell short on resources while benchmarking.
Continue Learning If you want to read up more on Graph Algorithms here is a Graph Analytics for Big Data course on Coursera by UCSanDiego, which I highly recommend to learn the basics of graph theory.
Thanks for the read. I am going to be writing more beginner-friendly posts in the future too. Follow me up at Medium or Subscribe to my blog.
Also, a small disclaimer — There might be some affiliate links in this post to relevant resources as sharing knowledge is never a bad idea.
]]>
        
      </content:encoded>
      
      
      
    </item>
    

    <item>
      <title>Data Scientists, The 5 Graph Algorithms that you should know</title>
      <link>https://mlwhiz.com/blog/2019/09/02/graph_algs/</link>
      <pubDate>Mon, 02 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2019/09/02/graph_algs/</guid>
      
      
      <media:content type="image/png" medium="image" width="700" height="400"
      url="https://mlwhiz.com/images/graphs/1.png"></media:content>
      

      
      <description>We as data scientists have gotten quite comfortable with Pandas or SQL or any other relational database.
We are used to seeing our users in rows with their attributes as columns. But does the real world really behave like that?
In a connected world, users cannot be considered as independent entities. They have got certain relationships between each other and we would sometimes like to include such relationships while building our machine learning models.</description>

      <content:encoded>  
        
        <![CDATA[  We as data scientists have gotten quite comfortable with Pandas or SQL or any other relational database.
We are used to seeing our users in rows with their attributes as columns. But does the real world really behave like that?
In a connected world, users cannot be considered as independent entities. They have got certain relationships between each other and we would sometimes like to include such relationships while building our machine learning models.
Now while in a relational database, we cannot use such relations between different rows(users), in a graph database it is fairly trivial to do that.
In this post, I am going to be talking about some of the most important graph algorithms you should know and how to implement them using Python.
Also, here is a Graph Analytics for Big Data course on Coursera by UCSanDiego which I highly recommend to learn the basics of graph theory.
1. Connected Components We all know how clustering works?
You can think of Connected Components in very layman’s terms as a sort of a hard clustering algorithm which finds clusters/islands in related/connected data.
As a concrete example: Say you have data about roads joining any two cities in the world. And you need to find out all the continents in the world and which city they contain.*
How will you achieve that? Come on give some thought.
The connected components algorithm that we use to do this is based on a special case of BFS/DFS. I won’t talk much about how it works here, but we will see how to get the code up and running using Networkx.
Applications From a Retail Perspective: Let us say, we have a lot of customers using a lot of accounts. One way in which we can use the Connected components algorithm is to find out distinct families in our dataset.
We can assume edges(roads) between CustomerIDs based on same credit card usage, or same address or same mobile number, etc. Once we have those connections, we can then run the connected component algorithm on the same to create individual clusters to which we can then assign a family ID.
We can then use these family IDs to provide personalized recommendations based on family needs. We can also use this family ID to fuel our classification algorithms by creating grouped features based on family.
From a Finance Perspective: Another use case would be to capture fraud using these family IDs. If an account has done fraud in the past, it is highly probable that the connected accounts are also susceptible to fraud.
The possibilities are only limited by your own imagination.
Code We will be using the Networkx module in Python for creating and analyzing our graphs.
Let us start with an example graph which we are using for our purpose. Contains cities and distance information between them.
We first start by creating a list of edges along with the distances which we will add as the weight of the edge:
edgelist = [[&amp;#39;Mannheim&amp;#39;, &amp;#39;Frankfurt&amp;#39;, 85], [&amp;#39;Mannheim&amp;#39;, &amp;#39;Karlsruhe&amp;#39;, 80], [&amp;#39;Erfurt&amp;#39;, &amp;#39;Wurzburg&amp;#39;, 186], [&amp;#39;Munchen&amp;#39;, &amp;#39;Numberg&amp;#39;, 167], [&amp;#39;Munchen&amp;#39;, &amp;#39;Augsburg&amp;#39;, 84], [&amp;#39;Munchen&amp;#39;, &amp;#39;Kassel&amp;#39;, 502], [&amp;#39;Numberg&amp;#39;, &amp;#39;Stuttgart&amp;#39;, 183], [&amp;#39;Numberg&amp;#39;, &amp;#39;Wurzburg&amp;#39;, 103], [&amp;#39;Numberg&amp;#39;, &amp;#39;Munchen&amp;#39;, 167], [&amp;#39;Stuttgart&amp;#39;, &amp;#39;Numberg&amp;#39;, 183], [&amp;#39;Augsburg&amp;#39;, &amp;#39;Munchen&amp;#39;, 84], [&amp;#39;Augsburg&amp;#39;, &amp;#39;Karlsruhe&amp;#39;, 250], [&amp;#39;Kassel&amp;#39;, &amp;#39;Munchen&amp;#39;, 502], [&amp;#39;Kassel&amp;#39;, &amp;#39;Frankfurt&amp;#39;, 173], [&amp;#39;Frankfurt&amp;#39;, &amp;#39;Mannheim&amp;#39;, 85], [&amp;#39;Frankfurt&amp;#39;, &amp;#39;Wurzburg&amp;#39;, 217], [&amp;#39;Frankfurt&amp;#39;, &amp;#39;Kassel&amp;#39;, 173], [&amp;#39;Wurzburg&amp;#39;, &amp;#39;Numberg&amp;#39;, 103], [&amp;#39;Wurzburg&amp;#39;, &amp;#39;Erfurt&amp;#39;, 186], [&amp;#39;Wurzburg&amp;#39;, &amp;#39;Frankfurt&amp;#39;, 217], [&amp;#39;Karlsruhe&amp;#39;, &amp;#39;Mannheim&amp;#39;, 80], [&amp;#39;Karlsruhe&amp;#39;, &amp;#39;Augsburg&amp;#39;, 250],[&amp;#34;Mumbai&amp;#34;, &amp;#34;Delhi&amp;#34;,400],[&amp;#34;Delhi&amp;#34;, &amp;#34;Kolkata&amp;#34;,500],[&amp;#34;Kolkata&amp;#34;, &amp;#34;Bangalore&amp;#34;,600],[&amp;#34;TX&amp;#34;, &amp;#34;NY&amp;#34;,1200],[&amp;#34;ALB&amp;#34;, &amp;#34;NY&amp;#34;,800]] Let us create a graph using Networkx:
g = nx.Graph() for edge in edgelist: g.add_edge(edge[0],edge[1], weight = edge[2]) Now we want to find out distinct continents and their cities from this graph.
We can now do this using the connected components algorithm as:
for i, x in enumerate(nx.connected_components(g)): print(&amp;#34;cc&amp;#34;&#43;str(i)&#43;&amp;#34;:&amp;#34;,x) cc0: {&#39;Frankfurt&#39;, &#39;Kassel&#39;, &#39;Munchen&#39;, &#39;Numberg&#39;, &#39;Erfurt&#39;, &#39;Stuttgart&#39;, &#39;Karlsruhe&#39;, &#39;Wurzburg&#39;, &#39;Mannheim&#39;, &#39;Augsburg&#39;} cc1: {&#39;Kolkata&#39;, &#39;Bangalore&#39;, &#39;Mumbai&#39;, &#39;Delhi&#39;} cc2: {&#39;ALB&#39;, &#39;NY&#39;, &#39;TX&#39;}  As you can see we are able to find distinct components in our data. Just by using Edges and Vertices. This algorithm could be run on different data to satisfy any use case that I presented above.
2. Shortest Path Continuing with the above example only, we are given a graph with the cities of Germany and the respective distance between them.
You want to find out how to go from Frankfurt (The starting node) to Munchen by covering the shortest distance.
The algorithm that we use for this problem is called Dijkstra. In Dijkstra’s own words:
 What is the shortest way to travel from Rotterdam to Groningen, in general: from given city to given city. It is the algorithm for the shortest path, which I designed in about twenty minutes. One morning I was shopping in Amsterdam with my young fiancée, and tired, we sat down on the café terrace to drink a cup of coffee and I was just thinking about whether I could do this, and I then designed the algorithm for the shortest path. As I said, it was a twenty-minute invention. In fact, it was published in ’59, three years later. The publication is still readable, it is, in fact, quite nice. One of the reasons that it is so nice was that I designed it without pencil and paper. I learned later that one of the advantages of designing without pencil and paper is that you are almost forced to avoid all avoidable complexities. Eventually that algorithm became, to my great amazement, one of the cornerstones of my fame. — Edsger Dijkstra, in an interview with Philip L. Frana, Communications of the ACM, 2001[3]
 Applications  Variations of the Dijkstra algorithm is used extensively in Google Maps to find the shortest routes.
 You are in a Walmart Store. You have different Aisles and distance between all the aisles. You want to provide the shortest pathway to the customer from Aisle A to Aisle D.
   You have seen how LinkedIn shows up 1st-degree connections, 2nd-degree connections. What goes on behind the scenes?  Code print(nx.shortest_path(g, &amp;#39;Stuttgart&amp;#39;,&amp;#39;Frankfurt&amp;#39;,weight=&amp;#39;weight&amp;#39;)) print(nx.shortest_path_length(g, &amp;#39;Stuttgart&amp;#39;,&amp;#39;Frankfurt&amp;#39;,weight=&amp;#39;weight&amp;#39;)) [&#39;Stuttgart&#39;, &#39;Numberg&#39;, &#39;Wurzburg&#39;, &#39;Frankfurt&#39;] 503  You can also find Shortest paths between all pairs using:
for x in nx.all_pairs_dijkstra_path(g,weight=&amp;#39;weight&amp;#39;): print(x) (&#39;Mannheim&#39;, {&#39;Mannheim&#39;: [&#39;Mannheim&#39;], &#39;Frankfurt&#39;: [&#39;Mannheim&#39;, &#39;Frankfurt&#39;], &#39;Karlsruhe&#39;: [&#39;Mannheim&#39;, &#39;Karlsruhe&#39;], &#39;Augsburg&#39;: [&#39;Mannheim&#39;, &#39;Karlsruhe&#39;, &#39;Augsburg&#39;], &#39;Kassel&#39;: [&#39;Mannheim&#39;, &#39;Frankfurt&#39;, &#39;Kassel&#39;], &#39;Wurzburg&#39;: [&#39;Mannheim&#39;, &#39;Frankfurt&#39;, &#39;Wurzburg&#39;], &#39;Munchen&#39;: [&#39;Mannheim&#39;, &#39;Karlsruhe&#39;, &#39;Augsburg&#39;, &#39;Munchen&#39;], &#39;Erfurt&#39;: [&#39;Mannheim&#39;, &#39;Frankfurt&#39;, &#39;Wurzburg&#39;, &#39;Erfurt&#39;], &#39;Numberg&#39;: [&#39;Mannheim&#39;, &#39;Frankfurt&#39;, &#39;Wurzburg&#39;, &#39;Numberg&#39;], &#39;Stuttgart&#39;: [&#39;Mannheim&#39;, &#39;Frankfurt&#39;, &#39;Wurzburg&#39;, &#39;Numberg&#39;, &#39;Stuttgart&#39;]}) (&#39;Frankfurt&#39;, {&#39;Frankfurt&#39;: [&#39;Frankfurt&#39;], &#39;Mannheim&#39;: [&#39;Frankfurt&#39;, &#39;Mannheim&#39;], &#39;Kassel&#39;: [&#39;Frankfurt&#39;, &#39;Kassel&#39;], &#39;Wurzburg&#39;: [&#39;Frankfurt&#39;, &#39;Wurzburg&#39;], &#39;Karlsruhe&#39;: [&#39;Frankfurt&#39;, &#39;Mannheim&#39;, &#39;Karlsruhe&#39;], &#39;Augsburg&#39;: [&#39;Frankfurt&#39;, &#39;Mannheim&#39;, &#39;Karlsruhe&#39;, &#39;Augsburg&#39;], &#39;Munchen&#39;: [&#39;Frankfurt&#39;, &#39;Wurzburg&#39;, &#39;Numberg&#39;, &#39;Munchen&#39;], &#39;Erfurt&#39;: [&#39;Frankfurt&#39;, &#39;Wurzburg&#39;, &#39;Erfurt&#39;], &#39;Numberg&#39;: [&#39;Frankfurt&#39;, &#39;Wurzburg&#39;, &#39;Numberg&#39;], &#39;Stuttgart&#39;: [&#39;Frankfurt&#39;, &#39;Wurzburg&#39;, &#39;Numberg&#39;, &#39;Stuttgart&#39;]}) ....  3. Minimum Spanning Tree Now we have another problem. We work for a water pipe laying company or an internet fiber company. We need to connect all the cities in the graph we have using the minimum amount of wire/pipe. How do we do this?
Applications  Minimum spanning trees have direct applications in the design of networks, including computer networks, telecommunications networks, transportation networks, water supply networks, and electrical grids (which they were first invented for)
 MST is used for approximating the traveling salesman problem
 Clustering — First construct MST and then determine a threshold value for breaking some edges in the MST using Intercluster distances and Intracluster distances.
 Image Segmentation — It was used for Image segmentation where we first construct an MST on a graph where pixels are nodes and distances between pixels are based on some similarity measure(color, intensity, etc.)
  Code # nx.minimum_spanning_tree(g) returns a instance of type graph nx.draw_networkx(nx.minimum_spanning_tree(g)) As you can see the above is the wire we gotta lay.
4. Pagerank This is the page sorting algorithm that powered google for a long time. It assigns scores to pages based on the number and quality of incoming and outgoing links.
Applications Pagerank can be used anywhere where we want to estimate node importance in any network.
 It has been used for finding the most influential papers using citations.
 Has been used by Google to rank pages
 It can be used to rank tweets- User and Tweets as nodes. Create Link between user if user A follows user B and Link between user and Tweets if user tweets/retweets a tweet.
 Recommendation engines
  Code For this exercise, we are going to be using Facebook data. We have a file of edges/links between facebook users. We first create the FB graph using:
# reading the dataset fb = nx.read_edgelist(&amp;#39;../input/facebook-combined.txt&amp;#39;, create_using = nx.Graph(), nodetype = int) This is how it looks:
pos = nx.spring_layout(fb) import warnings warnings.filterwarnings(&amp;#39;ignore&amp;#39;) plt.style.use(&amp;#39;fivethirtyeight&amp;#39;) plt.rcParams[&amp;#39;figure.figsize&amp;#39;] = (20, 15) plt.axis(&amp;#39;off&amp;#39;) nx.draw_networkx(fb, pos, with_labels = False, node_size = 35) plt.show() Now we want to find the users having high influence capability.
Intuitively, the Pagerank algorithm will give a higher score to a user who has a lot of friends who in turn have a lot of FB Friends.
pageranks = nx.pagerank(fb) print(pageranks) {0: 0.006289602618466542, 1: 0.00023590202311540972, 2: 0.00020310565091694562, 3: 0.00022552359869430617, 4: 0.00023849264701222462, ........}  We can get the sorted PageRank or most influential users using:
import operator sorted_pagerank = sorted(pagerank.items(), key=operator.itemgetter(1),reverse = True) print(sorted_pagerank) [(3437, 0.007614586844749603), (107, 0.006936420955866114), (1684, 0.0063671621383068295), (0, 0.006289602618466542), (1912, 0.0038769716008844974), (348, 0.0023480969727805783), (686, 0.0022193592598000193), (3980, 0.002170323579009993), (414, 0.0018002990470702262), (698, 0.0013171153138368807), (483, 0.0012974283300616082), (3830, 0.0011844348977671688), (376, 0.0009014073664792464), (2047, 0.000841029154597401), (56, 0.0008039024292749443), (25, 0.000800412660519768), (828, 0.0007886905420662135), (322, 0.0007867992190291396),......]  The above IDs are for the most influential users.
We can see the subgraph for the most influential user:
first_degree_connected_nodes = list(fb.neighbors(3437)) second_degree_connected_nodes = [] for x in first_degree_connected_nodes: second_degree_connected_nodes&#43;=list(fb.neighbors(x)) second_degree_connected_nodes.remove(3437) second_degree_connected_nodes = list(set(second_degree_connected_nodes)) subgraph_3437 = nx.subgraph(fb,first_degree_connected_nodes&#43;second_degree_connected_nodes) pos = nx.spring_layout(subgraph_3437) node_color = [&amp;#39;yellow&amp;#39; if v == 3437 else &amp;#39;red&amp;#39; for v in subgraph_3437] node_size = [1000 if v == 3437 else 35 for v in subgraph_3437] plt.style.use(&amp;#39;fivethirtyeight&amp;#39;) plt.rcParams[&amp;#39;figure.figsize&amp;#39;] = (20, 15) plt.axis(&amp;#39;off&amp;#39;) nx.draw_networkx(subgraph_3437, pos, with_labels = False, node_color=node_color,node_size=node_size ) plt.show() 5. Centrality Measures There are a lot of centrality measures which you can use as features to your machine learning models. I will talk about two of them. You can look at other measures here.
Betweenness Centrality: It is not only the users who have the most friends that are important, the users who connect one geography to another are also important as that lets users see content from diverse geographies. Betweenness centrality quantifies how many times a particular node comes in the shortest chosen path between two other nodes.
Degree Centrality: It is simply the number of connections for a node.
Applications Centrality measures can be used as a feature in any machine learning model.
Code Here is the code for finding the Betweenness centrality for the subgraph.
pos = nx.spring_layout(subgraph_3437) betweennessCentrality = **nx.betweenness_centrality(**subgraph_3437**,normalized=True, endpoints=True)** node_size = [v * 10000 for v in betweennessCentrality.values()] plt.figure(figsize=(20,20)) nx.draw_networkx(subgraph_3437, pos=pos, with_labels=False, node_size=node_size ) plt.axis(&amp;#39;off&amp;#39;) You can see the nodes sized by their betweenness centrality values here. They can be thought of as information passers. Breaking any of the nodes with a high betweenness Centrality will break the graph into many parts.
Conclusion In this post, I talked about some of the most influential graph algorithms that have changed the way we live.
With the advent of so much social data, network analysis could help a lot in improving our models and generating value.
And even understanding a little more about the world.
There are a lot of graph algorithms out there, but these are the ones I like the most. Do look into the algorithms in more detail if you like. In this post, I just wanted to get the required breadth into the area.
Let me know if you feel I have left your favorite algorithm in the comments.
Here is the Kaggle Kernel with the whole code.
If you want to read up more on Graph Algorithms here is a Graph Analytics for Big Data course on Coursera by UCSanDiego which I highly recommend to learn the basics of graph theory.
Thanks for the read. I am going to be writing more beginner-friendly posts in the future too. Follow me up at Medium or Subscribe to my blog.
]]>
        
      </content:encoded>
      
      
      
    </item>
    

    <item>
      <title>To all Data Scientists - The one Graph Algorithm you need to know</title>
      <link>https://mlwhiz.com/blog/2018/12/07/connected_components/</link>
      <pubDate>Fri, 07 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://mlwhiz.com/blog/2018/12/07/connected_components/</guid>
      
      
      <media:content type="image/jpeg" medium="image" width="700" height="400"
      url="https://mlwhiz.comhttps://upload.wikimedia.org/wikipedia/commons/8/85/Pseudoforest.svg"></media:content>
      

      
      <description>Graphs provide us with a very useful data structure. They can help us to find structure within our data. With the advent of Machine learning and big data we need to get as much information as possible about our data. Learning a little bit of graph theory can certainly help us with that.
Here is a Graph Analytics for Big Data course on Coursera by UCSanDiego which I highly recommend to learn the basics of graph theory.</description>

      <content:encoded>  
        
        <![CDATA[  Graphs provide us with a very useful data structure. They can help us to find structure within our data. With the advent of Machine learning and big data we need to get as much information as possible about our data. Learning a little bit of graph theory can certainly help us with that.
Here is a Graph Analytics for Big Data course on Coursera by UCSanDiego which I highly recommend to learn the basics of graph theory. You can start for free with the 7-day Free Trial.
One of the algorithms I am going to focus in the current post is called Connected Components. Why it is important. We all know clustering.
You can think of Connected Components in very layman&amp;rsquo;s terms as sort of a hard clustering algorithm which finds clusters/islands in related/connected data. As a concrete example: Say you have data about roads joining any two cities in the world. And you need to find out all the continents in the world and which city they contain.
How will you achieve that? Come on give some thought.
To put a Retail Perspective: Lets say, we have a lot of customers using a lot of accounts. One way in which we can use the Connected components algorithm is to find out distinct families in our dataset. We can assume edges(roads) between CustomerIDs based on same credit card usage, or same address or same mobile number etc. Once we have those connections, we can then run the connected component algorithm on the same to create individual clusters to which we can then assign a family ID. We can use these family IDs to provide personalized recommendations based on a family needs. We can also use this family ID to fuel our classification algorithms by creating grouped features based on family.
In Finance Perspective: Another use case would be to capture fraud using these family IDs. If an account has done fraud in past, it is highly probable that the connected accounts are also susceptible to fraud.
So enough of use cases. Lets start with a simple graph class written in Python to start up our exploits with code.
This post will revolve more around code from here onwards.
&amp;#34;&amp;#34;&amp;#34; A Python Class A simple Python graph class, demonstrating the essential facts and functionalities of graphs. Taken from https://www.python-course.eu/graphs_python.php Changed the implementation a little bit to include weighted edges &amp;#34;&amp;#34;&amp;#34; class Graph(object): def __init__(self, graph_dict=None): &amp;#34;&amp;#34;&amp;#34; initializes a graph object If no dictionary or None is given, an empty dictionary will be used &amp;#34;&amp;#34;&amp;#34; if graph_dict == None: graph_dict = {} self.__graph_dict = graph_dict def vertices(self): &amp;#34;&amp;#34;&amp;#34; returns the vertices of a graph &amp;#34;&amp;#34;&amp;#34; return list(self.__graph_dict.keys()) def edges(self): &amp;#34;&amp;#34;&amp;#34; returns the edges of a graph &amp;#34;&amp;#34;&amp;#34; return self.__generate_edges() def add_vertex(self, vertex): &amp;#34;&amp;#34;&amp;#34; If the vertex &amp;#34;vertex&amp;#34; is not in self.__graph_dict, a key &amp;#34;vertex&amp;#34; with an empty dict as a value is added to the dictionary. Otherwise nothing has to be done. &amp;#34;&amp;#34;&amp;#34; if vertex not in self.__graph_dict: self.__graph_dict[vertex] = {} def add_edge(self, edge,weight=1): &amp;#34;&amp;#34;&amp;#34; assumes that edge is of type set, tuple or list &amp;#34;&amp;#34;&amp;#34; edge = set(edge) (vertex1, vertex2) = tuple(edge) if vertex1 in self.__graph_dict: self.__graph_dict[vertex1][vertex2] = weight else: self.__graph_dict[vertex1] = {vertex2:weight} if vertex2 in self.__graph_dict: self.__graph_dict[vertex2][vertex1] = weight else: self.__graph_dict[vertex2] = {vertex1:weight} def __generate_edges(self): &amp;#34;&amp;#34;&amp;#34; A static method generating the edges of the graph &amp;#34;graph&amp;#34;. Edges are represented as sets with one (a loop back to the vertex) or two vertices &amp;#34;&amp;#34;&amp;#34; edges = [] for vertex in self.__graph_dict: for neighbour,weight in self.__graph_dict[vertex].iteritems(): if (neighbour, vertex, weight) not in edges: edges.append([vertex, neighbour, weight]) return edges def __str__(self): res = &amp;#34;vertices: &amp;#34; for k in self.__graph_dict: res &#43;= str(k) &#43; &amp;#34; &amp;#34; res &#43;= &amp;#34;\nedges: &amp;#34; for edge in self.__generate_edges(): res &#43;= str(edge) &#43; &amp;#34; &amp;#34; return res def adj_mat(self): return self.__graph_dict You can certainly play with our new graph class.Here we try to build some graphs.
g = { &amp;#34;a&amp;#34; : {&amp;#34;d&amp;#34;:2}, &amp;#34;b&amp;#34; : {&amp;#34;c&amp;#34;:2}, &amp;#34;c&amp;#34; : {&amp;#34;b&amp;#34;:5, &amp;#34;d&amp;#34;:3, &amp;#34;e&amp;#34;:5} } graph = Graph(g) print(&amp;#34;Vertices of graph:&amp;#34;) print(graph.vertices()) print(&amp;#34;Edges of graph:&amp;#34;) print(graph.edges()) print(&amp;#34;Add vertex:&amp;#34;) graph.add_vertex(&amp;#34;z&amp;#34;) print(&amp;#34;Vertices of graph:&amp;#34;) print(graph.vertices()) print(&amp;#34;Add an edge:&amp;#34;) graph.add_edge({&amp;#34;a&amp;#34;,&amp;#34;z&amp;#34;}) print(&amp;#34;Vertices of graph:&amp;#34;) print(graph.vertices()) print(&amp;#34;Edges of graph:&amp;#34;) print(graph.edges()) print(&amp;#39;Adding an edge {&amp;#34;x&amp;#34;,&amp;#34;y&amp;#34;} with new vertices:&amp;#39;) graph.add_edge({&amp;#34;x&amp;#34;,&amp;#34;y&amp;#34;}) print(&amp;#34;Vertices of graph:&amp;#34;) print(graph.vertices()) print(&amp;#34;Edges of graph:&amp;#34;) print(graph.edges()) Vertices of graph: [&#39;a&#39;, &#39;c&#39;, &#39;b&#39;] Edges of graph: [[&#39;a&#39;, &#39;d&#39;, 2], [&#39;c&#39;, &#39;b&#39;, 5], [&#39;c&#39;, &#39;e&#39;, 5], [&#39;c&#39;, &#39;d&#39;, 3], [&#39;b&#39;, &#39;c&#39;, 2]] Add vertex: Vertices of graph: [&#39;a&#39;, &#39;c&#39;, &#39;b&#39;, &#39;z&#39;] Add an edge: Vertices of graph: [&#39;a&#39;, &#39;c&#39;, &#39;b&#39;, &#39;z&#39;] Edges of graph: [[&#39;a&#39;, &#39;z&#39;, 1], [&#39;a&#39;, &#39;d&#39;, 2], [&#39;c&#39;, &#39;b&#39;, 5], [&#39;c&#39;, &#39;e&#39;, 5], [&#39;c&#39;, &#39;d&#39;, 3], [&#39;b&#39;, &#39;c&#39;, 2], [&#39;z&#39;, &#39;a&#39;, 1]] Adding an edge {&#34;x&#34;,&#34;y&#34;} with new vertices: Vertices of graph: [&#39;a&#39;, &#39;c&#39;, &#39;b&#39;, &#39;y&#39;, &#39;x&#39;, &#39;z&#39;] Edges of graph: [[&#39;a&#39;, &#39;z&#39;, 1], [&#39;a&#39;, &#39;d&#39;, 2], [&#39;c&#39;, &#39;b&#39;, 5], [&#39;c&#39;, &#39;e&#39;, 5], [&#39;c&#39;, &#39;d&#39;, 3], [&#39;b&#39;, &#39;c&#39;, 2], [&#39;y&#39;, &#39;x&#39;, 1], [&#39;x&#39;, &#39;y&#39;, 1], [&#39;z&#39;, &#39;a&#39;, 1]]  Lets do something interesting now.
We will use the above graph class for our understanding purpose. There are many Modules in python which we can use to do whatever I am going to do next,but to understand the methods we will write everything from scratch. Lets start with an example graph which we can use for our purpose.
  g = {&amp;#39;Frankfurt&amp;#39;: {&amp;#39;Mannheim&amp;#39;:85, &amp;#39;Wurzburg&amp;#39;:217, &amp;#39;Kassel&amp;#39;:173}, &amp;#39;Mannheim&amp;#39;: {&amp;#39;Frankfurt&amp;#39;:85, &amp;#39;Karlsruhe&amp;#39;:80}, &amp;#39;Karlsruhe&amp;#39;: {&amp;#39;Augsburg&amp;#39;:250, &amp;#39;Mannheim&amp;#39;:80}, &amp;#39;Augsburg&amp;#39;: {&amp;#39;Karlsruhe&amp;#39;:250, &amp;#39;Munchen&amp;#39;:84}, &amp;#39;Wurzburg&amp;#39;: {&amp;#39;Erfurt&amp;#39;:186, &amp;#39;Numberg&amp;#39;:103,&amp;#39;Frankfurt&amp;#39;:217}, &amp;#39;Erfurt&amp;#39;: {&amp;#39;Wurzburg&amp;#39;:186}, &amp;#39;Numberg&amp;#39;: {&amp;#39;Wurzburg&amp;#39;:103, &amp;#39;Stuttgart&amp;#39;:183,&amp;#39;Munchen&amp;#39;:167}, &amp;#39;Munchen&amp;#39;: {&amp;#39;Numberg&amp;#39;:167, &amp;#39;Augsburg&amp;#39;:84,&amp;#39;Kassel&amp;#39;:502}, &amp;#39;Kassel&amp;#39;: {&amp;#39;Frankfurt&amp;#39;:173, &amp;#39;Munchen&amp;#39;:502}, &amp;#39;Stuttgart&amp;#39;: {&amp;#39;Numberg&amp;#39;:183} } graph = Graph(g) print(&amp;#34;Vertices of graph:&amp;#34;) print(graph.vertices()) print(&amp;#34;Edges of graph:&amp;#34;) print(graph.edges()) Vertices of graph: [&#39;Mannheim&#39;, &#39;Erfurt&#39;, &#39;Munchen&#39;, &#39;Numberg&#39;, &#39;Stuttgart&#39;, &#39;Augsburg&#39;, &#39;Kassel&#39;, &#39;Frankfurt&#39;, &#39;Wurzburg&#39;, &#39;Karlsruhe&#39;] Edges of graph: [[&#39;Mannheim&#39;, &#39;Frankfurt&#39;, 85], [&#39;Mannheim&#39;, &#39;Karlsruhe&#39;, 80], [&#39;Erfurt&#39;, &#39;Wurzburg&#39;, 186], [&#39;Munchen&#39;, &#39;Numberg&#39;, 167], [&#39;Munchen&#39;, &#39;Augsburg&#39;, 84], [&#39;Munchen&#39;, &#39;Kassel&#39;, 502], [&#39;Numberg&#39;, &#39;Stuttgart&#39;, 183], [&#39;Numberg&#39;, &#39;Wurzburg&#39;, 103], [&#39;Numberg&#39;, &#39;Munchen&#39;, 167], [&#39;Stuttgart&#39;, &#39;Numberg&#39;, 183], [&#39;Augsburg&#39;, &#39;Munchen&#39;, 84], [&#39;Augsburg&#39;, &#39;Karlsruhe&#39;, 250], [&#39;Kassel&#39;, &#39;Munchen&#39;, 502], [&#39;Kassel&#39;, &#39;Frankfurt&#39;, 173], [&#39;Frankfurt&#39;, &#39;Mannheim&#39;, 85], [&#39;Frankfurt&#39;, &#39;Wurzburg&#39;, 217], [&#39;Frankfurt&#39;, &#39;Kassel&#39;, 173], [&#39;Wurzburg&#39;, &#39;Numberg&#39;, 103], [&#39;Wurzburg&#39;, &#39;Erfurt&#39;, 186], [&#39;Wurzburg&#39;, &#39;Frankfurt&#39;, 217], [&#39;Karlsruhe&#39;, &#39;Mannheim&#39;, 80], [&#39;Karlsruhe&#39;, &#39;Augsburg&#39;, 250]]  Lets say we are given a graph with the cities of Germany and respective distance between them. You want to find out how to go from Frankfurt (The starting node) to Munchen. There might be many ways in which you can traverse the graph but you need to find how many cities you will need to visit on a minimum to go from frankfurt to Munchen) This problem is analogous to finding out distance between nodes in an unweighted graph.
The algorithm that we use here is called as Breadth First Search.
def min_num_edges_between_nodes(graph,start_node): distance = 0 shortest_path = [] queue = [start_node] #FIFO levels = {} levels[start_node] = 0 shortest_paths = {} shortest_paths[start_node] = &amp;#34;:&amp;#34; visited = [start_node] while len(queue)!=0: start = queue.pop(0) neighbours = graph[start] for neighbour,_ in neighbours.iteritems(): if neighbour not in visited: queue.append(neighbour) visited.append(neighbour) levels[neighbour] = levels[start]&#43;1 shortest_paths[neighbour] = shortest_paths[start] &#43;&amp;#34;-&amp;gt;&amp;#34;&#43; start return levels, shortest_paths What we do in the above piece of code is create a queue and traverse it based on levels. We start with Frankfurt as starting node. We loop through its neighbouring cities(Menheim, Wurzburg and Kassel) and push them into the queue. We keep track of what level they are at and also the path through which we reached them. Since we are popping a first element of a queue we are sure we will visit cities in the order of their level.
Checkout this good post about BFS to understand more about queues and BFS.
min_num_edges_between_nodes(g,&amp;#39;Frankfurt&amp;#39;) ({&#39;Augsburg&#39;: 3, &#39;Erfurt&#39;: 2, &#39;Frankfurt&#39;: 0, &#39;Karlsruhe&#39;: 2, &#39;Kassel&#39;: 1, &#39;Mannheim&#39;: 1, &#39;Munchen&#39;: 2, &#39;Numberg&#39;: 2, &#39;Stuttgart&#39;: 3, &#39;Wurzburg&#39;: 1}, {&#39;Augsburg&#39;: &#39;:-Frankfurt-Mannheim-Karlsruhe&#39;, &#39;Erfurt&#39;: &#39;:-Frankfurt-Wurzburg&#39;, &#39;Frankfurt&#39;: &#39;:&#39;, &#39;Karlsruhe&#39;: &#39;:-Frankfurt-Mannheim&#39;, &#39;Kassel&#39;: &#39;:-Frankfurt&#39;, &#39;Mannheim&#39;: &#39;:-Frankfurt&#39;, &#39;Munchen&#39;: &#39;:-Frankfurt-Kassel&#39;, &#39;Numberg&#39;: &#39;:-Frankfurt-Wurzburg&#39;, &#39;Stuttgart&#39;: &#39;:-Frankfurt-Wurzburg-Numberg&#39;, &#39;Wurzburg&#39;: &#39;:-Frankfurt&#39;})  I did this example to show how BFS algorithm works. We can extend this algorithm to find out connected components in an unconnected graph. Lets say we need to find groups of unconnected vertices in the graph.
For example: the below graph has 3 unconnected sub-graphs. Can we find what nodes belong to a particular subgraph?
  #We add another countries in the loop graph = Graph(g) graph.add_edge((&amp;#34;Mumbai&amp;#34;, &amp;#34;Delhi&amp;#34;),400) graph.add_edge((&amp;#34;Delhi&amp;#34;, &amp;#34;Kolkata&amp;#34;),500) graph.add_edge((&amp;#34;Kolkata&amp;#34;, &amp;#34;Bangalore&amp;#34;),600) graph.add_edge((&amp;#34;TX&amp;#34;, &amp;#34;NY&amp;#34;),1200) graph.add_edge((&amp;#34;ALB&amp;#34;, &amp;#34;NY&amp;#34;),800) g = graph.adj_mat() def bfs_connected_components(graph): connected_components = [] nodes = graph.keys() while len(nodes)!=0: start_node = nodes.pop() queue = [start_node] #FIFO visited = [start_node] while len(queue)!=0: start = queue[0] queue.remove(start) neighbours = graph[start] for neighbour,_ in neighbours.iteritems(): if neighbour not in visited: queue.append(neighbour) visited.append(neighbour) nodes.remove(neighbour) connected_components.append(visited) return connected_components print bfs_connected_components(g) The above code is similar to the previous BFS code. We keep all the vertices of the graph in the nodes list. We take a node from the nodes list and start BFS on it. as we visit a node we remove that node from the nodes list. Whenever the BFS completes we start again with another node in the nodes list until the nodes list is empty.
[[&#39;Kassel&#39;, &#39;Munchen&#39;, &#39;Frankfurt&#39;, &#39;Numberg&#39;, &#39;Augsburg&#39;, &#39;Mannheim&#39;, &#39;Wurzburg&#39;, &#39;Stuttgart&#39;, &#39;Karlsruhe&#39;, &#39;Erfurt&#39;], [&#39;Bangalore&#39;, &#39;Kolkata&#39;, &#39;Delhi&#39;, &#39;Mumbai&#39;], [&#39;NY&#39;, &#39;ALB&#39;, &#39;TX&#39;]]  As you can see we are able to find distinct components in our data. Just by using Edges and Vertices. This algorithm could be run on different data to satisfy any use case I presented above.
But Normally using Connected Components for a retail case will involve a lot of data and you will need to scale this algorithm.
Connected Components in PySpark Below is an implementation from this paper on Connected Components in MapReduce and Beyond from Google Research. Read the PPT to understand the implementation better. Some ready to use code for you.
def create_edges(line): a = [int(x) for x in line.split(&amp;#34; &amp;#34;)] edges_list=[] for i in range(0, len(a)-1): for j in range(i&#43;1 ,len(a)): edges_list.append((a[i],a[j])) edges_list.append((a[j],a[i])) return edges_list # adj_list.txt is a txt file containing adjacency list of the graph. adjacency_list = sc.textFile(&amp;#34;adj_list.txt&amp;#34;) edges_rdd = adjacency_list.flatMap(lambda line : create_edges(line)).distinct() def largeStarInit(record): a, b = record yield (a,b) yield (b,a) def largeStar(record): a, b = record t_list = list(b) t_list.append(a) list_min = min(t_list) for x in b: if a &amp;lt; x: yield (x,list_min) def smallStarInit(record): a, b = record if b&amp;lt;=a: yield (a,b) else: yield (b,a) def smallStar(record): a, b = record t_list = list(b) t_list.append(a) list_min = min(t_list) for x in t_list: if x!=list_min: yield (x,list_min) #Handle case for single nodes def single_vertex(line): a = [int(x) for x in line.split(&amp;#34; &amp;#34;)] edges_list=[] if len(a)==1: edges_list.append((a[0],a[0])) return edges_list iteration_num =0 while 1==1: if iteration_num==0: print &amp;#34;iter&amp;#34;, iteration_num large_star_rdd = edges_rdd.groupByKey().flatMap(lambda x : largeStar(x)) small_star_rdd = large_star_rdd.flatMap(lambda x : smallStarInit(x)).groupByKey().flatMap(lambda x : smallStar(x)).distinct() iteration_num &#43;= 1 else: print &amp;#34;iter&amp;#34;, iteration_num large_star_rdd = small_star_rdd.flatMap(lambda x: largeStarInit(x)).groupByKey().flatMap(lambda x : largeStar(x)).distinct() small_star_rdd = large_star_rdd.flatMap(lambda x : smallStarInit(x)).groupByKey().flatMap(lambda x : smallStar(x)).distinct() iteration_num &#43;= 1 #check Convergence changes = (large_star_rdd.subtract(small_star_rdd).union(small_star_rdd.subtract(large_star_rdd))).collect() if len(changes) == 0 : break single_vertex_rdd = adjacency_list.flatMap(lambda line : single_vertex(line)).distinct() answer = single_vertex_rdd.collect() &#43; large_star_rdd.collect() print answer[:10] Or Use GraphFrames in PySpark To Install graphframes:
I ran on command line: pyspark &amp;ndash;packages graphframes:graphframes:0.5.0-spark2.1-s_2.11 which opened up my notebook and installed graphframes after i try to import in my notebook.
The string to be formatted as : graphframes:(latest version)-spark(your spark version)-s_(your scala version).
Checkout this guide on how to use GraphFrames for more information.
from graphframes import * def vertices(line): vert = [int(x) for x in line.split(&amp;#34; &amp;#34;)] return vert vertices = adjacency_list.flatMap(lambda x: vertices(x)).distinct().collect() vertices = sqlContext.createDataFrame([[x] for x in vertices], [&amp;#34;id&amp;#34;]) def create_edges(line): a = [int(x) for x in line.split(&amp;#34; &amp;#34;)] edges_list=[] if len(a)==1: edges_list.append((a[0],a[0])) for i in range(0, len(a)-1): for j in range(i&#43;1 ,len(a)): edges_list.append((a[i],a[j])) edges_list.append((a[j],a[i])) return edges_list edges = adjacency_list.flatMap(lambda x: create_edges(x)).distinct().collect() edges = sqlContext.createDataFrame(edges, [&amp;#34;src&amp;#34;, &amp;#34;dst&amp;#34;]) g = GraphFrame(vertices, edges) sc.setCheckpointDir(&amp;#34;.&amp;#34;) # graphframes uses the same paper we referenced apparently cc = g.connectedComponents() print cc.show() The GraphFrames library implements the CC algorithm as well as a variety of other graph algorithms.
The above post was a lot of code but hope it was helpful. It took me a lot of time to implement the algorithm so wanted to make it easy for the folks.
If you want to read up more on Graph Algorithms here is an Graph Analytics for Big Data course on Coursera by UCSanDiego which I highly recommend to learn the basics of graph theory.
References  Graphs in Python A Gentle Intoduction to Graph Theory Blog Graph Analytics for Big Data course on Coursera by UCSanDiego  ]]>
        
      </content:encoded>
      
      
      
    </item>
    
  </channel>
</rss>