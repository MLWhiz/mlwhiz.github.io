<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-NMQD44T');</script>
  <!-- End Google Tag Manager -->

  <meta charset="utf-8">
  <title>The story of every distribution - Discrete Distributions</title>
  <meta name="author" content="Rahul Agarwal">
  <meta name="description" content="Distributions play an important role in the life of every Statistician. I coming from a non-statistic background am not so well versed in these and keep forgetting about the properties of these famous distributions. That is why I chose to write my own understanding in an intuitive way to keep ..." >
  <meta name="keywords" content="distributions, pdf, cdf, expected value, variance, binomial,poisson, geometric, cdf proof, pdf proof, story, expected value proof" >

<!-- OpenGraph protocol tags: http://ogp.me/ -->
<!-- originally adopted to be used for: https://blog.kmonsoor.com -->
<meta property="og:site_name" content="mlwhiz" />
<meta property="og:type" content="article" />
    
<meta property="og:title" content="The story of every distribution - Discrete Distributions" />
<meta property="og:url" content="https://mlwhiz.com/blog/2017/09/14/discrete_distributions/" />
<meta property="og:description" content="Distributions play an important role in the life of every Statistician. I coming from a non-statistic background am not so well versed in these and keep forgetting about the properties of these famous distributions. That is why I chose to write my own understanding in an intuitive way to keep ..." />

<meta name="twitter:image" content="https://mlwhiz.com" />

<meta property="article:published_time" content="2017-09-14 04:43:00" />
<!-- End of OpenGraph protocol tags -->


<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:title" content="The story of every distribution - Discrete Distributions" />
<meta property="twitter:description" content="Distributions play an important role in the life of every Statistician. I coming from a non-statistic background am not so well versed in these and keep forgetting about the properties of these famous distributions. That is why I chose to write my own understanding in an intuitive way to keep ..." />
<meta property="twitter:url" content="https://mlwhiz.com/blog/2017/09/14/discrete_distributions/" />
<meta name="twitter:image" content="https://mlwhiz.com" />


  <link href="http://mlwhiz.com/atom.xml" type="application/atom+xml" rel="alternate"
        title="mlwhiz Atom Feed" />
  <link href="http://mlwhiz.com/feed.rss" type="application/rss+xml" rel="alternate"
        title="mlwhiz RSS Feed" />


<link rel="canonical" href="https://mlwhiz.com/blog/2017/09/14/discrete_distributions/"/>

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <link href="https://mlwhiz.com/favicon.png" rel="icon">
  <link href="https://mlwhiz.com/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">
      <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro" rel="stylesheet" type="text/css">
 <link href="https://mlwhiz.com/theme/css/custom.css"
        rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="https://mlwhiz.com/theme/highlight/styles/atelier-dune.dark.css">

  <script src="https://mlwhiz.com/theme/js/modernizr-2.0.js"></script>
  <script src="https://mlwhiz.com/theme/js/ender.js"></script>
  <script src="https://mlwhiz.com/theme/js/octopress.js" type="text/javascript"></script>

  <script src="https://mlwhiz.com/theme/highlight/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">

  <!--added buttons to share....-->

<!-- BEGIN SHAREAHOLIC CODE -->
<link rel='preload' href='//apps.shareaholic.com/assets/pub/shareaholic.js' as='script' />
<script type="text/javascript" data-cfasync="false" async src="//apps.shareaholic.com/assets/pub/shareaholic.js" data-shr-siteid="fd1ffa7fd7152e4e20568fbe49a489d0"></script>

<!-- END SHAREAHOLIC CODE -->
<!--
  <script src="//load.sumome.com/" data-sumo-site-id="22863fd8ad7ebbfab9b8ca60b7db8f65e9a15559f384f785f66903e365aa8f48" async="async"></script>
 --> 
<!--
  <script type='text/javascript' src='//platform-api.sharethis.com/js/sharethis.js#property=5a1bdf9806d3310011e61348&product=sticky-share-buttons' async='async'></script>
-->


<!-- SUMO CODE FOR EMAILS-->
  <script async>(function(s,u,m,o,j,v){j=u.createElement(m);v=u.getElementsByTagName(m)[0];j.async=1;j.src=o;j.dataset.sumoSiteId='22863fd8ad7ebbfab9b8ca60b7db8f65e9a15559f384f785f66903e365aa8f48';v.parentNode.insertBefore(j,v)})(window,document,'script','//load.sumo.com/');</script>


</head>

<body>
  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NMQD44T"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->
  <header role="banner"><hgroup>
  <h1><a href="https://mlwhiz.com/">mlwhiz</a></h1>
    <h2>Deep Learning, Data Science and NLP Enthusiast</h2>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="http://mlwhiz.com/atom.xml" rel="subscribe-atom">Atom</a></li>

</ul>


<form onsubmit="this['q'].value = this['q_raw'].value + ' site:mlwhiz.com';" method="get" action="https://google.com/search">
  <fieldset role="search">
	<input type="hidden" value="" name="q">
	<input class="search" type="text" placeholder="Search" results="0" name="q_raw">
  </fieldset>

</form>

<ul class="main-navigation">
    <li><a href="http://mlwhiz.com">Blog</a></li>
    <li><a href="http://mlwhiz.com/archives.html">Archives</a></li>
    <li><a href="http://mlwhiz.com/pages/about.html">About</a></li>
    <li><a href="http://mlwhiz.com/pages/links.html">Great Links</a></li>
  
</ul></nav>
  <div id="main">
    <div id="content">

<div>
  <article class="hentry" role="article">

<header>
      <h1 class="entry-title">The story of every distribution - Discrete Distributions</h1>
      <p class="meta"><time datetime="2017-09-14T04:43:00" pubdate>Sep 14, 2017</time></p>
</header>

  <div class="entry-content"><p>Distributions play an important role in the life of every Statistician. I coming from a non-statistic background am not so well versed in these and keep forgetting about the properties of these famous distributions. That is why I chose to write my own understanding in an intuitive way to keep a track.
One of the most helpful way to learn more about these is the <a href="https://projects.iq.harvard.edu/stat110/home">STAT110</a> course by Joe Blitzstein and his <a href="http://amzn.to/2xAsYzE">book</a>. You can check out this <a href="https://www.coursera.org/specializations/statistics?siteID=lVarvwc5BD0-1nQtJg8.ENATqSUIufAaaw&amp;utm_content=2&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0">Coursera</a> course too. Hope it could be useful to someone else too. So here goes:</p>
<h2>1. Bernoulli Distribution:</h2>
<p>Perhaps the most simple discrete distribution of all.</p>
<p><strong>Story:</strong> A Coin is tossed with probability p of heads.</p>
<p><strong>PMF of Bernoulli Distribution is given by:</strong></p>
<p>
<div class="math">$$P(X=k) = \begin{cases}1-p &amp; k = 0\\p &amp; k = 1\end{cases}$$</div>
</p>
<p><strong>CDF of Bernoulli Distribution is given by:</strong></p>
<p>
<div class="math">$$P(X&lt;=k) = \begin{cases}0 &amp; k &lt; 0\\1-p &amp; 0=&lt;k&lt;1 \\1 &amp; k &gt;= 1\end{cases}$$</div>
</p>
<p><strong> Expected Value:</strong></p>
<p>
<div class="math">$$E[X] = \sum kP(X=k)$$</div>
<div class="math">$$E[X] = 0*P(X=0)+1*P(X=1) = p$$</div>
</p>
<p><strong> Variance:</strong></p>
<p>
<div class="math">$$Var[X] = E[X^2] - E[X]^2$$</div>
Now we find,
<div class="math">$$E[X]^2 = p^2$$</div>
and
<div class="math">$$E[X^2] = \sum k^2P(X=k)$$</div>
<div class="math">$$E[X^2] =  0^2P(X=0) + 1^2P(X=1) = p $$</div>
Thus,
<div class="math">$$Var[X] = p(1-p)$$</div>
</p>
<h2>2. Binomial Distribution:</h2>
<div style="margin-top: 9px; margin-bottom: 10px;">
<center><img src="/images/maxresdefault.jpg"  height="400" width="500" ></center>
</div>

<p>One of the most basic distribution in the Statistician toolkit. The parameters of this distribution is n(number of trials) and p(probability of success).</p>
<p><strong>Story:</strong>
Probability of getting exactly k successes in n trials</p>
<p><strong>PMF of binomial Distribution is given by:</strong></p>
<p>
<div class="math">$$P(X=k) = \left(\begin{array}{c}n\\ k\end{array}\right) p^{k}(1-p)^{n-k}$$</div>
</p>
<p><strong>CDF of binomial Distribution is given by:</strong></p>
<p>
<div class="math">$$ P(X\leq k) = \sum_{i=0}^k  \left(\begin{array}{c}n\\ i\end{array}\right)  p^i(1-p)^{n-i} $$</div>
</p>
<p><strong> Expected Value:</strong></p>
<p>
<div class="math">$$E[X] = \sum kP(X=k)$$</div>
<div class="math">$$E[X] = \sum_{k=0}^n k \left(\begin{array}{c}n\\ k\end{array}\right) * p^{k}(1-p)^{n-k} = np $$</div>
</p>
<p>A better way to solve this:</p>
<p>
<div class="math">$$ X = I_{1} + I_{2} + ....+ I_{n-1}+ I_{n} $$</div>
</p>
<p>X is the sum on n Indicator Bernoulli random variables.</p>
<p>Thus,</p>
<p>
<div class="math">$$E[X] = E[I_{1} + I_{2} + ....+ I_{n-1}+ I_{n}]$$</div>
<div class="math">$$E[X] = E[I_{1}] + E[I_{2}] + ....+ E[I_{n-1}]+ E[I_{n}]$$</div>
<div class="math">$$E[X] = \underbrace{p + p + ....+ p + p}_{n} = np$$</div>
</p>
<p><strong> Variance:</strong></p>
<p>
<div class="math">$$ X = I_{1} + I_{2} + ....+ I_{n-1}+ I_{n} $$</div>
X is the sum on n Indicator Bernoulli random variables.
<div class="math">$$Var[X] = Var[I_{1} + I_{2} + ....+ I_{n-1}+ I_{n}]$$</div>
<div class="math">$$Var[X] = Var[I_{1}] + Var[I_{2}] + ....+ Var[I_{n-1}]+ Var[I_{n}]$$</div>
<div class="math">$$Var[X] = \underbrace{p(1-p) + p(1-p) + ....+ p(1-p) + p(1-p)}_{n} = np(1-p)$$</div>
</p>
<h2>3. Geometric Distribution:</h2>
<p>The parameters of this distribution is p(probability of success).</p>
<p><strong>Story:</strong>
The number of failures before the first success(Heads) when a coin with probability p is tossed</p>
<p><strong>PMF of Geometric Distribution is given by:</strong></p>
<p>
<div class="math">$$P(X=k) = (1-p)^kp$$</div>
</p>
<p><strong>CDF of Geometric Distribution is given by:</strong></p>
<p>
<div class="math">$$ P(X\leq k) = \sum_{i=0}^k (1-p)^{i}p$$</div>
<div class="math">$$ P(X\leq k) = p(1+q+q^2...+q^k)= p(1-q^k)/(1-q) = 1-(1-p)^k $$</div>
</p>
<p><strong> Expected Value:</strong></p>
<p>
<div class="math">$$E[X] = \sum kP(X=k)$$</div>
<div class="math">$$E[X] = \sum_{k=0}^{inf} k (1-p)^kp$$</div>
<div class="math">$$E[X] = qp +2q^2p +3q^3p +4q^4p .... $$</div>
<div class="math">$$E[X] = qp(1+2q+3q^2+4q^3+....)$$</div>
<div class="math">$$E[X] = qp/(1-q)^2 = q/p $$</div>
</p>
<p><strong> Variance:</strong></p>
<p>
<div class="math">$$Var[X] = E[X^2] - E[X]^2$$</div>
Now we find,
<div class="math">$$E[X]^2 = q^2/p^2$$</div>
and
<div class="math">$$E[X^2] = \sum_0^k k^2q^kp= qp + 4q^2p + 9q^3p +16q^4p ... = qp(1+4q+9q^2+16q^3....)$$</div>
<div class="math">$$E[X^2] = qp^{-2}(1+q)$$</div>
</p>
<p>Thus,
<div class="math">$$Var[X] =q/p^2$$</div>
</p>
<p>Check Math appendix at bottom of this post for Geometric Series Proofs.</p>
<p><strong> Example:</strong></p>
<p>Q. A doctor is seeking an anti-depressant for a newly diagnosed patient. Suppose that, of the available anti-depressant drugs, the probability that any particular drug will be effective for a particular patient is p=0.6. What is the probability that the first drug found to be effective for this patient is the first drug tried, the second drug tried, and so on? What is the expected number of drugs that will be tried to find one that is effective?</p>
<p>A. Expected number of drugs that will be tried to find one that is effective = q/p = .4/.6 =.67</p>
<h2>4. Negative Binomial Distribution:</h2>
<p>The parameters of this distribution is p(probability of success) and r(number of success).</p>
<p><strong>Story:</strong>
The <strong>number of failures</strong> of independent Bernoulli(p) trials before the rth success.</p>
<p><strong>PMF of Negative Binomial Distribution is given by:</strong></p>
<p>r successes , k failures , last attempt needs to be a success:
<div class="math">$$P(X=k) = \left(\begin{array}{c}k+r-1\\ k\end{array}\right) p^r(1-p)^k$$</div>
</p>
<p><strong> Expected Value:</strong></p>
<p>The negative binomial RV could be stated as the sum of r Geometric RVs
<div class="math">$$X = X^1+X^2.... X^{r-1} +X^r$$</div>
Thus,
<div class="math">$$E[X] = E[X^1]+E[X^2].... E[X^{r-1}] +E[X^r]$$</div>
</p>
<p>
<div class="math">$$E[X] = rq/p$$</div>
</p>
<p><strong> Variance:</strong></p>
<p>The negative binomial RV could be stated as the sum of r independent Geometric RVs
<div class="math">$$X = X^1+X^2.... X^{r-1} +X^r$$</div>
Thus,
<div class="math">$$Var[X] = Var[X^1]+Var[X^2].... Var[X^{r-1}] +Var[X^r]$$</div>
</p>
<p>
<div class="math">$$E[X] = rq/p^2$$</div>
</p>
<p><strong> Example:</strong></p>
<p>Q. Pat is required to sell candy bars to raise money for the 6th grade field trip. There are thirty houses in the neighborhood, and Pat is not supposed to return home until five candy bars have been sold. So the child goes door to door, selling candy bars. At each house, there is a 0.4 probability of selling one candy bar and a 0.6 probability of selling nothing.
What's the probability of selling the last candy bar at the nth house?</p>
<p>A. r = 5 ; k = n - r</p>
<p>Probability of selling the last candy bar at the nth house =
<div class="math">$$P(X=k) = \left(\begin{array}{c}k+r-1\\ k\end{array}\right) p^r(1-p)^k$$</div>
<div class="math">$$P(X=k) = \left(\begin{array}{c}n-1\\ n-5\end{array}\right) .4^5(.6)^{n-5}$$</div>
</p>
<h2>5. Poisson Distribution:</h2>
<p>The parameters of this distribution is <span class="math">\(\lambda\)</span> the rate parameter.</p>
<p><strong>Motivation:</strong>
There is as such no story to this distribution but only motivation for using this distribution. The Poisson distribution is often used for applications where we count the successes of a large number of trials where the per-trial success rate is small. For example, the Poisson distribution is a good starting point for counting the number of people who email you over the course of an hour.The number of chocolate chips in a chocolate chip cookie is another good candidate for a Poisson distribution, or the number of earthquakes in a year in some particular region</p>
<p><strong>PMF of Poisson Distribution is given by:</strong>
<div class="math">$$ P(X=k) = \frac{e^{-\lambda}\lambda^k} {k!}$$</div>
</p>
<p><strong> Expected Value:</strong>
<div class="math">$$E[X] = \sum kP(X=k)$$</div>
<div class="math">$$ E[X] = \sum_{k=0}^{inf} k \frac{e^{-\lambda}\lambda^k} {k!}$$</div>
<div class="math">$$ E[X] = \lambda e^{-\lambda}\sum_{k=0}^{inf}  \frac{\lambda^{k-1}} {(k-1)!}$$</div>
<div class="math">$$ E[X] = \lambda e^{-\lambda} e^{\lambda} = \lambda $$</div>
</p>
<p><strong> Variance:</strong>
<div class="math">$$Var[X] = E[X^2] - E[X]^2$$</div>
Now we find,
<div class="math">$$E[X]^2 = \lambda + \lambda^2$$</div>
Thus,
<div class="math">$$Var[X] = \lambda$$</div>
</p>
<p><strong> Example:</strong></p>
<p>Q. If electricity power failures occur according to a Poisson distribution with an average of 3 failures every twenty weeks, calculate the probability that there will not be more than one failure during a particular week?</p>
<p>A. Probability = P(X=0)+P(X=1) = $e^{-3/20} + e^{-3/20}3/20 = 23/20*e^{-3/20} $</p>
<p>Probability of selling the last candy bar at the nth house =
<div class="math">$$P(X=k) = \left(\begin{array}{c}k+r-1\\ k\end{array}\right) p^r(1-p)^k$$</div>
<div class="math">$$P(X=k) = \left(\begin{array}{c}n-1\\ n-5\end{array}\right) .4^5(.6)^{n-5}$$</div>
</p>
<h2>Math Appendix:</h2>
<p>Some Math (For Geometric Distribution) :</p>
<p>
<div class="math">$$a+ar+ar^2+ar^3+⋯=a/(1−r)=a(1−r)^{−1}$$</div>
Taking the derivatives of both sides, the first derivative with respect to r must be:
<div class="math">$$a+2ar+3ar^2+4ar^3⋯=a(1−r)^{−2}$$</div>
Multiplying above with r:
<div class="math">$$ar+2ar^2+3ar^3+4ar^4⋯=ar(1−r)^{−2}$$</div>
Taking the derivatives of both sides, the first derivative with respect to r must be:
<div class="math">$$a+4ar+9ar^2+16ar^3⋯=a(1−r)^{-3}(1+r)$$</div>
</p>
<h2>Bonus - Python Graphs and Functions:</h2>
<pre style="font-size:60%; padding:7px; margin:0em;">
<code class="python"># Useful Function to create graph
def chart_creator(x,y,title):
    import matplotlib.pyplot as plt  #sets up plotting under plt
    import seaborn as sns           #sets up styles and gives us more plotting options
    import pandas as pd             #lets us handle data as dataframes
    %matplotlib inline
    # Create a list of 100 Normal RVs
    data = pd.DataFrame(zip(x,y))
    data.columns = ['x','y']
    # We dont Probably need the Gridlines. Do we? If yes comment this line
    sns.set(style="ticks")

    # Here we create a matplotlib axes object. The extra parameters we use
    # "ci" to remove confidence interval
    # "marker" to have a x as marker.
    # "scatter_kws" to provide style info for the points.[s for size]
    # "line_kws" to provide style info for the line.[lw for line width]

    g = sns.regplot(x='x', y='y', data=data, ci = False,
        scatter_kws={"color":"darkred","alpha":0.3,"s":90},
        line_kws={"color":"g","alpha":0.5,"lw":0},marker="x")

    # remove the top and right line in graph
    sns.despine()

    # Set the size of the graph from here
    g.figure.set_size_inches(12,8)
    # Set the Title of the graph from here
    g.axes.set_title(title, fontsize=34,color="r",alpha=0.5)
    # Set the xlabel of the graph from here
    g.set_xlabel("k",size = 67,color="r",alpha=0.5)
    # Set the ylabel of the graph from here
    g.set_ylabel("pmf",size = 67,color="r",alpha=0.5)
    # Set the ticklabel size and color of the graph from here
    g.tick_params(labelsize=14,labelcolor="black")
</code></pre>

<p>And here I will generate the PMFs of the discrete distributions we just discussed above using Pythons built in functions. For more details on the upper function, please see my previous post - <a href="http://mlwhiz.com/blog/2015/09/13/seaborn_visualizations/">Create basic graph visualizations with SeaBorn</a>. Also take a look at the <a href="https://docs.scipy.org/doc/scipy/reference/stats.html">documentation</a> guide for the below functions</p>
<pre style="font-size:60%; padding:7px; margin:0em;">
<code class="python"># Binomial :
from scipy.stats import binom
n=30
p=0.5
k = range(0,n)
pmf = binom.pmf(k, n, p)
chart_creator(k,pmf,"Binomial PMF")
</code></pre>

<div style="margin-top: 9px; margin-bottom: 10px;">
<center><img src="/images/output_12_0.png"  height="400" width="700" ></center>
</div>

<pre style="font-size:60%; padding:7px; margin:0em;">
<code class="python"># Geometric :
from scipy.stats import geom
n=30
p=0.5
k = range(0,n)
# -1 here is the location parameter for generating the PMF we want.
pmf = geom.pmf(k, p,-1)
chart_creator(k,pmf,"Geometric PMF")
</code></pre>

<div style="margin-top: 9px; margin-bottom: 10px;">
<center><img src="/images/output_13_0.png"  height="400" width="700" ></center>
</div>

<pre style="font-size:60%; padding:7px; margin:0em;">
<code class="python"># Negative Binomial :
from scipy.stats import nbinom
r=5 # number of successes
p=0.5 # probability of Success
k = range(0,25) # number of failures
# -1 here is the location parameter for generating the PMF we want.
pmf = nbinom.pmf(k, r, p)
chart_creator(k,pmf,"Nbinom PMF")
</code></pre>

<div style="margin-top: 9px; margin-bottom: 10px;">
<center><img src="/images/output_14_0.png"  height="400" width="700" ></center>
</div>

<pre style="font-size:60%; padding:7px; margin:0em;">
<code class="python">#Poisson
from scipy.stats import poisson
lamb = .3 # Rate
k = range(0,5)
pmf = poisson.pmf(k, lamb)
chart_creator(k,pmf,"Poisson PMF")
</code></pre>

<div style="margin-top: 9px; margin-bottom: 10px;">
<center><img src="/images/output_15_0.png"  height="400" width="700" ></center>
</div>

<h2>References:</h2>
<ol>
<li><a href="http://amzn.to/2xAsYzE">Introduction to Probability by Joe Blitzstein</a></li>
<li><a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution">Wikipedia</a></li>
</ol>
<p>Next thing I want to come up with is a same sort of post for continuous distributions too. Keep checking for the same. Till then Ciao.</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processClass: 'mathjax', " +
        "        ignoreClass: 'no-mathjax', " +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script></div>

<a href="https://click.linksynergy.com/fs-bin/click?id=lVarvwc5BD0&offerid=467035.415&subid=0&type=4"><IMG border="0"   alt="Deep Learning Specialization on Coursera" src="https://ad.linksynergy.com/fs-bin/show?id=lVarvwc5BD0&bids=467035.415&subid=0&type=4&gridnum=16"></a>    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">Rahul Agarwal</span>
  </span>
<time datetime="2017-09-14T04:43:00" pubdate>Sep 14, 2017</time>  <span class="categories">
    <a class="category" href="https://mlwhiz.com/tag/distributions.html">distributions</a>
    <a class="category" href="https://mlwhiz.com/tag/pdf.html">pdf</a>
    <a class="category" href="https://mlwhiz.com/tag/cdf.html">cdf</a>
    <a class="category" href="https://mlwhiz.com/tag/expected-value.html">expected value</a>
    <a class="category" href="https://mlwhiz.com/tag/variance.html">variance</a>
    <a class="category" href="https://mlwhiz.com/tag/binomial.html">binomial</a>
    <a class="category" href="https://mlwhiz.com/tag/poisson.html">poisson</a>
    <a class="category" href="https://mlwhiz.com/tag/geometric.html">geometric</a>
  </span>
  <br>
  <span style="font-size:14px;color:green">
  Advertiser Disclosure: All Amazon links are affiliate links, which means I receive compensation for any purchases through them. You do not have to purchase via my links, but you support me if you do.
  </span>
</p><div class="shareaholic-canvas" data-app="share_buttons" data-app-id="28372088"></div>

<!--
<div class="sharing">
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://mlwhiz.com/blog/2017/09/14/discrete_distributions/" data-via="MLWhiz" data-counturl="mlwhiz.com/blog/2017/09/14/discrete_distributions/" >Tweet</a>
  <div class="g-plusone" data-size="medium"></div>
    <div class="fb-like" data-send="true" data-width="450" data-show-faces="false"></div>
</div>
-->    </footer>
  </article>
  
  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div>
  </section>

</div>
<aside class="sidebar">
  <section>

     <!-- Bbuy coffee ko-fi Form -->
  <div style="text-align:center">    
  <a href='https://ko-fi.com/S6S3NPCD' target='_blank'><img height='36' style='border:0px;height:36px;' src='https://az743702.vo.msecnd.net/cdn/kofi4.png?v=0' border='0' alt='Buy Me a Coffee at ko-fi.com' /></a>
  </div>

    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/">NLP Learning Series: Text Preprocessing Methods for Deep Learning</a>
      </li>
      <li class="post">
          <a href="https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/">A Layman guide to moving from Keras to Pytorch</a>
      </li>
      <li class="post">
          <a href="https://mlwhiz.com/blog/2018/12/17/text_classification/">What Kagglers are using for Text Classification</a>
      </li>
      <li class="post">
          <a href="https://mlwhiz.com/blog/2018/12/07/connected_components/">To all Data Scientists - The one Graph Algorithm you need to know</a>
      </li>
      <li class="post">
          <a href="https://mlwhiz.com/blog/2018/09/22/object_detection/">Object Detection: An End to End Theoretical Perspective</a>
      </li>
      <li class="post">
          <a href="https://mlwhiz.com/blog/2017/12/28/hyperopt_tuning_ml_model/">Hyperopt - A bayesian Parameter Tuning Framework</a>
      </li>
      <li class="post">
          <a href="https://mlwhiz.com/blog/2017/12/26/How_to_win_a_data_science_competition/">Using XGBoost for time series prediction tasks</a>
      </li>
    </ul>
  </section>
<!--
  <section>

    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="https://mlwhiz.com/category/ai-deep-learningkaggle.html">ai, deep learning,kaggle</a></li>
        <li><a href="https://mlwhiz.com/category/ai-deep-learningkaggle-nlp.html">ai, deep learning,kaggle, NLP</a></li>
        <li><a href="https://mlwhiz.com/category/big-data.html">Big Data</a></li>
        <li><a href="https://mlwhiz.com/category/data-science-statistics-resources-learning-books-python-distributions-statistical-inference-hadoop-spark-deep-learning.html">Data Science, Statistics, Resources, Learning, Books, Python, Distributions, Statistical Inference, hadoop, spark, deep learning</a></li>
        <li><a href="https://mlwhiz.com/category/deep-learning-image.html">deep learning, image</a></li>
        <li><a href="https://mlwhiz.com/category/hadoop.html">Hadoop</a></li>
        <li><a href="https://mlwhiz.com/category/machine-learning-statistics-linear-regression.html">Machine Learning, Statistics, Linear Regression</a></li>
        <li><a href="https://mlwhiz.com/category/pyspark-python.html">pyspark, python</a></li>
        <li><a href="https://mlwhiz.com/category/python.html">Python</a></li>
        <li><a href="https://mlwhiz.com/category/python-bash-tools.html">Python, bash, tools</a></li>
        <li><a href="https://mlwhiz.com/category/python-flask-ml.html">Python, Flask, ML</a></li>
        <li><a href="https://mlwhiz.com/category/python-kaggle-coursera.html">Python, kaggle, coursera,</a></li>
        <li><a href="https://mlwhiz.com/category/python-machine-learning.html">Python, machine learning</a></li>
        <li><a href="https://mlwhiz.com/category/python-machine-learning-hyperopt-bayesian-xgboost.html">Python, machine learning, hyperopt, bayesian, xgboost</a></li>
        <li><a href="https://mlwhiz.com/category/python-machine-learning-probability.html">Python, machine learning, probability</a></li>
        <li><a href="https://mlwhiz.com/category/python-nlp-algorithms-kaggle.html">Python, NLP, Algorithms, Kaggle</a></li>
        <li><a href="https://mlwhiz.com/category/python-nlp-algorithms-kaggle-tilt.html">Python, NLP, Algorithms, Kaggle ,TILT</a></li>
        <li><a href="https://mlwhiz.com/category/python-statistics.html">Python, Statistics</a></li>
        <li><a href="https://mlwhiz.com/category/python-visualization-statistics.html">Python, Visualization, Statistics</a></li>
        <li><a href="https://mlwhiz.com/category/statistics.html">Statistics</a></li>
        <li><a href="https://mlwhiz.com/category/statisticsdata-science.html">statistics,data science</a></li>
        <li><a href="https://mlwhiz.com/category/statisticsprobability.html">statistics,probability</a></li>
        <li><a href="https://mlwhiz.com/category/vw.html">VW</a></li>
    </ul>
  </section>


  <section>
  <h1>Tags</h1>
    <a href="https://mlwhiz.com/tag/.html"></a>,    <a href="https://mlwhiz.com/tag/nlp.html">NLP</a>,    <a href="https://mlwhiz.com/tag/data-munging.html">data munging</a>,    <a href="https://mlwhiz.com/tag/attention-models-for-text.html">Attention models for text</a>,    <a href="https://mlwhiz.com/tag/data-science.html">data science</a>,    <a href="https://mlwhiz.com/tag/probability.html">probability</a>,    <a href="https://mlwhiz.com/tag/big-data.html">Big Data</a>,    <a href="https://mlwhiz.com/tag/cdf.html">cdf</a>,    <a href="https://mlwhiz.com/tag/dataframe.html">dataframe</a>,    <a href="https://mlwhiz.com/tag/deep-learning.html">deep learning</a>,    <a href="https://mlwhiz.com/tag/rcnn.html">rcnn</a>,    <a href="https://mlwhiz.com/tag/books.html">Books</a>,    <a href="https://mlwhiz.com/tag/ggplot2.html">ggplot2</a>,    <a href="https://mlwhiz.com/tag/text-classification.html">text classification</a>,    <a href="https://mlwhiz.com/tag/learning.html">learning</a>,    <a href="https://mlwhiz.com/tag/statistic.html">Statistic</a>,    <a href="https://mlwhiz.com/tag/bidirectional-rnn.html">bidirectional RNN</a>,    <a href="https://mlwhiz.com/tag/graph-algorithms.html">graph algorithms</a>,    <a href="https://mlwhiz.com/tag/distributions.html">distributions</a>,    <a href="https://mlwhiz.com/tag/hyperparameter-tuning.html">hyperparameter tuning</a>,    <a href="https://mlwhiz.com/tag/stanford-software-seaborn.html">stanford software seaborn</a>,    <a href="https://mlwhiz.com/tag/apache-spark.html">Apache Spark</a>,    <a href="https://mlwhiz.com/tag/statistics.html">Statistics</a>,    <a href="https://mlwhiz.com/tag/vw.html">vw</a>,    <a href="https://mlwhiz.com/tag/pairplot-seaborn.html">pairplot seaborn</a>,    <a href="https://mlwhiz.com/tag/bidirectional-gru-for-text.html">bidirectional GRU for text</a>,    <a href="https://mlwhiz.com/tag/seaborn.html">Seaborn</a>,    <a href="https://mlwhiz.com/tag/artificial-intelligence.html">artificial intelligence</a>,    <a href="https://mlwhiz.com/tag/hadoop.html">hadoop</a>,    <a href="https://mlwhiz.com/tag/categorical-data.html">categorical data</a>,    <a href="https://mlwhiz.com/tag/birnn.html">birnn</a>,    <a href="https://mlwhiz.com/tag/machine-learning.html">machine learning</a>,    <a href="https://mlwhiz.com/tag/deeplearning.html">deeplearning</a>,    <a href="https://mlwhiz.com/tag/geometric.html">geometric</a>,    <a href="https://mlwhiz.com/tag/pandas.html">pandas</a>,    <a href="https://mlwhiz.com/tag/resources.html">Resources</a>,    <a href="https://mlwhiz.com/tag/linear-regression.html">Linear Regression</a>,    <a href="https://mlwhiz.com/tag/object-detection.html">object detection</a>,    <a href="https://mlwhiz.com/tag/pyspark.html">Pyspark</a>,    <a href="https://mlwhiz.com/tag/python.html">python</a>,    <a href="https://mlwhiz.com/tag/faster-rcnn.html">faster rcnn</a>,    <a href="https://mlwhiz.com/tag/kaggle.html">Kaggle</a>,    <a href="https://mlwhiz.com/tag/matplotlib.html">Matplotlib</a>,    <a href="https://mlwhiz.com/tag/binomial.html">binomial</a>,    <a href="https://mlwhiz.com/tag/variance.html">variance</a>,    <a href="https://mlwhiz.com/tag/regplot.html">regplot</a>,    <a href="https://mlwhiz.com/tag/python-visualizations.html">Python Visualizations</a>,    <a href="https://mlwhiz.com/tag/spark.html">spark</a>,    <a href="https://mlwhiz.com/tag/cs109.html">cs109</a>,    <a href="https://mlwhiz.com/tag/bash-for-data-science.html">bash for data science</a>,    <a href="https://mlwhiz.com/tag/web-scraping.html">web scraping</a>,    <a href="https://mlwhiz.com/tag/basics.html">Basics</a>,    <a href="https://mlwhiz.com/tag/ctr.html">ctr</a>,    <a href="https://mlwhiz.com/tag/statistical-inference.html">Statistical Inference</a>,    <a href="https://mlwhiz.com/tag/expected-value.html">expected value</a>,    <a href="https://mlwhiz.com/tag/bidirectional-lstm-for-text.html">bidirectional LSTM for text</a>,    <a href="https://mlwhiz.com/tag/layman-explanations.html">Layman Explanations</a>,    <a href="https://mlwhiz.com/tag/mapreduce.html">mapreduce</a>,    <a href="https://mlwhiz.com/tag/slr.html">SLR</a>,    <a href="https://mlwhiz.com/tag/openshift.html">Openshift</a>,    <a href="https://mlwhiz.com/tag/mlr.html">MLR</a>,    <a href="https://mlwhiz.com/tag/pretrained-models.html">pretrained models</a>,    <a href="https://mlwhiz.com/tag/algorithms.html">Algorithms</a>,    <a href="https://mlwhiz.com/tag/poisson.html">poisson</a>,    <a href="https://mlwhiz.com/tag/bayesian-optimization.html">bayesian optimization</a>,    <a href="https://mlwhiz.com/tag/bash-commands.html">bash commands</a>,    <a href="https://mlwhiz.com/tag/pdf.html">pdf</a>,    <a href="https://mlwhiz.com/tag/deploy-ml-models.html">Deploy ML Models</a>,    <a href="https://mlwhiz.com/tag/lmplot-seaborn.html">lmplot seaborn</a>,    <a href="https://mlwhiz.com/tag/flaskapp.html">FlaskApp</a>  </section>
-->
<!--

    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="http://mlwhiz.com/feed.rss" type="application/rss+xml" rel="alternate">RSS</a></li>
            <li><a href="http://mlwhiz.com/atom.xml" type="application/atom+xml" rel="alternate">Atom</a></li>
            <li><a href="http://twitter.com/mlwhiz" target="_blank">twitter</a></li>
        </ul>
    </section>


<section>
    <a href="http://twitter.com/MLWhiz" class="twitter-follow-button" data-show-count="true">Follow @MLWhiz</a>
</section>
-->

  <section>




 <!-- Begin shareaholic follow -->
   <div class="shareaholic-canvas" data-app="follow_buttons" data-app-id="28033293" style="white-space: inherit;"></div>
  <!-- Begin MailChimp Signup Form -->
<link href="//cdn-images.mailchimp.com/embedcode/slim-10_7.css" rel="stylesheet" type="text/css">
<style type="text/css">
  #mc_embed_signup .button {background-color: #127edc;}
  #mc_embed_signup form {
    display: block;
    position: relative;
    text-align: left;
    padding: 10px -5px 10px 3%;}
  /* Add your own MailChimp form style overrides in your site stylesheet or in this style block.
     We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
<form action="//mlwhiz.us15.list-manage.com/subscribe/post?u=4e9962f4ce4a94818bcc2f249&amp;id=87a48fafdd" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
    <input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required>
    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_4e9962f4ce4a94818bcc2f249_87a48fafdd" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>
</section>
<!--End mc_embed_signup-->

</aside>    </div>
  </div>
  <footer role="contentinfo" style="margin-bottom:0em"><p>
  <script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&adInstanceId=93f2f4f9-cf51-415d-84af-08cbb74b178f"></script>
    Copyright &copy;  2014-2019  - Rahul Agarwal -
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p>  <script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&adInstanceId=93f2f4f9-cf51-415d-84af-08cbb74b178f"></script>
  </footer>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-54777926-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
	ga.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 'stats.g.doubleclick.net/dc.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-54777926-1');
    
    ga('send', 'pageview');
</script>
	<script type="text/javascript">
	  var disqus_shortname = 'mlwhiz';
          var disqus_identifier = '/blog/2017/09/14/discrete_distributions/';
          var disqus_url = 'https://mlwhiz.com/blog/2017/09/14/discrete_distributions/';
          var disqus_title = 'The story of every distribution - Discrete Distributions';
	  (function() {
	    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	    dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
	    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	   })();
	</script>
  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
	  
    })();
  </script>
  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>
<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>
</body>

</html>