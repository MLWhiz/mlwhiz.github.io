<!doctype html><html lang=en-us><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-F34XSWQ5N4"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-F34XSWQ5N4")</script><meta charset=utf-8><title>Today I Learned This Part 2: Pretrained Neural Networks What are they? - MLWhiz</title>
<meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content="Your Daily dose of data science.This is a series of post in which I write about the things I learn almost everyday. This post particularly provides a way to use pretrained neural nets for classifying images."><meta name=author content="Rahul Agarwal"><meta name=generator content="Hugo 0.139.2"><link rel=stylesheet href=https://mlwhiz.com/plugins/compressjscss/main.css><meta property="og:title" content="Today I Learned This Part 2: Pretrained Neural Networks What are they? - MLWhiz"><meta property="og:description" content="Your Daily dose of data science.This is a series of post in which I write about the things I learn almost everyday. This post particularly provides a way to use pretrained neural nets for classifying images."><meta property="og:type" content="article"><meta property="og:url" content="https://mlwhiz.com/blog/2017/04/17/deep_learning_pretrained_models/"><meta property="og:image" content="https://mlwhiz.com/images/category_bgs/default_bg.jpg"><meta property="og:image:secure_url" content="https://mlwhiz.com/images/category_bgs/default_bg.jpg"><meta property="article:published_time" content="2017-04-17T00:00:00+00:00"><meta property="article:modified_time" content="2020-09-26T16:23:35+05:30"><meta property="article:tag" content="Deep Learning"><meta property="article:tag" content="Computer Vision"><meta name=twitter:card content="summary"><meta name=twitter:image content="https://mlwhiz.com/images/category_bgs/default_bg.jpg"><meta name=twitter:title content="Today I Learned This Part 2: Pretrained Neural Networks What are they? - MLWhiz"><meta name=twitter:description content="Your Daily dose of data science.This is a series of post in which I write about the things I learn almost everyday. This post particularly provides a way to use pretrained neural nets for classifying images."><meta name=twitter:site content="@mlwhiz"><meta name=twitter:creator content="@mlwhiz"><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href=https://mlwhiz.com/scss/style.min.css media=screen><link rel=stylesheet href=/css/style.css><link rel=stylesheet type=text/css href=/css/font/flaticon.css><link rel="shortcut icon" href=https://mlwhiz.com/images/logos/favicon-32x32.png type=image/x-icon><link rel=icon href=https://mlwhiz.com/images/logos/favicon.ico type=image/x-icon><link rel=canonical href=https://mlwhiz.com/blog/2017/04/17/deep_learning_pretrained_models/><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js></script><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://www.mlwhiz.com/#website","url":"https://www.mlwhiz.com/","name":"MLWhiz","description":"Want to Learn Computer Vision and NLP? - MLWhiz","potentialAction":{"@type":"SearchAction","target":"https://www.mlwhiz.com/search?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://mlwhiz.com/blog/2017/04/17/deep_learning_pretrained_models/#primaryimage","url":"https://mlwhiz.com/images/category_bgs/default_bg.jpg","width":700,"height":450},{"@type":"WebPage","@id":"https://mlwhiz.com/blog/2017/04/17/deep_learning_pretrained_models/#webpage","url":"https://mlwhiz.com/blog/2017/04/17/deep_learning_pretrained_models/","inLanguage":"en-US","name":"Today I Learned This Part 2: Pretrained Neural Networks What are they? - MLWhiz","isPartOf":{"@id":"https://www.mlwhiz.com/#website"},"primaryImageOfPage":{"@id":"https://mlwhiz.com/blog/2017/04/17/deep_learning_pretrained_models/#primaryimage"},"datePublished":"2017-04-17T00:00:00.00Z","dateModified":"2020-09-26T16:23:35.00Z","author":{"@id":"https://mlwhiz.com/about/#/schema/person/76376876bchxkzbchjsdjcca"},"description":"Your Daily dose of data science.This is a series of post in which I write about the things I learn almost everyday. This post particularly provides a way to use pretrained neural nets for classifying images."},{"@type":["Person"],"@id":"https://mlwhiz.com/about/#/schema/person/76376876bchxkzbchjsdjcca","name":"Rahul Agarwal","image":{"@type":"ImageObject","@id":"https://www.mlwhiz.com/#authorlogo","url":"https://mlwhiz.com/images/author.jpg","caption":"Rahul Agarwal"},"description":"Hi there, I\u2019m Rahul Agarwal. I\u2019m a data scientist consultant and big data engineer based in Bangalore. I see a lot of times  students and even professionals wasting their time and struggling to get started with Computer Vision, Deep Learning, and NLP. I Started this Site with a purpose to augment my own understanding about new things while helping others learn about them in the best possible way.","sameAs":["https://www.linkedin.com/in/rahulagwl/","https://medium.com/@rahul_agarwal","https://twitter.com/MLWhiz","https://www.facebook.com/mlwhizblog","https://github.com/MLWhiz","https://www.instagram.com/itsmlwhiz"]}]}</script><script async data-uid=a0ebaf958d src=https://mlwhiz.ck.page/a0ebaf958d/index.js></script><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var e,t=MathJax.Hub.getAllJax();for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"}),MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:"AMS"}}})</script><link href=//apps.shareaholic.com/assets/pub/shareaholic.js as=script><script type=text/javascript data-cfasync=false async src=//apps.shareaholic.com/assets/pub/shareaholic.js data-shr-siteid=fd1ffa7fd7152e4e20568fbe49a489d0></script><script>!function(e,t,n,s,o,i,a){if(e.fbq)return;o=e.fbq=function(){o.callMethod?o.callMethod.apply(o,arguments):o.queue.push(arguments)},e._fbq||(e._fbq=o),o.push=o,o.loaded=!0,o.version="2.0",o.queue=[],i=t.createElement(n),i.async=!0,i.src=s,a=t.getElementsByTagName(n)[0],a.parentNode.insertBefore(i,a)}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js"),fbq("init","402633927768628"),fbq("track","PageView")</script><noscript><img height=1 width=1 style=display:none src="https://www.facebook.com/tr?id=402633927768628&ev=PageView&noscript=1"></noscript><meta property="fb:pages" content="213104036293742"><meta name=facebook-domain-verification content="qciidcy7mm137sewruizlvh8zbfnv4"><meta name=impact-site-verification value=1670148355></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NMQD44T" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><div class=preloader></div><header class=navigation><div class=container><nav class="navbar navbar-expand-lg navbar-white bg-transparent border-bottom pl-0"><a class="navbar-brand mobile-view" href=https://mlwhiz.com/><img class=img-fluid src=https://mlwhiz.com/images/logos/logo.svg alt="MLWhiz - Your Home for DS, ML, AI!"></a>
<button class="navbar-toggler border-0" type=button data-toggle=collapse data-target=#navigation>
<i class="ti-menu h3"></i></button><div class="collapse navbar-collapse text-center" id=navigation><div class=desktop-view><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href="https://linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&amp;followMember=rahulagwl"><i class=ti-linkedin></i></a></li><li class=nav-item><a class=nav-link href=https://mlwhiz.medium.com/><i class=ti-book></i></a></li><li class=nav-item><a class=nav-link href=https://twitter.com/MLWhiz><i class=ti-twitter-alt></i></a></li><li class=nav-item><a class=nav-link href=https://www.facebook.com/mlwhizblog><i class=ti-facebook></i></a></li><li class=nav-item><a class=nav-link href=https://github.com/MLWhiz><i class=ti-github></i></a></li></ul></div><a class="navbar-brand mx-auto desktop-view" href=https://mlwhiz.com/><img class=img-fluid-custom src=https://mlwhiz.com/images/logos/logo.svg alt="MLWhiz - Your Home for DS, ML, AI!"></a><ul class=navbar-nav><li class=nav-item><a class=nav-link href=https://mlwhiz.com/about>About</a></li><li class=nav-item><a class=nav-link href=https://mlwhiz.com/blog>Blog</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Topics</a><div class=dropdown-menu><a class=dropdown-item href=https://mlwhiz.com/categories/natural-language-processing>NLP</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/computer-vision>Computer Vision</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/deep-learning>Deep Learning</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/data-science>DS/ML</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/big-data>Big Data</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/awesome-guides>My Best Content</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/learning-resources>Learning Resources</a></div></li></ul><div class="search pl-lg-4"><button id=searchOpen class=search-btn><i class=ti-search></i></button><div class=search-wrapper><form action=https://mlwhiz.com//search class=h-100><input class="search-box px-4" id=search-query name=s type=search placeholder="Type & Hit Enter..."></form><button id=searchClose class=search-close><i class="ti-close text-dark"></i></button></div></div></div></nav></div></header><section class=section-sm><div class=container><div class=row><div class="col-lg-8 mb-5 mb-lg-0"><a href=/categories/deep-learning class=categoryStyle>Deep Learning</a>
<a href=/categories/computer-vision class=categoryStyle>Computer Vision</a><h1>Today I Learned This Part 2: Pretrained Neural Networks What are they?</h1><div class="mb-3 post-meta"><span>By Rahul Agarwal</span>
<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
<span>17 April 2017</span></div><img src=https://mlwhiz.com/images/category_bgs/default_bg.jpg class="img-fluid w-100 mb-4" alt="Today I Learned This Part 2: Pretrained Neural Networks What are they?"><div class="content mb-5"><p>Deeplearning is the buzz word right now. I was working on the
<a href=http://www.fast.ai/ target=_blank rel="nofollow noopener">course</a>
for deep learning by Jeremy Howard and one thing I noticed were pretrained deep Neural Networks. In the first lesson he used the pretrained NN to predict on the
<a href=https://www.kaggle.com/c/dogs-vs-cats target=_blank rel="nofollow noopener">Dogs vs Cats</a>
competition on Kaggle to achieve very good results.</p><h2 id=what-are-pretrained-neural-networks>What are pretrained Neural Networks?</h2><p>So let me tell you about the background a little bit. There is a challenge that happens every year in the visual recognition community - The Imagenet Challenge. The task there is to classify the images in 1000 categories using Image training data. People train big convolutional deep learning models for this challenge.</p><p>Now what does training a neural model actually mean? It just means that they learn the weights for a NN. What if we can get the weights they learn? We can use those weights to load them into our own NN model and predict on the test dataset. Right?</p><p>But actually we can go further than that. We can add an extra layer on top of the NN they have prepared to classify our own dataset.</p><p>In a way you can think of the intermediate features created by the Pretrained neural networks to be the features for the next layer.</p><h2 id=why-it-works>Why it works?</h2><p>We are essentially doing the image classification task only. We need to find out edges, shapes, intensities and other features from the images that are given to us. The pretrained model is already pretty good at finding these sort of features. Forget neural nets, if we plug these features into a machine learning algorithm we should be good.</p><p>What we actually do here is replace the last layer of the neural network with a new prediction/output layer and train while keeping the weights for all the layers before the second last layer constant.</p><h2 id=code>Code:</h2><p>I assume that you understand Keras a little. If not you can look at the docs.
Let us get into coding now. First of all we will create the architecture of the neural network the VGG Team created in 2014. Then we will load the weights.</p><p>Import some stuff</p><div class=highlight><pre tabindex=0 style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#6ab825;font-weight:700>import</span> <span style=color:#447fcf;text-decoration:underline>numpy</span> <span style=color:#6ab825;font-weight:700>as</span> <span style=color:#447fcf;text-decoration:underline>np</span>
</span></span><span style=display:flex><span><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>numpy.random</span> <span style=color:#6ab825;font-weight:700>import</span> random, permutation
</span></span><span style=display:flex><span><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>scipy</span> <span style=color:#6ab825;font-weight:700>import</span> misc, ndimage
</span></span><span style=display:flex><span><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>scipy.ndimage.interpolation</span> <span style=color:#6ab825;font-weight:700>import</span> zoom
</span></span><span style=display:flex><span><span style=color:#6ab825;font-weight:700>import</span> <span style=color:#447fcf;text-decoration:underline>keras</span>
</span></span><span style=display:flex><span><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>keras</span> <span style=color:#6ab825;font-weight:700>import</span> backend <span style=color:#6ab825;font-weight:700>as</span> K
</span></span><span style=display:flex><span><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>keras.utils.data_utils</span> <span style=color:#6ab825;font-weight:700>import</span> get_file
</span></span><span style=display:flex><span><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>keras.models</span> <span style=color:#6ab825;font-weight:700>import</span> Sequential, Model
</span></span><span style=display:flex><span><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>keras.layers.core</span> <span style=color:#6ab825;font-weight:700>import</span> Flatten, Dense, Dropout, Lambda
</span></span><span style=display:flex><span><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>keras.layers</span> <span style=color:#6ab825;font-weight:700>import</span> Input
</span></span><span style=display:flex><span><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>keras.layers.convolutional</span> <span style=color:#6ab825;font-weight:700>import</span> Convolution2D, MaxPooling2D, ZeroPadding2D
</span></span><span style=display:flex><span><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>keras.optimizers</span> <span style=color:#6ab825;font-weight:700>import</span> SGD, RMSprop, Adam
</span></span><span style=display:flex><span><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>keras.preprocessing</span> <span style=color:#6ab825;font-weight:700>import</span> image
</span></span></code></pre></div><p>VGG has just one type of convolutional block, and one type of fully connected (&lsquo;dense&rsquo;) block. We start by defining the building blocks of our Deep learning model.</p><div class=highlight><pre tabindex=0 style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#6ab825;font-weight:700>def</span> <span style=color:#447fcf>ConvBlock</span>(layers, model, filters):
</span></span><span style=display:flex><span>    <span style=color:#6ab825;font-weight:700>for</span> i <span style=color:#6ab825;font-weight:700>in</span> <span style=color:#24909d>range</span>(layers):
</span></span><span style=display:flex><span>        model.add(ZeroPadding2D((<span style=color:#3677a9>1</span>,<span style=color:#3677a9>1</span>)))
</span></span><span style=display:flex><span>        model.add(Convolution2D(filters, <span style=color:#3677a9>3</span>, <span style=color:#3677a9>3</span>, activation=<span style=color:#ed9d13>&#39;relu&#39;</span>))
</span></span><span style=display:flex><span>    model.add(MaxPooling2D((<span style=color:#3677a9>2</span>,<span style=color:#3677a9>2</span>), strides=(<span style=color:#3677a9>2</span>,<span style=color:#3677a9>2</span>)))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6ab825;font-weight:700>def</span> <span style=color:#447fcf>FCBlock</span>(model):
</span></span><span style=display:flex><span>    model.add(Dense(<span style=color:#3677a9>4096</span>, activation=<span style=color:#ed9d13>&#39;relu&#39;</span>))
</span></span><span style=display:flex><span>    model.add(Dropout(<span style=color:#3677a9>0.5</span>))
</span></span></code></pre></div><script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"></script><p>Now the input of the VGG Model was images. When the VGG model was trained in 2014, the creators subtracted the average of each of the three (R,G,B) channels first, so that the data for each channel had a mean of zero. Furthermore, their software that expected the channels to be in B,G,R order, whereas Python by default uses R,G,B. We need to preprocess our data to make these two changes, so that it is compatible with the VGG model. We also add some helper functions.</p><div class=highlight><pre tabindex=0 style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#999;font-style:italic>#Mean of each channel as provided by VGG researchers</span>
</span></span><span style=display:flex><span>vgg_mean = np.array([<span style=color:#3677a9>123.68</span>, <span style=color:#3677a9>116.779</span>, <span style=color:#3677a9>103.939</span>]).reshape((<span style=color:#3677a9>3</span>,<span style=color:#3677a9>1</span>,<span style=color:#3677a9>1</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6ab825;font-weight:700>def</span> <span style=color:#447fcf>vgg_preprocess</span>(x):
</span></span><span style=display:flex><span>    x = x - vgg_mean     <span style=color:#999;font-style:italic># subtract mean</span>
</span></span><span style=display:flex><span>    <span style=color:#6ab825;font-weight:700>return</span> x[:, ::-<span style=color:#3677a9>1</span>]    <span style=color:#999;font-style:italic># reverse axis bgr-&gt;rgb</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6ab825;font-weight:700>def</span> <span style=color:#447fcf>VGG_16</span>():
</span></span><span style=display:flex><span>    model = Sequential()
</span></span><span style=display:flex><span>    model.add(Lambda(vgg_preprocess, input_shape=(<span style=color:#3677a9>3</span>,<span style=color:#3677a9>224</span>,<span style=color:#3677a9>224</span>)))
</span></span><span style=display:flex><span>    ConvBlock(<span style=color:#3677a9>2</span>, model, <span style=color:#3677a9>64</span>)
</span></span><span style=display:flex><span>    ConvBlock(<span style=color:#3677a9>2</span>, model, <span style=color:#3677a9>128</span>)
</span></span><span style=display:flex><span>    ConvBlock(<span style=color:#3677a9>3</span>, model, <span style=color:#3677a9>256</span>)
</span></span><span style=display:flex><span>    ConvBlock(<span style=color:#3677a9>3</span>, model, <span style=color:#3677a9>512</span>)
</span></span><span style=display:flex><span>    ConvBlock(<span style=color:#3677a9>3</span>, model, <span style=color:#3677a9>512</span>)
</span></span><span style=display:flex><span>    model.add(Flatten())
</span></span><span style=display:flex><span>    FCBlock(model)
</span></span><span style=display:flex><span>    FCBlock(model)
</span></span><span style=display:flex><span>    model.add(Dense(<span style=color:#3677a9>1000</span>, activation=<span style=color:#ed9d13>&#39;softmax&#39;</span>))
</span></span><span style=display:flex><span>    <span style=color:#6ab825;font-weight:700>return</span> model
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6ab825;font-weight:700>def</span> <span style=color:#447fcf>finetune</span>(model, num_classes):
</span></span><span style=display:flex><span>    <span style=color:#999;font-style:italic># Drop last layer</span>
</span></span><span style=display:flex><span>    model.pop()
</span></span><span style=display:flex><span>    <span style=color:#999;font-style:italic># Make all layers untrainable. i.e fix all weights</span>
</span></span><span style=display:flex><span>    <span style=color:#6ab825;font-weight:700>for</span> layer <span style=color:#6ab825;font-weight:700>in</span> model.layers: layer.trainable=<span style=color:#6ab825;font-weight:700>False</span>
</span></span><span style=display:flex><span>    <span style=color:#999;font-style:italic># Add a new layer which is the new output layer</span>
</span></span><span style=display:flex><span>    model.add(Dense(num_classes, activation=<span style=color:#ed9d13>&#39;softmax&#39;</span>))
</span></span><span style=display:flex><span>    model.compile(optimizer=Adam(lr=<span style=color:#3677a9>0.001</span>),
</span></span><span style=display:flex><span>                loss=<span style=color:#ed9d13>&#39;categorical_crossentropy&#39;</span>, metrics=[<span style=color:#ed9d13>&#39;accuracy&#39;</span>])
</span></span><span style=display:flex><span>    <span style=color:#6ab825;font-weight:700>return</span> model
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#999;font-style:italic># A way to generate batches of images</span>
</span></span><span style=display:flex><span><span style=color:#6ab825;font-weight:700>def</span> <span style=color:#447fcf>get_batches</span>(path, dirname, gen=image.ImageDataGenerator(), shuffle=<span style=color:#6ab825;font-weight:700>True</span>,
</span></span><span style=display:flex><span>                batch_size=<span style=color:#3677a9>64</span>, class_mode=<span style=color:#ed9d13>&#39;categorical&#39;</span>):
</span></span><span style=display:flex><span>    <span style=color:#6ab825;font-weight:700>return</span> gen.flow_from_directory(path+dirname, target_size=(<span style=color:#3677a9>224</span>,<span style=color:#3677a9>224</span>),
</span></span><span style=display:flex><span>                class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)
</span></span></code></pre></div><p>The hard part is done now. Just create a VGG object and load the weights.We will need to load pretrained weights into the model too. You can download the &ldquo;VGG16_weights.h5&rdquo; file
<a href=https://drive.google.com/file/d/0Bz7KyqmuGsilT0J5dmRCM0ROVHc/view target=_blank rel="nofollow noopener">here</a></p><div class=highlight><pre tabindex=0 style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>model = VGG_16()
</span></span><span style=display:flex><span>model.load_weights(<span style=color:#ed9d13>&#39;VGG16_weights.h5&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#999;font-style:italic># Since our dogs vs cat dataset is binary classification model</span>
</span></span><span style=display:flex><span>ftmodel = finetune(model,<span style=color:#3677a9>2</span>)
</span></span><span style=display:flex><span><span style=color:#24909d>print</span> ftmodel.summary()
</span></span></code></pre></div><div style=margin-top:9px;margin-bottom:10px><center><img src=/images/keras_net.png height=400 width=500></center></div>Showing a little bit of output here. This is how the last layers of our Neural net look after training. Now we have got a architecture which we got to train. Here we are only training to get the last layer weights. As you can see from the trainable params.<div class=highlight><pre tabindex=0 style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>path = <span style=color:#ed9d13>&#34;dogscats/&#34;</span>
</span></span><span style=display:flex><span>batch_size=<span style=color:#3677a9>64</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#999;font-style:italic># Iterators to get our images from our datasets. The datasets are folders named train and valid. Both folder contain two directories &#39;dogs&#39; and &#39;cats&#39;. In each directory the corresponding images are kept.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>batches = get_batches(path,<span style=color:#ed9d13>&#39;train&#39;</span>, batch_size=batch_size)
</span></span><span style=display:flex><span>val_batches = get_batches(path,<span style=color:#ed9d13>&#39;valid&#39;</span>, batch_size=batch_size)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#999;font-style:italic># Now run for some epochs till the validation loss stops decreasing.</span>
</span></span><span style=display:flex><span>no_of_epochs=<span style=color:#3677a9>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6ab825;font-weight:700>for</span> epoch <span style=color:#6ab825;font-weight:700>in</span> <span style=color:#24909d>range</span>(no_of_epochs):
</span></span><span style=display:flex><span>    <span style=color:#24909d>print</span> <span style=color:#ed9d13>&#34;Running epoch: </span><span style=color:#ed9d13>%d</span><span style=color:#ed9d13>&#34;</span> % epoch
</span></span><span style=display:flex><span>    ftmodel.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=<span style=color:#3677a9>1</span>,
</span></span><span style=display:flex><span>                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)
</span></span><span style=display:flex><span>    latest_weights_filename = <span style=color:#ed9d13>&#39;ft</span><span style=color:#ed9d13>%d</span><span style=color:#ed9d13>.h5&#39;</span> % epoch
</span></span><span style=display:flex><span>    ftmodel.save_weights(latest_weights_filename)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#999;font-style:italic>#Create Predictions on test set. The test images should be in the folder dogscats/test/test_images/ , which is a single directory containing all images.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>test_batches = get_batches(path, <span style=color:#ed9d13>&#39;test&#39;</span>, batch_size=<span style=color:#3677a9>2</span>*batch_size, class_mode=<span style=color:#6ab825;font-weight:700>None</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>preds = ftmodel.predict_generator(test_batches, test_batches.nb_sample)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>isdog = preds[:,<span style=color:#3677a9>1</span>]
</span></span><span style=display:flex><span>image_id = batches.filenames
</span></span><span style=display:flex><span>final_submission = np.stack([ids,isdog], axis=<span style=color:#3677a9>1</span>)
</span></span></code></pre></div><p>And we are done!</p><script async data-uid=8d7942551b src=https://mlwhiz.ck.page/8d7942551b/index.js></script><div class=shareaholic-canvas data-app=share_buttons data-app-id=28372088 style=margin-bottom:1px></div><a href=https://coursera.pxf.io/coursera rel=nofollow><img border=0 alt="Start your future with a Data Analysis Certificate." src="https://ad.linksynergy.com/fs-bin/show?id=lVarvwc5BD0&bids=759505.377&subid=0&type=4&gridnum=16"></a><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//mlwhiz.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div><div class=col-lg-4><div class=widget><script type=text/javascript src=https://ko-fi.com/widgets/widget_2.js></script><script type=text/javascript>kofiwidget2.init("Support Me on Ko-fi","#972EB4","S6S3NPCD"),kofiwidget2.draw()</script></div><div class=widget><h4 class=widget-title>About Me</h4><img src=https://mlwhiz.com/images/author.jpg alt class="img-fluid author-thumb-sm d-block mx-auto rounded-circle mb-4"><p><p>I’m a Machine Learning Engineer based in London, where I am currently working with <strong>Roku</strong> .</p></p><a href=https://mlwhiz.com/about/ class="btn btn-outline-primary">Know More</a></div><div class=widget><h4 class=widget-title>Topics</h4><ul class=list-unstyled><li><a class="categoryStyle text-white" href=/categories/awesome-guides>Awesome Guides</a></li><li><a class="categoryStyle text-white" href=/categories/bash>Bash</a></li><li><a class="categoryStyle text-white" href=/categories/big-data>Big Data</a></li><li><a class="categoryStyle text-white" href=/categories/chatgpt-series>Chatgpt Series</a></li><li><a class="categoryStyle text-white" href=/categories/computer-vision>Computer Vision</a></li><li><a class="categoryStyle text-white" href=/categories/data-science>Data Science</a></li><li><a class="categoryStyle text-white" href=/categories/deep-learning>Deep Learning</a></li><li><a class="categoryStyle text-white" href=/categories/learning-resources>Learning Resources</a></li><li><a class="categoryStyle text-white" href=/categories/machine-learning>Machine Learning</a></li><li><a class="categoryStyle text-white" href=/categories/natural-language-processing>Natural Language Processing</a></li><li><a class="categoryStyle text-white" href=/categories/opinion>Opinion</a></li><li><a class="categoryStyle text-white" href=/categories/programming>Programming</a></li></ul></div><div class=widget><h4 class=widget-title>Tags</h4><ul class=list-inline><li class=list-inline-item><a class="tagStyle text-white" href=/tags/algorithms>Algorithms</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/artificial-intelligence>Artificial Intelligence</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/awesome-guides>Awesome Guides</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/best-content>Best Content</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/big-data>Big Data</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/chatgpt>Chatgpt</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/computer-vision>Computer Vision</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/curated-resources>Curated Resources</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/dask>Dask</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/data-science>Data Science</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/deep-learning>Deep Learning</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/deployment>Deployment</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/ec2>Ec2</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/generative-adversarial-networks>Generative Adversarial Networks</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/graphs>Graphs</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/image-classification>Image Classification</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/instance-segmentation>Instance Segmentation</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/interpretability>Interpretability</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/jobs>Jobs</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/kaggle>Kaggle</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/language-modeling>Language Modeling</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/learning-resources>Learning Resources</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/machine-learning>Machine Learning</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/math>Math</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/multiprocessing>Multiprocessing</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/natural-language-processing>Natural Language Processing</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/object-detection>Object Detection</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/oop>Oop</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/opinion>Opinion</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/pandas>Pandas</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/production>Production</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/productivity>Productivity</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/python>Python</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/pytorch>Pytorch</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/spark>Spark</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/sql>SQL</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/statistics>Statistics</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/streamlit>Streamlit</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/text-classification>Text Classification</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/timeseries>Timeseries</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/tools>Tools</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/transformers>Transformers</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/translation>Translation</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/visualization>Visualization</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/xgboost>Xgboost</a></li></ul></div><div class=widget><h4 class=widget-title>Connect With Me</h4><ul class="list-inline social-links"><li class=list-inline-item><a href="https://linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&amp;followMember=rahulagwl"><i class=ti-linkedin></i></a></li><li class=list-inline-item><a href=https://mlwhiz.medium.com/><i class=ti-book></i></a></li><li class=list-inline-item><a href=https://twitter.com/MLWhiz><i class=ti-twitter-alt></i></a></li><li class=list-inline-item><a href=https://www.facebook.com/mlwhizblog><i class=ti-facebook></i></a></li><li class=list-inline-item><a href=https://github.com/MLWhiz><i class=ti-github></i></a></li></ul></div><script async data-uid=bfe9f82f10 src=https://mlwhiz.ck.page/bfe9f82f10/index.js></script><script async data-uid=3452d924e2 src=https://mlwhiz.ck.page/3452d924e2/index.js></script></div></div></div></section><footer><div class=container><div class=row><div class="col-12 text-center mb-5"><a href=https://mlwhiz.com/><img src=https://mlwhiz.com/images/logos/mlwhiz_black.png class=img-fluid-custom-bottom alt="MLWhiz - Your Home for DS, ML, AI!"></a></div><div class="col-12 border-top py-4 text-center">Copyright © 2020 <a href=https://mlwhiz.com style=color:#972eb4>MLWhiz</a> All Rights Reserved</div></div></div></footer><script>var indexURL="https://mlwhiz.com/index.json"</script><script src=https://mlwhiz.com/plugins/compressjscss/main.js></script><script src=https://mlwhiz.com/js/script.min.js></script><script>(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","//www.google-analytics.com/analytics.js","ga"),ga("create","UA-54777926-1","auto"),ga("send","pageview")</script></body></html>