<!DOCTYPE html>
<html class="no-js" lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Today I Learned This Part 2: Pretrained Neural Networks What are they?</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="Your Daily dose of data science.This is a series of post in which I write about the things I learn almost everyday. This post particularly provides a way to use pretrained neural nets for classifying images.">
	

	
	<link rel='preload' href='//apps.shareaholic.com/assets/pub/shareaholic.js' as='script' />
	<script type="text/javascript" data-cfasync="false" async src="//apps.shareaholic.com/assets/pub/shareaholic.js" data-shr-siteid="fd1ffa7fd7152e4e20568fbe49a489d0"></script>
	
	
	<meta name="generator" content="Hugo 0.53" />
	<meta property="og:title" content="Today I Learned This Part 2: Pretrained Neural Networks What are they?" />
<meta property="og:description" content="Your Daily dose of data science.This is a series of post in which I write about the things I learn almost everyday. This post particularly provides a way to use pretrained neural nets for classifying images." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mlwhiz.com/blog/2017/04/17/deep_learning_pretrained_models/" />
<meta property="og:image" content="https://image.slidesharecdn.com/practicaldeeplearning-160329181459/95/practical-deep-learning-16-638.jpg" />
<meta property="article:published_time" content="2017-04-17T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2017-04-17T00:00:00&#43;00:00"/>

	<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://image.slidesharecdn.com/practicaldeeplearning-160329181459/95/practical-deep-learning-16-638.jpg"/>

<meta name="twitter:title" content="Today I Learned This Part 2: Pretrained Neural Networks What are they?"/>
<meta name="twitter:description" content="Your Daily dose of data science.This is a series of post in which I write about the things I learn almost everyday. This post particularly provides a way to use pretrained neural nets for classifying images."/>


	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/css/style.css">
	<link rel="stylesheet" href="/css/custom.css">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="96x96" href="/favicon-96x96.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	
	
		
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-54777926-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

	
	<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
	new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
	j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
	'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
	})(window,document,'script','dataLayer','GTM-NMQD44T');</script>
	

	
	<script>
	  !function(f,b,e,v,n,t,s)
	  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
	  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
	  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
	  n.queue=[];t=b.createElement(e);t.async=!0;
	  t.src=v;s=b.getElementsByTagName(e)[0];
	  s.parentNode.insertBefore(t,s)}(window, document,'script',
	  'https://connect.facebook.net/en_US/fbevents.js');
	  fbq('init', '1062344757288542');
	  fbq('track', 'PageView');
	</script>
	<noscript><img height="1" width="1" style="display:none"
	  src="https://www.facebook.com/tr?id=1062344757288542&ev=PageView&noscript=1"
	/></noscript>
	


	
  	<script async>(function(s,u,m,o,j,v){j=u.createElement(m);v=u.getElementsByTagName(m)[0];j.async=1;j.src=o;j.dataset.sumoSiteId='22863fd8ad7ebbfab9b8ca60b7db8f65e9a15559f384f785f66903e365aa8f48';v.parentNode.insertBefore(j,v)})(window,document,'script','//load.sumo.com/');</script>
  	<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>
</head>
<body class="body">
	  
	  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NMQD44T"
	  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
	  
	<div class="container container--outer">
		<header class="header">
	<div class="container">
		<div class="logo">

			<a class="logo__link" href="/" title="MLWhiz" rel="home">

				<div class="logo__title">MLWhiz</div>
				<div class="logo__tagline">Deep Learning, Data Science and NLP Enthusiast</div>
			</a>
		</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/">Blog</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/archive">Archive</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/about/">About Me</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/nlpseries/">NLP</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/atom.xml">RSS</a>
		</li>
	</ul>
</nav>

	</div>
</header>


		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Today I Learned This Part 2: Pretrained Neural Networks What are they?</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
	<time class="meta__text" datetime="2017-04-17T00:00:00">April 17, 2017</time>
</div>
</div>
		</header>
		<div class="content post__content clearfix">
			

<p>Deeplearning is the buzz word right now. I was working on the <a href="http://www.fast.ai/" rel="nofollow" target="_blank">course</a> for deep learning by Jeremy Howard and one thing I noticed were pretrained deep Neural Networks. In the first lesson he used the pretrained NN to predict on the <a href="https://www.kaggle.com/c/dogs-vs-cats" rel="nofollow" target="_blank">Dogs vs Cats</a> competition on Kaggle to achieve very good results.</p>

<h2 id="what-are-pretrained-neural-networks">What are pretrained Neural Networks?</h2>

<p>So let me tell you about the background a little bit. There is a challenge that happens every year in the visual recognition community - The Imagenet Challenge. The task there is to classify the images in 1000 categories using Image training data. People train big convolutional deep learning models for this challenge.</p>

<p>Now what does training a neural model actually mean? It just means that they learn the weights for a NN. What if we can get the weights they learn? We can use those weights to load them into our own NN model and predict on the test dataset. Right?</p>

<p>But actually we can go further than that. We can add an extra layer on top of the NN they have prepared to classify our own dataset.</p>

<p>In a way you can think of the intermediate features created by the Pretrained neural networks to be the features for the next layer.</p>

<h2 id="why-it-works">Why it works?</h2>

<p>We are essentially doing the image classification task only. We need to find out edges, shapes, intensities and other features from the images that are given to us. The pretrained model is already pretty good at finding these sort of features. Forget neural nets, if we plug these features into a machine learning algorithm we should be good.</p>

<p>What we actually do here is replace the last layer of the neural network with a new prediction/output layer and train while keeping the weights for all the layers before the second last layer constant.</p>

<h2 id="code">Code:</h2>

<p>I assume that you understand Keras a little. If not you can look at the docs.
Let us get into coding now. First of all we will create the architecture of the neural network the VGG Team created in 2014. Then we will load the weights.</p>

<p>Import some stuff</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">from</span> numpy.random <span style="color:#f92672">import</span> random, permutation
<span style="color:#f92672">from</span> scipy <span style="color:#f92672">import</span> misc, ndimage
<span style="color:#f92672">from</span> scipy.ndimage.interpolation <span style="color:#f92672">import</span> zoom
<span style="color:#f92672">import</span> keras
<span style="color:#f92672">from</span> keras <span style="color:#f92672">import</span> backend <span style="color:#66d9ef">as</span> K
<span style="color:#f92672">from</span> keras.utils.data_utils <span style="color:#f92672">import</span> get_file
<span style="color:#f92672">from</span> keras.models <span style="color:#f92672">import</span> Sequential, Model
<span style="color:#f92672">from</span> keras.layers.core <span style="color:#f92672">import</span> Flatten, Dense, Dropout, Lambda
<span style="color:#f92672">from</span> keras.layers <span style="color:#f92672">import</span> Input
<span style="color:#f92672">from</span> keras.layers.convolutional <span style="color:#f92672">import</span> Convolution2D, MaxPooling2D, ZeroPadding2D
<span style="color:#f92672">from</span> keras.optimizers <span style="color:#f92672">import</span> SGD, RMSprop, Adam
<span style="color:#f92672">from</span> keras.preprocessing <span style="color:#f92672">import</span> image</code></pre></div>
<p>VGG has just one type of convolutional block, and one type of fully connected (&lsquo;dense&rsquo;) block. We start by defining the building blocks of our Deep learning model.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">ConvBlock</span>(layers, model, filters):
    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(layers):
        model<span style="color:#f92672">.</span>add(ZeroPadding2D((<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>)))
        model<span style="color:#f92672">.</span>add(Convolution2D(filters, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>))
    model<span style="color:#f92672">.</span>add(MaxPooling2D((<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>), strides<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>)))

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">FCBlock</span>(model):
    model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">4096</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>))
    model<span style="color:#f92672">.</span>add(Dropout(<span style="color:#ae81ff">0.5</span>))</code></pre></div>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"></script>

<p>Now the input of the VGG Model was images. When the VGG model was trained in 2014, the creators subtracted the average of each of the three (R,G,B) channels first, so that the data for each channel had a mean of zero. Furthermore, their software that expected the channels to be in B,G,R order, whereas Python by default uses R,G,B. We need to preprocess our data to make these two changes, so that it is compatible with the VGG model. We also add some helper functions.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e">#Mean of each channel as provided by VGG researchers</span>
vgg_mean <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">123.68</span>, <span style="color:#ae81ff">116.779</span>, <span style="color:#ae81ff">103.939</span>])<span style="color:#f92672">.</span>reshape((<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>))

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">vgg_preprocess</span>(x):
    x <span style="color:#f92672">=</span> x <span style="color:#f92672">-</span> vgg_mean     <span style="color:#75715e"># subtract mean</span>
    <span style="color:#66d9ef">return</span> x[:, ::<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]    <span style="color:#75715e"># reverse axis bgr-&gt;rgb</span>

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">VGG_16</span>():
    model <span style="color:#f92672">=</span> Sequential()
    model<span style="color:#f92672">.</span>add(Lambda(vgg_preprocess, input_shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">224</span>,<span style="color:#ae81ff">224</span>)))
    ConvBlock(<span style="color:#ae81ff">2</span>, model, <span style="color:#ae81ff">64</span>)
    ConvBlock(<span style="color:#ae81ff">2</span>, model, <span style="color:#ae81ff">128</span>)
    ConvBlock(<span style="color:#ae81ff">3</span>, model, <span style="color:#ae81ff">256</span>)
    ConvBlock(<span style="color:#ae81ff">3</span>, model, <span style="color:#ae81ff">512</span>)
    ConvBlock(<span style="color:#ae81ff">3</span>, model, <span style="color:#ae81ff">512</span>)
    model<span style="color:#f92672">.</span>add(Flatten())
    FCBlock(model)
    FCBlock(model)
    model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">1000</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;softmax&#39;</span>))
    <span style="color:#66d9ef">return</span> model


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">finetune</span>(model, num_classes):
    <span style="color:#75715e"># Drop last layer</span>
    model<span style="color:#f92672">.</span>pop()
    <span style="color:#75715e"># Make all layers untrainable. i.e fix all weights</span>
    <span style="color:#66d9ef">for</span> layer <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>layers: layer<span style="color:#f92672">.</span>trainable<span style="color:#f92672">=</span>False
    <span style="color:#75715e"># Add a new layer which is the new output layer</span>
    model<span style="color:#f92672">.</span>add(Dense(num_classes, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;softmax&#39;</span>))
    model<span style="color:#f92672">.</span>compile(optimizer<span style="color:#f92672">=</span>Adam(lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>),
                loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;categorical_crossentropy&#39;</span>, metrics<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;accuracy&#39;</span>])
    <span style="color:#66d9ef">return</span> model


<span style="color:#75715e"># A way to generate batches of images</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_batches</span>(path, dirname, gen<span style="color:#f92672">=</span>image<span style="color:#f92672">.</span>ImageDataGenerator(), shuffle<span style="color:#f92672">=</span>True,
                batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span>, class_mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;categorical&#39;</span>):
    <span style="color:#66d9ef">return</span> gen<span style="color:#f92672">.</span>flow_from_directory(path<span style="color:#f92672">+</span>dirname, target_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">224</span>,<span style="color:#ae81ff">224</span>),
                class_mode<span style="color:#f92672">=</span>class_mode, shuffle<span style="color:#f92672">=</span>shuffle, batch_size<span style="color:#f92672">=</span>batch_size)</code></pre></div>
<p>The hard part is done now. Just create a VGG object and load the weights.We will need to load pretrained weights into the model too. You can download the &ldquo;VGG16_weights.h5&rdquo; file <a href="https://drive.google.com/file/d/0Bz7KyqmuGsilT0J5dmRCM0ROVHc/view" rel="nofollow" target="_blank">here</a></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">model <span style="color:#f92672">=</span> VGG_16()
model<span style="color:#f92672">.</span>load_weights(<span style="color:#e6db74">&#39;VGG16_weights.h5&#39;</span>)
<span style="color:#75715e"># Since our dogs vs cat dataset is binary classification model</span>
ftmodel <span style="color:#f92672">=</span> finetune(model,<span style="color:#ae81ff">2</span>)
<span style="color:#66d9ef">print</span> ftmodel<span style="color:#f92672">.</span>summary()</code></pre></div>
<p><div style="margin-top: 9px; margin-bottom: 10px;">
<center><img src="/images/keras_net.png"  height="400" width="500" ></center>
</div>
Showing a little bit of output here. This is how the last layers of our Neural net look after training. Now we have got a architecture which we got to train. Here we are only training to get the last layer weights. As you can see from the trainable params.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;dogscats/&#34;</span>
batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span>

<span style="color:#75715e"># Iterators to get our images from our datasets. The datasets are folders named train and valid. Both folder contain two directories &#39;dogs&#39; and &#39;cats&#39;. In each directory the corresponding images are kept.</span>

batches <span style="color:#f92672">=</span> get_batches(path,<span style="color:#e6db74">&#39;train&#39;</span>, batch_size<span style="color:#f92672">=</span>batch_size)
val_batches <span style="color:#f92672">=</span> get_batches(path,<span style="color:#e6db74">&#39;valid&#39;</span>, batch_size<span style="color:#f92672">=</span>batch_size)

<span style="color:#75715e"># Now run for some epochs till the validation loss stops decreasing.</span>
no_of_epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>

<span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(no_of_epochs):
    <span style="color:#66d9ef">print</span> <span style="color:#e6db74">&#34;Running epoch: </span><span style="color:#e6db74">%d</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> epoch
    ftmodel<span style="color:#f92672">.</span>fit_generator(batches, samples_per_epoch<span style="color:#f92672">=</span>batches<span style="color:#f92672">.</span>nb_sample, nb_epoch<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
                validation_data<span style="color:#f92672">=</span>val_batches, nb_val_samples<span style="color:#f92672">=</span>val_batches<span style="color:#f92672">.</span>nb_sample)
    latest_weights_filename <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;ft</span><span style="color:#e6db74">%d</span><span style="color:#e6db74">.h5&#39;</span> <span style="color:#f92672">%</span> epoch
    ftmodel<span style="color:#f92672">.</span>save_weights(latest_weights_filename)

<span style="color:#75715e">#Create Predictions on test set. The test images should be in the folder dogscats/test/test_images/ , which is a single directory containing all images.</span>

test_batches <span style="color:#f92672">=</span> get_batches(path, <span style="color:#e6db74">&#39;test&#39;</span>, batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>batch_size, class_mode<span style="color:#f92672">=</span>None)

preds <span style="color:#f92672">=</span> ftmodel<span style="color:#f92672">.</span>predict_generator(test_batches, test_batches<span style="color:#f92672">.</span>nb_sample)

isdog <span style="color:#f92672">=</span> preds[:,<span style="color:#ae81ff">1</span>]
image_id <span style="color:#f92672">=</span> batches<span style="color:#f92672">.</span>filenames
final_submission <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>stack([ids,isdog], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)</code></pre></div>
<p>And we are done!</p>

		</div>
		
<div class="post__tags tags clearfix">
	<svg class="icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item"><a class="tags__link btn" href="/tags/deeplearning/" rel="tag">deeplearning</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/pretrained-models/" rel="tag">pretrained models</a></li>
	</ul>
</div>
		

<div class="shareaholic-canvas" data-app="share_buttons" data-app-id="28372088"></div>

<a href="https://click.linksynergy.com/fs-bin/click?id=lVarvwc5BD0&offerid=467035.372&subid=0&type=4" rel="nofollow"><IMG border="0"   alt="Start your future with a Data Science Certificate." src="https://ad.linksynergy.com/fs-bin/show?id=lVarvwc5BD0&bids=467035.372&subid=0&type=4&gridnum=16"></a>





























	</article>
</main>


<nav class="post-nav flex">
	<div class="post-nav__item post-nav__item--prev">
		<a class="post-nav__link" href="/blog/2017/04/16/maths_beats_intuition/" rel="prev"><span class="post-nav__caption">«&thinsp;Previous</span><p class="post-nav__post-title">Maths Beats Intuition probably every damn time</p></a>
	</div>
	<div class="post-nav__item post-nav__item--next">
		<a class="post-nav__link" href="/blog/2017/09/14/discrete_distributions/" rel="next"><span class="post-nav__caption">Next&thinsp;»</span><p class="post-nav__post-title">The story of every distribution - Discrete Distributions</p></a>
	</div>
</nav>

<section class="comments">
	<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "mlwhiz" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


			</div>
			<style type="text/css">

  .btn {
    display: inline-block;
    font-weight: 400;
    text-align: center;
    white-space: nowrap;
    vertical-align: middle;
    -webkit-user-select: none;
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none;
    border: 1px solid transparent;
    padding: .375rem .75rem;
    font-size: 1rem;
    line-height: 1.5;
    border-radius: .25rem;
    transition: color .15s ease-in-out,background-color .15s ease-in-out,border-color .15s ease-in-out,box-shadow .15s ease-in-out;
}

.btn-session {
    color: #fff;
    background-color: #28a745;
    border-color: #28a745;
}
</style>


<aside class="sidebar">
  <div style="text-align:center">    
    
    

  <a href='https://ko-fi.com/S6S3NPCD' target='_blank'><img height='36' style='border:0px;height:36px;' src='https://az743702.vo.msecnd.net/cdn/kofi4.png?v=0' border='0' alt='Buy Me a Coffee at ko-fi.com' /></a>
  </div>
  <br><div class="widget-search widget">
	<form class="widget-search__form" role="search" method="get" action="https://google.com/search">
		<label>
			<input class="widget-search__field" type="search" placeholder="SEARCH..." value="" name="q" aria-label="SEARCH...">
		</label>
		<input class="widget-search__submit" type="submit" value="Search">
		<input type="hidden" name="sitesearch" value="https://mlwhiz.com/" />
	</form>
</div>
<div class="widget-recent widget">
	<h4 class="widget__title">Recent Posts</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/blog/2020/03/29/coronatimes/">A Newspaper for COVID-19 — The CoronaTimes</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/03/27/covidcourses/">5 Online Courses you can take for free during COVID-19 Epidemic</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/03/24/coronaai/">Can AI help in fighting against Corona?</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/03/20/practicalspark/">Practical Spark Tips for Data Scientists</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/02/24/sparkcolumns/">5 Ways to add a new column in a PySpark Dataframe</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/02/24/job/">5 tips for getting your first Data Science job in 2020</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/02/23/bamboo/">Bamboolib — Learn and use Pandas without Coding</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/02/23/xgbparallel/">Lightning Fast XGBoost on Multiple GPUs</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/02/23/streamlitrec/">Share your Projects even more easily with this New Streamlit Feature</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/02/22/hyperspark/">100x faster Hyperparameter Search Framework with Pyspark</a></li>
		</ul>
	</div>
</div>


<div class="shareaholic-canvas" data-app="follow_buttons" data-app-id="28033293" style="white-space: inherit;"></div>


<link href="//cdn-images.mailchimp.com/embedcode/slim-10_7.css" rel="stylesheet" type="text/css">


<style type="text/css">
  #mc_embed_signup .button {background-color: #127edc;}
  #mc_embed_signup form .center{
    display: block;
    position: relative;
    text-align: center;
    padding: 10px -5px 10px 3%;}
   
</style>
<div id="mc_embed_signup">
<form action="//mlwhiz.us15.list-manage.com/subscribe/post?u=4e9962f4ce4a94818bcc2f249&amp;id=87a48fafdd" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
    <input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required>
    
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_4e9962f4ce4a94818bcc2f249_87a48fafdd" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy;  2014-2020 Rahul Agarwal.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>



	</div>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&adInstanceId=93f2f4f9-cf51-415d-84af-08cbb74b178f"></script>
<script async defer src="/js/menu.js"></script></body>
</html>