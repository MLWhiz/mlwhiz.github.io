<!doctype html><html lang=en-us><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-F34XSWQ5N4"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-F34XSWQ5N4')</script><meta charset=utf-8><title>Hadoop, Mapreduce and More – Part 1 - MLWhiz</title><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content="It has been some time since I was stalling learning Hadoop. Finally got some free time and realized that Hadoop may not be so difficult after all. This blog talks about how to stream data with hadoop."><meta name=author content="Rahul Agarwal"><meta name=generator content="Hugo 0.82.0"><link rel=stylesheet href=https://mlwhiz.com/plugins/compressjscss/main.css><meta property="og:title" content="Hadoop, Mapreduce and More – Part 1 - MLWhiz"><meta property="og:description" content="It has been some time since I was stalling learning Hadoop. Finally got some free time and realized that Hadoop may not be so difficult after all. This blog talks about how to stream data with hadoop."><meta property="og:type" content="article"><meta property="og:url" content="https://mlwhiz.com/blog/2014/09/27/hadoop_mapreduce/"><meta property="og:image" content="https://mlwhiz.com/images/category_bgs/default_bg.jpg"><meta property="og:image:secure_url" content="https://mlwhiz.com/images/category_bgs/default_bg.jpg"><meta property="article:published_time" content="2014-09-27T00:00:00+00:00"><meta property="article:modified_time" content="2023-07-11T19:17:16+01:00"><meta property="article:tag" content="Big Data"><meta property="article:tag" content="Machine Learning"><meta name=twitter:card content="summary"><meta name=twitter:image content="https://mlwhiz.com/images/category_bgs/default_bg.jpg"><meta name=twitter:title content="Hadoop, Mapreduce and More – Part 1 - MLWhiz"><meta name=twitter:description content="It has been some time since I was stalling learning Hadoop. Finally got some free time and realized that Hadoop may not be so difficult after all. This blog talks about how to stream data with hadoop."><meta name=twitter:site content="@mlwhiz"><meta name=twitter:creator content="@mlwhiz"><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href=https://mlwhiz.com/scss/style.min.css media=screen><link rel=stylesheet href=/css/style.css><link rel=stylesheet type=text/css href=/css/font/flaticon.css><link rel="shortcut icon" href=https://mlwhiz.com/images/logos/favicon-32x32.png type=image/x-icon><link rel=icon href=https://mlwhiz.com/images/logos/favicon.ico type=image/x-icon><link rel=canonical href=https://mlwhiz.com/blog/2014/09/27/hadoop_mapreduce/><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js></script><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://www.mlwhiz.com/#website","url":"https://www.mlwhiz.com/","name":"MLWhiz","description":"Want to Learn Computer Vision and NLP? - MLWhiz","potentialAction":{"@type":"SearchAction","target":"https://www.mlwhiz.com/search?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://mlwhiz.com/blog/2014/09/27/hadoop_mapreduce/#primaryimage","url":"https://mlwhiz.com/images/category_bgs/default_bg.jpg","width":700,"height":450},{"@type":"WebPage","@id":"https://mlwhiz.com/blog/2014/09/27/hadoop_mapreduce/#webpage","url":"https://mlwhiz.com/blog/2014/09/27/hadoop_mapreduce/","inLanguage":"en-US","name":"Hadoop, Mapreduce and More – Part 1 - MLWhiz","isPartOf":{"@id":"https://www.mlwhiz.com/#website"},"primaryImageOfPage":{"@id":"https://mlwhiz.com/blog/2014/09/27/hadoop_mapreduce/#primaryimage"},"datePublished":"2014-09-27T00:00:00.00Z","dateModified":"2023-07-11T19:17:16.00Z","author":{"@id":"https://mlwhiz.com/about/#/schema/person/76376876bchxkzbchjsdjcca"},"description":"It has been some time since I was stalling learning Hadoop. Finally got some free time and realized that Hadoop may not be so difficult after all. This blog talks about how to stream data with hadoop."},{"@type":["Person"],"@id":"https://mlwhiz.com/about/#/schema/person/76376876bchxkzbchjsdjcca","name":"Rahul Agarwal","image":{"@type":"ImageObject","@id":"https://www.mlwhiz.com/#authorlogo","url":"https://mlwhiz.com/images/author.jpg","caption":"Rahul Agarwal"},"description":"Hi there, I\u2019m Rahul Agarwal. I\u2019m a data scientist consultant and big data engineer based in Bangalore. I see a lot of times  students and even professionals wasting their time and struggling to get started with Computer Vision, Deep Learning, and NLP. I Started this Site with a purpose to augment my own understanding about new things while helping others learn about them in the best possible way.","sameAs":["https://www.linkedin.com/in/rahulagwl/","https://medium.com/@rahul_agarwal","https://twitter.com/MLWhiz","https://www.facebook.com/mlwhizblog","https://github.com/MLWhiz","https://www.instagram.com/itsmlwhiz"]}]}</script><script async data-uid=a0ebaf958d src=https://mlwhiz.ck.page/a0ebaf958d/index.js></script><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$']],processEscapes:!0,processEnvironments:!0,skipTags:['script','noscript','style','textarea','pre'],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var b=MathJax.Hub.getAllJax(),a;for(a=0;a<b.length;a+=1)b[a].SourceElement().parentNode.className+=' has-jax'}),MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:"AMS"}}})</script><link href=//apps.shareaholic.com/assets/pub/shareaholic.js as=script><script type=text/javascript data-cfasync=false async src=//apps.shareaholic.com/assets/pub/shareaholic.js data-shr-siteid=fd1ffa7fd7152e4e20568fbe49a489d0></script><script>!function(b,e,f,g,a,c,d){if(b.fbq)return;a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version='2.0',a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d)}(window,document,'script','https://connect.facebook.net/en_US/fbevents.js'),fbq('init','402633927768628'),fbq('track','PageView')</script><noscript><img height=1 width=1 style=display:none src="https://www.facebook.com/tr?id=402633927768628&ev=PageView&noscript=1"></noscript><meta property="fb:pages" content="213104036293742"><meta name=facebook-domain-verification content="qciidcy7mm137sewruizlvh8zbfnv4"></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NMQD44T" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><div class=preloader></div><header class=navigation><div class=container><nav class="navbar navbar-expand-lg navbar-white bg-transparent border-bottom pl-0"><a class="navbar-brand mobile-view" href=https://mlwhiz.com/><img class=img-fluid src=https://mlwhiz.com/images/logos/logo.svg alt="DS, ML, AI!"></a>
<button class="navbar-toggler border-0" type=button data-toggle=collapse data-target=#navigation>
<i class="ti-menu h3"></i></button><div class="collapse navbar-collapse text-center" id=navigation><div class=desktop-view><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href="www.linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=rahulagwl"><i class=ti-linkedin></i></a></li><li class=nav-item><a class=nav-link href=https://mlwhiz.medium.com/><i class=ti-book></i></a></li><li class=nav-item><a class=nav-link href=https://twitter.com/MLWhiz><i class=ti-twitter-alt></i></a></li><li class=nav-item><a class=nav-link href=https://www.facebook.com/mlwhizblog><i class=ti-facebook></i></a></li><li class=nav-item><a class=nav-link href=https://github.com/MLWhiz><i class=ti-github></i></a></li></ul></div><a class="navbar-brand mx-auto desktop-view" href=https://mlwhiz.com/><img class=img-fluid-custom src=https://mlwhiz.com/images/logos/logo.svg alt="DS, ML, AI!"></a><ul class=navbar-nav><li class=nav-item><a class=nav-link href=https://mlwhiz.com/about>About</a></li><li class=nav-item><a class=nav-link href=https://mlwhiz.com/blog>Blog</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Topics</a><div class=dropdown-menu><a class=dropdown-item href=https://mlwhiz.com/categories/natural-language-processing>NLP</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/computer-vision>Computer Vision</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/deep-learning>Deep Learning</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/data-science>DS/ML</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/big-data>Big Data</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/awesome-guides>My Best Content</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/learning-resources>Learning Resources</a></div></li></ul><div class="search pl-lg-4"><button id=searchOpen class=search-btn><i class=ti-search></i></button><div class=search-wrapper><form action=https://mlwhiz.com//search class=h-100><input class="search-box px-4" id=search-query name=s type=search placeholder="Type & Hit Enter..."></form><button id=searchClose class=search-close><i class="ti-close text-dark"></i></button></div></div></div></nav></div></header><section class=section-sm><div class=container><div class=row><div class="col-lg-8 mb-5 mb-lg-0"><a href=/categories/big-data class=categoryStyle>Big Data</a>
<a href=/categories/machine-learning class=categoryStyle>Machine Learning</a><h1>Hadoop, Mapreduce and More – Part 1</h1><div class="mb-3 post-meta"><span>By Rahul Agarwal</span><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
<span>27 September 2014</span></div><img src=https://mlwhiz.com/images/category_bgs/default_bg.jpg class="img-fluid w-100 mb-4" alt="Hadoop, Mapreduce and More – Part 1"><div class="content mb-5"><p>It has been some time since I was stalling learning Hadoop. Finally got some free time and realized that Hadoop may not be so difficult after all.
What I understood finally is that Hadoop is basically comprised of 3 elements:</p><ul><li>A File System</li><li>Map – Reduce</li><li>Its many individual Components.</li></ul><p>Let’s go through each of them one by one.</p><h2 id=1-hadoop-as-a-file-system>1. Hadoop as a File System:</h2><p>One of the main things that Hadoop provides is cheap data storage. What happens intrinsically is that the Hadoop system takes a file, cuts it into chunks and keeps those chunks at different places in a cluster. Suppose you have a big big file in your local system and you want that file to be:</p><ul><li>On the cloud for easy access</li><li>Processable in human time</li></ul><p>The one thing you can look forward to is Hadoop.</p><p>Assuming that you have got hadoop installed on the amazon cluster you are working on.</p><h3 id=start-the-hadoop-cluster>Start the Hadoop Cluster:</h3><p>You need to run the following commands to start the hadoop cluster(Based on location of hadoop installation directory):</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#24909d>cd</span> /usr/local/hadoop/
bin/start-all.sh
jps
</code></pre></div><p><strong>Adding File to HDFS:</strong> Every command in Hadoop starts with hadoop fs and the rest of it works like the UNIX syntax. To add a file “purchases.txt” to the hdfs system:</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>hadoop fs -put purchases.txt /usr/purchases.txt
</code></pre></div><h2 id=2-hadoop-for-map-reduce>2. Hadoop for Map-Reduce:</h2><p>MapReduce is a programming model and an associated implementation for processing and generating large data sets with a parallel, distributed algorithm on a cluster.</p><p>While Hadoop is implemented in Java, you can use almost any language to do map-reduce in hadoop using hadoop streaming. Suppose you have a big file containing the Name of store and sales of store each hour. And you want to find out the sales per store using map-reduce. Lets Write a sample code for that:</p><p>InputFile</p><pre style="font-family:courier new,monospace;background-color:#f6c6529c;color:#000">A,300,12:00
B,234,1:00
C,234,2:00
D,123,3:00
A,123,1:00
B,346,2:00
</pre><p>Mapper.py</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#6ab825;font-weight:700>import</span> <span style=color:#447fcf;text-decoration:underline>sys</span>
<span style=color:#6ab825;font-weight:700>def</span> <span style=color:#447fcf>mapper</span>():
    <span style=color:#999;font-style:italic># The Mapper takes inputs from stdin and prints out store name and value</span>
    <span style=color:#6ab825;font-weight:700>for</span> line <span style=color:#6ab825;font-weight:700>in</span> sys.stdin:
        data = line.strip().split(<span style=color:#ed9d13>&#34;,&#34;</span>)
        storeName,Value,time=data
        <span style=color:#6ab825;font-weight:700>print</span> <span style=color:#ed9d13>&#34;{0},{1}&#34;</span>.format(storeName,Value)
</code></pre></div><p>Reducer.py</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#6ab825;font-weight:700>import</span> <span style=color:#447fcf;text-decoration:underline>sys</span>
<span style=color:#6ab825;font-weight:700>def</span> <span style=color:#447fcf>reducer</span>():
    <span style=color:#999;font-style:italic># The reducer takes inputs from mapper and prints out aggregated store name and value</span>
    salesTotal = <span style=color:#3677a9>0</span>
    oldKey = None
    <span style=color:#6ab825;font-weight:700>for</span> line <span style=color:#6ab825;font-weight:700>in</span> sys.stdin:
        data = line.strip().split(<span style=color:#ed9d13>&#34;,&#34;</span>)
        <span style=color:#999;font-style:italic>#Adding a little bit of Defensive programming</span>
        <span style=color:#6ab825;font-weight:700>if</span> <span style=color:#24909d>len</span>(data) != <span style=color:#3677a9>2</span>:
            <span style=color:#6ab825;font-weight:700>continue</span>
        curKey,curVal = data
        <span style=color:#6ab825;font-weight:700>if</span> oldKey adn oldKey != curKey:
            <span style=color:#6ab825;font-weight:700>print</span> <span style=color:#ed9d13>&#34;{0},{1}&#34;</span>.format(oldKey,salesTotal)
            salesTotal=<span style=color:#3677a9>0</span>
        oldKey=curKey
        salesTotal += curVal
    <span style=color:#6ab825;font-weight:700>if</span> oldkey!=None:
        <span style=color:#6ab825;font-weight:700>print</span> <span style=color:#ed9d13>&#34;{0},{1}&#34;</span>.format(oldKey,salesTotal)
</code></pre></div><p>Running the program on shell using pipes</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>textfile.txt | ./mapper.py | sort | ./reducer.py
</code></pre></div><p>Running the program on mapreduce using Hadoop Streaming</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>hadoop jar contrib/streaming/hadoop-*streaming*.jar /
-file mapper.py -mapper mapper.py /
-file reducer.py -reducer reducer.py /
-input /inputfile -output /outputfile
</code></pre></div><h2 id=3-hadoop-components>3. Hadoop Components:</h2><p>Now if you have been following Hadoop you might have heard about Apache, Cloudera, HortonWorks etc. All of these are Hadoop vendors who provide Hadoop Along with its components. I will talk about the main component of Hadoop here – Hive.
So what exactly is Hive: Hive is a SQL like interface to map-reduce queries. So if you don’t understand all the hocus-pocus of map-reduce but know SQL, you can do map-reduce via Hive.
Seems Promising? It is.
While the syntax is mainly SQL, it is still a little different and there are some quirks that we need to understand to work with Hive.
First of all lets open hive command prompt: For that you just have to type “hive”, and voila you are in.
Here are some general commands</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>show databases  <span style=color:#999;font-style:italic>#   -- See all Databases</span>
use database     <span style=color:#999;font-style:italic>#     -- Use a particular Database</span>
show tables       <span style=color:#999;font-style:italic>#     -- See all tables in a particular Database</span>
describe table    
</code></pre></div><p>Creating an external table:</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>CREATE EXTERNAL TABLE IF NOT EXISTS BXDataSet
(ISBN STRING,BookTitle STRING, ImageURLL STRING)
ROW FORMAT DELIMITED  FIELDS TERMINATED BY ‘;’ STORED AS TEXTFILE;
LOAD DATA INPATH ‘/user/book.csv’ OVERWRITE INTO TABLE BXDataSet;
</code></pre></div><p>The query commands work the same way as in SQL. You can do all the group by and hive will automatically convert it in map-reduce:</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#6ab825;font-weight:700>select</span> * from tablename;
</code></pre></div><p>Stay Tuned for Part 2 – Where we will talk about another components of Hadoop – PIG
To learn more about hadoop in the meantime these are the books I recommend:</p><div style=text-align:center><a target=_blank href="https://www.amazon.com/gp/product/1491901632/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1491901632&linkCode=as2&tag=mlwhizcon-20&linkId=4122280e94f7bbd0ceebc9d13e60d103"><img border=0 src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&MarketPlace=US&ASIN=1491901632&ServiceVersion=20070822&ID=AsinImage&WS=1&Format=_SL250_&tag=mlwhizcon-20"></a><img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&l=am2&o=1&a=1491901632" width=1 height=1 border=0 alt style=border:none!important;margin:0!important></div><script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&adInstanceId=c4ca54df-6d53-4362-92c0-13cb9977639e"></script><script async data-uid=8d7942551b src=https://mlwhiz.ck.page/8d7942551b/index.js></script><div class=shareaholic-canvas data-app=share_buttons data-app-id=28372088 style=margin-bottom:1px></div><a href=https://coursera.pxf.io/coursera rel=nofollow><img border=0 alt="Start your future with a Data Analysis Certificate." src="https://ad.linksynergy.com/fs-bin/show?id=lVarvwc5BD0&bids=759505.377&subid=0&type=4&gridnum=16"></a><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return}var b=document,a=b.createElement('script');a.async=!0,a.src='//mlwhiz.disqus.com/embed.js',a.setAttribute('data-timestamp',+new Date),(b.head||b.body).appendChild(a)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div><div class=col-lg-4><div class=widget><script type=text/javascript src=https://ko-fi.com/widgets/widget_2.js></script><script type=text/javascript>kofiwidget2.init('Support Me on Ko-fi','#972EB4','S6S3NPCD'),kofiwidget2.draw()</script></div><div class=widget><h4 class=widget-title>About Me</h4><img src=https://mlwhiz.com/images/author.jpg alt class="img-fluid author-thumb-sm d-block mx-auto rounded-circle mb-4"><p>I’m a Machine Learning Engineer based in London, where I am currently working with Roku .</p><a href=https://mlwhiz.com/about/ class="btn btn-outline-primary">Know More</a></div><div class=widget><h4 class=widget-title>Topics</h4><ul class=list-unstyled><li><a class="categoryStyle text-white" href=/categories/awesome-guides>Awesome Guides</a></li><li><a class="categoryStyle text-white" href=/categories/bash>Bash</a></li><li><a class="categoryStyle text-white" href=/categories/big-data>Big Data</a></li><li><a class="categoryStyle text-white" href=/categories/chatgpt-series>Chatgpt Series</a></li><li><a class="categoryStyle text-white" href=/categories/computer-vision>Computer Vision</a></li><li><a class="categoryStyle text-white" href=/categories/data-science>Data Science</a></li><li><a class="categoryStyle text-white" href=/categories/deep-learning>Deep Learning</a></li><li><a class="categoryStyle text-white" href=/categories/learning-resources>Learning Resources</a></li><li><a class="categoryStyle text-white" href=/categories/machine-learning>Machine Learning</a></li><li><a class="categoryStyle text-white" href=/categories/natural-language-processing>Natural Language Processing</a></li><li><a class="categoryStyle text-white" href=/categories/opinion>Opinion</a></li><li><a class="categoryStyle text-white" href=/categories/programming>Programming</a></li></ul></div><div class=widget><h4 class=widget-title>Tags</h4><ul class=list-inline><li class=list-inline-item><a class="tagStyle text-white" href=/tags/algorithms>Algorithms</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/artificial-intelligence>Artificial Intelligence</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/chatgpt>Chatgpt</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/dask>Dask</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/deployment>Deployment</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/ec2>Ec2</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/generative-adversarial-networks>Generative Adversarial Networks</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/graphs>Graphs</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/image-classification>Image Classification</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/instance-segmentation>Instance Segmentation</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/interpretability>Interpretability</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/jobs>Jobs</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/kaggle>Kaggle</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/language-modeling>Language Modeling</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/machine-learning>Machine Learning</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/math>Math</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/multiprocessing>Multiprocessing</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/object-detection>Object Detection</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/oop>Oop</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/opinion>Opinion</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/pandas>Pandas</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/production>Production</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/productivity>Productivity</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/python>Python</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/pytorch>Pytorch</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/spark>Spark</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/sql>SQL</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/statistics>Statistics</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/streamlit>Streamlit</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/text-classification>Text Classification</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/timeseries>Timeseries</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/tools>Tools</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/transformers>Transformers</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/translation>Translation</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/visualization>Visualization</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/xgboost>Xgboost</a></li></ul></div><div class=widget><h4 class=widget-title>Connect With Me</h4><ul class="list-inline social-links"><li class=list-inline-item><a href="www.linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=rahulagwl"><i class=ti-linkedin></i></a></li><li class=list-inline-item><a href=https://mlwhiz.medium.com/><i class=ti-book></i></a></li><li class=list-inline-item><a href=https://twitter.com/MLWhiz><i class=ti-twitter-alt></i></a></li><li class=list-inline-item><a href=https://www.facebook.com/mlwhizblog><i class=ti-facebook></i></a></li><li class=list-inline-item><a href=https://github.com/MLWhiz><i class=ti-github></i></a></li></ul></div><script async data-uid=bfe9f82f10 src=https://mlwhiz.ck.page/bfe9f82f10/index.js></script><script async data-uid=3452d924e2 src=https://mlwhiz.ck.page/3452d924e2/index.js></script></div></div></div></section><footer><div class=container><div class=row><div class="col-12 text-center mb-5"><a href=https://mlwhiz.com/><img src=https://mlwhiz.com/images/logos/mlwhiz_black.png class=img-fluid-custom-bottom alt="DS, ML, AI!"></a></div><div class="col-12 border-top py-4 text-center">Copyright © 2020 <a href=https://mlwhiz.com style=color:#972eb4>MLWhiz</a> All Rights Reserved</div></div></div></footer><script>var indexURL="https://mlwhiz.com/index.json"</script><script src=https://mlwhiz.com/plugins/compressjscss/main.js></script><script src=https://mlwhiz.com/js/script.min.js></script><script>(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)})(window,document,'script','//www.google-analytics.com/analytics.js','ga'),ga('create','UA-54777926-1','auto'),ga('send','pageview')</script></body></html>