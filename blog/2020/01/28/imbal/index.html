<!doctype html><html lang=en-us><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-F34XSWQ5N4"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-F34XSWQ5N4')</script><meta charset=utf-8><title>The 5 most useful Techniques to Handle Imbalanced datasets - MLWhiz</title><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content="This post is about explaining the various techniques you can use to handle imbalanced datasets"><meta name=author content="Rahul Agarwal"><meta name=generator content="Hugo 0.82.0"><link rel=stylesheet href=https://mlwhiz.com/plugins/compressjscss/main.css><meta property="og:title" content="The 5 most useful Techniques to Handle Imbalanced datasets - MLWhiz"><meta property="og:description" content="This post is about explaining the various techniques you can use to handle imbalanced datasets"><meta property="og:type" content="article"><meta property="og:url" content="https://mlwhiz.com/blog/2020/01/28/imbal/"><meta property="og:image" content="https://mlwhiz.com/images/imbal/main.png"><meta property="og:image:secure_url" content="https://mlwhiz.com/images/imbal/main.png"><meta property="article:published_time" content="2020-01-28T00:00:00+00:00"><meta property="article:modified_time" content="2022-04-13T13:34:49+01:00"><meta property="article:tag" content="Data Science"><meta property="article:tag" content="Awesome Guides"><meta name=twitter:card content="summary"><meta name=twitter:image content="https://mlwhiz.com/images/imbal/main.png"><meta name=twitter:title content="The 5 most useful Techniques to Handle Imbalanced datasets - MLWhiz"><meta name=twitter:description content="This post is about explaining the various techniques you can use to handle imbalanced datasets"><meta name=twitter:site content="@mlwhiz"><meta name=twitter:creator content="@mlwhiz"><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href=https://mlwhiz.com/scss/style.min.css media=screen><link rel=stylesheet href=/css/style.css><link rel=stylesheet type=text/css href=/css/font/flaticon.css><link rel="shortcut icon" href=https://mlwhiz.com/images/favicon-200x200.png type=image/x-icon><link rel=icon href=https://mlwhiz.com/images/favicon.png type=image/x-icon><link rel=canonical href=https://mlwhiz.com/blog/2020/01/28/imbal/><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js></script><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://www.mlwhiz.com/#website","url":"https://www.mlwhiz.com/","name":"MLWhiz","description":"Want to Learn Computer Vision and NLP? - MLWhiz","potentialAction":{"@type":"SearchAction","target":"https://www.mlwhiz.com/search?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://mlwhiz.com/blog/2020/01/28/imbal/#primaryimage","url":"https://mlwhiz.com/images/imbal/main.png","width":700,"height":450},{"@type":"WebPage","@id":"https://mlwhiz.com/blog/2020/01/28/imbal/#webpage","url":"https://mlwhiz.com/blog/2020/01/28/imbal/","inLanguage":"en-US","name":"The 5 most useful Techniques to Handle Imbalanced datasets - MLWhiz","isPartOf":{"@id":"https://www.mlwhiz.com/#website"},"primaryImageOfPage":{"@id":"https://mlwhiz.com/blog/2020/01/28/imbal/#primaryimage"},"datePublished":"2020-01-28T00:00:00.00Z","dateModified":"2022-04-13T13:34:49.00Z","author":{"@id":"https://mlwhiz.com/about/#/schema/person/76376876bchxkzbchjsdjcca"},"description":"This post is about explaining the various techniques you can use to handle imbalanced datasets"},{"@type":["Person"],"@id":"https://mlwhiz.com/about/#/schema/person/76376876bchxkzbchjsdjcca","name":"Rahul Agarwal","image":{"@type":"ImageObject","@id":"https://www.mlwhiz.com/#authorlogo","url":"https://mlwhiz.com/images/author.jpg","caption":"Rahul Agarwal"},"description":"Hi there, I\u2019m Rahul Agarwal. I\u2019m a data scientist consultant and big data engineer based in Bangalore. I see a lot of times  students and even professionals wasting their time and struggling to get started with Computer Vision, Deep Learning, and NLP. I Started this Site with a purpose to augment my own understanding about new things while helping others learn about them in the best possible way.","sameAs":["https://www.linkedin.com/in/rahulagwl/","https://medium.com/@rahul_agarwal","https://twitter.com/MLWhiz","https://www.facebook.com/mlwhizblog","https://github.com/MLWhiz","https://www.instagram.com/itsmlwhiz"]}]}</script><script async data-uid=a0ebaf958d src=https://mlwhiz.ck.page/a0ebaf958d/index.js></script><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$']],processEscapes:!0,processEnvironments:!0,skipTags:['script','noscript','style','textarea','pre'],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var b=MathJax.Hub.getAllJax(),a;for(a=0;a<b.length;a+=1)b[a].SourceElement().parentNode.className+=' has-jax'}),MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:"AMS"}}})</script><link href=//apps.shareaholic.com/assets/pub/shareaholic.js as=script><script type=text/javascript data-cfasync=false async src=//apps.shareaholic.com/assets/pub/shareaholic.js data-shr-siteid=fd1ffa7fd7152e4e20568fbe49a489d0></script><script>!function(b,e,f,g,a,c,d){if(b.fbq)return;a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version='2.0',a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d)}(window,document,'script','https://connect.facebook.net/en_US/fbevents.js'),fbq('init','402633927768628'),fbq('track','PageView')</script><noscript><img height=1 width=1 style=display:none src="https://www.facebook.com/tr?id=402633927768628&ev=PageView&noscript=1"></noscript><meta property="fb:pages" content="213104036293742"><meta name=facebook-domain-verification content="qciidcy7mm137sewruizlvh8zbfnv4"></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NMQD44T" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><div class=preloader></div><header class=navigation><div class=container><nav class="navbar navbar-expand-lg navbar-white bg-transparent border-bottom pl-0"><a class="navbar-brand mobile-view" href=https://mlwhiz.com/><img class=img-fluid src=https://mlwhiz.com/images/logo.png alt="Helping You Learn Data Science!"></a>
<button class="navbar-toggler border-0" type=button data-toggle=collapse data-target=#navigation>
<i class="ti-menu h3"></i></button><div class="collapse navbar-collapse text-center" id=navigation><div class=desktop-view><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=https://www.linkedin.com/in/rahulagwl/><i class=ti-linkedin></i></a></li><li class=nav-item><a class=nav-link href=https://mlwhiz.medium.com/><i class=ti-book></i></a></li><li class=nav-item><a class=nav-link href=https://twitter.com/MLWhiz><i class=ti-twitter-alt></i></a></li><li class=nav-item><a class=nav-link href=https://www.facebook.com/mlwhizblog><i class=ti-facebook></i></a></li><li class=nav-item><a class=nav-link href=https://github.com/MLWhiz><i class=ti-github></i></a></li></ul></div><a class="navbar-brand mx-auto desktop-view" href=https://mlwhiz.com/><img class=img-fluid-custom src=https://mlwhiz.com/images/logo.png alt="Helping You Learn Data Science!"></a><ul class=navbar-nav><li class=nav-item><a class=nav-link href=https://mlwhiz.com/about>About</a></li><li class=nav-item><a class=nav-link href=https://mlwhiz.com/blog>Blog</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Topics</a><div class=dropdown-menu><a class=dropdown-item href=https://mlwhiz.com/categories/natural-language-processing>NLP</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/computer-vision>Computer Vision</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/deep-learning>Deep Learning</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/data-science>DS/ML</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/big-data>Big Data</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/awesome-guides>My Best Content</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/learning-resources>Learning Resources</a></div></li></ul><div class="search pl-lg-4"><button id=searchOpen class=search-btn><i class=ti-search></i></button><div class=search-wrapper><form action=https://mlwhiz.com//search class=h-100><input class="search-box px-4" id=search-query name=s type=search placeholder="Type & Hit Enter..."></form><button id=searchClose class=search-close><i class="ti-close text-dark"></i></button></div></div></div></nav></div></header><section class=section-sm><div class=container><div class=row><div class="col-lg-8 mb-5 mb-lg-0"><a href=/categories/data-science class=categoryStyle>Data Science</a>
<a href=/categories/awesome-guides class=categoryStyle>Awesome Guides</a><h1>The 5 most useful Techniques to Handle Imbalanced datasets</h1><div class="mb-3 post-meta"><span>By Rahul Agarwal</span><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
<span>28 January 2020</span></div><img src=https://mlwhiz.com/images/imbal/main.png class="img-fluid w-100 mb-4" alt="The 5 most useful Techniques to Handle Imbalanced datasets"><div class="content mb-5"><p>Have you ever faced an issue where you have such a small sample for the positive class in your dataset that the model is unable to learn?</p><p><em><strong>In such cases, you get a pretty high accuracy just by predicting the majority class, but you fail to capture the minority class, which is most often the point of creating the model in the first place.</strong></em></p><p>Such datasets are a pretty common occurrence and are called as an imbalanced dataset.</p><blockquote><p>Imbalanced datasets are a special case for classification problem where the class distribution is not uniform among the classes. Typically, they are composed by two classes: The majority (negative) class and the minority (positive) class</p></blockquote><p>Imbalanced datasets can be found for different use cases in various domains:</p><ul><li><p><strong>Finance</strong>: Fraud detection datasets commonly have a fraud rate of ~1–2%</p></li><li><p><strong>Ad Serving</strong>: Click prediction datasets also don’t have a high clickthrough rate.</p></li><li><p><strong>Transportation</strong>/<strong>Airline</strong>: Will Airplane failure occur?</p></li><li><p><strong>Medical</strong>: Does a patient has cancer?</p></li><li><p><strong>Content moderation</strong>: Does a post contain NSFW content?</p></li></ul><p>So how do we solve such problems?</p><p><em><strong>This post is about explaining the various techniques you can use to handle imbalanced datasets.</strong></em></p><hr><h2 id=1-random-undersampling-and-oversampling>1. Random Undersampling and Oversampling</h2><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="/images/imbal/0_huf1f60ae94db50a2a4b7f50b0e036705d_17139_500x0_resize_box_2.png 500w" src=/images/imbal/0.png alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence">
<em><a href=https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets#t1 target=_blank rel="nofollow noopener">Source</a></em></p><p>A widely adopted and perhaps the most straightforward method for dealing with highly imbalanced datasets is called resampling. It consists of removing samples from the majority class (under-sampling) and/or adding more examples from the minority class (over-sampling).</p><p>Let us first create some example imbalanced data.</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>sklearn.datasets</span> <span style=color:#6ab825;font-weight:700>import</span> make_classification

X, y = make_classification(
    n_classes=<span style=color:#3677a9>2</span>, class_sep=<span style=color:#3677a9>1.5</span>, weights=[<span style=color:#3677a9>0.9</span>, <span style=color:#3677a9>0.1</span>],
    n_informative=<span style=color:#3677a9>3</span>, n_redundant=<span style=color:#3677a9>1</span>, flip_y=<span style=color:#3677a9>0</span>,
    n_features=<span style=color:#3677a9>20</span>, n_clusters_per_class=<span style=color:#3677a9>1</span>,
    n_samples=<span style=color:#3677a9>100</span>, random_state=<span style=color:#3677a9>10</span>
)

X = pd.DataFrame(X)
X[<span style=color:#ed9d13>&#39;target&#39;</span>] = y
</code></pre></div><p>We can now do random oversampling and undersampling using:</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py>num_0 = <span style=color:#24909d>len</span>(X[X[<span style=color:#ed9d13>&#39;target&#39;</span>]==<span style=color:#3677a9>0</span>])
num_1 = <span style=color:#24909d>len</span>(X[X[<span style=color:#ed9d13>&#39;target&#39;</span>]==<span style=color:#3677a9>1</span>])
<span style=color:#6ab825;font-weight:700>print</span>(num_0,num_1)

<span style=color:#999;font-style:italic># random undersample</span>

undersampled_data = pd.concat([ X[X[<span style=color:#ed9d13>&#39;target&#39;</span>]==<span style=color:#3677a9>0</span>].sample(num_1) , X[X[<span style=color:#ed9d13>&#39;target&#39;</span>]==<span style=color:#3677a9>1</span>] ])
<span style=color:#6ab825;font-weight:700>print</span>(<span style=color:#24909d>len</span>(undersampled_data))

<span style=color:#999;font-style:italic># random oversample</span>

oversampled_data = pd.concat([ X[X[<span style=color:#ed9d13>&#39;target&#39;</span>]==<span style=color:#3677a9>0</span>] , X[X[<span style=color:#ed9d13>&#39;target&#39;</span>]==<span style=color:#3677a9>1</span>].sample(num_0, replace=True) ])
<span style=color:#6ab825;font-weight:700>print</span>(<span style=color:#24909d>len</span>(oversampled_data))
</code></pre></div><pre><code>OUTPUT:
90 10
20
180
</code></pre><hr><h2 id=2-undersampling-and-oversampling-using-imbalanced-learn>2. Undersampling and Oversampling using imbalanced-learn</h2><p>imbalanced-learn(<code>imblearn</code>) is a Python Package to tackle the curse of imbalanced datasets.</p><p>It provides a variety of methods to undersample and oversample.</p><h3 id=a-undersampling-using-tomek-links>a. Undersampling using Tomek Links:</h3><p>One of such methods it provides is called Tomek Links. Tomek links are pairs of examples of opposite classes in close vicinity.</p><p>In this algorithm, we end up removing the majority element from the Tomek link, which provides a better decision boundary for a classifier.</p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="/images/imbal/1_hubf0730b098fff787d09b5f9aa956817e_24275_500x0_resize_box_2.png 500w" src=/images/imbal/1.png alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p><em><a href=https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets#t1 target=_blank rel="nofollow noopener">Source</a></em></p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>imblearn.under_sampling</span> <span style=color:#6ab825;font-weight:700>import</span> TomekLinks

tl = TomekLinks(return_indices=True, ratio=<span style=color:#ed9d13>&#39;majority&#39;</span>)

X_tl, y_tl, id_tl = tl.fit_sample(X, y)
</code></pre></div><h3 id=b-oversampling-using-smote>b. Oversampling using SMOTE:</h3><p>In SMOTE (Synthetic Minority Oversampling Technique) we synthesize elements for the minority class, in the vicinity of already existing elements.</p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="/images/imbal/2_hu6fbd3531af225cde565004b597449758_13829_500x0_resize_box_2.png 500w" src=/images/imbal/2.png alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p><em><a href=https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets#t1 target=_blank rel="nofollow noopener">Source</a></em></p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>imblearn.over_sampling</span> <span style=color:#6ab825;font-weight:700>import</span> SMOTE

smote = SMOTE(ratio=<span style=color:#ed9d13>&#39;minority&#39;</span>)

X_sm, y_sm = smote.fit_sample(X, y)
</code></pre></div><p>There are a variety of other methods in the
<a href=https://github.com/scikit-learn-contrib/imbalanced-learn#id3 target=_blank rel="nofollow noopener">imblearn</a>
package for both undersampling(Cluster Centroids, NearMiss, etc.) and oversampling(ADASYN and bSMOTE) that you can check out.</p><hr><h2 id=3-class-weights-in-the-models>3. Class weights in the models</h2><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="/images/imbal/3_hu3c8bebb13f5cb36d625c5d42094d05f7_32382_500x0_resize_box_2.png 500w
, /images/imbal/3_hu3c8bebb13f5cb36d625c5d42094d05f7_32382_800x0_resize_box_2.png 800w" src=/images/imbal/3.png alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p>Most of the machine learning models provide a parameter called class_weights. For example, in a random forest classifier using, class_weights we can specify a higher weight for the minority class using a dictionary.</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>sklearn.linear_model</span> <span style=color:#6ab825;font-weight:700>import</span> LogisticRegression

clf = LogisticRegression(class_weight={<span style=color:#3677a9>0</span>:<span style=color:#3677a9>1</span>,<span style=color:#3677a9>1</span>:<span style=color:#3677a9>10</span>})
</code></pre></div><p><em><strong>But what happens exactly in the background?</strong></em></p><p>In logistic Regression, we calculate loss per example using binary cross-entropy:</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py>Loss = -ylog(p) - (<span style=color:#3677a9>1</span>-y)log(<span style=color:#3677a9>1</span>-p)
</code></pre></div><p>In this particular form, we give equal weight to both the positive and the negative classes. When we set class_weight as <code>class_weight = {0:1,1:20}</code>, the classifier in the background tries to minimize:</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py>NewLoss = -<span style=color:#3677a9>20</span>ylog(p) - <span style=color:#3677a9>1</span>(<span style=color:#3677a9>1</span>-y)log(<span style=color:#3677a9>1</span>-p)
</code></pre></div><p><em><strong>So what happens exactly here?</strong></em></p><ul><li><p>If our model gives a probability of 0.3 and we misclassify a positive example, the NewLoss acquires a value of -20log(0.3) = 10.45</p></li><li><p>If our model gives a probability of 0.7 and we misclassify a negative example, the NewLoss acquires a value of -log(0.3) = 0.52</p></li></ul><p>That means we penalize our model around twenty times more when it misclassifies a positive minority example in this case.</p><p><em><strong>How can we compute class_weights?</strong></em></p><p><em>There is no one method to do this, and this should be constructed as a hyperparameter search problem for your particular problem.</em></p><p>But if you want to get class_weights using the distribution of the y variable, you can use the following nifty utility from sklearn.</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>sklearn.utils.class_weight</span> <span style=color:#6ab825;font-weight:700>import</span> compute_class_weight

class_weights = compute_class_weight(<span style=color:#ed9d13>&#39;balanced&#39;</span>, np.unique(y), y)
</code></pre></div><hr><h2 id=4-change-your-evaluation-metric>4. Change your Evaluation Metric</h2><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="/images/imbal/4_huff6b7a9f14c7f9e198e046db0db15bae_3575290_500x0_resize_box_2.png 500w
, /images/imbal/4_huff6b7a9f14c7f9e198e046db0db15bae_3575290_800x0_resize_box_2.png 800w
, /images/imbal/4_huff6b7a9f14c7f9e198e046db0db15bae_3575290_1200x0_resize_box_2.png 1200w
, /images/imbal/4_huff6b7a9f14c7f9e198e046db0db15bae_3575290_1500x0_resize_box_2.png 1500w" src=/images/imbal/4.png alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p>Choosing the right evaluation metric is pretty essential whenever we work with imbalanced datasets. Generally, in such cases, the F1 Score is what I want as my
<a href=https://towardsdatascience.com/the-5-classification-evaluation-metrics-you-must-know-aa97784ff226 target=_blank rel="nofollow noopener">&lt;em>&lt;strong>evaluation metric&lt;/strong>&lt;/em></a>
.</p><p>The F1 score is a number between 0 and 1 and is the harmonic mean of precision and recall.</p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset src=/images/imbal/5.png alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p><em><strong>So how does it help?</strong></em></p><p>Let us start with a binary prediction problem. <em><strong>We are predicting if an asteroid will hit the earth or not.</strong></em></p><p>So we create a model that predicts “No” for the whole training set.</p><p><em><strong>What is the accuracy(Normally the most used evaluation metric)?</strong></em></p><p>It is more than 99%, and so according to accuracy, this model is pretty good, but it is worthless.</p><p><em><strong>Now, what is the F1 score?</strong></em></p><p>Our precision here is 0. What is the recall of our positive class? It is zero. And hence the F1 score is also 0.</p><p>And thus we get to know that the classifier that has an accuracy of 99% is worthless for our case. And hence it solves our problem.</p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset src=/images/imbal/6.png alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p>Simply stated the <em><strong>F1 score sort of maintains a balance between the precision and recall for your classifier</strong></em>. If your precision is low, the F1 is low, and if the recall is low again, your F1 score is low.</p><blockquote><p>If you are a police inspector and you want to catch criminals, you want to be sure that the person you catch is a criminal (Precision) and you also want to capture as many criminals (Recall) as possible. The F1 score manages this tradeoff.</p></blockquote><h3 id=how-to-use>How to Use?</h3><p>You can calculate the F1 score for binary prediction problems using:</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>sklearn.metrics</span> <span style=color:#6ab825;font-weight:700>import</span> f1_score
y_true = [<span style=color:#3677a9>0</span>, <span style=color:#3677a9>1</span>, <span style=color:#3677a9>1</span>, <span style=color:#3677a9>0</span>, <span style=color:#3677a9>1</span>, <span style=color:#3677a9>1</span>]
y_pred = [<span style=color:#3677a9>0</span>, <span style=color:#3677a9>0</span>, <span style=color:#3677a9>1</span>, <span style=color:#3677a9>0</span>, <span style=color:#3677a9>0</span>, <span style=color:#3677a9>1</span>]
f1_score(y_true, y_pred)
</code></pre></div><p>This is one of the functions which I use to get the best threshold for maximizing F1 score for binary predictions. The below function iterates through possible threshold values to find the one that gives the best F1 score.</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#999;font-style:italic># y_pred is an array of predictions</span>
<span style=color:#6ab825;font-weight:700>def</span> <span style=color:#447fcf>bestThresshold</span>(y_true,y_pred):
    best_thresh = None
    best_score = <span style=color:#3677a9>0</span>
    <span style=color:#6ab825;font-weight:700>for</span> thresh <span style=color:#6ab825;font-weight:700>in</span> np.arange(<span style=color:#3677a9>0.1</span>, <span style=color:#3677a9>0.501</span>, <span style=color:#3677a9>0.01</span>):
        score = f1_score(y_true, np.array(y_pred)&gt;thresh)
        <span style=color:#6ab825;font-weight:700>if</span> score &gt; best_score:
            best_thresh = thresh
            best_score = score
    <span style=color:#6ab825;font-weight:700>return</span> best_score , best_thresh
</code></pre></div><hr><h2 id=5-miscellaneous>5. Miscellaneous</h2><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="/images/imbal/7_hu31cb4201afead9e0bf7c643b8f421929_4112313_500x0_resize_box_2.png 500w
, /images/imbal/7_hu31cb4201afead9e0bf7c643b8f421929_4112313_800x0_resize_box_2.png 800w
, /images/imbal/7_hu31cb4201afead9e0bf7c643b8f421929_4112313_1200x0_resize_box_2.png 1200w
, /images/imbal/7_hu31cb4201afead9e0bf7c643b8f421929_4112313_1500x0_resize_box_2.png 1500w" src=/images/imbal/7.png alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p>Various other methods might work depending on your use case and the problem you are trying to solve:</p><h3 id=a-collect-more-data>a) Collect more Data</h3><p>This is a definite thing you should try if you can. Getting more data with more positive examples is going to help your models get a more varied perspective of both the majority and minority classes.</p><h3 id=b-treat-the-problem-as-anomaly-detection>b) Treat the problem as anomaly detection</h3><p>You might want to treat your classification problem as an anomaly detection problem.</p><p><strong>Anomaly detection</strong> is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data</p><p>You can use Isolation forests or autoencoders for anomaly detection.</p><h3 id=c-model-based>c) Model-based</h3><p>Some models are particularly suited for imbalanced datasets.</p><p>For example, in boosting models, we give more weights to the cases that get misclassified in each tree iteration.</p><hr><h2 id=conclusion>Conclusion</h2><p>There is no one size fits all when working with imbalanced datasets. You will have to try multiple things based on your problem.</p><p>In this post, I talked about the usual suspects that come to my mind whenever I face such a problem.</p><p>A suggestion would be to try using all of the above approaches and try to see whatever works best for your use case.</p><p>If you want to
<a href="https://towardsdatascience.com/how-did-i-start-with-data-science-3f4de6b501b0?source=---------8------------------" target=_blank rel="nofollow noopener">learn</a>
more about imbalanced datasets and the problems they pose, I would like to call out this
<a href=https://coursera.pxf.io/NKERRq target=_blank rel="nofollow noopener">&lt;em>&lt;strong>excellent course&lt;/strong>&lt;/em></a>
by Andrew Ng. This was the one that got me started. Do check it out.</p><p>Thanks for the read. I am going to be writing more beginner-friendly posts in the future too. Follow me up at
<a href="https://mlwhiz.medium.com/?source=post_page---------------------------" target=_blank rel="nofollow noopener">&lt;strong>Medium&lt;/strong></a>
or Subscribe to my
<a href=https://mlwhiz.ck.page/a9b8bda70c target=_blank rel="nofollow noopener">&lt;strong>blog&lt;/strong></a>
.</p><p>Also, a small disclaimer — There might be some affiliate links in this post to relevant resources, as sharing knowledge is never a bad idea.</p><script async data-uid=8d7942551b src=https://mlwhiz.ck.page/8d7942551b/index.js></script><div class=shareaholic-canvas data-app=share_buttons data-app-id=28372088 style=margin-bottom:1px></div><a href=https://coursera.pxf.io/coursera rel=nofollow><img border=0 alt="Start your future with a Data Analysis Certificate." src="https://ad.linksynergy.com/fs-bin/show?id=lVarvwc5BD0&bids=759505.377&subid=0&type=4&gridnum=16"></a><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return}var b=document,a=b.createElement('script');a.async=!0,a.src='//mlwhiz.disqus.com/embed.js',a.setAttribute('data-timestamp',+new Date),(b.head||b.body).appendChild(a)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div><div class=col-lg-4><div class=widget><script type=text/javascript src=https://ko-fi.com/widgets/widget_2.js></script><script type=text/javascript>kofiwidget2.init('Support Me on Ko-fi','#00aaa1','S6S3NPCD'),kofiwidget2.draw()</script></div><div class=widget><h4 class=widget-title>About Me</h4><img src=https://mlwhiz.com/images/author.jpg alt class="img-fluid author-thumb-sm d-block mx-auto rounded-circle mb-4"><p>I’m a data scientist consultant and big data engineer based in London, where I am currently working with Facebook .</p><a href=https://mlwhiz.com/about/ class="btn btn-outline-primary">Know More</a></div><div class=widget><h4 class=widget-title>Topics</h4><ul class=list-unstyled><li><a class=categoryStyle style=color:#fff href=/categories/awesome-guides>Awesome Guides</a></li><li><a class=categoryStyle style=color:#fff href=/categories/bash>Bash</a></li><li><a class=categoryStyle style=color:#fff href=/categories/big-data>Big Data</a></li><li><a class=categoryStyle style=color:#fff href=/categories/chatgpt-series>Chatgpt Series</a></li><li><a class=categoryStyle style=color:#fff href=/categories/computer-vision>Computer Vision</a></li><li><a class=categoryStyle style=color:#fff href=/categories/data-science>Data Science</a></li><li><a class=categoryStyle style=color:#fff href=/categories/deep-learning>Deep Learning</a></li><li><a class=categoryStyle style=color:#fff href=/categories/learning-resources>Learning Resources</a></li><li><a class=categoryStyle style=color:#fff href=/categories/machine-learning>Machine Learning</a></li><li><a class=categoryStyle style=color:#fff href=/categories/natural-language-processing>Natural Language Processing</a></li><li><a class=categoryStyle style=color:#fff href=/categories/opinion>Opinion</a></li><li><a class=categoryStyle style=color:#fff href=/categories/programming>Programming</a></li></ul></div><div class=widget><h4 class=widget-title>Tags</h4><ul class=list-inline><li class=list-inline-item><a class="tagStyle text-white" href=/tags/algorithms>Algorithms</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/artificial-intelligence>Artificial Intelligence</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/chatgpt>Chatgpt</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/dask>Dask</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/deployment>Deployment</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/ec2>Ec2</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/generative-adversarial-networks>Generative Adversarial Networks</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/graphs>Graphs</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/image-classification>Image Classification</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/instance-segmentation>Instance Segmentation</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/interpretability>Interpretability</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/jobs>Jobs</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/kaggle>Kaggle</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/language-modeling>Language Modeling</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/machine-learning>Machine Learning</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/math>Math</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/multiprocessing>Multiprocessing</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/object-detection>Object Detection</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/oop>Oop</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/opinion>Opinion</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/pandas>Pandas</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/production>Production</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/productivity>Productivity</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/python>Python</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/pytorch>Pytorch</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/spark>Spark</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/sql>SQL</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/statistics>Statistics</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/streamlit>Streamlit</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/text-classification>Text Classification</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/timeseries>Timeseries</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/tools>Tools</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/transformers>Transformers</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/translation>Translation</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/visualization>Visualization</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/xgboost>Xgboost</a></li></ul></div><div class=widget><h4 class=widget-title>Connect With Me</h4><ul class="list-inline social-links"><li class=list-inline-item><a href=https://www.linkedin.com/in/rahulagwl/><i class=ti-linkedin></i></a></li><li class=list-inline-item><a href=https://mlwhiz.medium.com/><i class=ti-book></i></a></li><li class=list-inline-item><a href=https://twitter.com/MLWhiz><i class=ti-twitter-alt></i></a></li><li class=list-inline-item><a href=https://www.facebook.com/mlwhizblog><i class=ti-facebook></i></a></li><li class=list-inline-item><a href=https://github.com/MLWhiz><i class=ti-github></i></a></li></ul></div><script async data-uid=bfe9f82f10 src=https://mlwhiz.ck.page/bfe9f82f10/index.js></script><script async data-uid=3452d924e2 src=https://mlwhiz.ck.page/3452d924e2/index.js></script></div></div></div></section><footer><div class=container><div class=row><div class="col-12 text-center mb-5"><a href=https://mlwhiz.com/><img src=https://mlwhiz.com/images/logo.png class=img-fluid-custom-bottom alt="Helping You Learn Data Science!"></a></div><div class="col-12 border-top py-4 text-center">Copyright © 2020 <a href=https://mlwhiz.com>MLWhiz</a> All Rights Reserved</div></div></div></footer><script>var indexURL="https://mlwhiz.com/index.json"</script><script src=https://mlwhiz.com/plugins/compressjscss/main.js></script><script src=https://mlwhiz.com/js/script.min.js></script><script>(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)})(window,document,'script','//www.google-analytics.com/analytics.js','ga'),ga('create','UA-54777926-1','auto'),ga('send','pageview')</script></body></html>