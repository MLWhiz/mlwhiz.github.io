<!DOCTYPE html>
<html class="no-js" lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Practical Spark Tips for Data Scientists</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="This post is going to be about Practical Spark and memory management tips for Data Scientists.">
	

	
	<link rel='preload' href='//apps.shareaholic.com/assets/pub/shareaholic.js' as='script' />
	<script type="text/javascript" data-cfasync="false" async src="//apps.shareaholic.com/assets/pub/shareaholic.js" data-shr-siteid="fd1ffa7fd7152e4e20568fbe49a489d0"></script>
	
	
	<meta name="generator" content="Hugo 0.53" />
	<meta property="og:title" content="Practical Spark Tips for Data Scientists" />
<meta property="og:description" content="This post is going to be about Practical Spark and memory management tips for Data Scientists." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mlwhiz.com/blog/2020/03/20/practicalspark/" />
<meta property="og:image" content="https://mlwhiz.com/images/practicalspark/main.png" />
<meta property="article:published_time" content="2020-03-20T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2020-03-20T00:00:00&#43;00:00"/>

	<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://mlwhiz.com/images/practicalspark/main.png"/>

<meta name="twitter:title" content="Practical Spark Tips for Data Scientists"/>
<meta name="twitter:description" content="This post is going to be about Practical Spark and memory management tips for Data Scientists."/>


	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/css/style.css">
	<link rel="stylesheet" href="/css/custom.css">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="96x96" href="/favicon-96x96.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	
	
		
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-54777926-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

	
	<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
	new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
	j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
	'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
	})(window,document,'script','dataLayer','GTM-NMQD44T');</script>
	

	
	<script>
	  !function(f,b,e,v,n,t,s)
	  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
	  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
	  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
	  n.queue=[];t=b.createElement(e);t.async=!0;
	  t.src=v;s=b.getElementsByTagName(e)[0];
	  s.parentNode.insertBefore(t,s)}(window, document,'script',
	  'https://connect.facebook.net/en_US/fbevents.js');
	  fbq('init', '1062344757288542');
	  fbq('track', 'PageView');
	</script>
	<noscript><img height="1" width="1" style="display:none"
	  src="https://www.facebook.com/tr?id=1062344757288542&ev=PageView&noscript=1"
	/></noscript>
	


	
  	<script async>(function(s,u,m,o,j,v){j=u.createElement(m);v=u.getElementsByTagName(m)[0];j.async=1;j.src=o;j.dataset.sumoSiteId='22863fd8ad7ebbfab9b8ca60b7db8f65e9a15559f384f785f66903e365aa8f48';v.parentNode.insertBefore(j,v)})(window,document,'script','//load.sumo.com/');</script>
  	<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>
</head>
<body class="body">
	  
	  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NMQD44T"
	  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
	  
	<div class="container container--outer">
		<header class="header">
	<div class="container">
		<div class="logo">

			<a class="logo__link" href="/" title="MLWhiz" rel="home">

				<div class="logo__title">MLWhiz</div>
				<div class="logo__tagline">Deep Learning, Data Science and NLP Enthusiast</div>
			</a>
		</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/">Blog</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/archive">Archive</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/about/">About Me</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/nlpseries/">NLP</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/resources/index.html">Learning Resources</a>
		</li>
	</ul>
</nav>

	</div>
</header>


		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Practical Spark Tips for Data Scientists</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
	<time class="meta__text" datetime="2020-03-20T00:00:00">March 20, 2020</time>
</div>
</div>
		</header>
		<div class="content post__content clearfix">
			

<p><img src="/images/practicalspark/main.png" alt="" /></p>

<p><strong><em>I know — Spark is sometimes frustrating to work with.</em></strong></p>

<p><strong><em>Although sometimes we can manage our big data using tools like <a href="https://towardsdatascience.com/minimal-pandas-subset-for-data-scientist-on-gpu-d9a6c7759c7f?source=---------5------------------" rel="nofollow" target="_blank">Rapids</a> or <a href="https://towardsdatascience.com/add-this-single-word-to-make-your-pandas-apply-faster-90ee2fffe9e8?source=---------11------------------" rel="nofollow" target="_blank">Parallelization</a>,</em></strong> there is no way around using Spark if you are working with Terabytes of data.</p>

<p>In my <a href="https://towardsdatascience.com/the-hitchhikers-guide-to-handle-big-data-using-spark-90b9be0fe89a" rel="nofollow" target="_blank">l</a>ast few posts on Spark, I explained how to work with <a href="https://towardsdatascience.com/the-hitchhikers-guide-to-handle-big-data-using-spark-90b9be0fe89a" rel="nofollow" target="_blank">PySpark RDDs</a> and <a href="https://towardsdatascience.com/5-ways-to-add-a-new-column-in-a-pyspark-dataframe-4e75c2fd8c08" rel="nofollow" target="_blank">Dataframes</a>. Although these posts explain a lot on how to work with RDDs and Dataframe operations, they still are not quite enough.</p>

<p>Why? Because Spark gives memory errors a lot of times, and it is only when you genuinely work on big datasets with spark, would you be able to truly work with Spark.</p>

<p><strong>This post is going to be about — “Practical Spark and memory management tips for Data Scientists.”</strong></p>

<hr />

<h2 id="1-map-side-joins">1. Map Side Joins</h2>

<p><img src="/images/practicalspark/0.png" alt="Joining Dataframes" /></p>

<p>The syntax of joins in Spark is pretty similar to pandas:</p>

<pre><code>df3 = df1.join(df2, df1.column == df2.column,how='left')
</code></pre>

<p>But I faced a problem. The df1 had around 1Billion rows while df2 had around 100 Rows. When I tried the above join, it didn’t work and failed with memory exhausted errors after running for 20 minutes.</p>

<p>I was writing this code on a pretty big cluster with more than 400 executors with each executor having more than 4GB RAM. I was stumped as I tried to repartition my data frames using multiple schemes, but nothing seemed to work.</p>

<p>So what should I do? Is Spark not able to work with a mere billion rows? Not Really. I just needed to use Map-side joins or broadcasting in Spark terminology.</p>

<pre><code>from pyspark.sql.functions import broadcast
df3 = df1.join(broadcast(df2), df1.column == df2.column,how='left')
</code></pre>

<p>Using the simple broadcasting code above, I was able to send the smaller df2 to all the nodes, and this didn’t take a lot of time or memory. What happens in the backend is that a copy of df2 is sent to all the partitions and each partition uses that copy to do the join. That means that there is no data movement when it comes to df1, which is a lot bigger than df2.</p>

<hr />

<h2 id="2-spark-cluster-configurations">2. Spark Cluster Configurations</h2>

<p><img src="/images/practicalspark/1.png" alt="Set the Parallelism and worker nodes based on your task size" /><em>Set the Parallelism and worker nodes based on your task size</em></p>

<p>What also made my life difficult while I was starting work with Spark was the way the Spark cluster needs to be configured. Your spark cluster might need a lot of custom configuration ad tuning based on the job you want to run.</p>

<p>Some of the most important configurations and options are as follows:</p>

<h3 id="a-spark-sql-shuffle-partitions-and-spark-default-parallelism">a. spark.sql.shuffle.partitions and spark.default.parallelism:</h3>

<p>spark.sql.shuffle.partitions configures the number of partitions to use when shuffling data for joins or aggregations. The spark.default.parallelism is the default number of partitions in RDDs returned by transformations like join, reduceByKey, and parallelize when not set by the user. The default value for these is 200.</p>

<p><strong><em>In simple words, these set the degree of parallelism you want to have in your cluster.</em></strong></p>

<p>If you don’t have a lot of data, the value of 200 is fine, but if you have huge data, you might want to increase these numbers. It also depends on the number of executors you have. My cluster was pretty big with 400 executors, so I kept this at 1200. A rule of thumb is to keep it as a multiple of the number of executors so that each executor ends up with multiple jobs.</p>

<pre><code>sqlContext.setConf( &quot;spark.sql.shuffle.partitions&quot;, 800)
sqlContext.setConf( &quot;spark.default.parallelism&quot;, 800)
</code></pre>

<h3 id="b-spark-sql-parquet-binaryasstring">b. spark.sql.parquet.binaryAsString</h3>

<p>I was working with .parquet files in Spark, and most of my data columns were strings. But somehow whenever I loaded the data in Spark, the string columns got converted into binary format on which I was not able to use any string manipulation functions. The way I solved this was by using:</p>

<pre><code>sqlContext.setConf(&quot;spark.sql.parquet.binaryAsString&quot;,&quot;true&quot;)
</code></pre>

<p>The above configuration converts the binary format to string while loading parquet files. Now it is a default configuration I set whenever I work with Spark.</p>

<h3 id="c-yarn-configurations">c. Yarn Configurations:</h3>

<p>There are other configurations that you might need to tune that define your cluster. But these need to be set up when the cluster is starting and are not as dynamic as the above ones. The few I want to put down here are for managing memory spills on the executor nodes. Sometimes the executor core gets a lot of work.</p>

<ul>
<li><p>spark.yarn.executor.memoryOverhead: 8192</p></li>

<li><p>yarn.nodemanager.vmem-check-enabled: False</p></li>
</ul>

<p>There are a lot of configurations that you might want to tune while setting up your spark cluster. You can take a look at them in the <a href="https://spark.apache.org/docs/latest/configuration.html" rel="nofollow" target="_blank">official docs</a>.</p>

<hr />

<h2 id="3-repartitioning">3. Repartitioning</h2>

<p><img src="/images/practicalspark/2.png" alt="Keeping the workers happy by having them handle an equal amount of data" /><em>Keeping the workers happy by having them handle an equal amount of data</em></p>

<p>You might want to repartition your data if you feel your data has been skewed while working with all the transformations and joins. The simplest way to do it is by using:</p>

<pre><code>df = df.repartition(1000)
</code></pre>

<p>Sometimes you might also want to repartition by a known scheme as this scheme might be used by a certain join or aggregation operation later on. You can use multiple columns to repartition using:</p>

<pre><code>df = df.repartition('cola', 'colb','colc','cold')
</code></pre>

<p>You can get the number of partitions in a data frame using:</p>

<pre><code>df.rdd.getNumPartitions()
</code></pre>

<p>You can also check out the distribution of records in a partition by using the glom function. This helps in understanding the skew in the data that happens while working with various transformations.</p>

<pre><code>df.glom().map(len).collect()
</code></pre>

<hr />

<h2 id="conclusion">Conclusion</h2>

<p>There are a lot of things we don’t know, we don’t know. These are called unknown unknowns. It is only by multiple code failures and reading up on multiple stack overflow threads that we understand what we need.</p>

<p>Here I have tried to summarize a few of the problems that I faced around memory issues and configurations while working with Spark and how to solve them. There are a lot of other configuration options in Spark, which I have not covered, but I hope this post gave you some clarity on how to set these and use them.</p>

<p>Now, if you need to learn Spark basics, take a look at my previous post:
<a href="https://towardsdatascience.com/the-hitchhikers-guide-to-handle-big-data-using-spark-90b9be0fe89a" rel="nofollow" target="_blank"><strong>The Hitchhikers guide to handle Big Data using Spark</strong>
*Not just an Introduction*towardsdatascience.com</a></p>

<p>Also, if you want to learn more about Spark and Spark DataFrames, I would like to call out these excellent courses on <a href="https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;offerid=467035.11468293556&amp;type=2&amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Fbig-data-essentials" rel="nofollow" target="_blank">Big Data Essentials: HDFS, MapReduce and Spark RDD</a> and <a href="https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;offerid=467035.11468293488&amp;type=2&amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Fbig-data-analysis" rel="nofollow" target="_blank">Big Data Analysis: Hive, Spark SQL, DataFrames and GraphFrames</a> by Yandex on Coursera.</p>

<p>Thanks for the read. I am going to be writing more beginner-friendly posts in the future too. Follow me up at <a href="https://medium.com/@rahul_agarwal?source=post_page---------------------------" rel="nofollow" target="_blank">Medium</a> or Subscribe to my <a href="http://eepurl.com/dbQnuX?source=post_page---------------------------" rel="nofollow" target="_blank">blog</a> to be informed about them. As always, I welcome feedback and constructive criticism and can be reached on Twitter <a href="https://twitter.com/MLWhiz?source=post_page---------------------------" rel="nofollow" target="_blank">@mlwhiz</a></p>

<p>Also, a small disclaimer — There might be some affiliate links in this post to relevant resources, as sharing knowledge is never a bad idea.</p>

		</div>
		
<div class="post__tags tags clearfix">
	<svg class="icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item"><a class="tags__link btn" href="/tags/python/" rel="tag">Python</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/statistics/" rel="tag">Statistics</a></li>
	</ul>
</div>
		

<div class="shareaholic-canvas" data-app="share_buttons" data-app-id="28372088"></div>

<a href="https://click.linksynergy.com/fs-bin/click?id=lVarvwc5BD0&offerid=467035.372&subid=0&type=4" rel="nofollow"><IMG border="0"   alt="Start your future with a Data Science Certificate." src="https://ad.linksynergy.com/fs-bin/show?id=lVarvwc5BD0&bids=467035.372&subid=0&type=4&gridnum=16"></a>





























	</article>
</main>


<nav class="post-nav flex">
	<div class="post-nav__item post-nav__item--prev">
		<a class="post-nav__link" href="/blog/2020/02/24/sparkcolumns/" rel="prev"><span class="post-nav__caption">«&thinsp;Previous</span><p class="post-nav__post-title">5 Ways to add a new column in a PySpark Dataframe</p></a>
	</div>
	<div class="post-nav__item post-nav__item--next">
		<a class="post-nav__link" href="/blog/2020/03/24/coronaai/" rel="next"><span class="post-nav__caption">Next&thinsp;»</span><p class="post-nav__post-title">Can AI help in fighting against Corona?</p></a>
	</div>
</nav>

<section class="comments">
	<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "mlwhiz" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


			</div>
			<style type="text/css">

  .btn {
    display: inline-block;
    font-weight: 400;
    text-align: center;
    white-space: nowrap;
    vertical-align: middle;
    -webkit-user-select: none;
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none;
    border: 1px solid transparent;
    padding: .375rem .75rem;
    font-size: 1rem;
    line-height: 1.5;
    border-radius: .25rem;
    transition: color .15s ease-in-out,background-color .15s ease-in-out,border-color .15s ease-in-out,box-shadow .15s ease-in-out;
}

.btn-session {
    color: #fff;
    background-color: #28a745;
    border-color: #28a745;
}
</style>


<aside class="sidebar">
  <div style="text-align:center">     
    
  <a href='https://ko-fi.com/S6S3NPCD' target='_blank'><img height='36' style='border:0px;height:36px;' src='https://az743702.vo.msecnd.net/cdn/kofi4.png?v=0' border='0' alt='Buy Me a Coffee at ko-fi.com' /></a>
  </div>
  <br><div class="widget-search widget">
	<form class="widget-search__form" role="search" method="get" action="https://google.com/search">
		<label>
			<input class="widget-search__field" type="search" placeholder="SEARCH..." value="" name="q" aria-label="SEARCH...">
		</label>
		<input class="widget-search__submit" type="submit" value="Search">
		<input type="hidden" name="sitesearch" value="https://mlwhiz.com/" />
	</form>
</div>
<div class="widget-recent widget">
	<h4 class="widget__title">Recent Posts</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/blog/2020/05/25/democratize/">Don’t Democratize Data Science</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/05/25/cogbias/">Five Cognitive Biases In Data Science (And how to avoid them)</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/05/25/dls/">Stop Worrying and Create your Deep Learning Server in 30 minutes</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/05/24/fstring/">How and Why to use f strings in Python3?</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/05/24/multitextclass/">Using Deep Learning for End to End Multiclass Text Classification</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/03/29/coronatimes/">A Newspaper for COVID-19 — The CoronaTimes</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/03/27/covidcourses/">5 Online Courses you can take for free during COVID-19 Epidemic</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/03/24/coronaai/">Can AI help in fighting against Corona?</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/03/20/practicalspark/">Practical Spark Tips for Data Scientists</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/02/24/sparkcolumns/">5 Ways to add a new column in a PySpark Dataframe</a></li>
		</ul>
	</div>
</div>

<div style="text-align:center">     
    
    <a class="btn btn-session" href="https://www.patreon.com/bePatron?u=28135435" role="button">1:1 Session</a>
  </div>

<br>

<div class="shareaholic-canvas" data-app="follow_buttons" data-app-id="28033293" style="white-space: inherit;"></div>

<center><strong>Subsribe to Get</strong>
<a href="https://www.amazon.in/Advanced-Python-Tips-explained-Simply-ebook/dp/B07TM3D279">
  <img src="https://m.media-amazon.com/images/I/41IoozUrQWL.jpg" width="70%" height="70%"></img></a>
  

<link href="//cdn-images.mailchimp.com/embedcode/slim-10_7.css" rel="stylesheet" type="text/css">


<style type="text/css">
  #mc_embed_signup .button {background-color: #127edc;
 
  }
  #mc_embed_signup form .center{
    display: block;
    position: relative;
    text-align: -webkit-center;
    padding: 10px -5px 10px 3%;}  
 
  #mc_embed_signup form {
    text-align: -webkit-center;
    } 

    #mc_embed_signup input.button {
    min-width: 100px;
}
   
</style>

<div id="mc_embed_signup">
<form action="//mlwhiz.us15.list-manage.com/subscribe/post?u=4e9962f4ce4a94818bcc2f249&amp;id=87a48fafdd" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
    <input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required>
    
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_4e9962f4ce4a94818bcc2f249_87a48fafdd" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>
</center>
</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy;  2014-2020 Rahul Agarwal.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>



	</div>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&adInstanceId=93f2f4f9-cf51-415d-84af-08cbb74b178f"></script>
<script async defer src="/js/menu.js"></script></body>
</html>