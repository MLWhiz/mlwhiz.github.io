<!DOCTYPE html>
<html class="no-js" lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>The Simple Math behind 3 Decision Tree Splitting criterions</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="This post is about various evaluation metrics and how and when to use them.">
	

	
	<link rel='preload' href='//apps.shareaholic.com/assets/pub/shareaholic.js' as='script' />
	<script type="text/javascript" data-cfasync="false" async src="//apps.shareaholic.com/assets/pub/shareaholic.js" data-shr-siteid="fd1ffa7fd7152e4e20568fbe49a489d0"></script>
	
	
	<meta name="generator" content="Hugo 0.53" />
	<meta property="og:title" content="The Simple Math behind 3 Decision Tree Splitting criterions" />
<meta property="og:description" content="This post is about various evaluation metrics and how and when to use them." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mlwhiz.com/blog/2019/11/12/dtsplits/" />
<meta property="og:image" content="https://mlwhiz.com/images/dtsplits/main.png" />
<meta property="article:published_time" content="2019-11-12T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2019-11-12T00:00:00&#43;00:00"/>

	<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://mlwhiz.com/images/dtsplits/main.png"/>

<meta name="twitter:title" content="The Simple Math behind 3 Decision Tree Splitting criterions"/>
<meta name="twitter:description" content="This post is about various evaluation metrics and how and when to use them."/>


	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/css/style.css">
	<link rel="stylesheet" href="/css/custom.css">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="96x96" href="/favicon-96x96.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	
	
		
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-54777926-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

	
	<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
	new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
	j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
	'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
	})(window,document,'script','dataLayer','GTM-NMQD44T');</script>
	

	
	<script>
	  !function(f,b,e,v,n,t,s)
	  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
	  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
	  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
	  n.queue=[];t=b.createElement(e);t.async=!0;
	  t.src=v;s=b.getElementsByTagName(e)[0];
	  s.parentNode.insertBefore(t,s)}(window, document,'script',
	  'https://connect.facebook.net/en_US/fbevents.js');
	  fbq('init', '1062344757288542');
	  fbq('track', 'PageView');
	</script>
	<noscript><img height="1" width="1" style="display:none"
	  src="https://www.facebook.com/tr?id=1062344757288542&ev=PageView&noscript=1"
	/></noscript>
	


	
  	<script async>(function(s,u,m,o,j,v){j=u.createElement(m);v=u.getElementsByTagName(m)[0];j.async=1;j.src=o;j.dataset.sumoSiteId='22863fd8ad7ebbfab9b8ca60b7db8f65e9a15559f384f785f66903e365aa8f48';v.parentNode.insertBefore(j,v)})(window,document,'script','//load.sumo.com/');</script>
  	<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>
</head>
<body class="body">
	  
	  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NMQD44T"
	  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
	  
	<div class="container container--outer">
		<header class="header">
	<div class="container">
		<div class="logo">

			<a class="logo__link" href="/" title="MLWhiz" rel="home">

				<div class="logo__title">MLWhiz</div>
				<div class="logo__tagline">Deep Learning, Data Science and NLP Enthusiast</div>
			</a>
		</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/">Blog</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/archive">Archive</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/about/">About Me</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/nlpseries/">NLP</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/atom.xml">RSS</a>
		</li>
	</ul>
</nav>

	</div>
</header>


		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">The Simple Math behind 3 Decision Tree Splitting criterions</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
	<time class="meta__text" datetime="2019-11-12T00:00:00">November 12, 2019</time>
</div>
</div>
		</header>
		<div class="content post__content clearfix">
			

<p>Decision Trees are great and are useful for a variety of tasks. They form the backbone of most of the best performing models in the industry like XGboost and Lightgbm.</p>

<p>But how do they work exactly? In fact, this is one of the most asked questions in ML/DS interviews.</p>

<p>We generally know they work in a stepwise manner and have a tree structure where we split a node using some feature on some criterion.</p>

<p><strong><em>But how do these features get selected and how a particular threshold or value gets chosen for a feature?</em></strong></p>

<p><strong><em>In this post, I will talk about three of the main splitting criteria used in Decision trees and why they work.</em></strong> This is something that has been written about repeatedly but never really well enough.</p>

<h2 id="1-gini-impurity">1. Gini Impurity</h2>

<p>According to Wikipedia,</p>

<blockquote>
<p>Gini impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset.</p>
</blockquote>

<p>In simple terms, Gini impurity is the <strong><em>measure of impurity in a node</em></strong>. Its formula is:</p>

<p><img src="/images/dtsplits/0.png" alt="" /></p>

<p>where J is the number of classes present in the node and p is the distribution of the class in the node.</p>

<p>So to understand the formula a little better, let us talk specifically about the binary case where we have nodes with only two classes.</p>

<p>So in the below five examples of candidate nodes labelled A-E and with the distribution of positive and negative class shown, which is the ideal condition to be in?</p>

<p>I reckon you would say A or E and you are right. What is the worst situation to be in? C, I suppose as the data is precisely 50:50 in that node.</p>

<p><img src="/images/dtsplits/1.png" alt="" /></p>

<p>Now, this all looks good, intuitively. Gini Impurity gives us a way to quantify it.</p>

<p>Let us calculate the Gini impurity for all five nodes separately and check the values.</p>

<p><img src="/images/dtsplits/2.png" alt="" /></p>

<p>✅ Gini Impurity works as expected. Maximum for Node C and the minimum for both A and E. We need to choose the node with Minimum Gini Impurity.</p>

<p>We could also see the plot of Gini Impurity for the binary case to verify the above.</p>

<p><img src="/images/dtsplits/3.png" alt="Gini Impurity" /></p>

<p>❓So how do we exactly use it in a Decision Tree?</p>

<p>Suppose, we have the UCI Heart Disease data. The “target” field refers to the presence of heart disease in the patient. It is 0 (no presence) or 1.</p>

<p><img src="/images/dtsplits/4.png" alt="" /></p>

<p>We now already have a measure in place(Gini Impurity) using which we can evaluate a split on a particular variable with a certain threshold(continuous) or value(categorical).</p>

<h3 id="categorical-variable-splits">Categorical Variable Splits</h3>

<p>For simplicity, let us start with a categorical variable — sex.</p>

<p>If we split by Sex, our tree will look like below:</p>

<p><img src="/images/dtsplits/11.png" alt="If we split on Gender" /></p>

<p>Notice that we use Sex=0 and Sex!=0 so that this generalises well to categories with multiple levels. Our root node has 165 +ve examples and 138 -ve examples. And we get two child nodes when we split by sex.</p>

<p>We already know how to calculate the impurity for a node. So we calculate the impurity of the left child as well as the right child.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">I_Left <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> (<span style="color:#ae81ff">72</span><span style="color:#f92672">/</span><span style="color:#ae81ff">96</span>)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">-</span> (<span style="color:#ae81ff">24</span><span style="color:#f92672">/</span><span style="color:#ae81ff">96</span>)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>
I_Right <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> (<span style="color:#ae81ff">93</span><span style="color:#f92672">/</span><span style="color:#ae81ff">207</span>)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">-</span> (<span style="color:#ae81ff">114</span><span style="color:#f92672">/</span><span style="color:#ae81ff">207</span>)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Left Node Impurity:&#34;</span>,I_Left)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Right Node Impurity:&#34;</span>,I_Right)</code></pre></div>
<pre><code>Left Node Impurity: 0.375
Right Node Impurity: 0.4948540222642302
</code></pre>

<p>We get two numbers here. We need to get a single number which provides the impurity of a single split. So what do we do? Should, we take an average? We can take an average, but what will happen if one node gets only one example and another node has all other examples?</p>

<p>To mitigate the above, we take a weighted average of the two impurities weighted by the number of examples in the individual node. In code:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">gender_split_impurity <span style="color:#f92672">=</span> <span style="color:#ae81ff">96</span><span style="color:#f92672">/</span>(<span style="color:#ae81ff">96</span><span style="color:#f92672">+</span><span style="color:#ae81ff">207</span>)<span style="color:#f92672">*</span>I_Left <span style="color:#f92672">+</span> <span style="color:#ae81ff">207</span><span style="color:#f92672">/</span>(<span style="color:#ae81ff">96</span><span style="color:#f92672">+</span><span style="color:#ae81ff">207</span>)<span style="color:#f92672">*</span>I_Right
<span style="color:#66d9ef">print</span>(gender_split_impurity)</code></pre></div>
<pre><code>0.45688047065576126
</code></pre>

<h3 id="continuous-variable-splits">Continuous Variable Splits</h3>

<p>We can split by a continuous variable too. Let us try to split using cholesterol feature in the dataset. We chose a threshold of 250 and created a tree.</p>

<p><img src="/images/dtsplits/12.png" alt="" /></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">I_Left <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> (<span style="color:#ae81ff">58</span><span style="color:#f92672">/</span><span style="color:#ae81ff">126</span>)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">-</span> (<span style="color:#ae81ff">68</span><span style="color:#f92672">/</span><span style="color:#ae81ff">126</span>)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>
I_Right <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> (<span style="color:#ae81ff">107</span><span style="color:#f92672">/</span><span style="color:#ae81ff">177</span>)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">-</span> (<span style="color:#ae81ff">70</span><span style="color:#f92672">/</span><span style="color:#ae81ff">177</span>)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Left Node Impurity:&#34;</span>,I_Left)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Right Node Impurity:&#34;</span>,I_Right)</code></pre></div>
<pre><code>Left Node Impurity: 0.49685059208868737
Right Node Impurity: 0.47815123368125373
</code></pre>

<p>Just by looking at both the impurities close to 0.5, we can infer that it is not a good split. Still, we calculate our weighted Gini impurity as before:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">chol_split_impurity <span style="color:#f92672">=</span> <span style="color:#ae81ff">126</span><span style="color:#f92672">/</span>(<span style="color:#ae81ff">126</span><span style="color:#f92672">+</span><span style="color:#ae81ff">177</span>)<span style="color:#f92672">*</span>I_Left <span style="color:#f92672">+</span> <span style="color:#ae81ff">177</span><span style="color:#f92672">/</span>(<span style="color:#ae81ff">126</span><span style="color:#f92672">+</span><span style="color:#ae81ff">177</span>)<span style="color:#f92672">*</span>I_Right
<span style="color:#66d9ef">print</span>(chol_split_impurity)</code></pre></div>
<pre><code>0.48592720450414695
</code></pre>

<p>Since the chol_split_impurity&gt;gender_split_impurity, we split based on Gender.</p>

<p>In reality, we evaluate a lot of different splits. With different threshold values for a continuous variable. And all the levels for categorical variables. And then choose the split which provides us with the lowest weighted impurity in the child nodes.</p>

<hr />

<h2 id="2-entropy">2. Entropy</h2>

<p><img src="/images/dtsplits/7.png" alt="Entropy == Randomness" /></p>

<p>Another very popular way to split nodes in the decision tree is Entropy. Entropy is the measure of Randomness in the system. The formula for Entropy is:</p>

<p><img src="/images/dtsplits/8.png" alt="" /></p>

<p>where C is the number of classes present in the node and p is the distribution of the class in the node.</p>

<p>So again talking about the binary case we talked about before. What is the value of Entropy for all the 5 cases from A-E?</p>

<p><img src="/images/dtsplits/9.png" alt="" /></p>

<p>Entropy values work as expected. Maximum for Node C and the minimum for both A and E. We need to choose the node with Minimum Entropy.</p>

<p>We could also see the plot of Entropy for the binary case to verify the above.</p>

<p><img src="/images/dtsplits/10.png" alt="Entropy" /></p>

<p>So how do we exactly use Entropy in a Decision Tree?</p>

<p>We are using the Heartrate example as before. We now already have a measure in place(Entropy) using which we can evaluate a split on an individual variable with a certain threshold(continuous) or value(categorical).</p>

<h3 id="categorical-variable-splits-1">Categorical Variable Splits</h3>

<p>For simplicity, let us start with a categorical variable — sex.</p>

<p>If we split by Sex, our tree will look like below:</p>

<p><img src="/images/dtsplits/11.png" alt="If we split on Gender" /><em>If we split on Gender</em></p>

<p>We already know how to calculate the randomness for a node. So we calculate the randomness of the left child as well as the right child.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">E_Left <span style="color:#f92672">=</span> <span style="color:#f92672">-</span>(<span style="color:#ae81ff">72</span><span style="color:#f92672">/</span><span style="color:#ae81ff">96</span>)<span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>log2(<span style="color:#ae81ff">72</span><span style="color:#f92672">/</span><span style="color:#ae81ff">96</span>) <span style="color:#f92672">-</span> (<span style="color:#ae81ff">24</span><span style="color:#f92672">/</span><span style="color:#ae81ff">96</span>)<span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>log2(<span style="color:#ae81ff">24</span><span style="color:#f92672">/</span><span style="color:#ae81ff">96</span>)
E_Right <span style="color:#f92672">=</span> <span style="color:#f92672">-</span>(<span style="color:#ae81ff">93</span><span style="color:#f92672">/</span><span style="color:#ae81ff">207</span>)<span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>log2(<span style="color:#ae81ff">93</span><span style="color:#f92672">/</span><span style="color:#ae81ff">207</span>) <span style="color:#f92672">-</span> (<span style="color:#ae81ff">114</span><span style="color:#f92672">/</span><span style="color:#ae81ff">207</span>)<span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>log2(<span style="color:#ae81ff">114</span><span style="color:#f92672">/</span><span style="color:#ae81ff">207</span>)

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Left Node Randomness:&#34;</span>,E_Left)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Right Node Randomness:&#34;</span>,E_Right)</code></pre></div>
<pre><code>Left Node Randomness: 0.8112781244591328
Right Node Randomness: 0.992563136012236
</code></pre>

<p>We get two numbers here. We need to get a single number which provides the Randomness of a single split. So what do we do? We again take a weighted average where we weight by the number of examples in the individual node. In code:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">gender_split_randomness <span style="color:#f92672">=</span> <span style="color:#ae81ff">96</span><span style="color:#f92672">/</span>(<span style="color:#ae81ff">96</span><span style="color:#f92672">+</span><span style="color:#ae81ff">207</span>)<span style="color:#f92672">*</span>E_Left <span style="color:#f92672">+</span> <span style="color:#ae81ff">207</span><span style="color:#f92672">/</span>(<span style="color:#ae81ff">96</span><span style="color:#f92672">+</span><span style="color:#ae81ff">207</span>)<span style="color:#f92672">*</span>E_Right
<span style="color:#66d9ef">print</span>(gender_split_randomness)</code></pre></div>
<pre><code>0.9351263006686785
</code></pre>

<h3 id="continuous-variable-splits-1">Continuous Variable Splits</h3>

<p>Again as before, we can split by a continuous variable too. Let us try to split using cholesterol feature in the dataset. We chose a threshold of 250 and create a tree.</p>

<p><img src="/images/dtsplits/12.png" alt="" /></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">E_Left <span style="color:#f92672">=</span> <span style="color:#f92672">-</span>(<span style="color:#ae81ff">58</span><span style="color:#f92672">/</span><span style="color:#ae81ff">126</span>)<span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>log2(<span style="color:#ae81ff">58</span><span style="color:#f92672">/</span><span style="color:#ae81ff">126</span>) <span style="color:#f92672">-</span> (<span style="color:#ae81ff">68</span><span style="color:#f92672">/</span><span style="color:#ae81ff">126</span>)<span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>log2(<span style="color:#ae81ff">68</span><span style="color:#f92672">/</span><span style="color:#ae81ff">126</span>)
E_Right <span style="color:#f92672">=</span> <span style="color:#f92672">-</span>(<span style="color:#ae81ff">107</span><span style="color:#f92672">/</span><span style="color:#ae81ff">177</span>)<span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>log2(<span style="color:#ae81ff">107</span><span style="color:#f92672">/</span><span style="color:#ae81ff">177</span>) <span style="color:#f92672">-</span> (<span style="color:#ae81ff">70</span><span style="color:#f92672">/</span><span style="color:#ae81ff">177</span>)<span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>log2(<span style="color:#ae81ff">70</span><span style="color:#f92672">/</span><span style="color:#ae81ff">177</span>)

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Left Node Randomness:&#34;</span>,E_Left)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Right Node Randomness:&#34;</span>,E_Right)</code></pre></div>
<pre><code>Left Node Randomness: 0.9954515828457715
Right Node Randomness: 0.9682452182690404
</code></pre>

<p>Just by looking at both the randomness close to 1, we can infer that it is not a good split. Still, we calculate our weighted Entropy as before:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">chol_split_randomness <span style="color:#f92672">=</span> <span style="color:#ae81ff">126</span><span style="color:#f92672">/</span>(<span style="color:#ae81ff">126</span><span style="color:#f92672">+</span><span style="color:#ae81ff">177</span>)<span style="color:#f92672">*</span>E_Left <span style="color:#f92672">+</span> <span style="color:#ae81ff">177</span><span style="color:#f92672">/</span>(<span style="color:#ae81ff">126</span><span style="color:#f92672">+</span><span style="color:#ae81ff">177</span>)<span style="color:#f92672">*</span>E_Right
<span style="color:#66d9ef">print</span>(chol_split_randomness)</code></pre></div>
<pre><code>0.9795587560138196
</code></pre>

<p>Since the chol_split_randomness&gt;gender_split_randomness, we split based on Gender. Precisely the same results we got from Gini.</p>

<hr />

<h2 id="3-variance">3. Variance</h2>

<p>Gini Impurity and Entropy work pretty well for the classification scenario.</p>

<p>But what about regression?</p>

<p>In the case of regression, the most common split measure used is just the weighted variance of the nodes. It makes sense too: We want minimum variation in the nodes after the split.</p>

<p><img src="/images/dtsplits/13.png" alt="" /></p>

<p>We want a regression task for this. So, we have the data for 50 startups, and we want to predict Profit.</p>

<p><img src="/images/dtsplits/14.png" alt="" /></p>

<h3 id="categorical-variable-splits-2">Categorical Variable Splits</h3>

<p>Let us try a split by a categorical variable ⇒State=Florida.</p>

<p>If we split by State=FL, our tree will look like below:</p>

<p><img src="/images/dtsplits/15.png" alt="" /></p>

<p>Overall Variance then is just the weighted sums of individual variances:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">overall_variance <span style="color:#f92672">=</span> <span style="color:#ae81ff">16</span><span style="color:#f92672">/</span>(<span style="color:#ae81ff">16</span><span style="color:#f92672">+</span><span style="color:#ae81ff">34</span>)<span style="color:#f92672">*</span>Var_Left <span style="color:#f92672">+</span> <span style="color:#ae81ff">34</span><span style="color:#f92672">/</span>(<span style="color:#ae81ff">16</span><span style="color:#f92672">+</span><span style="color:#ae81ff">34</span>)<span style="color:#f92672">*</span>Var_Right
<span style="color:#66d9ef">print</span>(overall_variance)</code></pre></div>
<pre><code>1570582843
</code></pre>

<h3 id="continuous-variable-splits-2">Continuous Variable Splits</h3>

<p>Again as before, we can split by a continuous variable too. Let us try to split using R&amp;D spend feature in the dataset. We chose a threshold of 100000 and create a tree.</p>

<p><img src="/images/dtsplits/16.png" alt="Splitting on R&amp;D" /><em>Splitting on R&amp;D</em></p>

<p>Just by looking at this, we can see it is better than our previous split. So, we find the overall variance in this case:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">overall_variance <span style="color:#f92672">=</span> <span style="color:#ae81ff">14</span><span style="color:#f92672">/</span>(<span style="color:#ae81ff">14</span><span style="color:#f92672">+</span><span style="color:#ae81ff">36</span>)<span style="color:#f92672">*</span><span style="color:#ae81ff">419828105</span> <span style="color:#f92672">+</span> <span style="color:#ae81ff">36</span><span style="color:#f92672">/</span>(<span style="color:#ae81ff">14</span><span style="color:#f92672">+</span><span style="color:#ae81ff">36</span>)<span style="color:#f92672">*</span><span style="color:#ae81ff">774641406</span>
<span style="color:#66d9ef">print</span>(overall_variance)</code></pre></div>
<pre><code>675293681.7199999
</code></pre>

<p>Since the overall_variance(R&amp;D&gt;=100000)&lt; overall_variance(State==FL), we prefer a split based on R&amp;D.</p>

<h2 id="continue-learning">Continue Learning</h2>

<p><img src="/images/dtsplits/17.png" alt="" /></p>

<p>If you want to learn more about Data Science, I would like to call out this <a href="https://www.coursera.org/learn/machine-learning?ranMID=40328&amp;ranEAID=lVarvwc5BD0&amp;ranSiteID=lVarvwc5BD0-btd7XBdF681VKxRe2H_Oyg&amp;siteID=lVarvwc5BD0-btd7XBdF681VKxRe2H_Oyg&amp;utm_content=2&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0" rel="nofollow" target="_blank"><strong><em>excellent course</em></strong></a> by Andrew Ng. This was the one that got me started. Do check it out.</p>

<p>Thanks for the read. I am going to be writing more beginner-friendly posts in the future too. Follow me up at <a href="https://medium.com/@rahul_agarwal" rel="nofollow" target="_blank"><strong>Medium</strong></a> or Subscribe to my <a href="http://eepurl.com/dbQnuX" rel="nofollow" target="_blank"><strong>blog</strong></a> to be informed about them. As always, I welcome feedback and constructive criticism and can be reached on Twitter <a href="https://twitter.com/MLWhiz" rel="nofollow" target="_blank">@mlwhiz</a>.</p>

<p>Also, a small disclaimer — There might be some affiliate links in this post to relevant resources as sharing knowledge is never a bad idea.</p>

		</div>
		
<div class="post__tags tags clearfix">
	<svg class="icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item"><a class="tags__link btn" href="/tags/python/" rel="tag">Python</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/statistics/" rel="tag">Statistics</a></li>
	</ul>
</div>
		

<div class="shareaholic-canvas" data-app="share_buttons" data-app-id="28372088"></div>

<a href="https://click.linksynergy.com/fs-bin/click?id=lVarvwc5BD0&offerid=467035.372&subid=0&type=4" rel="nofollow"><IMG border="0"   alt="Start your future with a Data Science Certificate." src="https://ad.linksynergy.com/fs-bin/show?id=lVarvwc5BD0&bids=467035.372&subid=0&type=4&gridnum=16"></a>





























	</article>
</main>


<nav class="post-nav flex">
	<div class="post-nav__item post-nav__item--prev">
		<a class="post-nav__link" href="/blog/2019/11/11/pval/" rel="prev"><span class="post-nav__caption">«&thinsp;Previous</span><p class="post-nav__post-title">P-value Explained Simply for Data Scientists</p></a>
	</div>
	<div class="post-nav__item post-nav__item--next">
		<a class="post-nav__link" href="/blog/2019/11/27/cities/" rel="next"><span class="post-nav__caption">Next&thinsp;»</span><p class="post-nav__post-title">Top 5 Cities for Data Scientists to Thrive In</p></a>
	</div>
</nav>

<section class="comments">
	<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "mlwhiz" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


			</div>
			<style type="text/css">

  .btn {
    display: inline-block;
    font-weight: 400;
    text-align: center;
    white-space: nowrap;
    vertical-align: middle;
    -webkit-user-select: none;
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none;
    border: 1px solid transparent;
    padding: .375rem .75rem;
    font-size: 1rem;
    line-height: 1.5;
    border-radius: .25rem;
    transition: color .15s ease-in-out,background-color .15s ease-in-out,border-color .15s ease-in-out,box-shadow .15s ease-in-out;
}

.btn-session {
    color: #fff;
    background-color: #28a745;
    border-color: #28a745;
}
</style>


<aside class="sidebar">
  <div style="text-align:center">    
    
    <a class="btn btn-session" href="https://www.patreon.com/bePatron?u=28135435" role="button">1:1 Session</a>
	     
  </div>
  <br><div class="widget-search widget">
	<form class="widget-search__form" role="search" method="get" action="https://google.com/search">
		<label>
			<input class="widget-search__field" type="search" placeholder="SEARCH..." value="" name="q" aria-label="SEARCH...">
		</label>
		<input class="widget-search__submit" type="submit" value="Search">
		<input type="hidden" name="sitesearch" value="https://mlwhiz.com/" />
	</form>
</div>
<div class="widget-recent widget">
	<h4 class="widget__title">Recent Posts</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/blog/2020/02/24/sparkcolumns/">5 Ways to add a new column in a PySpark Dataframe</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/02/24/job/">5 tips for getting your first Data Science job in 2020</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/02/23/bamboo/">Bamboolib — Learn and use Pandas without Coding</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/02/23/xgbparallel/">Lightning Fast XGBoost on Multiple GPUs</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/02/23/streamlitrec/">Share your Projects even more easily with this New Streamlit Feature</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/02/22/hyperspark/">100x faster Hyperparameter Search Framework with Pyspark</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/02/22/streamlitec2/">How to Deploy a Streamlit App using an Amazon Free ec2 instance?</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/02/22/pandas_gpu/">Minimal Pandas Subset for Data Scientists on GPU</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/02/21/ds2020/">Become a Data Scientist in 2020 with these 10 resources</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/02/21/ci/">Confidence Intervals Explained Simply for Data Scientists</a></li>
		</ul>
	</div>
</div>


<div class="shareaholic-canvas" data-app="follow_buttons" data-app-id="28033293" style="white-space: inherit;"></div>


<link href="//cdn-images.mailchimp.com/embedcode/slim-10_7.css" rel="stylesheet" type="text/css">


<style type="text/css">
  #mc_embed_signup .button {background-color: #127edc;}
  #mc_embed_signup form .center{
    display: block;
    position: relative;
    text-align: center;
    padding: 10px -5px 10px 3%;}
   
</style>
<div id="mc_embed_signup">
<form action="//mlwhiz.us15.list-manage.com/subscribe/post?u=4e9962f4ce4a94818bcc2f249&amp;id=87a48fafdd" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
    <input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required>
    
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_4e9962f4ce4a94818bcc2f249_87a48fafdd" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy;  2014-2020 Rahul Agarwal.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>



	</div>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&adInstanceId=93f2f4f9-cf51-415d-84af-08cbb74b178f"></script>
<script async defer src="/js/menu.js"></script></body>
</html>