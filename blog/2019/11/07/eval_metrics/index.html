<!doctype html><html lang=en-us><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-F34XSWQ5N4"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-F34XSWQ5N4')</script><meta charset=utf-8><title>The 5 Classification Evaluation metrics every Data Scientist must know - MLWhiz</title><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content="This post is about various evaluation metrics and how and when to use them."><meta name=author content="Rahul Agarwal"><meta name=generator content="Hugo 0.82.0"><link rel=stylesheet href=https://mlwhiz.com/plugins/compressjscss/main.css><meta property="og:title" content="The 5 Classification Evaluation metrics every Data Scientist must know - MLWhiz"><meta property="og:description" content="This post is about various evaluation metrics and how and when to use them."><meta property="og:type" content="article"><meta property="og:url" content="https://mlwhiz.com/blog/2019/11/07/eval_metrics/"><meta property="og:image" content="https://mlwhiz.com/images/eval/main.jpeg"><meta property="og:image:secure_url" content="https://mlwhiz.com/images/eval/main.jpeg"><meta property="article:published_time" content="2019-11-07T00:00:00+00:00"><meta property="article:modified_time" content="2023-07-11T20:51:48+01:00"><meta property="article:tag" content="Awesome Guides"><meta property="article:tag" content="Data Science"><meta name=twitter:card content="summary"><meta name=twitter:image content="https://mlwhiz.com/images/eval/main.jpeg"><meta name=twitter:title content="The 5 Classification Evaluation metrics every Data Scientist must know - MLWhiz"><meta name=twitter:description content="This post is about various evaluation metrics and how and when to use them."><meta name=twitter:site content="@mlwhiz"><meta name=twitter:creator content="@mlwhiz"><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href=https://mlwhiz.com/scss/style.min.css media=screen><link rel=stylesheet href=/css/style.css><link rel=stylesheet type=text/css href=/css/font/flaticon.css><link rel="shortcut icon" href=https://mlwhiz.com/images/logos/favicon-32x32.png type=image/x-icon><link rel=icon href=https://mlwhiz.com/images/logos/favicon.ico type=image/x-icon><link rel=canonical href=https://mlwhiz.com/blog/2019/11/07/eval_metrics/><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js></script><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://www.mlwhiz.com/#website","url":"https://www.mlwhiz.com/","name":"MLWhiz","description":"Want to Learn Computer Vision and NLP? - MLWhiz","potentialAction":{"@type":"SearchAction","target":"https://www.mlwhiz.com/search?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://mlwhiz.com/blog/2019/11/07/eval_metrics/#primaryimage","url":"https://mlwhiz.com/images/eval/main.jpeg","width":700,"height":450},{"@type":"WebPage","@id":"https://mlwhiz.com/blog/2019/11/07/eval_metrics/#webpage","url":"https://mlwhiz.com/blog/2019/11/07/eval_metrics/","inLanguage":"en-US","name":"The 5 Classification Evaluation metrics every Data Scientist must know - MLWhiz","isPartOf":{"@id":"https://www.mlwhiz.com/#website"},"primaryImageOfPage":{"@id":"https://mlwhiz.com/blog/2019/11/07/eval_metrics/#primaryimage"},"datePublished":"2019-11-07T00:00:00.00Z","dateModified":"2023-07-11T20:51:48.00Z","author":{"@id":"https://mlwhiz.com/about/#/schema/person/76376876bchxkzbchjsdjcca"},"description":"This post is about various evaluation metrics and how and when to use them."},{"@type":["Person"],"@id":"https://mlwhiz.com/about/#/schema/person/76376876bchxkzbchjsdjcca","name":"Rahul Agarwal","image":{"@type":"ImageObject","@id":"https://www.mlwhiz.com/#authorlogo","url":"https://mlwhiz.com/images/author.jpg","caption":"Rahul Agarwal"},"description":"Hi there, I\u2019m Rahul Agarwal. I\u2019m a data scientist consultant and big data engineer based in Bangalore. I see a lot of times  students and even professionals wasting their time and struggling to get started with Computer Vision, Deep Learning, and NLP. I Started this Site with a purpose to augment my own understanding about new things while helping others learn about them in the best possible way.","sameAs":["https://www.linkedin.com/in/rahulagwl/","https://medium.com/@rahul_agarwal","https://twitter.com/MLWhiz","https://www.facebook.com/mlwhizblog","https://github.com/MLWhiz","https://www.instagram.com/itsmlwhiz"]}]}</script><script async data-uid=a0ebaf958d src=https://mlwhiz.ck.page/a0ebaf958d/index.js></script><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$']],processEscapes:!0,processEnvironments:!0,skipTags:['script','noscript','style','textarea','pre'],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var b=MathJax.Hub.getAllJax(),a;for(a=0;a<b.length;a+=1)b[a].SourceElement().parentNode.className+=' has-jax'}),MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:"AMS"}}})</script><link href=//apps.shareaholic.com/assets/pub/shareaholic.js as=script><script type=text/javascript data-cfasync=false async src=//apps.shareaholic.com/assets/pub/shareaholic.js data-shr-siteid=fd1ffa7fd7152e4e20568fbe49a489d0></script><script>!function(b,e,f,g,a,c,d){if(b.fbq)return;a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version='2.0',a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d)}(window,document,'script','https://connect.facebook.net/en_US/fbevents.js'),fbq('init','402633927768628'),fbq('track','PageView')</script><noscript><img height=1 width=1 style=display:none src="https://www.facebook.com/tr?id=402633927768628&ev=PageView&noscript=1"></noscript><meta property="fb:pages" content="213104036293742"><meta name=facebook-domain-verification content="qciidcy7mm137sewruizlvh8zbfnv4"></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NMQD44T" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><div class=preloader></div><header class=navigation><div class=container><nav class="navbar navbar-expand-lg navbar-white bg-transparent border-bottom pl-0"><a class="navbar-brand mobile-view" href=https://mlwhiz.com/><img class=img-fluid src=https://mlwhiz.com/images/logos/logo.svg alt="MLWhiz - Your Home for DS, ML, AI!"></a>
<button class="navbar-toggler border-0" type=button data-toggle=collapse data-target=#navigation>
<i class="ti-menu h3"></i></button><div class="collapse navbar-collapse text-center" id=navigation><div class=desktop-view><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href="https://linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=rahulagwl"><i class=ti-linkedin></i></a></li><li class=nav-item><a class=nav-link href=https://mlwhiz.medium.com/><i class=ti-book></i></a></li><li class=nav-item><a class=nav-link href=https://twitter.com/MLWhiz><i class=ti-twitter-alt></i></a></li><li class=nav-item><a class=nav-link href=https://www.facebook.com/mlwhizblog><i class=ti-facebook></i></a></li><li class=nav-item><a class=nav-link href=https://github.com/MLWhiz><i class=ti-github></i></a></li></ul></div><a class="navbar-brand mx-auto desktop-view" href=https://mlwhiz.com/><img class=img-fluid-custom src=https://mlwhiz.com/images/logos/logo.svg alt="MLWhiz - Your Home for DS, ML, AI!"></a><ul class=navbar-nav><li class=nav-item><a class=nav-link href=https://mlwhiz.com/about>About</a></li><li class=nav-item><a class=nav-link href=https://mlwhiz.com/blog>Blog</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Topics</a><div class=dropdown-menu><a class=dropdown-item href=https://mlwhiz.com/categories/natural-language-processing>NLP</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/computer-vision>Computer Vision</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/deep-learning>Deep Learning</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/data-science>DS/ML</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/big-data>Big Data</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/awesome-guides>My Best Content</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/learning-resources>Learning Resources</a></div></li></ul><div class="search pl-lg-4"><button id=searchOpen class=search-btn><i class=ti-search></i></button><div class=search-wrapper><form action=https://mlwhiz.com//search class=h-100><input class="search-box px-4" id=search-query name=s type=search placeholder="Type & Hit Enter..."></form><button id=searchClose class=search-close><i class="ti-close text-dark"></i></button></div></div></div></nav></div></header><section class=section-sm><div class=container><div class=row><div class="col-lg-8 mb-5 mb-lg-0"><a href=/categories/awesome-guides class=categoryStyle>Awesome Guides</a>
<a href=/categories/data-science class=categoryStyle>Data Science</a><h1>The 5 Classification Evaluation metrics every Data Scientist must know</h1><div class="mb-3 post-meta"><span>By Rahul Agarwal</span><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
<span>07 November 2019</span></div><img src=https://mlwhiz.com/images/eval/main.jpeg class="img-fluid w-100 mb-4" alt="The 5 Classification Evaluation metrics every Data Scientist must know"><div class="content mb-5"><p><em><strong>What do we want to optimize for?</strong></em> Most of the businesses fail to answer this simple question.</p><p><em><strong>Every business problem is a little different, and it should be optimized differently.</strong></em></p><p>We all have created classification models. A lot of time we try to increase evaluate our models on accuracy. <em><strong>But do we really want accuracy as a metric of our model performance?</strong></em></p><p><em><strong>What if we are predicting the number of asteroids that will hit the earth.</strong></em></p><p>Just say zero all the time. And you will be 99% accurate. My model can be reasonably accurate, but not at all valuable. What should we do in such cases?</p><blockquote><p><em>Designing a Data Science project is much more important than the modeling itself.</em></p></blockquote><p><em><strong>This post is about various evaluation metrics and how and when to use them.</strong></em></p><hr><h2 id=1-accuracy-precision-and-recall>1. Accuracy, Precision, and Recall:</h2><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="/images/eval/7_hu2274c12139c04f386d79f570c4d2bf8c_22385_500x0_resize_box_2.png 500w" src=/images/eval/7.png alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><h3 id=a-accuracy>A. Accuracy</h3><p>Accuracy is the quintessential classification metric. It is pretty easy to understand. And easily suited for binary as well as a multiclass classification problem.</p><p>Accuracy = (TP+TN)/(TP+FP+FN+TN)</p><p>Accuracy is the proportion of true results among the total number of cases examined.</p><h4 id=when-to-use><em><strong>When to use?</strong></em></h4><p>Accuracy is a valid choice of evaluation for classification problems which are well balanced and not skewed or No class imbalance.</p><h4 id=caveats><em><strong>Caveats</strong></em></h4><p>Let us say that our target class is very sparse. Do we want accuracy as a metric of our model performance? <em><strong>What if we are predicting if an asteroid will hit the earth?</strong></em> Just say No all the time. And you will be 99% accurate. My model can be reasonably accurate, but not at all valuable.</p><h3 id=b-precision>B. Precision</h3><p>Let’s start with <em>precision</em>, which answers the following question: what proportion of <strong>predicted Positives</strong> is truly Positive?</p><p>Precision = (TP)/(TP+FP)</p><p>In the asteroid prediction problem, we never predicted a true positive.</p><p>And thus precision=0</p><h4 id=when-to-use-1><em><strong>When to use?</strong></em></h4><p>Precision is a valid choice of evaluation metric when we want to be very sure of our prediction. For example: If we are building a system to predict if we should decrease the credit limit on a particular account, we want to be very sure about our prediction or it may result in customer dissatisfaction.</p><h4 id=caveats-1><em><strong>Caveats</strong></em></h4><p><em>Being very precise means our model will leave a lot of credit defaulters untouched and hence lose money.</em></p><h3 id=c-recall>C. Recall</h3><p>Another very useful measure is <em>recall</em>, which answers a different question: what proportion of <strong>actual Positives</strong> is correctly classified?</p><p>Recall = (TP)/(TP+FN)</p><p>In the asteroid prediction problem, we never predicted a true positive.</p><p>And thus recall is also equal to 0.</p><h4 id=when-to-use-2><em><strong>When to use?</strong></em></h4><p>Recall is a valid choice of evaluation metric when we want to capture as many positives as possible. For example: If we are building a system to predict if a person has cancer or not, we want to capture the disease even if we are not very sure.</p><h4 id=caveats-2><em><strong>Caveats</strong></em></h4><p><em><strong>Recall is 1 if we predict 1 for all examples.</strong></em></p><p>And thus comes the idea of utilizing tradeoff of precision vs. recall — <em><strong>F1 Score</strong></em>.</p><hr><h2 id=2-f1-score>2. F1 Score:</h2><p>This is my <em><strong>favorite evaluation metric</strong></em> and I tend to use this a lot in my classification projects.</p><p>The F1 score is a number between 0 and 1 and is the harmonic mean of precision and recall.</p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset src=/images/eval/1.png alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p>Let us start with a binary prediction problem. <em><strong>We are predicting if an asteroid will hit the earth or not.</strong></em></p><p>So if we say “No” for the whole training set. Our precision here is 0. What is the recall of our positive class? It is zero. What is the accuracy? It is more than 99%.</p><p>And hence the F1 score is also 0. And thus we get to know that the classifier that has an accuracy of 99% is basically worthless for our case. And hence it solves our problem.</p><h3 id=when-to-use-3><em><strong>When to use?</strong></em></h3><p>We want to have a model with both good precision and recall.</p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset src=/images/eval/2.png alt="Precision-Recall Tradeoff"></p><p>Simply stated the <em><strong>F1 score sort of maintains a balance between the precision and recall for your classifier</strong></em>. If your precision is low, the F1 is low and if the recall is low again your F1 score is low.</p><blockquote><h1 id=if-you-are-a-police-inspector-and-you-want-to-catch-criminals-you-want-to-be-sure-that-the-person-you-catch-is-a-criminal-precision-and-you-also-want-to-capture-as-many-criminals-recall-as-possible-the-f1-score-manages-this-tradeoff>If you are a police inspector and you want to catch criminals, you want to be sure that the person you catch is a criminal (Precision) and you also want to capture as many criminals (Recall) as possible. The F1 score manages this tradeoff.</h1></blockquote><h3 id=how-to-use>How to Use?</h3><p>You can calculate the F1 score for binary prediction problems using:</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>sklearn.metrics</span> <span style=color:#6ab825;font-weight:700>import</span> f1_score
y_true = [<span style=color:#3677a9>0</span>, <span style=color:#3677a9>1</span>, <span style=color:#3677a9>1</span>, <span style=color:#3677a9>0</span>, <span style=color:#3677a9>1</span>, <span style=color:#3677a9>1</span>]
y_pred = [<span style=color:#3677a9>0</span>, <span style=color:#3677a9>0</span>, <span style=color:#3677a9>1</span>, <span style=color:#3677a9>0</span>, <span style=color:#3677a9>0</span>, <span style=color:#3677a9>1</span>]

f1_score(y_true, y_pred)
</code></pre></div><p>This is one of my functions which I use to get the best threshold for maximizing F1 score for binary predictions. The below function iterates through possible threshold values to find the one that gives the best F1 score.</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#999;font-style:italic># y_pred is an array of predictions</span>
<span style=color:#6ab825;font-weight:700>def</span> <span style=color:#447fcf>bestThresshold</span>(y_true,y_pred):
    best_thresh = None
    best_score = <span style=color:#3677a9>0</span>
    <span style=color:#6ab825;font-weight:700>for</span> thresh <span style=color:#6ab825;font-weight:700>in</span> np.arange(<span style=color:#3677a9>0.1</span>, <span style=color:#3677a9>0.501</span>, <span style=color:#3677a9>0.01</span>):
        score = f1_score(y_true, np.array(y_pred)&gt;thresh)
        <span style=color:#6ab825;font-weight:700>if</span> score &gt; best_score:
            best_thresh = thresh
            best_score = score
    <span style=color:#6ab825;font-weight:700>return</span> best_score , best_thresh
</code></pre></div><h4 id=caveats-3>Caveats</h4><p>The main problem with the F1 score is that it gives equal weight to precision and recall. We might sometimes need to include domain knowledge in our evaluation where we want to have more recall or more precision.</p><p>To solve this, we can do this by creating a weighted F1 metric as below where beta manages the tradeoff between precision and recall.</p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset src=/images/eval/3.png alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p>Here we give β times as much importance to recall as precision.</p><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>sklearn.metrics</span> <span style=color:#6ab825;font-weight:700>import</span> fbeta_score

y_true = [<span style=color:#3677a9>0</span>, <span style=color:#3677a9>1</span>, <span style=color:#3677a9>1</span>, <span style=color:#3677a9>0</span>, <span style=color:#3677a9>1</span>, <span style=color:#3677a9>1</span>]
y_pred = [<span style=color:#3677a9>0</span>, <span style=color:#3677a9>0</span>, <span style=color:#3677a9>1</span>, <span style=color:#3677a9>0</span>, <span style=color:#3677a9>0</span>, <span style=color:#3677a9>1</span>]

fbeta_score(y_true, y_pred,beta=<span style=color:#3677a9>0.5</span>)
</code></pre></div><p>F1 Score can also be used for Multiclass problems. See
<a href=https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1 target=_blank rel="nofollow noopener">this</a>
awesome blog post by
<a href=undefined>Boaz Shmueli</a>
for details.</p><hr><h2 id=3-log-lossbinary-crossentropy>3. Log Loss/Binary Crossentropy</h2><p>Log loss is a pretty good evaluation metric for binary classifiers and it is sometimes the optimization objective as well in case of Logistic regression and Neural Networks.</p><p>Binary Log loss for an example is given by the below formula where p is the probability of predicting 1.</p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset src=/images/eval/4.png alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="/images/eval/5_hu1e9f9d7f23c0b21e02b26d3a1f8ac8a8_15797_500x0_resize_box_2.png 500w" src=/images/eval/5.png alt="As you can see the log loss decreases as we are fairly certain in our prediction of 1 and the true label is 1."></p><p><em>As you can see the log loss decreases as we are fairly certain in our prediction of 1 and the true label is 1.</em></p><h4 id=when-to-use-4>When to Use?</h4><p><em>When the output of a classifier is prediction probabilities.</em> <strong>Log Loss takes into account the uncertainty of your prediction based on how much it varies from the actual label.</strong> This gives us a more nuanced view of the performance of our model. In general, minimizing Log Loss gives greater accuracy for the classifier.</p><h4 id=how-to-use-1>How to Use?</h4><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>sklearn.metrics</span> <span style=color:#6ab825;font-weight:700>import</span> log_loss  

<span style=color:#999;font-style:italic># where y_pred are probabilities and y_true are binary class labels</span>
log_loss(y_true, y_pred, eps=<span style=color:#3677a9>1e-15</span>)
</code></pre></div><h4 id=caveats-4>Caveats</h4><p>It is susceptible in case of
<a href=https://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c target=_blank rel="nofollow noopener">imbalanced</a>
datasets. You might have to introduce class weights to penalize minority errors more or you may use this after balancing your dataset.</p><hr><h2 id=4-categorical-crossentropy>4. Categorical Crossentropy</h2><p>The log loss also generalizes to the multiclass problem. The classifier in a multiclass setting must assign a probability to each class for all examples. If there are N samples belonging to M classes, then the <em>Categorical Crossentropy</em> is the summation of -ylogp values:</p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset src=/images/eval/6.png alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p>$y_{ij}$ is 1 if the sample i belongs to class j else 0</p><p>$p_{ij}$ is the probability our classifier predicts of sample i belonging to class j.</p><h4 id=when-to-use-5>When to Use?</h4><p><em>When the output of a classifier is multiclass prediction probabilities. We generally use Categorical Crossentropy in case of Neural Nets.</em> In general, minimizing Categorical cross-entropy gives greater accuracy for the classifier.</p><h4 id=how-to-use-2>How to Use?</h4><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>sklearn.metrics</span> <span style=color:#6ab825;font-weight:700>import</span> log_loss  

<span style=color:#999;font-style:italic># Where y_pred is a matrix of probabilities with shape ***= (n_samples, n_classes)*** and y_true is an array of class labels</span>
log_loss(y_true, y_pred, eps=<span style=color:#3677a9>1e-15</span>)
</code></pre></div><h4 id=caveats-5>Caveats:</h4><p>It is susceptible in case of
<a href=https://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c target=_blank rel="nofollow noopener">imbalanced</a>
datasets.</p><hr><h2 id=5-auc>5. AUC</h2><p>AUC is the area under the ROC curve.</p><p><em><strong>AUC ROC indicates how well the probabilities from the positive classes are separated from the negative classes</strong></em></p><p><em><strong>What is the ROC curve?</strong></em></p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="/images/eval/7_hu2274c12139c04f386d79f570c4d2bf8c_22385_500x0_resize_box_2.png 500w" src=/images/eval/7.png alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p>We have got the probabilities from our classifier. We can use various threshold values to plot our sensitivity(TPR) and (1-specificity)(FPR) on the cure and we will have a ROC curve.</p><p>Where True positive rate or TPR is just the proportion of trues we are capturing using our algorithm.</p><p>Sensitivty = TPR(True Positive Rate)= Recall = TP/(TP+FP)</p><p>and False positive rate or FPR is just the proportion of false we are capturing using our algorithm.</p><p>1- Specificity = FPR(False Positive Rate)= FP/(TN+FP)</p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="/images/eval/8_hue87754ba0f519d0c01c5fe3895031b41_78353_500x0_resize_box_2.png 500w
, /images/eval/8_hue87754ba0f519d0c01c5fe3895031b41_78353_800x0_resize_box_2.png 800w" src=/images/eval/8.png alt="ROC Curve"></p><p>Here we can use the ROC curves to decide on a Threshold value.
The choice of threshold value will also depend on how the classifier is intended to be used.</p><p>If it is a cancer classification application you don’t want your threshold to be as big as 0.5. Even if a patient has a 0.3 probability of having cancer you would classify him to be 1.</p><p>Otherwise, in an application for reducing the limits on the credit card, you don’t want your threshold to be as less as 0.5. You are here a little worried about the negative effect of decreasing limits on customer satisfaction.</p><h4 id=when-to-use-6>When to Use?</h4><p>AUC is <strong>scale-invariant</strong>. It measures how well predictions are ranked, rather than their absolute values. So, for example, if you as a marketer want to find a list of users who will respond to a marketing campaign. AUC is a good metric to use since the predictions ranked by probability is the order in which you will create a list of users to send the marketing campaign.</p><p>Another benefit of using AUC is that it is <strong>classification-threshold-invariant</strong> like log loss. It measures the quality of the model’s predictions irrespective of what classification threshold is chosen, unlike F1 score or accuracy which depend on the choice of threshold.</p><h4 id=how-to-use-3>How to Use?</h4><div class=highlight><pre style=color:#d0d0d0;background-color:#202020;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#6ab825;font-weight:700>import</span> <span style=color:#447fcf;text-decoration:underline>numpy</span> <span style=color:#6ab825;font-weight:700>as</span> <span style=color:#447fcf;text-decoration:underline>np</span>
<span style=color:#6ab825;font-weight:700>from</span> <span style=color:#447fcf;text-decoration:underline>sklearn.metrics</span> <span style=color:#6ab825;font-weight:700>import</span> roc_auc_score
y_true = np.array([<span style=color:#3677a9>0</span>, <span style=color:#3677a9>0</span>, <span style=color:#3677a9>1</span>, <span style=color:#3677a9>1</span>])
y_scores = np.array([<span style=color:#3677a9>0.1</span>, <span style=color:#3677a9>0.4</span>, <span style=color:#3677a9>0.35</span>, <span style=color:#3677a9>0.8</span>])

<span style=color:#6ab825;font-weight:700>print</span>(roc_auc_score(y_true, y_scores))
</code></pre></div><h4 id=caveats-6>Caveats</h4><p>Sometimes we will need well-calibrated probability outputs from our models and AUC doesn’t help with that.</p><hr><h2 id=conclusion>Conclusion</h2><p>An important step while creating our
<a href=https://towardsdatascience.com/6-important-steps-to-build-a-machine-learning-system-d75e3b83686 target=_blank rel="nofollow noopener">machine learning pipeline</a>
is evaluating our different models against each other. A bad choice of an evaluation metric could wreak havoc to your whole system.</p><p><em><strong>So, always be watchful of what you are predicting and how the choice of evaluation metric might affect/alter your final predictions.</strong></em></p><p>Also, the choice of an evaluation metric should be well aligned with the business objective and hence it is a bit subjective. And you can come up with your own evaluation metric as well.</p><h2 id=continue-learning>Continue Learning</h2><p>If you want to
<a href="https://towardsdatascience.com/how-did-i-start-with-data-science-3f4de6b501b0?source=---------8------------------" target=_blank rel="nofollow noopener">learn</a>
more about how to structure a Machine Learning project and the best practices, I would like to call out his awesome
<a href=https://coursera.pxf.io/KeEOO7 target=_blank rel="nofollow noopener">third course</a>
named Structuring Machine learning projects in the Coursera
<a href=https://coursera.pxf.io/7mKnnY target=_blank rel="nofollow noopener">Deep Learning Specialization</a>
. Do check it out. It talks about the pitfalls and a lot of basic ideas to improve your models.</p><p>Thanks for the read. I am going to be writing more beginner-friendly posts in the future too. Follow me up at
<a href="https://mlwhiz.medium.com/?source=post_page---------------------------" target=_blank rel="nofollow noopener">&lt;strong>Medium&lt;/strong></a>
or Subscribe to my
<a href=https://mlwhiz.ck.page/a9b8bda70c target=_blank rel="nofollow noopener">&lt;strong>blog&lt;/strong></a></p><p>Also, a small disclaimer — There might be some affiliate links in this post to relevant resources as sharing knowledge is never a bad idea.</p><script async data-uid=8d7942551b src=https://mlwhiz.ck.page/8d7942551b/index.js></script><div class=shareaholic-canvas data-app=share_buttons data-app-id=28372088 style=margin-bottom:1px></div><a href=https://coursera.pxf.io/coursera rel=nofollow><img border=0 alt="Start your future with a Data Analysis Certificate." src="https://ad.linksynergy.com/fs-bin/show?id=lVarvwc5BD0&bids=759505.377&subid=0&type=4&gridnum=16"></a><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return}var b=document,a=b.createElement('script');a.async=!0,a.src='//mlwhiz.disqus.com/embed.js',a.setAttribute('data-timestamp',+new Date),(b.head||b.body).appendChild(a)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div><div class=col-lg-4><div class=widget><script type=text/javascript src=https://ko-fi.com/widgets/widget_2.js></script><script type=text/javascript>kofiwidget2.init('Support Me on Ko-fi','#972EB4','S6S3NPCD'),kofiwidget2.draw()</script></div><div class=widget><h4 class=widget-title>About Me</h4><img src=https://mlwhiz.com/images/author.jpg alt class="img-fluid author-thumb-sm d-block mx-auto rounded-circle mb-4"><p>I’m a Machine Learning Engineer based in London, where I am currently working with Roku .</p><a href=https://mlwhiz.com/about/ class="btn btn-outline-primary">Know More</a></div><div class=widget><h4 class=widget-title>Topics</h4><ul class=list-unstyled><li><a class="categoryStyle text-white" href=/categories/awesome-guides>Awesome Guides</a></li><li><a class="categoryStyle text-white" href=/categories/bash>Bash</a></li><li><a class="categoryStyle text-white" href=/categories/big-data>Big Data</a></li><li><a class="categoryStyle text-white" href=/categories/chatgpt-series>Chatgpt Series</a></li><li><a class="categoryStyle text-white" href=/categories/computer-vision>Computer Vision</a></li><li><a class="categoryStyle text-white" href=/categories/data-science>Data Science</a></li><li><a class="categoryStyle text-white" href=/categories/deep-learning>Deep Learning</a></li><li><a class="categoryStyle text-white" href=/categories/learning-resources>Learning Resources</a></li><li><a class="categoryStyle text-white" href=/categories/machine-learning>Machine Learning</a></li><li><a class="categoryStyle text-white" href=/categories/natural-language-processing>Natural Language Processing</a></li><li><a class="categoryStyle text-white" href=/categories/opinion>Opinion</a></li><li><a class="categoryStyle text-white" href=/categories/programming>Programming</a></li></ul></div><div class=widget><h4 class=widget-title>Tags</h4><ul class=list-inline><li class=list-inline-item><a class="tagStyle text-white" href=/tags/algorithms>Algorithms</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/artificial-intelligence>Artificial Intelligence</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/chatgpt>Chatgpt</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/dask>Dask</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/deployment>Deployment</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/ec2>Ec2</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/generative-adversarial-networks>Generative Adversarial Networks</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/graphs>Graphs</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/image-classification>Image Classification</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/instance-segmentation>Instance Segmentation</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/interpretability>Interpretability</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/jobs>Jobs</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/kaggle>Kaggle</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/language-modeling>Language Modeling</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/machine-learning>Machine Learning</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/math>Math</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/multiprocessing>Multiprocessing</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/object-detection>Object Detection</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/oop>Oop</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/opinion>Opinion</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/pandas>Pandas</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/production>Production</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/productivity>Productivity</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/python>Python</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/pytorch>Pytorch</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/spark>Spark</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/sql>SQL</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/statistics>Statistics</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/streamlit>Streamlit</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/text-classification>Text Classification</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/timeseries>Timeseries</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/tools>Tools</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/transformers>Transformers</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/translation>Translation</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/visualization>Visualization</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/xgboost>Xgboost</a></li></ul></div><div class=widget><h4 class=widget-title>Connect With Me</h4><ul class="list-inline social-links"><li class=list-inline-item><a href="https://linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=rahulagwl"><i class=ti-linkedin></i></a></li><li class=list-inline-item><a href=https://mlwhiz.medium.com/><i class=ti-book></i></a></li><li class=list-inline-item><a href=https://twitter.com/MLWhiz><i class=ti-twitter-alt></i></a></li><li class=list-inline-item><a href=https://www.facebook.com/mlwhizblog><i class=ti-facebook></i></a></li><li class=list-inline-item><a href=https://github.com/MLWhiz><i class=ti-github></i></a></li></ul></div><script async data-uid=bfe9f82f10 src=https://mlwhiz.ck.page/bfe9f82f10/index.js></script><script async data-uid=3452d924e2 src=https://mlwhiz.ck.page/3452d924e2/index.js></script></div></div></div></section><footer><div class=container><div class=row><div class="col-12 text-center mb-5"><a href=https://mlwhiz.com/><img src=https://mlwhiz.com/images/logos/mlwhiz_black.png class=img-fluid-custom-bottom alt="MLWhiz - Your Home for DS, ML, AI!"></a></div><div class="col-12 border-top py-4 text-center">Copyright © 2020 <a href=https://mlwhiz.com style=color:#972eb4>MLWhiz</a> All Rights Reserved</div></div></div></footer><script>var indexURL="https://mlwhiz.com/index.json"</script><script src=https://mlwhiz.com/plugins/compressjscss/main.js></script><script src=https://mlwhiz.com/js/script.min.js></script><script>(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)})(window,document,'script','//www.google-analytics.com/analytics.js','ga'),ga('create','UA-54777926-1','auto'),ga('send','pageview')</script></body></html>