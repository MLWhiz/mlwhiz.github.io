<!doctype html><html lang=en-us><head><meta charset=utf-8><title>NLP Learning Series: Part 4 - Transfer Learning Intuition for Text Classification - MLWhiz</title><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content="Recently, I started up with an NLP competition on Kaggle called Quora Question insincerity challenge. It is an NLP Challenge on text classification, and as the problem has become more clear after working through the competition as well as by going through the invaluable kernels put up by the kaggle experts, I thought of sharing the knowledge. In this post, I will try to take you through some basic conventional models like TFIDF, Count Vectorizer, Hashing, etc. that have been used in text classification and try to access their performance to create a baseline."><meta name=author content="Rahul Agarwal"><meta name=generator content="Hugo 0.74.3"><link rel=stylesheet href=https://mlwhiz.com/plugins/compressjscss/main.css><meta property="og:title" content="NLP  Learning Series: Part 4 - Transfer Learning Intuition for Text Classification - MLWhiz"><meta property="og:description" content="Recently, I started up with an NLP competition on Kaggle called Quora Question insincerity challenge. It is an NLP Challenge on text classification, and as the problem has become more clear after working through the competition as well as by going through the invaluable kernels put up by the kaggle experts, I thought of sharing the knowledge. In this post, I will try to take you through some basic conventional models like TFIDF, Count Vectorizer, Hashing, etc. that have been used in text classification and try to access their performance to create a baseline."><meta property="og:type" content="article"><meta property="og:url" content="https://mlwhiz.com/blog/2019/03/30/transfer_learning_text_classification/"><meta property="og:image" content="https://mlwhiz.com/images/nlp_tl/spiderman.jpeg"><meta property="og:image:secure_url" content="https://mlwhiz.com/images/nlp_tl/spiderman.jpeg"><meta property="article:published_time" content="2019-03-30T00:00:00+00:00"><meta property="article:modified_time" content="2020-11-27T22:43:58+00:00"><meta property="article:tag" content="Natural Language Processing"><meta property="article:tag" content="Deep Learning"><meta property="article:tag" content="Awesome Guides"><meta name=twitter:card content="summary"><meta name=twitter:image content="https://mlwhiz.com/images/nlp_tl/spiderman.jpeg"><meta name=twitter:title content="NLP  Learning Series: Part 4 - Transfer Learning Intuition for Text Classification - MLWhiz"><meta name=twitter:description content="Recently, I started up with an NLP competition on Kaggle called Quora Question insincerity challenge. It is an NLP Challenge on text classification, and as the problem has become more clear after working through the competition as well as by going through the invaluable kernels put up by the kaggle experts, I thought of sharing the knowledge. In this post, I will try to take you through some basic conventional models like TFIDF, Count Vectorizer, Hashing, etc. that have been used in text classification and try to access their performance to create a baseline."><meta name=twitter:site content="@mlwhiz"><meta name=twitter:creator content="@mlwhiz"><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href=https://mlwhiz.com/scss/style.min.css media=screen><link rel=stylesheet href=/css/style.css><link rel=stylesheet type=text/css href=/css/font/flaticon.css><link rel="shortcut icon" href=https://mlwhiz.com/images/favicon-200x200.png type=image/x-icon><link rel=icon href=https://mlwhiz.com/images/favicon.png type=image/x-icon><link rel=canonical href=https://mlwhiz.com/blog/2019/03/30/transfer_learning_text_classification/><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js></script><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://www.mlwhiz.com/#website","url":"https://www.mlwhiz.com/","name":"MLWhiz","description":"Want to Learn Computer Vision and NLP? - MLWhiz","potentialAction":{"@type":"SearchAction","target":"https://www.mlwhiz.com/search?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://mlwhiz.com/blog/2019/03/30/transfer_learning_text_classification/#primaryimage","url":"https://mlwhiz.com/images/nlp_tl/spiderman.jpeg","width":700,"height":450},{"@type":"WebPage","@id":"https://mlwhiz.com/blog/2019/03/30/transfer_learning_text_classification/#webpage","url":"https://mlwhiz.com/blog/2019/03/30/transfer_learning_text_classification/","inLanguage":"en-US","name":"NLP  Learning Series: Part 4 - Transfer Learning Intuition for Text Classification - MLWhiz","isPartOf":{"@id":"https://www.mlwhiz.com/#website"},"primaryImageOfPage":{"@id":"https://mlwhiz.com/blog/2019/03/30/transfer_learning_text_classification/#primaryimage"},"datePublished":"2019-03-30T00:00:00.00Z","dateModified":"2020-11-27T22:43:58.00Z","author":{"@id":"https://mlwhiz.com/about/#/schema/person/76376876bchxkzbchjsdjcca"},"description":"Recently, I started up with an NLP competition on Kaggle called Quora Question insincerity challenge. It is an NLP Challenge on text classification, and as the problem has become more clear after working through the competition as well as by going through the invaluable kernels put up by the kaggle experts, I thought of sharing the knowledge. In this post, I will try to take you through some basic conventional models like TFIDF, Count Vectorizer, Hashing, etc. that have been used in text classification and try to access their performance to create a baseline."},{"@type":["Person"],"@id":"https://mlwhiz.com/about/#/schema/person/76376876bchxkzbchjsdjcca","name":"Rahul Agarwal","image":{"@type":"ImageObject","@id":"https://www.mlwhiz.com/#authorlogo","url":"https://mlwhiz.com/images/author.jpg","caption":"Rahul Agarwal"},"description":"Hi there, I\u2019m Rahul Agarwal. I\u2019m a data scientist consultant and big data engineer based in Bangalore. I see a lot of times  students and even professionals wasting their time and struggling to get started with Computer Vision, Deep Learning, and NLP. I Started this Site with a purpose to augment my own understanding about new things while helping others learn about them in the best possible way.","sameAs":["https://www.linkedin.com/in/rahulagwl/","https://medium.com/@rahul_agarwal","https://twitter.com/MLWhiz","https://www.facebook.com/mlwhizblog","https://github.com/MLWhiz","https://www.instagram.com/itsmlwhiz"]}]}</script><script async data-uid=a0ebaf958d src=https://mlwhiz.ck.page/a0ebaf958d/index.js></script><script type=text/javascript async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$']],processEscapes:true,processEnvironments:true,skipTags:['script','noscript','style','textarea','pre'],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}});MathJax.Hub.Queue(function(){var all=MathJax.Hub.getAllJax(),i;for(i=0;i<all.length;i+=1){all[i].SourceElement().parentNode.className+=' has-jax';}});MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:"AMS"}}});</script><link href=//apps.shareaholic.com/assets/pub/shareaholic.js as=script><script type=text/javascript data-cfasync=false async src=//apps.shareaholic.com/assets/pub/shareaholic.js data-shr-siteid=fd1ffa7fd7152e4e20568fbe49a489d0></script><script>!function(f,b,e,v,n,t,s)
{if(f.fbq)return;n=f.fbq=function(){n.callMethod?n.callMethod.apply(n,arguments):n.queue.push(arguments)};if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';n.queue=[];t=b.createElement(e);t.async=!0;t.src=v;s=b.getElementsByTagName(e)[0];s.parentNode.insertBefore(t,s)}(window,document,'script','https://connect.facebook.net/en_US/fbevents.js');fbq('init','402633927768628');fbq('track','PageView');</script><noscript><img height=1 width=1 style=display:none src="https://www.facebook.com/tr?id=402633927768628&ev=PageView&noscript=1"></noscript><meta property="fb:pages" content="213104036293742"><meta name=facebook-domain-verification content="qciidcy7mm137sewruizlvh8zbfnv4"></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NMQD44T" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><div class=preloader></div><header class=navigation><div class=container><nav class="navbar navbar-expand-lg navbar-white bg-transparent border-bottom pl-0"><a class="navbar-brand mobile-view" href=https://mlwhiz.com/><img class=img-fluid src=https://mlwhiz.com/images/logo.png alt="Helping You Learn Data Science!"></a>
<button class="navbar-toggler border-0" type=button data-toggle=collapse data-target=#navigation>
<i class="ti-menu h3"></i></button><div class="collapse navbar-collapse text-center" id=navigation><div class=desktop-view><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=https://www.linkedin.com/in/rahulagwl/><i class=ti-linkedin></i></a></li><li class=nav-item><a class=nav-link href=https://mlwhiz.medium.com/><i class=ti-book></i></a></li><li class=nav-item><a class=nav-link href=https://twitter.com/MLWhiz><i class=ti-twitter-alt></i></a></li><li class=nav-item><a class=nav-link href=https://www.facebook.com/mlwhizblog><i class=ti-facebook></i></a></li><li class=nav-item><a class=nav-link href=https://github.com/MLWhiz><i class=ti-github></i></a></li></ul></div><a class="navbar-brand mx-auto desktop-view" href=https://mlwhiz.com/><img class=img-fluid-custom src=https://mlwhiz.com/images/logo.png alt="Helping You Learn Data Science!"></a><ul class=navbar-nav><li class=nav-item><a class=nav-link href=https://mlwhiz.com/about>About</a></li><li class=nav-item><a class=nav-link href=https://mlwhiz.com/blog>Blog</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Topics</a><div class=dropdown-menu><a class=dropdown-item href=https://mlwhiz.com/categories/natural-language-processing>NLP</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/computer-vision>Computer Vision</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/deep-learning>Deep Learning</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/data-science>DS/ML</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/big-data>Big Data</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/awesome-guides>My Best Content</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/learning-resources>Learning Resources</a></div></li></ul><div class="search pl-lg-4"><button id=searchOpen class=search-btn><i class=ti-search></i></button><div class=search-wrapper><form action=https://mlwhiz.com//search class=h-100><input class="search-box px-4" id=search-query name=s type=search placeholder="Type & Hit Enter..."></form><button id=searchClose class=search-close><i class="ti-close text-dark"></i></button></div></div></div></nav></div></header><section class=section-sm><div class=container><div class=row><div class="col-lg-8 mb-5 mb-lg-0"><a href=/categories/natural-language-processing class=categoryStyle>Natural Language Processing</a>
<a href=/categories/deep-learning class=categoryStyle>Deep Learning</a>
<a href=/categories/awesome-guides class=categoryStyle>Awesome Guides</a><h1>NLP Learning Series: Part 4 - Transfer Learning Intuition for Text Classification</h1><div class="mb-3 post-meta"><span>By Rahul Agarwal</span><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
<span>30 March 2019</span></div><img src=https://mlwhiz.com/images/nlp_tl/spiderman.jpeg class="img-fluid w-100 mb-4" alt="NLP  Learning Series: Part 4 - Transfer Learning Intuition for Text Classification"><div class="content mb-5"><p>This post is the fourth post of the NLP Text classification series. To give you a recap, I started up with an NLP text classification competition on Kaggle called Quora Question insincerity challenge. So I thought to share the knowledge via a series of blog posts on text classification. The
<a href=/blog/2019/01/17/deeplearning_nlp_preprocess/>first post</a>
talked about the different <strong>preprocessing techniques that work with Deep learning models</strong> and <strong>increasing embeddings coverage</strong>. In the
<a href=/blog/2019/02/08/deeplearning_nlp_conventional_methods/>second post</a>
, I talked through some <strong>basic conventional models</strong> like TFIDF, Count Vectorizer, Hashing, etc. that have been used in text classification and tried to access their performance to create a baseline. In the
<a href=/blog/2019/03/09/deeplearning_architectures_text_classification/>third post</a>
, I delved deeper into <strong>Deep learning models and the various architectures</strong> we could use to solve the text Classification problem. In this post, I will try to use ULMFit model which is a transfer learning approach to this data.</p><p><strong>As a side note</strong>: If you want to know more about NLP, I would like to recommend this awesome
<a href=https://coursera.pxf.io/9WjZo0 target=_blank rel="nofollow noopener">Natural Language Processing Specialization</a>
. You can start for free with the 7-day Free Trial. This course covers a wide range of tasks in Natural Language Processing from basic to advanced: sentiment analysis, summarization, dialogue state tracking, to name a few.</p><p>Before introducing the notion of transfer learning to NLP applications, we will first need to understand a little bit about Language models.</p><hr><h2 id=language-models-and-nlp-transfer-learning-intuition>Language Models And NLP Transfer Learning Intuition:</h2><p>In very basic terms the objective of the language model is to <strong>predict the next word given a stream of input words.</strong> In the past, many different approaches have been used to solve this particular problem. Probabilistic models using Markov assumption is one example of this sort of models.</p><p>$$ P(W_n) = P(W_n|W_{n-1}) $$</p><p>In the recent era, people have been using <em>RNNs/LSTMs</em> to create such language models. They take as input a word embedding and at each time state return the probability distribution of next word probability over the dictionary words. An example of this is shown below in which the below Neural Network uses multiple stacked layers of RNN cells to learn a language model to predict the next word.</p><div style=margin-top:9px;margin-bottom:10px><center><img src=/images/nlp_tl/language_model.png height=400 width=700></center></div><p><em>Now why do we need the concept of Language Modeling? Or How does predicting the next word tie with the current task of text classification?</em> The intuition ties to the way that the neural network gets trained. The neural network that can predict the next word after being trained on a massive corpus like Wikipedia already has learned a lot of structure in a particular language. Can we use this knowledge in the weights of the network for our advantage? Yes, we can, and that is where the idea of Transfer Learning in NLP stems from. So to make this intuition more concrete, Let us think that our neural network is divided into two parts -</p><ul><li><strong>Language Specific</strong>: The lower part of the neural network is language specific. That is it learns the features of the language. This part could be used to transfer our knowledge from a language corpus to our current task</li><li><strong>Task Specific</strong>: I will call the upper part of our network as task specific. The weights in these layers are trained so that it learns to predict the next word.</li></ul><div style=margin-top:9px;margin-bottom:10px><center><img src=/images/nlp_tl/language_model_2.png height=400 width=700></center></div><p>Now as it goes in a lot of transfer learning models for Image, we stack the Language Specific part with some dense and softmax layers(Our new task) and train on our new task to achieve what we want to do.</p><hr><h2 id=ulmfit>ULMFit:</h2><p>Now the concept of Transfer learning in NLP is not entirely new and people already used Language models for transfer learning back in 2015-16 without good result. So what has changed now?</p><p>The thing that has changed is that people like Jeremy Howard and Sebastian Ruder have done a lot of research on how to train these networks. And so we have achieved state of the art results on many text datasets with Transfer Learning approaches.</p><p>Let&rsquo;s follow up with the key research findings in the
<a href=https://arxiv.org/pdf/1801.06146.pdf target=_blank rel="nofollow noopener">ULMFit paper</a>
written by them along with the code.</p><hr><h2 id=change-in-the-way-transfer-learning-networks-are-trained>Change in the way Transfer Learning networks are trained:</h2><div style=margin-top:9px;margin-bottom:10px><center><img src=/images/nlp_tl/ulmfit_training.png height=400 width=700></center></div><p>Training a model as per ULMFiT we need to take these three steps:</p><p>a) <strong>Create a Base Language Model:</strong> Training the language model on a general-domain corpus that captures high-level natural language features
b) <strong>Finetune Base Language Model on Task Specific Data:</strong> Fine-tuning the pre-trained language model on target task data
c) <strong>Finetune Base Language Model Layers + Task Specific Layers on Task Specific Data:</strong> Fine-tuning the classifier on target task data</p><p>So let us go through these three steps one by one along with the code that is provided to us with the FastAI library.</p><h4 id=a-create-a-base-language-model>a) Create a Base Language Model:</h4><p>This task might be the most time-consuming task. This model is analogous to resnet50 or Inception for the vision task. In the paper, they use the language model AWD-LSTM, a regular LSTM architecture trained with various tuned dropout hyperparameters. This model was trained on Wikitext-103 consisting of 28,595 preprocessed Wikipedia articles and 103 million words. We won&rsquo;t perform this task ourselves and will use the fabulous FastAI library to use this model as below. The code below will take our data and preprocess it for usage in the AWD_LSTM model as well as load the model.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#75715e># Language model data : We use test_df as validation for language model</span>
data_lm <span style=color:#f92672>=</span> TextLMDataBunch<span style=color:#f92672>.</span>from_df(path <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&#34;</span>,train_df<span style=color:#f92672>=</span> train_df ,valid_df <span style=color:#f92672>=</span> test_df)
learn <span style=color:#f92672>=</span> language_model_learner(data_lm, AWD_LSTM, drop_mult<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>)
</code></pre></div><p>It is also where we preprocess the data as per the required usage for the FastAI models. For example:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#66d9ef>print</span>(train_df)
</code></pre></div><div style=margin-top:9px;margin-bottom:10px><center><img src=/images/nlp_tl/train_df.png height=400 width=700></center></div><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#66d9ef>print</span>(data_lm)
</code></pre></div><pre><code>TextLMDataBunch;

Train: LabelList (1306122 items)
x: LMTextList
xxbos xxmaj how did xxmaj quebec nationalists see their province as a nation in the 1960s ?,xxbos xxmaj do you have an adopted dog , how would you encourage people to adopt and not shop ?,xxbos xxmaj why does velocity affect time ? xxmaj does velocity affect space geometry ?,xxbos xxmaj how did xxmaj otto von xxmaj guericke used the xxmaj magdeburg hemispheres ?,xxbos xxmaj can i convert montra xxunk d to a mountain bike by just changing the tyres ?
y: LMLabelList
,,,,
Path: .;

Valid: LabelList (375806 items)
x: LMTextList
xxbos xxmaj why do so many women become so rude and arrogant when they get just a little bit of wealth and power ?,xxbos xxmaj when should i apply for xxup rv college of engineering and xxup bms college of engineering ? xxmaj should i wait for the xxup comedk result or am i supposed to apply before the result ?,xxbos xxmaj what is it really like to be a nurse practitioner ?,xxbos xxmaj who are entrepreneurs ?,xxbos xxmaj is education really making good people nowadays ?
y: LMLabelList
,,,,
Path: .;

Test: None
</code></pre><p>The tokenized prepared data is based on a lot of research from the FastAI developers. To make this post a little bit complete, I am sharing some of the tokens definition as well.</p><ul><li><em>xxunk</em> is for an unknown word (one that isn&rsquo;t present in the current vocabulary)</li><li><em>xxpad</em> is the token used for padding, if we need to regroup several texts of different lengths in a batch</li><li><em>xxbos</em> represents the beginning of a text in your dataset</li><li><em>xxmaj</em> is used to indicate the next word begins with a capital in the original text</li><li><em>xxup</em> is used to indicate the next word is written in all caps in the original text</li></ul><h4 id=b-finetune-base-language-model-on-task-specific-data>b) Finetune Base Language Model on Task Specific Data</h4><p>This task is also pretty easy when we look at the code. The specific details of how we do the training is what holds the essence.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#75715e># Learning with Discriminative fine tuning</span>
learn<span style=color:#f92672>.</span>fit_one_cycle(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1e-2</span>)
learn<span style=color:#f92672>.</span>unfreeze()
learn<span style=color:#f92672>.</span>fit_one_cycle(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1e-3</span>)
<span style=color:#75715e># Save encoder Object</span>
learn<span style=color:#f92672>.</span>save_encoder(<span style=color:#e6db74>&#39;ft_enc&#39;</span>)
</code></pre></div><p>The paper introduced two general concepts for this learning stage:</p><ul><li><strong>Discriminative fine-tuning:</strong></li></ul><p>The Main Idea is: As different layers capture different types of information, they should be fine-tuned to different extents.
Instead of using the same learning rate for all layers of the model, discriminative fine-tuning allows us to tune each layer with different learning
rates. In the paper, the authors suggest first to finetune only the last layer, and then unfreeze all the layers with a learning rate lowered by a factor of 2.6.</p><ul><li><strong>Slanted triangular learning rates:</strong></li></ul><div style=margin-top:9px;margin-bottom:10px><center><img src=/images/nlp_tl/Stlr.png height=200 width=400></center></div><p>According to the authors: <em>&ldquo;For adapting its parameters to task-specific features, we would like the model to quickly converge to a suitable region of the parameter space in the beginning of training and then refine its parameters&rdquo;</em>
The Main Idea is to use a high learning rate at the starting stage for increased learning and low learning rates to finetune at later stages in an epoch.</p><p>After training our Language model on the Quora dataset, we should be able to see how our model performs on the Language Model task itself. FastAI library provides us with a simple function to do that.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#75715e># check how the language model performs</span>
learn<span style=color:#f92672>.</span>predict(<span style=color:#e6db74>&#34;What should&#34;</span>, n_words<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>)
</code></pre></div><pre><code>'What should be the likelihood of a tourist visiting Mumbai for'
</code></pre><hr><h4 id=c-finetune-base-language-model-layers--task-specific-layers-on-task-specific-data>c) Finetune Base Language Model Layers + Task Specific Layers on Task Specific Data</h4><p>This is the stage where task-specific learning takes place that is we add the classification layers and fine tune them.</p><p>The authors augment the pretrained language model with two additional
linear blocks. Each block uses batch normalization (Ioffe and Szegedy, 2015) and dropout, with ReLU activations for the intermediate layer and a
softmax activation that outputs a probability distribution over target classes at the last layer. The params of these task-specific layers are the only ones that are learned from scratch.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#75715e>#Creating Classification Data</span>
data_clas <span style=color:#f92672>=</span> TextClasDataBunch<span style=color:#f92672>.</span>from_df(path <span style=color:#f92672>=</span><span style=color:#e6db74>&#34;&#34;</span>, train_df<span style=color:#f92672>=</span>train, valid_df <span style=color:#f92672>=</span>valid,  test_df<span style=color:#f92672>=</span>test_df, vocab<span style=color:#f92672>=</span>data_lm<span style=color:#f92672>.</span>train_ds<span style=color:#f92672>.</span>vocab, bs<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>,label_cols <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;target&#39;</span>)

<span style=color:#75715e># Creating Classifier Object</span>
learn <span style=color:#f92672>=</span> text_classifier_learner(data_clas, AWD_LSTM, drop_mult<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>)
<span style=color:#75715e># Add weights of finetuned Language model</span>
learn<span style=color:#f92672>.</span>load_encoder(<span style=color:#e6db74>&#39;ft_enc&#39;</span>)
<span style=color:#75715e># Fitting Classifier Object</span>
learn<span style=color:#f92672>.</span>fit_one_cycle(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1e-2</span>)
<span style=color:#75715e># Fitting Classifier Object after freezing all but last 2 layers</span>
learn<span style=color:#f92672>.</span>freeze_to(<span style=color:#f92672>-</span><span style=color:#ae81ff>2</span>)
learn<span style=color:#f92672>.</span>fit_one_cycle(<span style=color:#ae81ff>1</span>, slice(<span style=color:#ae81ff>5e-3</span><span style=color:#f92672>/</span><span style=color:#ae81ff>2.</span>, <span style=color:#ae81ff>5e-3</span>))
<span style=color:#75715e># Fitting Classifier Object - discriminative learning</span>
learn<span style=color:#f92672>.</span>unfreeze()
learn<span style=color:#f92672>.</span>fit_one_cycle(<span style=color:#ae81ff>1</span>, slice(<span style=color:#ae81ff>2e-3</span><span style=color:#f92672>/</span><span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>2e-3</span>))
</code></pre></div><p>Here also the Authors have derived a few novel methods:</p><ul><li><strong>Concat Pooling:</strong></li></ul><p>The authors use not only the concatenation of all the hidden state but also the Maxpool and Meanpool representation of all hidden states as input to the linear layers.</p><p>$$ H = [h_1, . . . , h_T ] $$</p><p>$$ h_c = [h_T , maxpool(H), meanpool(H)] $$</p><ul><li><strong>Gradual Unfreezing:</strong></li></ul><p>Rather than fine-tuning all layers at once, which risks catastrophic forgetting(Forgetting everything we have learned so far from language models), the authors propose to gradually unfreeze the model starting from the last layer as this contains the least general knowledge. The Authors first unfreeze the last layer and fine-tune all unfrozen layers for one epoch. They then unfreeze the next lower frozen layer and repeat, until they finetune all layers until convergence at the last iteration. The function <code>slice(2e-3/100, 2e-3)</code> means that we train every layer with different learning rates ranging from max to min value.</p><p>One can get the predictions for the test data at once using:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py>test_preds <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(learn<span style=color:#f92672>.</span>get_preds(DatasetType<span style=color:#f92672>.</span>Test, ordered<span style=color:#f92672>=</span>True)[<span style=color:#ae81ff>0</span>])[:,<span style=color:#ae81ff>1</span>]
</code></pre></div><p>I am a big fan of Kaggle Kernels. One could not have imagined having all that compute for free. You can find a running version of the above code in this
<a href=https://www.kaggle.com/mlwhiz/ulmfit target=_blank rel="nofollow noopener">kaggle kernel</a>
. Do try to experiment with it after forking and running the code. Also please upvote the kernel if you find it helpful.</p><hr><h2 id=results>Results:</h2><p>Here are the final results of all the different approaches I have tried on the Kaggle Dataset. I ran a 5 fold Stratified CV.</p><h3 id=a-conventional-methods>a. Conventional Methods:</h3><div style=margin-top:9px;margin-bottom:10px><center><img src=/images/results_conv.png style=height:40%;width:40%></center></div><h3 id=b-deep-learning-methods>b. Deep Learning Methods:</h3><div style=margin-top:9px;margin-bottom:10px><center><img src=/images/results_deep_learning.png style=height:50%;width:50%></center></div><h3 id=c-transfer-learning-methodsulmfit>c. Transfer Learning Methods(ULMFIT):</h3><div style=margin-top:9px;margin-bottom:10px><center><img src=/images/nlp_tl/results_ulm.png style=height:30%;width:30%></center></div><p>The results achieved were not very good compared to deep learning methods, but I still liked the idea of the transfer learning approach, and it was so easy to implement it using fastAI. Also running the code took a lot of time at 9 hours, compared to other methods which got over in 2 hours.</p><p>Even if this approach didn&rsquo;t work well for this dataset, it is a valid approach for other datasets, as the Authors of the paper have achieved pretty good results on different datasets — definitely a genuine method to try out.</p><p><strong>PS:</strong> Note that I didn&rsquo;t work on tuning the above models, so these results are only cursory. You can try to squeeze more performance by performing hyperparams tuning
<a href=/blog/2017/12/28/hyperopt_tuning_ml_model/>using hyperopt</a>
or just old fashioned Grid-search.</p><hr><h2 id=conclusion>Conclusion:</h2><p>Finally, this post concludes my NLP Learning series. It took a lot of time to write, but the effort was well worth it. I hope you found it helpful in your work. I will try to write some more on this topic when I get some time. Follow me up at
<a href=https://mlwhiz.medium.com/ target=_blank rel="nofollow noopener">Medium</a>
or Subscribe to my blog to be informed about my next posts.</p><p>If you want to know more about NLP, I would like to recommend this awesome
<a href=https://coursera.pxf.io/9WjZo0 target=_blank rel="nofollow noopener">Natural Language Processing Specialization</a>
. You can start for free with the 7-day Free Trial. This course covers a wide range of tasks in Natural Language Processing from basic to advanced: sentiment analysis, summarization, dialogue state tracking, to name a few.</p><p>Let me know if you think I can add something more to the post; I will try to incorporate it.</p><p>Cheers!!!</p><script async data-uid=8d7942551b src=https://mlwhiz.ck.page/8d7942551b/index.js></script><div class=shareaholic-canvas data-app=share_buttons data-app-id=28372088 style=margin-bottom:1px></div><a href=https://coursera.pxf.io/coursera rel=nofollow><img border=0 alt="Start your future with a Data Analysis Certificate." src="https://ad.linksynergy.com/fs-bin/show?id=lVarvwc5BD0&bids=759505.377&subid=0&type=4&gridnum=16"></a><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return;}
var d=document,s=d.createElement('script');s.async=true;s.src='//'+"mlwhiz"+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div><div class=col-lg-4><div class=widget><script type=text/javascript src=https://ko-fi.com/widgets/widget_2.js></script><script type=text/javascript>kofiwidget2.init('Support Me on Ko-fi','#00aaa1','S6S3NPCD');kofiwidget2.draw();</script></div><div class=widget><h4 class=widget-title>About Me</h4><img src=https://mlwhiz.com/images/author.jpg alt class="img-fluid author-thumb-sm d-block mx-auto rounded-circle mb-4"><p>Hi, Impact!!!
I’m a data scientist consultant and big data engineer based in Bangalore, where I am currently working with WalmartLabs .</p><a href=https://mlwhiz.com/about/ class="btn btn-outline-primary">Know More</a></div><div class=widget><h4 class=widget-title>Topics</h4><ul class=list-unstyled><li><a class=categoryStyle style=color:#fff href=/categories/awesome-guides>Awesome Guides</a></li><li><a class=categoryStyle style=color:#fff href=/categories/big-data>Big Data</a></li><li><a class=categoryStyle style=color:#fff href=/categories/computer-vision>Computer Vision</a></li><li><a class=categoryStyle style=color:#fff href=/categories/data-science>Data Science</a></li><li><a class=categoryStyle style=color:#fff href=/categories/deep-learning>Deep Learning</a></li><li><a class=categoryStyle style=color:#fff href=/categories/learning-resources>Learning Resources</a></li><li><a class=categoryStyle style=color:#fff href=/categories/natural-language-processing>Natural Language Processing</a></li><li><a class=categoryStyle style=color:#fff href=/categories/programming>Programming</a></li></ul></div><div class=widget><h4 class=widget-title>Tags</h4><ul class=list-inline><li class=list-inline-item><a class="tagStyle text-white" href=/tags/algorithms>Algorithms</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/artificial-intelligence>Artificial Intelligence</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/dask>Dask</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/deployment>Deployment</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/ec2>Ec2</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/generative-adversarial-networks>Generative Adversarial Networks</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/graphs>Graphs</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/image-classification>Image Classification</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/instance-segmentation>Instance Segmentation</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/interpretability>Interpretability</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/jobs>Jobs</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/kaggle>Kaggle</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/language-modeling>Language Modeling</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/machine-learning>Machine Learning</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/math>Math</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/multiprocessing>Multiprocessing</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/object-detection>Object Detection</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/oop>Oop</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/opinion>Opinion</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/pandas>Pandas</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/production>Production</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/productivity>Productivity</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/python>Python</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/pytorch>Pytorch</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/spark>Spark</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/sql>Sql</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/statistics>Statistics</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/streamlit>Streamlit</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/text-classification>Text Classification</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/timeseries>Timeseries</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/tools>Tools</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/transformers>Transformers</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/translation>Translation</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/visualization>Visualization</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/xgboost>Xgboost</a></li></ul></div><div class=widget><h4 class=widget-title>Connect With Me</h4><ul class="list-inline social-links"><li class=list-inline-item><a href=https://www.linkedin.com/in/rahulagwl/><i class=ti-linkedin></i></a></li><li class=list-inline-item><a href=https://mlwhiz.medium.com/><i class=ti-book></i></a></li><li class=list-inline-item><a href=https://twitter.com/MLWhiz><i class=ti-twitter-alt></i></a></li><li class=list-inline-item><a href=https://www.facebook.com/mlwhizblog><i class=ti-facebook></i></a></li><li class=list-inline-item><a href=https://github.com/MLWhiz><i class=ti-github></i></a></li></ul></div><script async data-uid=bfe9f82f10 src=https://mlwhiz.ck.page/bfe9f82f10/index.js></script><script async data-uid=3452d924e2 src=https://mlwhiz.ck.page/3452d924e2/index.js></script></div></div></div></section><footer><div class=container><div class=row><div class="col-12 text-center mb-5"><a href=https://mlwhiz.com/><img src=https://mlwhiz.com/images/logo.png class=img-fluid-custom-bottom alt="Helping You Learn Data Science!"></a></div><div class="col-lg-3 col-sm-6 mb-5"><h6 class=mb-4>Contact Me</h6><ul class=list-unstyled><li class=mb-3><i class="ti-location-pin mr-3 text-primary"></i>India, Bangalore</li><li class=mb-3><a class=text-dark href=mailto:rahul@mlwhiz.com><i class="ti-email mr-3 text-primary"></i>rahul@mlwhiz.com</a></li></ul></div><div class="col-lg-3 col-sm-6 mb-5"><h6 class=mb-4>Social Contacts</h6><ul class=list-unstyled><li class=mb-3><a class=text-dark href=https://www.linkedin.com/in/rahulagwl/>Linkedin</a></li><li class=mb-3><a class=text-dark href=https://mlwhiz.medium.com/>Medium</a></li><li class=mb-3><a class=text-dark href=https://twitter.com/MLWhiz>Twitter</a></li><li class=mb-3><a class=text-dark href=https://www.facebook.com/mlwhizblog>Facebook</a></li><li class=mb-3><a class=text-dark href=https://github.com/MLWhiz>Github</a></li></ul></div><div class="col-lg-3 col-sm-6 mb-5"><h6 class=mb-4>Categories</h6><ul class=list-unstyled><li class=mb-3><a class=text-dark href=/categories/awesome-guides>Awesome Guides</a></li><li class=mb-3><a class=text-dark href=/categories/big-data>Big Data</a></li><li class=mb-3><a class=text-dark href=/categories/computer-vision>Computer Vision</a></li><li class=mb-3><a class=text-dark href=/categories/data-science>Data Science</a></li><li class=mb-3><a class=text-dark href=/categories/deep-learning>Deep Learning</a></li><li class=mb-3><a class=text-dark href=/categories/learning-resources>Learning Resources</a></li><li class=mb-3><a class=text-dark href=/categories/natural-language-processing>Natural Language Processing</a></li><li class=mb-3><a class=text-dark href=/categories/programming>Programming</a></li></ul></div><div class="col-lg-3 col-sm-6 mb-5"><h6 class=mb-4>Quick Links</h6><ul class=list-unstyled><li class=mb-3><a class=text-dark href=https://mlwhiz.com/about>About</a></li><li class=mb-3><a class=text-dark href=https://mlwhiz.com/blog>Post</a></li></ul></div><div class="col-12 border-top py-4 text-center">Copyright © 2020 <a href=https://mlwhiz.com>MLWhiz</a> All Rights Reserved</div></div></div></footer><script>var indexURL="https://mlwhiz.com/index.json"</script><script src=https://mlwhiz.com/plugins/compressjscss/main.js></script><script src=https://mlwhiz.com/js/script.min.js></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-54777926-1','auto');ga('send','pageview');</script></body></html>