<!DOCTYPE html>
<html class="no-js" lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Using Gradient Boosting for Time Series prediction tasks</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="In this post, we will try to solve the time series problem using XGBoost.">
	

	
	<link rel='preload' href='//apps.shareaholic.com/assets/pub/shareaholic.js' as='script' />
	<script type="text/javascript" data-cfasync="false" async src="//apps.shareaholic.com/assets/pub/shareaholic.js" data-shr-siteid="fd1ffa7fd7152e4e20568fbe49a489d0"></script>
	
	
	<meta name="generator" content="Hugo 0.53" />
	<meta property="og:title" content="Using Gradient Boosting for Time Series prediction tasks" />
<meta property="og:description" content="In this post, we will try to solve the time series problem using XGBoost." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mlwhiz.com/blog/2019/12/28/timeseries/" />
<meta property="og:image" content="https://mlwhiz.com/images/timeseries/main.png" />
<meta property="article:published_time" content="2019-12-28T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2019-12-28T00:00:00&#43;00:00"/>

	<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://mlwhiz.com/images/timeseries/main.png"/>

<meta name="twitter:title" content="Using Gradient Boosting for Time Series prediction tasks"/>
<meta name="twitter:description" content="In this post, we will try to solve the time series problem using XGBoost."/>


	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/css/style.css">
	<link rel="stylesheet" href="/css/custom.css">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="96x96" href="/favicon-96x96.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	
	
		
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-54777926-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

	
	<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
	new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
	j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
	'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
	})(window,document,'script','dataLayer','GTM-NMQD44T');</script>
	

	
	<script>
	  !function(f,b,e,v,n,t,s)
	  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
	  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
	  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
	  n.queue=[];t=b.createElement(e);t.async=!0;
	  t.src=v;s=b.getElementsByTagName(e)[0];
	  s.parentNode.insertBefore(t,s)}(window, document,'script',
	  'https://connect.facebook.net/en_US/fbevents.js');
	  fbq('init', '1062344757288542');
	  fbq('track', 'PageView');
	</script>
	<noscript><img height="1" width="1" style="display:none"
	  src="https://www.facebook.com/tr?id=1062344757288542&ev=PageView&noscript=1"
	/></noscript>
	


	
  	<script async>(function(s,u,m,o,j,v){j=u.createElement(m);v=u.getElementsByTagName(m)[0];j.async=1;j.src=o;j.dataset.sumoSiteId='22863fd8ad7ebbfab9b8ca60b7db8f65e9a15559f384f785f66903e365aa8f48';v.parentNode.insertBefore(j,v)})(window,document,'script','//load.sumo.com/');</script>
  	<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>
</head>
<body class="body">
	  
	  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NMQD44T"
	  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
	  
	<div class="container container--outer">
		<header class="header">
	<div class="container">
		<div class="logo">

			<a class="logo__link" href="/" title="MLWhiz" rel="home">

				<div class="logo__title">MLWhiz</div>
				<div class="logo__tagline">Deep Learning, Data Science and NLP Enthusiast</div>
			</a>
		</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/">Blog</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/archive">Archive</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/about/">About Me</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/nlpseries/">NLP</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/atom.xml">RSS</a>
		</li>
	</ul>
</nav>

	</div>
</header>


		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Using Gradient Boosting for Time Series prediction tasks</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
	<time class="meta__text" datetime="2019-12-28T00:00:00">December 28, 2019</time>
</div>
</div>
		</header>
		<div class="content post__content clearfix">
			

<p><img src="/images/timeseries/main.png" alt="" /></p>

<p>Time series prediction problems are pretty frequent in the retail domain.</p>

<p>Companies like Walmart and Target need to keep track of how much product should be shipped from Distribution Centres to stores. Even a small improvement in such a demand forecasting system can help save a lot of dollars in term of workforce management, inventory cost and out of stock loss.</p>

<p>While there are many techniques to solve this particular problem like ARIMA, Prophet, and LSTMs, we can also treat such a problem as a regression problem too and use trees to solve it.</p>

<p><strong><em>In this post, we will try to solve the time series problem using XGBoost.</em></strong></p>

<p><strong><em>The main things I am going to focus on are the sort of features such a setup takes and how to create such features.</em></strong></p>

<hr />

<h2 id="dataset">Dataset</h2>

<p><img src="https://cdn-images-1.medium.com/max/2000/0*gLUSm0_14D8A3NvR.jpg" alt="" /></p>

<p>Kaggle master Kazanova along with some of his friends released a <a href="https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-BShznKdc3CUauhfsM7_8xw&amp;utm_content=2&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0" rel="nofollow" target="_blank">“How to win a data science competition”</a> Coursera course. The Course involved a final project which itself was a time series prediction problem.</p>

<p>In this competition, we are given a challenging time-series dataset consisting of daily sales data, provided by one of the largest Russian software firms — 1C Company.</p>

<p>We have to predict total sales for every product and store in the next month.</p>

<p>Here is how the data looks like:</p>

<p><img src="https://cdn-images-1.medium.com/max/2072/1*hN1eF-iQzfTp6EGg3VBAlA.png" alt="" /></p>

<p>We are given the data at a daily level, and we want to build a model which predicts total sales for every product and store in the next month.</p>

<p>The variable date_block_num is a consecutive month number, used for convenience. January 2013 is 0, and October 2015 is 33. You can think of it as a proxy to month variable. I think all the other variables are self-explanatory.</p>

<p><strong><em>So how do we approach this sort of a problem?</em></strong></p>

<hr />

<h2 id="data-preparation">Data Preparation</h2>

<p>The main thing that I noticed is that the data preparation and <a href="https://towardsdatascience.com/the-hitchhikers-guide-to-feature-extraction-b4c157e96631" rel="nofollow" target="_blank">feature generation</a> aspect is by far the most important thing when we attempt to solve the time series problem using regression.</p>

<h3 id="1-do-basic-eda-and-remove-outliers">1. Do Basic EDA and remove outliers</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">sales <span style="color:#f92672">=</span> sales[sales[<span style="color:#e6db74">&#39;item_price&#39;</span>]<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">100000</span>]
sales <span style="color:#f92672">=</span> sales[sales[<span style="color:#e6db74">&#39;item_cnt_day&#39;</span>]<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">1000</span>]</code></pre></div>
<h3 id="2-group-data-at-a-level-you-want-your-predictions-to-be">2. Group data at a level you want your predictions to be:</h3>

<p>We start with creating a dataframe of distinct date_block_num, store and item combinations.</p>

<p>This is important because in the months we don’t have a data for an item store combination, the machine learning algorithm needs to be told explicitly that the sales are zero.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#f92672">from</span> itertools <span style="color:#f92672">import</span> product
<span style="color:#75715e"># Create &#34;grid&#34; with columns</span>
index_cols <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;shop_id&#39;</span>, <span style="color:#e6db74">&#39;item_id&#39;</span>, <span style="color:#e6db74">&#39;date_block_num&#39;</span>]

<span style="color:#75715e"># For every month we create a grid from all shops/items combinations from that month</span>
grid <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> block_num <span style="color:#f92672">in</span> sales[<span style="color:#e6db74">&#39;date_block_num&#39;</span>]<span style="color:#f92672">.</span>unique():
    cur_shops <span style="color:#f92672">=</span> sales<span style="color:#f92672">.</span>loc[sales[<span style="color:#e6db74">&#39;date_block_num&#39;</span>] <span style="color:#f92672">==</span> block_num, <span style="color:#e6db74">&#39;shop_id&#39;</span>]<span style="color:#f92672">.</span>unique()
    cur_items <span style="color:#f92672">=</span> sales<span style="color:#f92672">.</span>loc[sales[<span style="color:#e6db74">&#39;date_block_num&#39;</span>] <span style="color:#f92672">==</span> block_num, <span style="color:#e6db74">&#39;item_id&#39;</span>]<span style="color:#f92672">.</span>unique()
    grid<span style="color:#f92672">.</span>append(np<span style="color:#f92672">.</span>array(list(product(<span style="color:#f92672">*</span>[cur_shops, cur_items, [block_num]])),dtype<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;int32&#39;</span>))

grid <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(np<span style="color:#f92672">.</span>vstack(grid), columns <span style="color:#f92672">=</span> index_cols,dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>int32)
grid<span style="color:#f92672">.</span>head()</code></pre></div>
<p><img src="https://cdn-images-1.medium.com/max/2000/1*yDLbk-d9EbYV7EG38MXYeg.png" alt="" /></p>

<p>The grid dataFrame contains all the shop, items and month combinations.</p>

<p>We then merge the Grid with Sales to get the monthly sales DataFrame. We also replace all the NA’s with zero for months that didn’t have any sales.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">sales_m <span style="color:#f92672">=</span> sales<span style="color:#f92672">.</span>groupby([<span style="color:#e6db74">&#39;date_block_num&#39;</span>,<span style="color:#e6db74">&#39;shop_id&#39;</span>,<span style="color:#e6db74">&#39;item_id&#39;</span>])<span style="color:#f92672">.</span>agg({<span style="color:#e6db74">&#39;item_cnt_day&#39;</span>: <span style="color:#e6db74">&#39;sum&#39;</span>,<span style="color:#e6db74">&#39;item_price&#39;</span>: np<span style="color:#f92672">.</span>mean})<span style="color:#f92672">.</span>reset_index()

<span style="color:#75715e"># Merging sales numbers with the grid dataframe</span>
sales_m <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>merge(grid,sales_m,on<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;date_block_num&#39;</span>,<span style="color:#e6db74">&#39;shop_id&#39;</span>,<span style="color:#e6db74">&#39;item_id&#39;</span>],how<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;left&#39;</span>)<span style="color:#f92672">.</span>fillna(<span style="color:#ae81ff">0</span>)

<span style="color:#75715e"># adding the category id too from the items table.</span>
sales_m <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>merge(sales_m,items,on<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;item_id&#39;</span>],how<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;left&#39;</span>)</code></pre></div>
<p><img src="https://cdn-images-1.medium.com/max/3364/1*V_SzSZkoyGT7ce-FtPlLQw.png" alt="" /></p>

<hr />

<h3 id="3-create-target-encodings">3. Create Target Encodings</h3>

<p>To create target encodings, we group by a particular column and take the mean/min/sum etc. of the target column on it. These features are the first features we create in our model.</p>

<p><strong><em>Please note that these features may induce a lot of leakage/overfitting in our system and thus we don’t use them directly in our models. We will use the lag based version of these features in our models which we will create next.</em></strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">groupcollist <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;item_id&#39;</span>,<span style="color:#e6db74">&#39;shop_id&#39;</span>,<span style="color:#e6db74">&#39;item_category_id&#39;</span>]

aggregationlist <span style="color:#f92672">=</span> [(<span style="color:#e6db74">&#39;item_price&#39;</span>,np<span style="color:#f92672">.</span>mean,<span style="color:#e6db74">&#39;avg&#39;</span>),(<span style="color:#e6db74">&#39;item_cnt_day&#39;</span>,np<span style="color:#f92672">.</span>sum,<span style="color:#e6db74">&#39;sum&#39;</span>),(<span style="color:#e6db74">&#39;item_cnt_day&#39;</span>,np<span style="color:#f92672">.</span>mean,<span style="color:#e6db74">&#39;avg&#39;</span>)]

<span style="color:#66d9ef">for</span> type_id <span style="color:#f92672">in</span> groupcollist:
    <span style="color:#66d9ef">for</span> column_id,aggregator,aggtype <span style="color:#f92672">in</span> aggregationlist:
        <span style="color:#75715e"># get numbers from sales data and set column names</span>
        mean_df <span style="color:#f92672">=</span> sales_m<span style="color:#f92672">.</span>groupby([type_id,<span style="color:#e6db74">&#39;date_block_num&#39;</span>])<span style="color:#f92672">.</span>aggregate(aggregator)<span style="color:#f92672">.</span>reset_index()[[column_id,type_id,<span style="color:#e6db74">&#39;date_block_num&#39;</span>]]
        mean_df<span style="color:#f92672">.</span>columns <span style="color:#f92672">=</span> [type_id<span style="color:#f92672">+</span><span style="color:#e6db74">&#39;_&#39;</span><span style="color:#f92672">+</span>aggtype<span style="color:#f92672">+</span><span style="color:#e6db74">&#39;_&#39;</span><span style="color:#f92672">+</span>column_id,type_id,<span style="color:#e6db74">&#39;date_block_num&#39;</span>]
        <span style="color:#75715e"># merge new columns on sales_m data</span>
        sales_m <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>merge(sales_m,mean_df,on<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;date_block_num&#39;</span>,type_id],how<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;left&#39;</span>)</code></pre></div>
<p>We group by item_id, shop_id, and item_category_id and aggregate on the item_price and item_cnt_day column to create the following new features:</p>

<p><img src="https://cdn-images-1.medium.com/max/2804/1*TNJdVv0Bka75S5QKHV0D-w.png" alt="We create the highlighted target encodings" /></p>

<p>We could also have used <a href="https://towardsdatascience.com/the-hitchhikers-guide-to-feature-extraction-b4c157e96631" rel="nofollow" target="_blank">featuretools</a> for this. <strong>Featuretools</strong> is a framework to perform automated feature engineering. It excels at transforming temporal and relational datasets into feature matrices for machine learning.</p>

<hr />

<h3 id="4-create-lag-features">4. Create Lag Features</h3>

<p>The next set of features our model needs are the lag based Features.</p>

<p>When we create regular classification models, we treat training examples as fairly independent of each other. But in case of time series problems, at any point in time, the model needs information on what happened in the past.</p>

<p>We can’t do this for all the past days, but we can provide the models with the most recent information nonetheless using our target encoded features.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">lag_variables  <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;item_id_avg_item_price&#39;</span>,<span style="color:#e6db74">&#39;item_id_sum_item_cnt_day&#39;</span>,<span style="color:#e6db74">&#39;item_id_avg_item_cnt_day&#39;</span>,<span style="color:#e6db74">&#39;shop_id_avg_item_price&#39;</span>,<span style="color:#e6db74">&#39;shop_id_sum_item_cnt_day&#39;</span>,<span style="color:#e6db74">&#39;shop_id_avg_item_cnt_day&#39;</span>,<span style="color:#e6db74">&#39;item_category_id_avg_item_price&#39;</span>,<span style="color:#e6db74">&#39;item_category_id_sum_item_cnt_day&#39;</span>,<span style="color:#e6db74">&#39;item_category_id_avg_item_cnt_day&#39;</span>,<span style="color:#e6db74">&#39;item_cnt_day&#39;</span>]
lags <span style="color:#f92672">=</span> [<span style="color:#ae81ff">1</span> ,<span style="color:#ae81ff">2</span> ,<span style="color:#ae81ff">3</span> ,<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">12</span>]
<span style="color:#75715e"># we will keep the results in thsi dataframe</span>
sales_means <span style="color:#f92672">=</span> sales_m<span style="color:#f92672">.</span>copy()
<span style="color:#66d9ef">for</span> lag <span style="color:#f92672">in</span> lags:
    sales_new_df <span style="color:#f92672">=</span> sales_m<span style="color:#f92672">.</span>copy()
    sales_new_df<span style="color:#f92672">.</span>date_block_num<span style="color:#f92672">+=</span>lag
    <span style="color:#75715e"># subset only the lag variables we want</span>
    sales_new_df <span style="color:#f92672">=</span> sales_new_df[[<span style="color:#e6db74">&#39;date_block_num&#39;</span>,<span style="color:#e6db74">&#39;shop_id&#39;</span>,<span style="color:#e6db74">&#39;item_id&#39;</span>]<span style="color:#f92672">+</span>lag_variables]
    sales_new_df<span style="color:#f92672">.</span>columns <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;date_block_num&#39;</span>,<span style="color:#e6db74">&#39;shop_id&#39;</span>,<span style="color:#e6db74">&#39;item_id&#39;</span>]<span style="color:#f92672">+</span> [lag_feat<span style="color:#f92672">+</span><span style="color:#e6db74">&#39;_lag_&#39;</span><span style="color:#f92672">+</span>str(lag) <span style="color:#66d9ef">for</span> lag_feat <span style="color:#f92672">in</span> lag_variables]
    <span style="color:#75715e"># join with date_block_num,shop_id and item_id</span>
    sales_means <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>merge(sales_means, sales_new_df,on<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;date_block_num&#39;</span>,<span style="color:#e6db74">&#39;shop_id&#39;</span>,<span style="color:#e6db74">&#39;item_id&#39;</span>] ,how<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;left&#39;</span>)</code></pre></div>
<p>So we aim to add past information for a few features in our data. We do it for all the new features we created and the item_cnt_day feature.</p>

<p>We fill the NA’s with zeros once we have the lag features.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#66d9ef">for</span> feat <span style="color:#f92672">in</span> sales_means<span style="color:#f92672">.</span>columns:
    <span style="color:#66d9ef">if</span> <span style="color:#e6db74">&#39;item_cnt&#39;</span> <span style="color:#f92672">in</span> feat:
        sales_means[feat]<span style="color:#f92672">=</span>sales_means[feat]<span style="color:#f92672">.</span>fillna(<span style="color:#ae81ff">0</span>)
    <span style="color:#66d9ef">elif</span> <span style="color:#e6db74">&#39;item_price&#39;</span> <span style="color:#f92672">in</span> feat:
    sales_means[feat]<span style="color:#f92672">=</span>sales_means[feat]<span style="color:#f92672">.</span>fillna(sales_means[feat]<span style="color:#f92672">.</span>median())</code></pre></div>
<p>We end up creating a lot of lag features with different lags:</p>

<pre><code>'item_id_avg_item_price_lag_1','item_id_sum_item_cnt_day_lag_1', 'item_id_avg_item_cnt_day_lag_1','shop_id_avg_item_price_lag_1', 'shop_id_sum_item_cnt_day_lag_1','shop_id_avg_item_cnt_day_lag_1','item_category_id_avg_item_price_lag_1','item_category_id_sum_item_cnt_day_lag_1','item_category_id_avg_item_cnt_day_lag_1', 'item_cnt_day_lag_1',

'item_id_avg_item_price_lag_2', 'item_id_sum_item_cnt_day_lag_2','item_id_avg_item_cnt_day_lag_2', 'shop_id_avg_item_price_lag_2','shop_id_sum_item_cnt_day_lag_2', 'shop_id_avg_item_cnt_day_lag_2','item_category_id_avg_item_price_lag_2','item_category_id_sum_item_cnt_day_lag_2','item_category_id_avg_item_cnt_day_lag_2', 'item_cnt_day_lag_2',

...
</code></pre>

<hr />

<h2 id="modelling">Modelling</h2>

<h3 id="1-drop-the-unrequired-columns">1. Drop the unrequired columns</h3>

<p>As previously said, we are going to drop the target encoded features as they might induce a lot of overfitting in the model. We also lose the item_name and item_price feature.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">cols_to_drop <span style="color:#f92672">=</span> lag_variables[:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">+</span> [<span style="color:#e6db74">&#39;item_name&#39;</span>,<span style="color:#e6db74">&#39;item_price&#39;</span>]

<span style="color:#66d9ef">for</span> col <span style="color:#f92672">in</span> cols_to_drop:
    <span style="color:#66d9ef">del</span> sales_means[col]</code></pre></div>
<h3 id="2-take-a-recent-bit-of-data-only">2. Take a recent bit of data only</h3>

<p>When we created the lag variables, we induced a lot of zeroes in the system. We used the maximum lag as 12. To counter that we remove the first 12 months indexes.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">sales_means <span style="color:#f92672">=</span> sales_means[sales_means[<span style="color:#e6db74">&#39;date_block_num&#39;</span>]<span style="color:#f92672">&gt;</span><span style="color:#ae81ff">11</span>]</code></pre></div>
<h3 id="3-train-and-cv-split">3. Train and CV Split</h3>

<p>When we do a time series split, we usually don’t take a cross-sectional split as the data is time-dependent. We want to create a model that sees till now and can predict the next month well.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">X_train <span style="color:#f92672">=</span> sales_means[sales_means[<span style="color:#e6db74">&#39;date_block_num&#39;</span>]<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">33</span>]
X_cv <span style="color:#f92672">=</span>  sales_means[sales_means[<span style="color:#e6db74">&#39;date_block_num&#39;</span>]<span style="color:#f92672">==</span><span style="color:#ae81ff">33</span>]

Y_train <span style="color:#f92672">=</span> X_train[<span style="color:#e6db74">&#39;item_cnt_day&#39;</span>]
Y_cv <span style="color:#f92672">=</span> X_cv[<span style="color:#e6db74">&#39;item_cnt_day&#39;</span>]

<span style="color:#66d9ef">del</span> X_train[<span style="color:#e6db74">&#39;item_cnt_day&#39;</span>]
<span style="color:#66d9ef">del</span> X_cv[<span style="color:#e6db74">&#39;item_cnt_day&#39;</span>]</code></pre></div>
<h3 id="4-create-baseline">4. Create Baseline</h3>

<p><img src="https://cdn-images-1.medium.com/max/2000/0*Ujr-irYHlXd0SAGP.jpg" alt="" /></p>

<p>Before we proceed with modelling steps, lets check the RMSE of a naive model, as we want to <a href="https://towardsdatascience.com/take-your-machine-learning-models-to-production-with-these-5-simple-steps-35aa55e3a43c" rel="nofollow" target="_blank">have an RMSE to compare</a> to. We assume that we are going to predict the last month sales as current month sale for our baseline model. We can quantify the performance of our model using this baseline RMSE.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> mean_squared_error
sales_m_test <span style="color:#f92672">=</span> sales_m[sales_m[<span style="color:#e6db74">&#39;date_block_num&#39;</span>]<span style="color:#f92672">==</span><span style="color:#ae81ff">33</span>]

preds <span style="color:#f92672">=</span> sales_m<span style="color:#f92672">.</span>copy()
preds[<span style="color:#e6db74">&#39;date_block_num&#39;</span>]<span style="color:#f92672">=</span>preds[<span style="color:#e6db74">&#39;date_block_num&#39;</span>]<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>
preds <span style="color:#f92672">=</span> preds[preds[<span style="color:#e6db74">&#39;date_block_num&#39;</span>]<span style="color:#f92672">==</span><span style="color:#ae81ff">33</span>]
preds <span style="color:#f92672">=</span> preds<span style="color:#f92672">.</span>rename(columns<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#39;item_cnt_day&#39;</span>:<span style="color:#e6db74">&#39;preds_item_cnt_day&#39;</span>})
preds <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>merge(sales_m_test,preds,on <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;shop_id&#39;</span>,<span style="color:#e6db74">&#39;item_id&#39;</span>],how<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;left&#39;</span>)[[<span style="color:#e6db74">&#39;shop_id&#39;</span>,<span style="color:#e6db74">&#39;item_id&#39;</span>,<span style="color:#e6db74">&#39;preds_item_cnt_day&#39;</span>,<span style="color:#e6db74">&#39;item_cnt_day&#39;</span>]]<span style="color:#f92672">.</span>fillna(<span style="color:#ae81ff">0</span>)

<span style="color:#75715e"># We want our predictions clipped at (0,20). Competition Specific</span>
preds[<span style="color:#e6db74">&#39;item_cnt_day&#39;</span>] <span style="color:#f92672">=</span> preds[<span style="color:#e6db74">&#39;item_cnt_day&#39;</span>]<span style="color:#f92672">.</span>clip(<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">20</span>)
preds[<span style="color:#e6db74">&#39;preds_item_cnt_day&#39;</span>] <span style="color:#f92672">=</span> preds[<span style="color:#e6db74">&#39;preds_item_cnt_day&#39;</span>]<span style="color:#f92672">.</span>clip(<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">20</span>)
baseline_rmse <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sqrt(mean_squared_error(preds[<span style="color:#e6db74">&#39;item_cnt_day&#39;</span>],preds[<span style="color:#e6db74">&#39;preds_item_cnt_day&#39;</span>]))

<span style="color:#66d9ef">print</span>(baseline_rmse)</code></pre></div>
<pre><code>1.1358170090812756
</code></pre>

<hr />

<h3 id="5-train-xgb">5. Train XGB</h3>

<p>We use the XGBRegressor object from the xgboost scikit API to build our model. Parameters are taken from this <a href="https://www.kaggle.com/dlarionov/feature-engineering-xgboost" rel="nofollow" target="_blank">kaggle kernel</a>. If you have time, you can use hyperopt to <a href="https://towardsdatascience.com/automate-hyperparameter-tuning-for-your-models-71b18f819604" rel="nofollow" target="_blank">automatically find out the hyperparameters</a> yourself.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#f92672">from</span> xgboost <span style="color:#f92672">import</span> XGBRegressor

model <span style="color:#f92672">=</span> XGBRegressor(
    max_depth<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>,
    n_estimators<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>,
    min_child_weight<span style="color:#f92672">=</span><span style="color:#ae81ff">300</span>, 
    colsample_bytree<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>, 
    subsample<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>, 
    eta<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span>,    
    seed<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)

model<span style="color:#f92672">.</span>fit(
    X_train, 
    Y_train, 
    eval_metric<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;rmse&#34;</span>, 
    eval_set<span style="color:#f92672">=</span>[(X_train, Y_train), (X_cv, Y_cv)], 
    verbose<span style="color:#f92672">=</span>True, 
    early_stopping_rounds <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>)</code></pre></div>
<p><img src="https://cdn-images-1.medium.com/max/2288/1*uK9IjFKLEWPGbbeDLc2hfg.png" alt="" /></p>

<p>After running this, we can see RMSE in ranges of <strong><em>0.93</em></strong> on the CV set. And that is pretty impressive based on our baseline validation RMSE of <strong><em>1.13</em></strong>. And so we work on deploying this model as part of our <a href="https://towardsdatascience.com/take-your-machine-learning-models-to-production-with-these-5-simple-steps-35aa55e3a43c" rel="nofollow" target="_blank">continuous integration</a> effort.</p>

<h3 id="5-plot-feature-importance">5. Plot Feature Importance</h3>

<p>We can also see the important features that come from XGB.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">feature_importances <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#39;col&#39;</span>: columns,<span style="color:#e6db74">&#39;imp&#39;</span>:model<span style="color:#f92672">.</span>feature_importances_})
feature_importances <span style="color:#f92672">=</span> feature_importances<span style="color:#f92672">.</span>sort_values(by<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;imp&#39;</span>,ascending<span style="color:#f92672">=</span>False)
px<span style="color:#f92672">.</span>bar(feature_importances,x<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;col&#39;</span>,y<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;imp&#39;</span>)</code></pre></div>
<p><img src="https://cdn-images-1.medium.com/max/3716/1*TZ_BawTl6O1kMuTUTMYoHw.png" alt="Feature importances" /></p>

<hr />

<h2 id="conclusion">Conclusion</h2>

<p>In this post, we talked about how we can use trees for even time series modelling. The purpose was not to get perfect scores on the kaggle leaderboard but to gain an understanding of how such models work.</p>

<p><img src="https://cdn-images-1.medium.com/max/3004/0*vsyzeBzrG4q4Z33z.png" alt="" /></p>

<p>When I took part in this competition as part of the <a href="https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-BShznKdc3CUauhfsM7_8xw&amp;utm_content=2&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0" rel="nofollow" target="_blank">course</a>, a couple of years back, using trees I reached near the top of the leaderboard.</p>

<p>Over time people have worked a lot on tweaking the model, hyperparameter tuning and creating even more informative features. But the basic approach has remained the same.</p>

<p>You can find the whole running code on <a href="https://github.com/MLWhiz/data_science_blogs/tree/master/time_series_xgb" rel="nofollow" target="_blank">GitHub</a>.</p>

<p>Take a look at the <a href="https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;utm_content=2&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0" rel="nofollow" target="_blank">How to Win a Data Science Competition: Learn from Top Kagglers</a> course in the <a href="https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;utm_content=2&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0" rel="nofollow" target="_blank">Advanced machine learning specialization</a> by Kazanova. This course talks about a lot of ways to improve your models using feature engineering and hyperparameter tuning.</p>

<p>I am going to be writing more beginner-friendly posts in the future too. Let me know what you think about the series. Follow me up at <a href="https://medium.com/@rahul_agarwal" rel="nofollow" target="_blank"><strong>Medium</strong></a> or Subscribe to my <a href="http://eepurl.com/dbQnuX" rel="nofollow" target="_blank"><strong>blog</strong></a> to be informed about them. As always, I welcome feedback and constructive criticism and can be reached on Twitter <a href="https://twitter.com/MLWhiz" rel="nofollow" target="_blank">@mlwhiz</a>.</p>

<p>Also, a small disclaimer — There might be some affiliate links in this post to relevant resources, as sharing knowledge is never a bad idea.</p>

		</div>
		
<div class="post__tags tags clearfix">
	<svg class="icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item"><a class="tags__link btn" href="/tags/python/" rel="tag">Python</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/statistics/" rel="tag">Statistics</a></li>
	</ul>
</div>
		

<div class="shareaholic-canvas" data-app="share_buttons" data-app-id="28372088"></div>

<a href="https://click.linksynergy.com/fs-bin/click?id=lVarvwc5BD0&offerid=467035.372&subid=0&type=4" rel="nofollow"><IMG border="0"   alt="Start your future with a Data Science Certificate." src="https://ad.linksynergy.com/fs-bin/show?id=lVarvwc5BD0&bids=467035.372&subid=0&type=4&gridnum=16"></a>





























	</article>
</main>


<nav class="post-nav flex">
	<div class="post-nav__item post-nav__item--prev">
		<a class="post-nav__link" href="/blog/2019/12/25/prod/" rel="prev"><span class="post-nav__caption">«&thinsp;Previous</span><p class="post-nav__post-title">Take your Machine Learning Models to Production with these 5 simple steps</p></a>
	</div>
	<div class="post-nav__item post-nav__item--next">
		<a class="post-nav__link" href="/blog/2020/01/15/ind/" rel="next"><span class="post-nav__caption">Next&thinsp;»</span><p class="post-nav__post-title">3 Industries That Benefit from Data Science</p></a>
	</div>
</nav>

<section class="comments">
	<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "mlwhiz" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


			</div>
			<style type="text/css">

  .btn {
    display: inline-block;
    font-weight: 400;
    text-align: center;
    white-space: nowrap;
    vertical-align: middle;
    -webkit-user-select: none;
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none;
    border: 1px solid transparent;
    padding: .375rem .75rem;
    font-size: 1rem;
    line-height: 1.5;
    border-radius: .25rem;
    transition: color .15s ease-in-out,background-color .15s ease-in-out,border-color .15s ease-in-out,box-shadow .15s ease-in-out;
}

.btn-session {
    color: #fff;
    background-color: #28a745;
    border-color: #28a745;
}
</style>


<aside class="sidebar">
  <div style="text-align:center">    
    
    <a class="btn btn-session" href="https://www.patreon.com/bePatron?u=28135435" role="button">1:1 Session</a>
	     
  </div>
  <br><div class="widget-search widget">
	<form class="widget-search__form" role="search" method="get" action="https://google.com/search">
		<label>
			<input class="widget-search__field" type="search" placeholder="SEARCH..." value="" name="q" aria-label="SEARCH...">
		</label>
		<input class="widget-search__submit" type="submit" value="Search">
		<input type="hidden" name="sitesearch" value="https://mlwhiz.com/" />
	</form>
</div>
<div class="widget-recent widget">
	<h4 class="widget__title">Recent Posts</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/blog/2020/01/29/altr/">Handling Trees in Data Science Algorithmic Interview</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/01/28/ll/">A simple introduction to Linked Lists for Data Scientists</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/01/28/dp/">Dynamic Programming for Data Scientists</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/01/28/imbal/">The 5 most useful Techniques to Handle Imbalanced datasets</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2020/01/15/ind/">3 Industries That Benefit from Data Science</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2019/12/28/timeseries/">Using Gradient Boosting for Time Series prediction tasks</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2019/12/25/prod/">Take your Machine Learning Models to Production with these 5 simple steps</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2019/12/24/mistakes/">3 Mistakes you should not make in a Data Science Interview</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2019/12/09/pc/">3 Programming concepts for Data Scientists</a></li>
			<li class="widget__item"><a class="widget__link" href="/blog/2019/12/07/streamlit/">How to write Web apps using simple Python for Data Scientists?</a></li>
		</ul>
	</div>
</div>


<div class="shareaholic-canvas" data-app="follow_buttons" data-app-id="28033293" style="white-space: inherit;"></div>


<link href="//cdn-images.mailchimp.com/embedcode/slim-10_7.css" rel="stylesheet" type="text/css">


<style type="text/css">
  #mc_embed_signup .button {background-color: #127edc;}
  #mc_embed_signup form .center{
    display: block;
    position: relative;
    text-align: center;
    padding: 10px -5px 10px 3%;}
   
</style>
<div id="mc_embed_signup">
<form action="//mlwhiz.us15.list-manage.com/subscribe/post?u=4e9962f4ce4a94818bcc2f249&amp;id=87a48fafdd" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
    <input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required>
    
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_4e9962f4ce4a94818bcc2f249_87a48fafdd" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy;  2014-2020 Rahul Agarwal.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>



	</div>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&adInstanceId=93f2f4f9-cf51-415d-84af-08cbb74b178f"></script>
<script async defer src="/js/menu.js"></script></body>
</html>