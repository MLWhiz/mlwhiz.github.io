<!doctype html><html lang=en-us><head><meta charset=utf-8><title>MLWhiz: Helping You Learn Data Science!</title><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content="An intuitive description of The way MCMC Algorithm works."><meta name=author content="Rahul Agarwal"><meta name=generator content="Hugo 0.74.3"><link rel=stylesheet href=https://mlwhiz.com/plugins/compressjscss/main.css><meta property="og:title" content="My Tryst With MCMC Algorithms"><meta property="og:description" content="An intuitive description of The way MCMC Algorithm works."><meta property="og:type" content="article"><meta property="og:url" content="https://mlwhiz.com/blog/2015/08/19/mcmc_algorithms_b_distribution/"><meta property="og:image" content="https://mlwhiz.com/images/category_bgs/default_bg.jpg"><meta property="og:image:secure_url" content="https://mlwhiz.com/images/category_bgs/default_bg.jpg"><meta property="article:published_time" content="2015-08-19T00:00:00+00:00"><meta property="article:modified_time" content="2020-09-26T16:23:35+05:30"><meta property="article:tag" content="Data Science"><meta property="article:tag" content="Awesome Guides"><meta name=twitter:card content="summary"><meta name=twitter:image content="https://mlwhiz.com/images/category_bgs/default_bg.jpg"><meta name=twitter:title content="My Tryst With MCMC Algorithms"><meta name=twitter:description content="An intuitive description of The way MCMC Algorithm works."><meta name=twitter:site content="@mlwhiz"><meta name=twitter:creator content="@mlwhiz"><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href=https://mlwhiz.com/scss/style.min.css media=screen><link rel=stylesheet href=/css/style.css><link rel=stylesheet type=text/css href=/css/font/flaticon.css><link rel="shortcut icon" href=https://mlwhiz.com/images/favicon-200x200.png type=image/x-icon><link rel=icon href=https://mlwhiz.com/images/favicon.png type=image/x-icon><link rel=canonical href=https://mlwhiz.com/blog/2015/08/19/mcmc_algorithms_b_distribution/><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js></script><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://www.mlwhiz.com/#website","url":"https://www.mlwhiz.com/","name":"MLWhiz","description":"Want to Learn Computer Vision and NLP? - MLWhiz","potentialAction":{"@type":"SearchAction","target":"https://www.mlwhiz.com/search?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://mlwhiz.com/blog/2015/08/19/mcmc_algorithms_b_distribution/#primaryimage","url":"https://mlwhiz.com/images/category_bgs/default_bg.jpg","width":700,"height":450},{"@type":"WebPage","@id":"https://mlwhiz.com/blog/2015/08/19/mcmc_algorithms_b_distribution/#webpage","url":"https://mlwhiz.com/blog/2015/08/19/mcmc_algorithms_b_distribution/","inLanguage":"en-US","name":"My Tryst With MCMC Algorithms - MLWhiz","isPartOf":{"@id":"https://www.mlwhiz.com/#website"},"primaryImageOfPage":{"@id":"https://mlwhiz.com/blog/2015/08/19/mcmc_algorithms_b_distribution/#primaryimage"},"datePublished":"2015-08-19T00:00:00.00Z","dateModified":"2020-09-26T16:23:35.00Z","author":{"@id":"https://mlwhiz.com/about/#/schema/person/76376876bchxkzbchjsdjcca"},"description":"An intuitive description of The way MCMC Algorithm works."},{"@type":["Person"],"@id":"https://mlwhiz.com/about/#/schema/person/76376876bchxkzbchjsdjcca","name":"Rahul Agarwal","image":{"@type":"ImageObject","@id":"https://www.mlwhiz.com/#authorlogo","url":"https://mlwhiz.com/images/author.jpg","caption":"Rahul Agarwal"},"description":"Hi there, I\u2019m Rahul Agarwal. I\u2019m a data scientist consultant and big data engineer based in Bangalore. I see a lot of times  students and even professionals wasting their time and struggling to get started with Computer Vision, Deep Learning, and NLP. I Started this Site with a purpose to augment my own understanding about new things while helping others learn about them in the best possible way.","sameAs":["https://www.linkedin.com/in/rahulagwl/","https://medium.com/@rahul_agarwal","https://twitter.com/MLWhiz","https://www.facebook.com/mlwhizblog","https://github.com/MLWhiz","https://www.instagram.com/itsmlwhiz"]}]}</script><script async data-uid=a0ebaf958d src=https://mlwhiz.ck.page/a0ebaf958d/index.js></script><script type=text/javascript async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$']],processEscapes:true,processEnvironments:true,skipTags:['script','noscript','style','textarea','pre'],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}});MathJax.Hub.Queue(function(){var all=MathJax.Hub.getAllJax(),i;for(i=0;i<all.length;i+=1){all[i].SourceElement().parentNode.className+=' has-jax';}});MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:"AMS"}}});</script><link href=//apps.shareaholic.com/assets/pub/shareaholic.js as=script><script type=text/javascript data-cfasync=false async src=//apps.shareaholic.com/assets/pub/shareaholic.js data-shr-siteid=fd1ffa7fd7152e4e20568fbe49a489d0></script></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NMQD44T" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><div class=preloader></div><header class=navigation><div class=container><nav class="navbar navbar-expand-lg navbar-white bg-transparent border-bottom pl-0"><a class="navbar-brand mobile-view" href=https://mlwhiz.com/><img class=img-fluid src=https://mlwhiz.com/images/logo.png alt="MLWhiz: Helping You Learn Data Science!"></a>
<button class="navbar-toggler border-0" type=button data-toggle=collapse data-target=#navigation>
<i class="ti-menu h3"></i></button><div class="collapse navbar-collapse text-center" id=navigation><div class=desktop-view><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=https://www.linkedin.com/in/rahulagwl/><i class=ti-linkedin></i></a></li><li class=nav-item><a class=nav-link href=https://medium.com/@rahul_agarwal><i class=ti-book></i></a></li><li class=nav-item><a class=nav-link href=https://twitter.com/MLWhiz><i class=ti-twitter-alt></i></a></li><li class=nav-item><a class=nav-link href=https://www.facebook.com/mlwhizblog><i class=ti-facebook></i></a></li><li class=nav-item><a class=nav-link href=https://github.com/MLWhiz><i class=ti-github></i></a></li></ul></div><a class="navbar-brand mx-auto desktop-view" href=https://mlwhiz.com/><img class=img-fluid-custom src=https://mlwhiz.com/images/logo.png alt="MLWhiz: Helping You Learn Data Science!"></a><ul class=navbar-nav><li class=nav-item><a class=nav-link href=https://mlwhiz.com/about>About</a></li><li class=nav-item><a class=nav-link href=https://mlwhiz.com/blog>Blog</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>Topics</a><div class=dropdown-menu><a class=dropdown-item href=https://mlwhiz.com/categories/natural-language-processing>NLP</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/computer-vision>Computer Vision</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/deep-learning>Deep Learning</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/data-science>DS/ML</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/big-data>Big Data</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/awesome-guides>My Best Content</a>
<a class=dropdown-item href=https://mlwhiz.com/categories/learning-resources>Learning Resources</a></div></li></ul><div class="search pl-lg-4"><button id=searchOpen class=search-btn><i class=ti-search></i></button><div class=search-wrapper><form action=https://mlwhiz.com//search class=h-100><input class="search-box px-4" id=search-query name=s type=search placeholder="Type & Hit Enter..."></form><button id=searchClose class=search-close><i class="ti-close text-dark"></i></button></div></div></div></nav></div></header><section class=section-sm><div class=container><div class=row><div class="col-lg-8 mb-5 mb-lg-0"><a href=/categories/data-science class=categoryStyle>Data Science</a>
<a href=/categories/awesome-guides class=categoryStyle>Awesome Guides</a><h1>My Tryst With MCMC Algorithms</h1><div class="mb-3 post-meta"><span>By Rahul Agarwal</span><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
<span>19 August 2015</span></div><img src=https://mlwhiz.com/images/category_bgs/default_bg.jpg class="img-fluid w-100 mb-4" alt="My Tryst With MCMC Algorithms"><div class="content mb-5"><p>The things that I find hard to understand push me to my limits. One of the things that I have always found hard is <strong>Markov Chain Monte Carlo Methods</strong>.
When I first encountered them, I read a lot about them but mostly it ended like this.</p><div style=margin-top:9px;margin-bottom:10px><center><img src=/images/flabbergasted.png></center></div><p>The meaning is normally hidden in deep layers of Mathematical noise and not easy to decipher.
This blog post is intended to clear up the confusion around MCMC methods, Know what they are actually useful for and Get hands on with some applications.</p><h2 id=so-what-really-are-mcmc-methods><strong>So what really are MCMC Methods?</strong></h2><p>First of all we have to understand what are <em><strong>Monte Carlo</strong></em> Methods!!!</p><p><a href=https://en.wikipedia.org/wiki/Monte_Carlo_method target=_blank rel="nofollow noopener">Monte Carlo</a>
methods derive their name from Monte Carlo Casino in Monaco. There are many card games that need probability of winning against the dealer. Sometimes calculating this probability can be mathematically complex or highly intractable. But we can always run a computer simulation to simulate the whole game many times and see the probability as the number of wins divided by the number of games played.</p><p>So that is all you need to know about Monte carlo Methods. Yes it is just a simple simulation technique with a Fancy Name.</p><p>So as we have got the first part of MCMC, we also need to understand what are <em><strong><a href=https://en.wikipedia.org/wiki/Markov_chain target=_blank rel="nofollow noopener">Markov Chains</a>
</strong></em>.
Before Jumping onto Markov Chains let us learn a little bit about <strong>Markov Property</strong>.</p><p>Suppose you have a system of $M$ possible states, and you are hopping from one state to another.
<em>Markov Property</em> says that given a process which is at a state $X_n$ at a particular point of time, the probability of $X_{n+1} = k$, where $k$ is any of the $M$ states the process can hop to, will only be dependent on which state it is at the given moment of time.
And not on how it reached the current state.</p><p>Mathematically speaking:</p><div>$$P(X_{n+1}=k | X_n=k_n,X_{n-1}=k_{n-1},....,X_1=k_1) = P(X_{n+1}=k|X_n=k_n)$$</div><p>If a process exhibits the Markov Property than it is known as a Markov Process.</p><p>Now Why is a Markov Chain important?
It is important because of its <strong>stationary distribution</strong>.</p><p>So what is a <strong>Stationary Distribution</strong>?</p><p>Assume you have a markov process like below. You start from any state $X_i$ and want to find out the state Probability distribution at $X_{i+1}$.</p><div style=margin-top:10px;margin-bottom:-10px><center><img src=/images/Finance_Markov_chain_example_state_space.svg></center></div><p>You have a matrix of transition probability</p><div style=margin-top:9px;margin-bottom:10px><center><img src=/images/transition_matrix.png></center></div><p>which defines the probability of going from a state $X_i$ to $X_j$.
You start calculating the Probability distribution for the next state. If you are at Bull Market State at time $i$ , you have a state Probability distribution as [0,1,0]</p><p>you want to get the state pdf at $X_{i+1}$. That is given by</p><div><center>$$s_{i+1} = s_{i}Q$$</center></div><div><center>$$ s_{i+1}=\left[ {\begin{array}{cc} .15 & .8 & .05      \end{array} } \right]$$</center></div>And the next state distribution could be found out by<div><center>$$s_{i+1} = s_iQ^2$$</center></div>div><p>and so on.
Eventually you will reach a stationary state s where:</p><center>$$sQ=s$$</center>
For this transition matrix Q the Stationary distribution $s$ is<div><center>$$ s_{i+1}=\left[ {\begin{array}{cc} .625 & .3125 & .0625      \end{array} } \right]$$</center></div><p>The stationary state distribution is important because it lets you define the probability for every state of a system at a random time. That is for this particular example we can say that 62.5% of the times market will be in a bull market state, 31.25% of weeks it will be a bear market and 6.25% of weeks it will be stagnant</p><p>Intuitively you can think of it as an random walk on a chain. You might visit some nodes more often than others based on node probabilities. In the <em>Google Pagerank</em> problem you might think of a node as a page, and the probability of a page in the stationary distribution as its relative importance.</p><p><em><strong>Woah!</strong></em> That was a lot of information and we have yet not started talking about the MCMC Methods. Well if you are with me till now, we can now get on to the real topic now.</p><h2 id=so-what-is-mcmc>So What is MCMC?</h2><p>According to
<a href=https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo target=_blank rel=nofollow>Wikipedia</a>:</p><blockquote>**Markov Chain Monte Carlo** (MCMC) methods are a class of algorithms for **sampling from a probability distribution** based on constructing a Markov chain that has the desired distribution as its stationary distribution. The state of the chain after a number of steps is then used as a sample of the desired distribution. The quality of the sample improves as a function of the number of steps.</blockquote><p>So let&rsquo;s explain this with an example: Assume that <strong>we want to sample from a <a href=https://en.wikipedia.org/wiki/Beta_distribution target=_blank rel=nofollow>Beta distribution</a></strong>. The <em>PDF</em> is:</p><center>$$f(x) = Cx^{\alpha -1}(1-x)^{\beta -1}$$</center>
where $C$ is the normalizing constant *(which we actually don't need to Sample from the distribution as we will see later)*.<p>This is a <strong>fairly difficult problem</strong> with the Beta Distribution if not intractable. In reality you might need to work with a lot harder Distribution Functions and sometimes you won&rsquo;t actually know the normalizing constants.</p><p>MCMC methods make life easier for us by providing us with algorithms that could create a Markov Chain which has the Beta distribution as its <strong>stationary distribution</strong> given that we can sample from a uniform distribution(which is <em>fairly</em> easy).</p><p>If we start from a random state and traverse to the next state based on some algorithm repeatedly, we will end up creating a Markov Chain which has the Beta distribution as its <strong>stationary distribution</strong> and the states we are at after a long time could be used as sample from the Beta Distribution.</p><p>One such MCMC Algorithm is the
<strong><a href=https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm target=_blank rel=nofollow>Metropolis Hastings Algorithm</a></strong></p><h2 id=metropolis-hastings-algorithm>Metropolis Hastings Algorithm</h2><p>Let $s=(s_1,s_2,&mldr;.,s_M)$ be the desired stationary distribution. We want to create a Markov Chain that has this stationary distribution. We start with an arbitrary Markov Chain $P$ with $M$ states with transition matrix $Q$, so that $Q_{ij}$ represents the probability of going from state $i$ to $j$. Intuitively we know how to wander around this Markov Chain but this Markov Chain does not have the required Stationary Distribution. This chain does have some stationary distribution(which is not of our use)</p><p>Our Goal is to change the way we wander on the this Markov Chain $P$ so that this chain has the desired Stationary distribution.</p><p>To do this we:</p><ol><li>Start at a random initial State $i$.</li><li>Randomly pick a new <em>Proposal State</em> by looking at the transition probabilities in the ith row of the transition matrix Q.</li><li>Compute an measure called the <em>Acceptance Probability</em> which is defined as: $a_{ij} = min(s_jp_{ji}/s_{i}p_{ij},1)$</li><li>Now Flip a coin that lands head with probability $a_{ij}$. If the coin comes up heads, accept the proposal i.e move to next state else reject the proposal i.e. stay at the current state.</li><li>Repeat for a long time</li></ol><p>After a long time this chain will converge and will have a stationary distribution $s$. <strong>We can then use the states of the chain as the sample from any distribution.</strong></p><p>While doing this to sample the Beta Distribution, the only time we are using the PDF is to find the acceptance probability and in that we divide $s_j$ by $s_i$, i.e. the <strong>normalizing constant $C$ gets cancelled</strong>.</p><p>Now Let&rsquo;s Talk about the intuition. For the Intuition I am quoting an <a href=http://stats.stackexchange.com/a/12657 target=_blank rel=nofollow>Answer</a> from the site Stack Exchange,as this was the best intuitive explanation that I could find:</p><blockquote>I think there's a nice and simple intuition to be gained from the (independence-chain) Metropolis-Hastings algorithm.<br><br>First, what's the goal? The goal of MCMC is to **draw samples from some probability distribution** without having to know its exact height at any point(We don't need to know C). The way MCMC achieves this is to **"wander around" on that distribution in such a way that the amount of time spent in each location is proportional to the height of the distribution**. If the "wandering around" process is set up correctly, you can make sure that this proportionality (between time spent and height of the distribution) is achieved.<br><br>Intuitively, what we want to do is to to walk around on some (lumpy) surface in such a way that the amount of time we spend (or # samples drawn) in each location is proportional to the height of the surface at that location. So, e.g., we'd like to spend twice as much time on a hilltop that's at an altitude of 100m as we do on a nearby hill that's at an altitude of 50m. The nice thing is that we can do this even if we don't know the absolute heights of points on the surface: all we have to know are the relative heights. e.g., if one hilltop A is twice as high as hilltop B, then we'd like to spend twice as much time at A as we spend at B.<br><br>The simplest variant of the Metropolis-Hastings algorithm (independence chain sampling) achieves this as follows: assume that in every (discrete) time-step, we pick a random new "proposed" location (selected uniformly across the entire surface). If the proposed location is higher than where we're standing now, move to it. If the proposed location is lower, then move to the new location with probability p, where p is the ratio of the height of that point to the height of the current location. (i.e., flip a coin with a probability p of getting heads; if it comes up heads, move to the new location; if it comes up tails, stay where we are). Keep a list of the locations you've been at on every time step, and that list will (asyptotically) have the right proportion of time spent in each part of the surface. (And for the A and B hills described above, you'll end up with twice the probability of moving from B to A as you have of moving from A to B).<br><br>There are more complicated schemes for proposing new locations and the rules for accepting them, but the basic idea is still: **(1) pick a new "proposed" location; (2) figure out how much higher or lower that location is compared to your current location; (3) probabilistically stay put or move to that location in a way that respects the overall goal of spending time proportional to height of the location.**</blockquote><h2 id=sampling-from-beta-distribution>Sampling from Beta Distribution</h2><p>Now Let&rsquo;s Move on to the problem of Simulating from Beta Distribution. Now Beta Distribution is a continuous Distribution on [0,1] and it can have infinite states on [0,1].</p><p>Lets Assume an arbitrary Markov Chain P with infinite states on [0,1] having transition Matrix Q such that $Q_{ij} = Q_{ji} = $ All entries in Matrix. We don&rsquo;t really need the Matrix Q as we will see later, But I want to keep the problem description as close to the algorihm we suggested.</p><ul><li>Start at a random <strong>initial State $i$</strong> given by Unif(0,1).</li><li>Randomly pick a new <strong>Proposal State</strong> by looking at the transition probabilities in the ith row of the transition matrix Q. Lets say we pick up another Unif(0,1) state as a proposal state $j$.</li><li>Compute an measure called the <strong>Acceptance Probability</strong> :</li></ul><div><center>$$a_{ij} = min(s_jp_{ji}/s_{i}p_{ij},1)$$</center></div>which is,<div><center>$$a_{ij} = min(s_j/s_i,1)$$</center></div>where,<div><center>$$s_i = Ci^{\alpha -1}(1-i)^{\beta -1}$$</center></div>and,<div><center>$$s_j = Cj^{\alpha -1}(1-j)^{\beta -1}$$</center></div><ul><li>Now Flip a coin that lands head with probability $a_{ij}$. If the coin comes up heads, accept the proposal i.e move to next state else reject the proposal i.e. stay at the current state.</li><li>Repeat for a long time</li></ul><p>So enough with theory, Let&rsquo;s Move on to python to create our Beta Simulations Now&mldr;.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#f92672>import</span> random
<span style=color:#75715e># Lets define our Beta Function to generate s for any particular state. We don&#39;t care for the normalizing constant here.</span>
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>beta_s</span>(w,a,b):
    <span style=color:#66d9ef>return</span> w<span style=color:#f92672>**</span>(a<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)<span style=color:#f92672>*</span>(<span style=color:#ae81ff>1</span><span style=color:#f92672>-</span>w)<span style=color:#f92672>**</span>(b<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)

<span style=color:#75715e># This Function returns True if the coin with probability P of heads comes heads when flipped.</span>
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>random_coin</span>(p):
    unif <span style=color:#f92672>=</span> random<span style=color:#f92672>.</span>uniform(<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>1</span>)
    <span style=color:#66d9ef>if</span> unif<span style=color:#f92672>&gt;=</span>p:
        <span style=color:#66d9ef>return</span> False
    <span style=color:#66d9ef>else</span>:
        <span style=color:#66d9ef>return</span> True

<span style=color:#75715e># This Function runs the MCMC chain for Beta Distribution.</span>
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>beta_mcmc</span>(N_hops,a,b):
    states <span style=color:#f92672>=</span> []
    cur <span style=color:#f92672>=</span> random<span style=color:#f92672>.</span>uniform(<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>1</span>)
    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>0</span>,N_hops):
        states<span style=color:#f92672>.</span>append(cur)
        next <span style=color:#f92672>=</span> random<span style=color:#f92672>.</span>uniform(<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>1</span>)
        ap <span style=color:#f92672>=</span> min(beta_s(next,a,b)<span style=color:#f92672>/</span>beta_s(cur,a,b),<span style=color:#ae81ff>1</span>) <span style=color:#75715e># Calculate the acceptance probability</span>
        <span style=color:#66d9ef>if</span> random_coin(ap):
            cur <span style=color:#f92672>=</span> next
    <span style=color:#66d9ef>return</span> states[<span style=color:#f92672>-</span><span style=color:#ae81ff>1000</span>:] <span style=color:#75715e># Returns the last 100 states of the chain</span>
</code></pre></div><p>Let us check our results of the MCMC Sampled Beta distribution against the actual beta distribution.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=color:#f92672>import</span> numpy <span style=color:#f92672>as</span> np
<span style=color:#f92672>import</span> pylab <span style=color:#f92672>as</span> pl
<span style=color:#f92672>import</span> scipy.special <span style=color:#f92672>as</span> ss
<span style=color:#f92672>%</span>matplotlib inline
pl<span style=color:#f92672>.</span>rcParams[<span style=color:#e6db74>&#39;figure.figsize&#39;</span>] <span style=color:#f92672>=</span> (<span style=color:#ae81ff>17.0</span>, <span style=color:#ae81ff>4.0</span>)

<span style=color:#75715e># Actual Beta PDF.</span>
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>beta</span>(a, b, i):
    e1 <span style=color:#f92672>=</span> ss<span style=color:#f92672>.</span>gamma(a <span style=color:#f92672>+</span> b)
    e2 <span style=color:#f92672>=</span> ss<span style=color:#f92672>.</span>gamma(a)
    e3 <span style=color:#f92672>=</span> ss<span style=color:#f92672>.</span>gamma(b)
    e4 <span style=color:#f92672>=</span> i <span style=color:#f92672>**</span> (a <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>)
    e5 <span style=color:#f92672>=</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> i) <span style=color:#f92672>**</span> (b <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>)
    <span style=color:#66d9ef>return</span> (e1<span style=color:#f92672>/</span>(e2<span style=color:#f92672>*</span>e3)) <span style=color:#f92672>*</span> e4 <span style=color:#f92672>*</span> e5

<span style=color:#75715e># Create a function to plot Actual Beta PDF with the Beta Sampled from MCMC Chain.</span>
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>plot_beta</span>(a, b):
    Ly <span style=color:#f92672>=</span> []
    Lx <span style=color:#f92672>=</span> []
    i_list <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>mgrid[<span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>100j</span>]
    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> i_list:
        Lx<span style=color:#f92672>.</span>append(i)
        Ly<span style=color:#f92672>.</span>append(beta(a, b, i))
    pl<span style=color:#f92672>.</span>plot(Lx, Ly, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Real Distribution: a=&#34;</span><span style=color:#f92672>+</span>str(a)<span style=color:#f92672>+</span><span style=color:#e6db74>&#34;, b=&#34;</span><span style=color:#f92672>+</span>str(b))
    pl<span style=color:#f92672>.</span>hist(beta_mcmc(<span style=color:#ae81ff>100000</span>,a,b),normed<span style=color:#f92672>=</span>True,bins <span style=color:#f92672>=</span><span style=color:#ae81ff>25</span>, histtype<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;step&#39;</span>,label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Simulated_MCMC: a=&#34;</span><span style=color:#f92672>+</span>str(a)<span style=color:#f92672>+</span><span style=color:#e6db74>&#34;, b=&#34;</span><span style=color:#f92672>+</span>str(b))
    pl<span style=color:#f92672>.</span>legend()
    pl<span style=color:#f92672>.</span>show()

plot_beta(<span style=color:#ae81ff>0.1</span>, <span style=color:#ae81ff>0.1</span>)
plot_beta(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>)
plot_beta(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>3</span>)
</code></pre></div><div style=margin-top:-9px;margin-bottom:30px><img src=/images/graphs.png></div><p>As we can see our sampled beta values closely resemble the beta distribution.</p><p>So MCMC Methods are useful for the following basic problems.</p><ol><li>Simulating from a Random Variable PDF. Example: Simulate from a Beta(0.5,0.5) or from a Normal(0,1).</li><li>Solve problems with a large state space.For Example: Knapsack Problem, Encrytion Cipher etc. We will work on this in the
<a href=/blog/2015/08/21/mcmc_algorithms_cryptography/>Next Blog Post</a>
as this one has already gotten bigger than what I expected.</li></ol><p>Till Then Ciao!!!!!!</p><h2 id=references-and-sources>References and Sources:</h2><ol><li><a href=http://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science-ebook/dp/B00MMOJ19I target=_blank rel=nofollow>Introduction to Probability Joseph K Blitzstein, Jessica Hwang</a></li><li><a href=https://en.wikipedia.org/wiki/ target=_blank rel=nofollow>Wikipedia</a></li><li><a href=http://stats.stackexchange.com/a/12657 target=_blank rel=nofollow>StackExchange</a></li></ol><p>One of the newest and best resources that you can keep an eye on is the <a href="https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&utm_content=2&utm_medium=partners&utm_source=linkshare&utm_campaign=lVarvwc5BD0" target=_blank rel=nofollow>Bayesian Methods for Machine Learning</a> course in the <a href="https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&utm_content=2&utm_medium=partners&utm_source=linkshare&utm_campaign=lVarvwc5BD0" target=_blank rel=nofollow>Advanced machine learning specialization</a> created jointly by Kazanova(Number 3 Kaggler at the time of writing)</p><p>Apart from that I also found a course on <strong><a href="https://click.linksynergy.com/link?id=lVarvwc5BD0&offerid=495576.8910375858&type=2&murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Fbayesian" target=_blank rel=nofollow>Bayesian Statistics on Coursera</a></strong>. In the process of doing it right now so couldn&rsquo;t really comment on it. But since I had done an course on <strong><a href="https://click.linksynergy.com/link?id=lVarvwc5BD0&offerid=495576.8839843074&type=2&murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Finferential-statistics-intro" target=_blank rel=nofollow>Inferential Statistics</a></strong> taught by the same professor before(Mine Çetinkaya-Rundel), I am very hopeful for this course. Let&rsquo;s see.</p><p>Also look out for these two books to learn more about MCMC. I have not yet read them whole but still I liked whatever I read:</p><div style=margin-left:1em;text-align:center><p><a target=_blank rel=nofollow href="https://www.amazon.com/gp/product/1439840954/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1439840954&linkCode=as2&tag=mlwhizcon-20&linkId=d55979088adc0aabeaed88f4f14b48b6"><img border=0 src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&MarketPlace=US&ASIN=1439840954&ServiceVersion=20070822&ID=AsinImage&WS=1&Format=_SL250_&tag=mlwhizcon-20"></a><img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&l=am2&o=1&a=1439840954" width=1 height=1 border=0 alt style=border:none!important;margin:0!important></t></t>
<a target=_blank rel=nofollow href="https://www.amazon.com/gp/product/1584885874/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1584885874&linkCode=as2&tag=mlwhizcon-20&linkId=ee3e2a0bc99359d6c5db0463ab1abb13"><img border=0 src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&MarketPlace=US&ASIN=1584885874&ServiceVersion=20070822&ID=AsinImage&WS=1&Format=_SL250_&tag=mlwhizcon-20"></a><img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&l=am2&o=1&a=1584885874" width=1 height=1 border=0 alt style=border:none!important;margin:0!important></p></div><p>Both these books are pretty high level and hard on math. But these are the best texts out there too. :)</p><script async data-uid=8d7942551b src=https://mlwhiz.ck.page/8d7942551b/index.js></script><div class=shareaholic-canvas data-app=share_buttons data-app-id=28372088 style=margin-bottom:1px></div><a href="https://click.linksynergy.com/fs-bin/click?id=lVarvwc5BD0&offerid=759505.377&subid=0&type=4" rel=nofollow><img border=0 alt="Start your future with a Data Analysis Certificate." src="https://ad.linksynergy.com/fs-bin/show?id=lVarvwc5BD0&bids=759505.377&subid=0&type=4&gridnum=16"></a><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return;}
var d=document,s=d.createElement('script');s.async=true;s.src='//'+"mlwhiz"+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div><div class=col-lg-4><div class=widget><script type=text/javascript src=https://ko-fi.com/widgets/widget_2.js></script><script type=text/javascript>kofiwidget2.init('Support Me on Ko-fi','#00aaa1','S6S3NPCD');kofiwidget2.draw();</script></div><div class=widget><h4 class=widget-title>About Me</h4><img src=https://mlwhiz.com/images/author.jpg alt class="img-fluid author-thumb-sm d-block mx-auto rounded-circle mb-4"><p>I’m a data scientist consultant and big data engineer based in Bangalore, where I am currently working with WalmartLabs .</p><a href=https://mlwhiz.com/about/ class="btn btn-outline-primary">Know More</a></div><div class=widget><h4 class=widget-title>Topics</h4><ul class=list-unstyled><li><a class=categoryStyle style=color:#fff href=/categories/awesome-guides>Awesome Guides</a></li><li><a class=categoryStyle style=color:#fff href=/categories/big-data>Big Data</a></li><li><a class=categoryStyle style=color:#fff href=/categories/computer-vision>Computer Vision</a></li><li><a class=categoryStyle style=color:#fff href=/categories/data-science>Data Science</a></li><li><a class=categoryStyle style=color:#fff href=/categories/deep-learning>Deep Learning</a></li><li><a class=categoryStyle style=color:#fff href=/categories/learning-resources>Learning Resources</a></li><li><a class=categoryStyle style=color:#fff href=/categories/natural-language-processing>Natural Language Processing</a></li><li><a class=categoryStyle style=color:#fff href=/categories/programming>Programming</a></li></ul></div><div class=widget><h4 class=widget-title>Tags</h4><ul class=list-inline><li class=list-inline-item><a class="tagStyle text-white" href=/tags/algorithms>Algorithms</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/artificial-intelligence>Artificial Intelligence</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/dask>Dask</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/deployment>Deployment</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/ec2>Ec2</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/generative-adversarial-networks>Generative Adversarial Networks</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/graphs>Graphs</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/image-classification>Image Classification</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/instance-segmentation>Instance Segmentation</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/interpretability>Interpretability</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/jobs>Jobs</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/kaggle>Kaggle</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/language-modeling>Language Modeling</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/machine-learning>Machine Learning</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/math>Math</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/multiprocessing>Multiprocessing</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/object-detection>Object Detection</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/opinion>Opinion</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/pandas>Pandas</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/production>Production</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/productivity>Productivity</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/python>Python</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/pytorch>Pytorch</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/spark>Spark</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/sql>Sql</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/statistics>Statistics</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/streamlit>Streamlit</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/text-classification>Text Classification</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/timeseries>Timeseries</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/tools>Tools</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/translation>Translation</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/visualization>Visualization</a></li><li class=list-inline-item><a class="tagStyle text-white" href=/tags/xgboost>Xgboost</a></li></ul></div><div class=widget><h4 class=widget-title>Connect With Me</h4><ul class="list-inline social-links"><li class=list-inline-item><a href=https://www.linkedin.com/in/rahulagwl/><i class=ti-linkedin></i></a></li><li class=list-inline-item><a href=https://medium.com/@rahul_agarwal><i class=ti-book></i></a></li><li class=list-inline-item><a href=https://twitter.com/MLWhiz><i class=ti-twitter-alt></i></a></li><li class=list-inline-item><a href=https://www.facebook.com/mlwhizblog><i class=ti-facebook></i></a></li><li class=list-inline-item><a href=https://github.com/MLWhiz><i class=ti-github></i></a></li></ul></div><script async data-uid=bfe9f82f10 src=https://mlwhiz.ck.page/bfe9f82f10/index.js></script><script async data-uid=3452d924e2 src=https://mlwhiz.ck.page/3452d924e2/index.js></script></div></div></div></section><footer><div class=container><div class=row><div class="col-12 text-center mb-5"><a href=https://mlwhiz.com/><img src=https://mlwhiz.com/images/logo.png class=img-fluid-custom-bottom alt="MLWhiz: Helping You Learn Data Science!"></a></div><div class="col-lg-3 col-sm-6 mb-5"><h6 class=mb-4>Contact Me</h6><ul class=list-unstyled><li class=mb-3><i class="ti-location-pin mr-3 text-primary"></i>India, Bangalore</li><li class=mb-3><a class=text-dark href=mailto:rahul@mlwhiz.com><i class="ti-email mr-3 text-primary"></i>rahul@mlwhiz.com</a></li></ul></div><div class="col-lg-3 col-sm-6 mb-5"><h6 class=mb-4>Social Contacts</h6><ul class=list-unstyled><li class=mb-3><a class=text-dark href=https://www.linkedin.com/in/rahulagwl/>Linkedin</a></li><li class=mb-3><a class=text-dark href=https://medium.com/@rahul_agarwal>Medium</a></li><li class=mb-3><a class=text-dark href=https://twitter.com/MLWhiz>Twitter</a></li><li class=mb-3><a class=text-dark href=https://www.facebook.com/mlwhizblog>Facebook</a></li><li class=mb-3><a class=text-dark href=https://github.com/MLWhiz>Github</a></li></ul></div><div class="col-lg-3 col-sm-6 mb-5"><h6 class=mb-4>Categories</h6><ul class=list-unstyled><li class=mb-3><a class=text-dark href=/categories/awesome-guides>Awesome Guides</a></li><li class=mb-3><a class=text-dark href=/categories/big-data>Big Data</a></li><li class=mb-3><a class=text-dark href=/categories/computer-vision>Computer Vision</a></li><li class=mb-3><a class=text-dark href=/categories/data-science>Data Science</a></li><li class=mb-3><a class=text-dark href=/categories/deep-learning>Deep Learning</a></li><li class=mb-3><a class=text-dark href=/categories/learning-resources>Learning Resources</a></li><li class=mb-3><a class=text-dark href=/categories/natural-language-processing>Natural Language Processing</a></li><li class=mb-3><a class=text-dark href=/categories/programming>Programming</a></li></ul></div><div class="col-lg-3 col-sm-6 mb-5"><h6 class=mb-4>Quick Links</h6><ul class=list-unstyled><li class=mb-3><a class=text-dark href=https://mlwhiz.com/about>About</a></li><li class=mb-3><a class=text-dark href=https://mlwhiz.com/blog>Post</a></li></ul></div><div class="col-12 border-top py-4 text-center">Copyright © 2020 <a href=https://mlwhiz.com>MLWhiz</a> All Rights Reserved</div></div></div></footer><script>var indexURL="https://mlwhiz.com/index.json"</script><script src=https://mlwhiz.com/plugins/compressjscss/main.js></script><script src=https://mlwhiz.com/js/script.min.js></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-54777926-1','auto');ga('send','pageview');</script></body></html>