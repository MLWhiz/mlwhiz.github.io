<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-NMQD44T');</script>
  <!-- End Google Tag Manager -->

  <meta charset="utf-8">
  <title>My Tryst With MCMC Algorithms</title>
  <meta name="author" content="Rahul Agarwal">
  <meta name="description" content="The things that I find hard to understand push me to my limits. One of the things that I have always found hard is Markov Chain Monte Carlo Methods. When I first encountered them, I read a lot about them but mostly it ended like this. The meaning is normally ..." >
  <meta name="keywords" content="Statistics, Machine Learning, MCMC, Bayesian Learning, Data Science, Monte carlo Markov Chain,metropolis algorithm explained,mcmc explained, metropolis hastings explained" >

<!-- OpenGraph protocol tags: http://ogp.me/ -->
<!-- originally adopted to be used for: https://blog.kmonsoor.com -->
<meta property="og:site_name" content="mlwhiz" />
<meta property="og:type" content="article" />
    
<meta property="og:title" content="My Tryst With MCMC Algorithms" />
<meta property="og:url" content="https://mlwhiz.com/blog/2015/08/19/MCMC_Algorithms_Beta_Distribution/" />
<meta property="og:description" content="The things that I find hard to understand push me to my limits. One of the things that I have always found hard is Markov Chain Monte Carlo Methods. When I first encountered them, I read a lot about them but mostly it ended like this. The meaning is normally ..." />

<meta name="twitter:image" content="https://mlwhiz.com" />

<meta property="article:published_time" content="2015-08-19 13:43:00" />
<!-- End of OpenGraph protocol tags -->


<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:title" content="My Tryst With MCMC Algorithms" />
<meta property="twitter:description" content="The things that I find hard to understand push me to my limits. One of the things that I have always found hard is Markov Chain Monte Carlo Methods. When I first encountered them, I read a lot about them but mostly it ended like this. The meaning is normally ..." />
<meta property="twitter:url" content="https://mlwhiz.com/blog/2015/08/19/MCMC_Algorithms_Beta_Distribution/" />
<meta name="twitter:image" content="https://mlwhiz.com" />


  <link href="http://mlwhiz.com/atom.xml" type="application/atom+xml" rel="alternate"
        title="mlwhiz Atom Feed" />
  <link href="http://mlwhiz.com/feed.rss" type="application/rss+xml" rel="alternate"
        title="mlwhiz RSS Feed" />


<link rel="canonical" href="https://mlwhiz.com/blog/2015/08/19/MCMC_Algorithms_Beta_Distribution/"/>

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <link href="https://mlwhiz.com/favicon.png" rel="icon">
  <link href="https://mlwhiz.com/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">
      <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro" rel="stylesheet" type="text/css">
 <link href="https://mlwhiz.com/theme/css/custom.css"
        rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="https://mlwhiz.com/theme/highlight/styles/atelier-dune.dark.css">

  <script src="https://mlwhiz.com/theme/js/modernizr-2.0.js"></script>
  <script src="https://mlwhiz.com/theme/js/ender.js"></script>
  <script src="https://mlwhiz.com/theme/js/octopress.js" type="text/javascript"></script>

  <script src="https://mlwhiz.com/theme/highlight/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">

  <!--added buttons to share....-->

<!-- BEGIN SHAREAHOLIC CODE -->
<link rel='preload' href='//apps.shareaholic.com/assets/pub/shareaholic.js' as='script' />
<script type="text/javascript" data-cfasync="false" async src="//apps.shareaholic.com/assets/pub/shareaholic.js" data-shr-siteid="fd1ffa7fd7152e4e20568fbe49a489d0"></script>

<!-- END SHAREAHOLIC CODE -->
<!--
  <script src="//load.sumome.com/" data-sumo-site-id="22863fd8ad7ebbfab9b8ca60b7db8f65e9a15559f384f785f66903e365aa8f48" async="async"></script>
 --> 
<!--
  <script type='text/javascript' src='//platform-api.sharethis.com/js/sharethis.js#property=5a1bdf9806d3310011e61348&product=sticky-share-buttons' async='async'></script>
-->


<!-- SUMO CODE FOR EMAILS-->
  <script async>(function(s,u,m,o,j,v){j=u.createElement(m);v=u.getElementsByTagName(m)[0];j.async=1;j.src=o;j.dataset.sumoSiteId='22863fd8ad7ebbfab9b8ca60b7db8f65e9a15559f384f785f66903e365aa8f48';v.parentNode.insertBefore(j,v)})(window,document,'script','//load.sumo.com/');</script>


</head>

<body>
  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NMQD44T"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->
  <header role="banner"><hgroup>
  <h1><a href="https://mlwhiz.com/">mlwhiz</a></h1>
    <h2>Deep Learning, Data Science and NLP Enthusiast</h2>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="http://mlwhiz.com/atom.xml" rel="subscribe-atom">Atom</a></li>

</ul>


<form onsubmit="this['q'].value = this['q_raw'].value + ' site:mlwhiz.com';" method="get" action="https://google.com/search">
  <fieldset role="search">
	<input type="hidden" value="" name="q">
	<input class="search" type="text" placeholder="Search" results="0" name="q_raw">
  </fieldset>

</form>

<ul class="main-navigation">
    <li><a href="http://mlwhiz.com">Blog</a></li>
    <li><a href="http://mlwhiz.com/archives.html">Archives</a></li>
    <li><a href="http://mlwhiz.com/pages/about.html">About</a></li>
    <li><a href="http://mlwhiz.com/pages/links.html">Great Links</a></li>
  
</ul></nav>
  <div id="main">
    <div id="content">

<div>
  <article class="hentry" role="article">

<header>
      <h1 class="entry-title">My Tryst With MCMC Algorithms</h1>
      <p class="meta"><time datetime="2015-08-19T13:43:00" pubdate>Aug 19, 2015</time></p>
</header>

  <div class="entry-content"><p>The things that I find hard to understand push me to my limits. One of the things that I have always found hard is <strong>Markov Chain Monte Carlo Methods</strong>. 
When I first encountered them, I read a lot about them but mostly it ended like this.</p>
<div style="margin-top: 9px; margin-bottom: 10px;">
<center><img src="/images/flabbergasted.png"></center>
</div>

<p>The meaning is normally hidden in deep layers of Mathematical noise and not easy to decipher.
This blog post is intended to clear up the confusion around MCMC methods, Know what they are actually useful for and Get hands on with some applications.</p>
<h2><strong>So what really are MCMC Methods?</strong></h2>
<p>First of all we have to understand what are <strong><em>Monte Carlo</em></strong> Methods!!!</p>
<p><a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo</a> methods derive their name from Monte Carlo Casino in Monaco. There are many card games that need probability of winning against the dealer. Sometimes calculating this probability can be mathematically complex or highly intractable. But we can always run a computer simulation to simulate the whole game many times and see the probability as the number of wins divided by the number of games played.</p>
<p>So that is all you need to know about Monte carlo Methods. Yes it is just a simple simulation technique with a Fancy Name.</p>
<p>So as we have got the first part of MCMC, we also need to understand what are <strong><em><a href="https://en.wikipedia.org/wiki/Markov_chain">Markov Chains</a></em></strong>.
Before Jumping onto Markov Chains let us learn a little bit about <strong>Markov Property</strong>.</p>
<p>Suppose you have a system of <span class="math">\(M\)</span> possible states, and you are hopping from one state to another.
<em>Markov Property</em> says that given a process which is at a state <span class="math">\(X_n\)</span> at a particular point of time, the probability of <span class="math">\(X_{n+1} = k\)</span>, where <span class="math">\(k\)</span> is any of the <span class="math">\(M\)</span> states the process can hop to, will only be dependent on which state it is at the given moment of time.
And not on how it reached the current state.</p>
<p>Mathematically speaking:</p>
<p><center><div class="math">$$ P(X_{n+1}=k | X_n=k_n,X_{n-1}=k_{n-1},....,X_1=k_1) = P(X_{n+1}=k|X_n=k_n)$$</div></center></p>
<p>If a process exhibits the Markov Property than it is known as a Markov Process.</p>
<p>Now Why is a Markov Chain important? 
It is important because of its <strong>stationary distribution</strong>.</p>
<p>So what is a <strong>Stationary Distribution</strong>?</p>
<p>Assume you have a markov process like below. You start from any state <span class="math">\(X_i\)</span> and want to find out the state Probability distribution at <span class="math">\(X_{i+1}\)</span>.</p>
<div style="margin-top: 10px; margin-bottom: -10px;">
<center><img src="/images/Finance_Markov_chain_example_state_space.svg"></center>
</div>

<p>You have a matrix of transition probability
<div style="margin-top: 9px; margin-bottom: 10px;">
<center><img src="/images/transition_matrix.png"></center>
</div></p>
<p>which defines the probability of going from a state <span class="math">\(X_i\)</span> to <span class="math">\(X_j\)</span>.
You start calculating the Probability distribution for the next state. If you are at Bull Market State at time <span class="math">\(i\)</span> , you have a state Probability distribution as [0,1,0]</p>
<p>you want to get the state pdf at <span class="math">\(X_{i+1}\)</span>. That is given by</p>
<div><center>$$s_{i+1} = s_{i}Q$$</center></div>

<div><center>$$ s_{i+1}=\left[ {\begin{array}{cc}   .15 & .8 & .05      \end{array} } \right]$$</center></div>

<p>And the next state distribution could be found out by</p>
<p><center><div class="math">$$s_{i+1} = s_iQ^2$$</div></center></p>
<p>and so on. 
Eventually you will reach a stationary state s where:
<center><div class="math">$$sQ=s$$</div></center>
For this transition matrix Q the Stationary distribution <span class="math">\(s\)</span> is
<center><div class="math">$$ s_{i+1}=\left[ {\begin{array}{cc}   .625 &amp; .3125 &amp; .0625      \end{array} } \right]$$</div></center></p>
<p>The stationary state distribution is important because it lets you define the probability for every state of a system at a random time. That is for this particular example we can say that 62.5% of the times market will be in a bull market state, 31.25% of weeks it will be a bear market and 6.25% of weeks it will be stagnant</p>
<p>Intuitively you can think of it as an random walk on a chain. You might visit some nodes more often than others based on node probabilities. In the <em>Google Pagerank</em> problem you might think of a node as a page, and the probability of a page in the stationary distribution as its relative importance.</p>
<p><strong><em>Woah!</em></strong> That was a lot of information and we have yet not started talking about the MCMC Methods. Well if you are with me till now, we can now get on to the real topic now.</p>
<h2>So What is MCMC?</h2>
<p>According to <a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">Wikipedia</a>: 
<blockquote>
<strong>Markov Chain Monte Carlo</strong> (MCMC) methods are a class of algorithms for <strong>sampling from a probability distribution</strong> based on constructing a Markov chain that has the desired distribution as its stationary distribution. The state of the chain after a number of steps is then used as a sample of the desired distribution. The quality of the sample improves as a function of the number of steps.
</blockquote></p>
<p>So let's explain this with an example: Assume that <strong>we want to sample from a <a href="https://en.wikipedia.org/wiki/Beta_distribution">Beta distribution</a></strong>. The <em>PDF</em> is:</p>
<p><center><div class="math">$$f(x) = Cx^{\alpha -1}(1-x)^{\beta -1}$$</div></center>
where <span class="math">\(C\)</span> is the normalizing constant <em>(which we actually don't need to Sample from the distribution as we will see later)</em>.</p>
<p>This is a <strong>fairly difficult problem</strong> with the Beta Distribution if not intractable. In reality you might need to work with a lot harder Distribution Functions and sometimes you won't actually know the normalizing constants. </p>
<p>MCMC methods make life easier for us by providing us with algorithms that could create a Markov Chain which has the Beta distribution as its <strong>stationary distribution</strong> given that we can sample from a uniform distribution(which is <em>fairly</em> easy). </p>
<p>If we start from a random state and traverse to the next state based on some algorithm repeatedly, we will end up creating a Markov Chain which has the Beta distribution as its <strong>stationary distribution</strong> and the states we are at after a long time could be used as sample from the Beta Distribution.</p>
<p>One such MCMC Algorithm is the <strong><a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm">Metropolis Hastings Algorithm</a></strong>.</p>
<h2>Metropolis Hastings Algorithm</h2>
<p>Let <span class="math">\(s=(s_1,s_2,....,s_M)\)</span> be the desired stationary distribution. We want to create a Markov Chain that has this stationary distribution. We start with an arbitrary Markov Chain <span class="math">\(P\)</span> with <span class="math">\(M\)</span> states with transition matrix <span class="math">\(Q\)</span>, so that <span class="math">\(Q_{ij}\)</span> represents the probability of going from state <span class="math">\(i\)</span> to <span class="math">\(j\)</span>. Intuitively we know how to wander around this Markov Chain but this Markov Chain does not have the required Stationary Distribution. This chain does have some stationary distribution(which is not of our use)</p>
<p>Our Goal is to change the way we wander on the this Markov Chain <span class="math">\(P\)</span> so that this chain has the desired Stationary distribution.</p>
<p>To do this we:</p>
<ol>
<li>Start at a random initial State <span class="math">\(i\)</span>.</li>
<li>Randomly pick a new <em>Proposal State</em> by looking at the transition probabilities in the ith row of the transition matrix Q.</li>
<li>Compute an measure called the <em>Acceptance Probability</em> which is defined as:
<center><div class="math">$$a_{ij} = min(s_jp_{ji}/s_{i}p_{ij},1)$$</div></center></li>
<li>Now Flip a coin that lands head with probability <span class="math">\(a_{ij}\)</span>. If the coin comes up heads, accept the proposal i.e move to next state else reject the proposal i.e. stay at the current state.</li>
<li>Repeat for a long time</li>
</ol>
<p>After a long time this chain will converge and will have a stationary distribution <span class="math">\(s\)</span>. <strong>We can then use the states of the chain as the sample from any distribution.</strong></p>
<p>While doing this to sample the Beta Distribution, the only time we are using the PDF is to find the acceptance probability and in that we divide <span class="math">\(s_j\)</span> by <span class="math">\(s_i\)</span>, i.e. the <strong>normalizing constant <span class="math">\(C\)</span> gets cancelled</strong>.</p>
<p>Now Let's Talk about the intuition. For the Intuition I am quoting an <a href="http://stats.stackexchange.com/a/12657">Answer</a> from the site Stack Exchange,as this was the best intuitive explanation that I could find:
<blockquote>
I think there's a nice and simple intuition to be gained from the (independence-chain) Metropolis-Hastings algorithm.
<br>
<br>
First, what's the goal? The goal of MCMC is to <strong>draw samples from some probability distribution</strong> without having to know its exact height at any point(We don't need to know C). The way MCMC achieves this is to <strong>"wander around" on that distribution in such a way that the amount of time spent in each location is proportional to the height of the distribution</strong>. If the "wandering around" process is set up correctly, you can make sure that this proportionality (between time spent and height of the distribution) is achieved.
<br>
<br>
Intuitively, what we want to do is to to walk around on some (lumpy) surface in such a way that the amount of time we spend (or # samples drawn) in each location is proportional to the height of the surface at that location. So, e.g., we'd like to spend twice as much time on a hilltop that's at an altitude of 100m as we do on a nearby hill that's at an altitude of 50m. The nice thing is that we can do this even if we don't know the absolute heights of points on the surface: all we have to know are the relative heights. e.g., if one hilltop A is twice as high as hilltop B, then we'd like to spend twice as much time at A as we spend at B.
<br>
<br>
The simplest variant of the Metropolis-Hastings algorithm (independence chain sampling) achieves this as follows: assume that in every (discrete) time-step, we pick a random new "proposed" location (selected uniformly across the entire surface). If the proposed location is higher than where we're standing now, move to it. If the proposed location is lower, then move to the new location with probability p, where p is the ratio of the height of that point to the height of the current location. (i.e., flip a coin with a probability p of getting heads; if it comes up heads, move to the new location; if it comes up tails, stay where we are). Keep a list of the locations you've been at on every time step, and that list will (asyptotically) have the right proportion of time spent in each part of the surface. (And for the A and B hills described above, you'll end up with twice the probability of moving from B to A as you have of moving from A to B).
<br>
<br>
There are more complicated schemes for proposing new locations and the rules for accepting them, but the basic idea is still: <strong>(1) pick a new "proposed" location; (2) figure out how much higher or lower that location is compared to your current location; (3) probabilistically stay put or move to that location in a way that respects the overall goal of spending time proportional to height of the location. """</strong>
</blockquote></p>
<h2>Sampling from Beta Distribution</h2>
<p>Now Let's Move on to the problem of Simulating from Beta Distribution. Now Beta Distribution is a continuous Distribution on [0,1] and it can have infinite states on [0,1]. </p>
<p>Lets Assume an arbitrary Markov Chain P with infinite states on [0,1] having transition Matrix Q such that $Q_{ij} = Q_{ji} = $ All entries in Matrix. We don't really need the Matrix Q as we will see later, But I want to keep the problem description as close to the algorihm we suggested.</p>
<ol>
<li>Start at a random <strong>initial State <span class="math">\(i\)</span></strong> given by Unif(0,1).</li>
<li>Randomly pick a new <strong>Proposal State</strong> by looking at the transition probabilities in the ith row of the transition matrix Q. Lets say we pick up another Unif(0,1) state as a proposal state <span class="math">\(j\)</span>.</li>
<li>Compute an measure called the <strong>Acceptance Probability</strong> :
<center><div class="math">$$a_{ij} = min(s_jp_{ji}/s_{i}p_{ij},1)$$</div></center> which is, <center><div class="math">$$a_{ij} = min(s_j/s_i,1)$$</div></center> where, <center><div class="math">$$s_i = Ci^{\alpha -1}(1-i)^{\beta -1}$$</div></center> and, <center><div class="math">$$s_j = Cj^{\alpha -1}(1-j)^{\beta -1}$$</div></center></li>
<li>Now Flip a coin that lands head with probability <span class="math">\(a_{ij}\)</span>. If the coin comes up heads, accept the proposal i.e move to next state else reject the proposal i.e. stay at the current state.</li>
<li>Repeat for a long time</li>
</ol>
<p>So enough with theory, Let's Move on to python to create our Beta Simulations Now....</p>
<pre style="font-size:60%">
<code class="python">import random
# Lets define our Beta Function to generate s for any particular state. We don't care for the normalizing constant here.
def beta_s(w,a,b):
    return w**(a-1)*(1-w)**(b-1)

# This Function returns True if the coin with probability P of heads comes heads when flipped.
def random_coin(p):
    unif = random.uniform(0,1)
    if unif>=p:
        return False
    else:
        return True

# This Function runs the MCMC chain for Beta Distribution.
def beta_mcmc(N_hops,a,b):
    states = []
    cur = random.uniform(0,1)
    for i in range(0,N_hops):
        states.append(cur)
        next = random.uniform(0,1)
        ap = min(beta_s(next,a,b)/beta_s(cur,a,b),1) # Calculate the acceptance probability
        if random_coin(ap):
            cur = next
    return states[-1000:] # Returns the last 100 states of the chain
</code></pre>

<p>Let us check our results of the MCMC Sampled Beta distribution against the actual beta distribution.</p>
<pre style="font-size:60%">
<code class="python">import numpy as np
import pylab as pl
import scipy.special as ss
%matplotlib inline
pl.rcParams['figure.figsize'] = (17.0, 4.0)

# Actual Beta PDF.
def beta(a, b, i):
    e1 = ss.gamma(a + b)
    e2 = ss.gamma(a)
    e3 = ss.gamma(b)
    e4 = i ** (a - 1)
    e5 = (1 - i) ** (b - 1)
    return (e1/(e2*e3)) * e4 * e5

# Create a function to plot Actual Beta PDF with the Beta Sampled from MCMC Chain.
def plot_beta(a, b):
    Ly = []
    Lx = []
    i_list = np.mgrid[0:1:100j]
    for i in i_list:
        Lx.append(i)
        Ly.append(beta(a, b, i))
    pl.plot(Lx, Ly, label="Real Distribution: a="+str(a)+", b="+str(b))
    pl.hist(beta_mcmc(100000,a,b),normed=True,bins =25, histtype='step',label="Simulated_MCMC: a="+str(a)+", b="+str(b))
    pl.legend()
    pl.show()

plot_beta(0.1, 0.1)
plot_beta(1, 1)
plot_beta(2, 3)
</code></pre>

<div style="margin-top: -9px; margin-bottom: 30px;">
<img src="/images/graphs.png">
</div>

<p>As we can see our sampled beta values closely resemble the beta distribution.</p>
<p>So MCMC Methods are useful for the following basic problems.</p>
<ol>
<li>Simulating from a Random Variable PDF. Example: Simulate from a Beta(0.5,0.5) or from a Normal(0,1).</li>
<li>Solve problems with a large state space.For Example: Knapsack Problem, Encrytion Cipher etc. We will work on this in the <a href="http://mlwhiz.com/blog/2015/08/21/MCMC_Algorithms_Cryptography/">Next Blog Post</a> as this one has already gotten bigger than what I expected.</li>
</ol>
<p>Till Then Ciao!!!!!!</p>
<h2>References and Sources:</h2>
<ol>
<li><a href="http://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science-ebook/dp/B00MMOJ19I">Introduction to Probability Joseph K Blitzstein, Jessica Hwang</a></li>
<li><a href="https://en.wikipedia.org/wiki/">Wikipedia</a></li>
<li><a href="http://stats.stackexchange.com/a/12657">StackExchange</a></li>
</ol>
<p>One of the newest and best resources that you can keep an eye on is the <a href="https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;utm_content=2&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0">Bayesian Methods for Machine Learning</a> course in the <a href="https://www.coursera.org/specializations/aml?siteID=lVarvwc5BD0-AqkGMb7JzoCMW0Np1uLfCA&amp;utm_content=2&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=lVarvwc5BD0">Advanced machine learning specialization</a> created jointly by Kazanova(Number 3 Kaggler at the time of writing)</p>
<p>Apart from that I also found a course on <strong><a href="https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;offerid=495576.8910375858&amp;type=2&amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Fbayesian">Bayesian Statistics on Coursera</a></strong>. In the process of doing it right now so couldn't really comment on it. But since I had done an course on <strong><a href="https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;offerid=495576.8839843074&amp;type=2&amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Finferential-statistics-intro">Inferential Statistics</a></strong> taught by the same professor before(Mine Ã‡etinkaya-Rundel), I am very hopeful for this course. Let's see.</p>
<p>Also look out for these two books to learn more about MCMC. I have not yet read them whole but still I liked whatever I read:</p>
<div style="margin-left:1em ; text-align: center;">

<a target="_blank"  href="https://www.amazon.com/gp/product/1439840954/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1439840954&linkCode=as2&tag=mlwhizcon-20&linkId=d55979088adc0aabeaed88f4f14b48b6"><img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&MarketPlace=US&ASIN=1439840954&ServiceVersion=20070822&ID=AsinImage&WS=1&Format=_SL250_&tag=mlwhizcon-20" ></a><img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&l=am2&o=1&a=1439840954" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" />
</t></t>
<a target="_blank"  href="https://www.amazon.com/gp/product/1584885874/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1584885874&linkCode=as2&tag=mlwhizcon-20&linkId=ee3e2a0bc99359d6c5db0463ab1abb13"><img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&MarketPlace=US&ASIN=1584885874&ServiceVersion=20070822&ID=AsinImage&WS=1&Format=_SL250_&tag=mlwhizcon-20" ></a><img src="//ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&l=am2&o=1&a=1584885874" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" />
</div>

<p>Both these books are pretty high level and hard on math. But these are the best texts out there too. :)</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processClass: 'mathjax', " +
        "        ignoreClass: 'no-mathjax', " +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script></div>

<a href="https://click.linksynergy.com/fs-bin/click?id=lVarvwc5BD0&offerid=495576.362&subid=0&type=4"><IMG border="0"   alt="Online data science courses to jumpstart your future." src="https://ad.linksynergy.com/fs-bin/show?id=lVarvwc5BD0&bids=495576.362&subid=0&type=4&gridnum=16"></a>    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">Rahul Agarwal</span>
  </span>
<time datetime="2015-08-19T13:43:00" pubdate>Aug 19, 2015</time>  <span class="categories">
    <a class="category" href="https://mlwhiz.com/tag/statistics.html">Statistics</a>
    <a class="category" href="https://mlwhiz.com/tag/python.html">python</a>
  </span>
  <br>
  <span style="font-size:14px;color:green">
  Advertiser Disclosure: All Amazon links are affiliate links, which means I receive compensation for any purchases through them. You do not have to purchase via my links, but you support me if you do.
  </span>
</p><div class="shareaholic-canvas" data-app="share_buttons" data-app-id="28372088"></div>

<!--
<div class="sharing">
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://mlwhiz.com/blog/2015/08/19/MCMC_Algorithms_Beta_Distribution/" data-via="MLWhiz" data-counturl="mlwhiz.com/blog/2015/08/19/MCMC_Algorithms_Beta_Distribution/" >Tweet</a>
  <div class="g-plusone" data-size="medium"></div>
    <div class="fb-like" data-send="true" data-width="450" data-show-faces="false"></div>
</div>
-->    </footer>
  </article>
  
  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div>
  </section>

</div>
<aside class="sidebar">
  <section>

     <!-- Bbuy coffee ko-fi Form -->
  <div style="text-align:center">    
  <a href='https://ko-fi.com/S6S3NPCD' target='_blank'><img height='36' style='border:0px;height:36px;' src='https://az743702.vo.msecnd.net/cdn/kofi4.png?v=0' border='0' alt='Buy Me a Coffee at ko-fi.com' /></a>
  </div>

    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="https://mlwhiz.com/blog/2018/12/17/text_classification/">What Kagglers are using for Text Classification</a>
      </li>
      <li class="post">
          <a href="https://mlwhiz.com/blog/2018/12/07/connected_components/">To all Data Scientists - The one Graph Algorithm you need to know</a>
      </li>
      <li class="post">
          <a href="https://mlwhiz.com/blog/2018/09/22/object_detection/">Object Detection: An End to End Theoretical Perspective</a>
      </li>
      <li class="post">
          <a href="https://mlwhiz.com/blog/2017/12/28/hyperopt_tuning_ml_model/">Hyperopt - A bayesian Parameter Tuning Framework</a>
      </li>
      <li class="post">
          <a href="https://mlwhiz.com/blog/2017/12/26/How_to_win_a_data_science_competition/">Using XGBoost for time series prediction tasks</a>
      </li>
      <li class="post">
          <a href="https://mlwhiz.com/blog/2017/09/14/discrete_distributions/">The story of every distribution - Discrete Distributions</a>
      </li>
      <li class="post">
          <a href="https://mlwhiz.com/blog/2017/09/14/kaggle_tricks/">Good Feature Building Techniques - Tricks for Kaggle - My Kaggle Code Repository</a>
      </li>
    </ul>
  </section>
<!--
  <section>

    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="https://mlwhiz.com/category/big-data.html">Big Data</a></li>
        <li><a href="https://mlwhiz.com/category/data-science-statistics-resources-learning-books-python-distributions-statistical-inference-hadoop-spark-deep-learning.html">Data Science, Statistics, Resources, Learning, Books, Python, Distributions, Statistical Inference, hadoop, spark, deep learning</a></li>
        <li><a href="https://mlwhiz.com/category/deep-learning-image.html">deep learning, image</a></li>
        <li><a href="https://mlwhiz.com/category/hadoop.html">Hadoop</a></li>
        <li><a href="https://mlwhiz.com/category/machine-learning-statistics-linear-regression.html">Machine Learning, Statistics, Linear Regression</a></li>
        <li><a href="https://mlwhiz.com/category/pyspark-python.html">pyspark, python</a></li>
        <li><a href="https://mlwhiz.com/category/python.html">Python</a></li>
        <li><a href="https://mlwhiz.com/category/python-bash-tools.html">Python, bash, tools</a></li>
        <li><a href="https://mlwhiz.com/category/python-flask-ml.html">Python, Flask, ML</a></li>
        <li><a href="https://mlwhiz.com/category/python-kaggle-coursera.html">Python, kaggle, coursera,</a></li>
        <li><a href="https://mlwhiz.com/category/python-machine-learning.html">Python, machine learning</a></li>
        <li><a href="https://mlwhiz.com/category/python-machine-learning-hyperopt-bayesian-xgboost.html">Python, machine learning, hyperopt, bayesian, xgboost</a></li>
        <li><a href="https://mlwhiz.com/category/python-machine-learning-probability.html">Python, machine learning, probability</a></li>
        <li><a href="https://mlwhiz.com/category/python-nlp-algorithms-kaggle.html">Python, NLP, Algorithms, Kaggle</a></li>
        <li><a href="https://mlwhiz.com/category/python-nlp-algorithms-kaggle-tilt.html">Python, NLP, Algorithms, Kaggle ,TILT</a></li>
        <li><a href="https://mlwhiz.com/category/python-statistics.html">Python, Statistics</a></li>
        <li><a href="https://mlwhiz.com/category/python-visualization-statistics.html">Python, Visualization, Statistics</a></li>
        <li><a href="https://mlwhiz.com/category/statistics.html">Statistics</a></li>
        <li><a href="https://mlwhiz.com/category/statisticsdata-science.html">statistics,data science</a></li>
        <li><a href="https://mlwhiz.com/category/statisticsprobability.html">statistics,probability</a></li>
        <li><a href="https://mlwhiz.com/category/vw.html">VW</a></li>
    </ul>
  </section>


  <section>
  <h1>Tags</h1>
    <a href="https://mlwhiz.com/tag/.html"></a>,    <a href="https://mlwhiz.com/tag/nlp.html">NLP</a>,    <a href="https://mlwhiz.com/tag/data-munging.html">data munging</a>,    <a href="https://mlwhiz.com/tag/attention-models-for-text.html">Attention models for text</a>,    <a href="https://mlwhiz.com/tag/data-science.html">data science</a>,    <a href="https://mlwhiz.com/tag/probability.html">probability</a>,    <a href="https://mlwhiz.com/tag/big-data.html">Big Data</a>,    <a href="https://mlwhiz.com/tag/cdf.html">cdf</a>,    <a href="https://mlwhiz.com/tag/dataframe.html">dataframe</a>,    <a href="https://mlwhiz.com/tag/deep-learning.html">deep learning</a>,    <a href="https://mlwhiz.com/tag/rcnn.html">rcnn</a>,    <a href="https://mlwhiz.com/tag/books.html">Books</a>,    <a href="https://mlwhiz.com/tag/ggplot2.html">ggplot2</a>,    <a href="https://mlwhiz.com/tag/text-classification.html">text classification</a>,    <a href="https://mlwhiz.com/tag/learning.html">learning</a>,    <a href="https://mlwhiz.com/tag/statistic.html">Statistic</a>,    <a href="https://mlwhiz.com/tag/bidirectional-rnn.html">bidirectional RNN</a>,    <a href="https://mlwhiz.com/tag/graph-algorithms.html">graph algorithms</a>,    <a href="https://mlwhiz.com/tag/distributions.html">distributions</a>,    <a href="https://mlwhiz.com/tag/hyperparameter-tuning.html">hyperparameter tuning</a>,    <a href="https://mlwhiz.com/tag/stanford-software-seaborn.html">stanford software seaborn</a>,    <a href="https://mlwhiz.com/tag/apache-spark.html">Apache Spark</a>,    <a href="https://mlwhiz.com/tag/statistics.html">Statistics</a>,    <a href="https://mlwhiz.com/tag/vw.html">vw</a>,    <a href="https://mlwhiz.com/tag/pairplot-seaborn.html">pairplot seaborn</a>,    <a href="https://mlwhiz.com/tag/bidirectional-gru-for-text.html">bidirectional GRU for text</a>,    <a href="https://mlwhiz.com/tag/seaborn.html">Seaborn</a>,    <a href="https://mlwhiz.com/tag/hadoop.html">hadoop</a>,    <a href="https://mlwhiz.com/tag/categorical-data.html">categorical data</a>,    <a href="https://mlwhiz.com/tag/birnn.html">birnn</a>,    <a href="https://mlwhiz.com/tag/machine-learning.html">machine learning</a>,    <a href="https://mlwhiz.com/tag/deeplearning.html">deeplearning</a>,    <a href="https://mlwhiz.com/tag/geometric.html">geometric</a>,    <a href="https://mlwhiz.com/tag/pandas.html">pandas</a>,    <a href="https://mlwhiz.com/tag/resources.html">Resources</a>,    <a href="https://mlwhiz.com/tag/linear-regression.html">Linear Regression</a>,    <a href="https://mlwhiz.com/tag/object-detection.html">object detection</a>,    <a href="https://mlwhiz.com/tag/pyspark.html">Pyspark</a>,    <a href="https://mlwhiz.com/tag/python.html">python</a>,    <a href="https://mlwhiz.com/tag/faster-rcnn.html">faster rcnn</a>,    <a href="https://mlwhiz.com/tag/kaggle.html">Kaggle</a>,    <a href="https://mlwhiz.com/tag/matplotlib.html">Matplotlib</a>,    <a href="https://mlwhiz.com/tag/binomial.html">binomial</a>,    <a href="https://mlwhiz.com/tag/variance.html">variance</a>,    <a href="https://mlwhiz.com/tag/regplot.html">regplot</a>,    <a href="https://mlwhiz.com/tag/python-visualizations.html">Python Visualizations</a>,    <a href="https://mlwhiz.com/tag/spark.html">spark</a>,    <a href="https://mlwhiz.com/tag/cs109.html">cs109</a>,    <a href="https://mlwhiz.com/tag/bash-for-data-science.html">bash for data science</a>,    <a href="https://mlwhiz.com/tag/web-scraping.html">web scraping</a>,    <a href="https://mlwhiz.com/tag/basics.html">Basics</a>,    <a href="https://mlwhiz.com/tag/ctr.html">ctr</a>,    <a href="https://mlwhiz.com/tag/statistical-inference.html">Statistical Inference</a>,    <a href="https://mlwhiz.com/tag/expected-value.html">expected value</a>,    <a href="https://mlwhiz.com/tag/bidirectional-lstm-for-text.html">bidirectional LSTM for text</a>,    <a href="https://mlwhiz.com/tag/layman-explanations.html">Layman Explanations</a>,    <a href="https://mlwhiz.com/tag/mapreduce.html">mapreduce</a>,    <a href="https://mlwhiz.com/tag/slr.html">SLR</a>,    <a href="https://mlwhiz.com/tag/openshift.html">Openshift</a>,    <a href="https://mlwhiz.com/tag/mlr.html">MLR</a>,    <a href="https://mlwhiz.com/tag/pretrained-models.html">pretrained models</a>,    <a href="https://mlwhiz.com/tag/algorithms.html">Algorithms</a>,    <a href="https://mlwhiz.com/tag/poisson.html">poisson</a>,    <a href="https://mlwhiz.com/tag/bayesian-optimization.html">bayesian optimization</a>,    <a href="https://mlwhiz.com/tag/bash-commands.html">bash commands</a>,    <a href="https://mlwhiz.com/tag/pdf.html">pdf</a>,    <a href="https://mlwhiz.com/tag/deploy-ml-models.html">Deploy ML Models</a>,    <a href="https://mlwhiz.com/tag/lmplot-seaborn.html">lmplot seaborn</a>,    <a href="https://mlwhiz.com/tag/flaskapp.html">FlaskApp</a>  </section>
-->
<!--

    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="http://mlwhiz.com/feed.rss" type="application/rss+xml" rel="alternate">RSS</a></li>
            <li><a href="http://mlwhiz.com/atom.xml" type="application/atom+xml" rel="alternate">Atom</a></li>
            <li><a href="http://twitter.com/mlwhiz" target="_blank">twitter</a></li>
        </ul>
    </section>


<section>
    <a href="http://twitter.com/MLWhiz" class="twitter-follow-button" data-show-count="true">Follow @MLWhiz</a>
</section>
-->

  <section>




 <!-- Begin shareaholic follow -->
   <div class="shareaholic-canvas" data-app="follow_buttons" data-app-id="28033293" style="white-space: inherit;"></div>
  <!-- Begin MailChimp Signup Form -->
<link href="//cdn-images.mailchimp.com/embedcode/slim-10_7.css" rel="stylesheet" type="text/css">
<style type="text/css">
  #mc_embed_signup .button {background-color: #127edc;}
  #mc_embed_signup form {
    display: block;
    position: relative;
    text-align: left;
    padding: 10px -5px 10px 3%;}
  /* Add your own MailChimp form style overrides in your site stylesheet or in this style block.
     We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
<form action="//mlwhiz.us15.list-manage.com/subscribe/post?u=4e9962f4ce4a94818bcc2f249&amp;id=87a48fafdd" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
    <input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required>
    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_4e9962f4ce4a94818bcc2f249_87a48fafdd" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>
</section>
<!--End mc_embed_signup-->

</aside>    </div>
  </div>
  <footer role="contentinfo" style="margin-bottom:0em"><p>
  <script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&adInstanceId=93f2f4f9-cf51-415d-84af-08cbb74b178f"></script>
    Copyright &copy;  2014-2018  - Rahul Agarwal -
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p>  <script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&adInstanceId=93f2f4f9-cf51-415d-84af-08cbb74b178f"></script>
  </footer>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-54777926-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
	ga.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 'stats.g.doubleclick.net/dc.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-54777926-1');
    
    ga('send', 'pageview');
</script>
	<script type="text/javascript">
	  var disqus_shortname = 'mlwhiz';
          var disqus_identifier = '/blog/2015/08/19/MCMC_Algorithms_Beta_Distribution/';
          var disqus_url = 'https://mlwhiz.com/blog/2015/08/19/MCMC_Algorithms_Beta_Distribution/';
          var disqus_title = 'My Tryst With MCMC Algorithms';
	  (function() {
	    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	    dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
	    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	   })();
	</script>
  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
	  
    })();
  </script>
  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>
<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>
</body>

</html>