{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Vowpal Wabbit with the Avazu Clickthrough Prediction Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In online advertising, click-through rate (CTR) is a very important metric for evaluating ad performance. As a result, click prediction systems are essential and widely used for sponsored search and real-time bidding.\n",
    "\n",
    "For this competition, we have provided 11 days worth of Avazu data to build and test prediction models. Can you find a strategy that beats standard classification algorithms? The winning models from this competition will be released under an open-source \n",
    "license."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Fields\n",
    "\n",
    "\n",
    "    id: ad identifier\n",
    "    click: 0/1 for non-click/click\n",
    "    hour: format is YYMMDDHH, so 14091123 means 23:00 on Sept. 11, 2014 UTC.\n",
    "    C1 -- anonymized categorical variable\n",
    "    banner_pos\n",
    "    site_id\n",
    "    site_domain\n",
    "    site_category\n",
    "    app_id\n",
    "    app_domain\n",
    "    app_category\n",
    "    device_id\n",
    "    device_ip\n",
    "    device_model\n",
    "    device_type\n",
    "    device_conn_type\n",
    "    C14-C21 -- anonymized categorical variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the data \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string as stri\n",
    "\n",
    "#too large data not keeping it in memory.\n",
    "# will be using line by line scripting.\n",
    "#data = pd.read_csv(\"/Users/RahulAgarwal/kaggle_cpr/train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data istoo large around 6 gb , we will proceed by doing line by line analysis of data. We will try to use vowpal wabbit first of all as it is an online model and it also gives us the option of minimizing log loss as a default. It is also very fast to run and will give us quite an intuition as to how good our prediction can be.\n",
    "- I will use all the variables in the first implementation and we will rediscover things as we move on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Vowpal Wabbit\n",
    "#### Creating data in vowpal format (One Time Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def csv_to_vw(loc_csv, loc_output, train=True):\n",
    "    start = datetime.now()\n",
    "    print(\"\\nTurning %s into %s. Is_train_set? %s\"%(loc_csv,loc_output,train))\n",
    "    i = open(loc_csv, \"r\")\n",
    "    j = open(loc_output, 'wb')\n",
    "    counter=0\n",
    "    with i as infile:\n",
    "        line_count=0\n",
    "        for line in infile:\n",
    "            # to counter the header\n",
    "            if line_count==0:\n",
    "                line_count=1\n",
    "                continue\n",
    "            # The data has all categorical features\n",
    "            #numerical_features = \"\"\n",
    "            categorical_features = \"\"\n",
    "            counter = counter+1\n",
    "            #print counter\n",
    "            line = line.split(\",\")\n",
    "            if train:\n",
    "                #working on the date column. We will take day , hour\n",
    "                a = line[2]\n",
    "                new_date= datetime(int(\"20\"+a[0:2]),int(a[2:4]),int(a[4:6]))\n",
    "                day = new_date.strftime(\"%A\")\n",
    "                hour= a[6:8]\n",
    "                categorical_features += \" |hr %s\" % hour\n",
    "                categorical_features += \" |day %s\" % day\n",
    "                # 24 columns in data    \n",
    "                for i in range(3,24):\n",
    "                    if line[i] != \"\":\n",
    "                        categorical_features += \"|c%s %s\" % (str(i),line[i])\n",
    "            else:\n",
    "                a = line[1]\n",
    "                new_date= datetime(int(\"20\"+a[0:2]),int(a[2:4]),int(a[4:6]))\n",
    "                day = new_date.strftime(\"%A\")\n",
    "                hour= a[6:8]\n",
    "                categorical_features += \" |hr %s\" % hour\n",
    "                categorical_features += \" |day %s\" % day\n",
    "                for i in range(2,23):\n",
    "                    if line[i] != \"\":\n",
    "                        categorical_features += \" |c%s %s\" % (str(i+1),line[i])\n",
    "  #Creating the labels\n",
    "            #print \"a\"\n",
    "            if train: #we care about labels\n",
    "                if line[1] == \"1\":\n",
    "                    label = 1\n",
    "                else:\n",
    "                    label = -1 #we set negative label to -1\n",
    "                #print (numerical_features)\n",
    "                #print categorical_features\n",
    "                j.write( \"%s '%s %s\\n\" % (label,line[0],categorical_features))\n",
    "\n",
    "            else: #we dont care about labels\n",
    "                #print ( \"1 '%s |i%s |c%s\\n\" % (line[0],numerical_features,categorical_features) )\n",
    "                j.write( \"1 '%s %s\\n\" % (line[0],categorical_features) )\n",
    "\n",
    "  #Reporting progress\n",
    "            #print counter\n",
    "            if counter % 1000000 == 0:\n",
    "                print(\"%s\\t%s\"%(counter, str(datetime.now() - start)))\n",
    "\n",
    "    print(\"\\n %s Task execution time:\\n\\t%s\"%(counter, str(datetime.now() - start)))\n",
    "\n",
    "#csv_to_vw(\"/Users/RahulAgarwal/kaggle_cpr/train\", \"/Users/RahulAgarwal/kaggle_cpr/click.train_original_data.vw\",train=True)\n",
    "#csv_to_vw(\"/Users/RahulAgarwal/kaggle_cpr/test\", \"/Users/RahulAgarwal/kaggle_cpr/click.test_original_data.vw\",train=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Vowpal Wabbit on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Vowpal Wabbit will be run on the command line itself.\n",
    "\n",
    "Training VW:\n",
    "\n",
    "vw click.train_original_data.vw -f click.model.vw --loss_function logistic\n",
    "\n",
    "Testing VW:\n",
    "\n",
    "vw click.test_original_data.vw  -t -i click.model.vw -p click.preds.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Creating Kaggle Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def zygmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "with open(\"kaggle.click.submission.csv\",\"wb\") as outfile:\n",
    "    outfile.write(\"id,click\\n\")\n",
    "    for line in open(\"click.preds.txt\"):\n",
    "        \n",
    "        row = line.strip().split(\" \")\n",
    "        try:\n",
    "            outfile.write(\"%s,%f\\n\"%(row[1],zygmoid(float(row[0]))))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution ranked 211/371 submissions at the time and the leaderboard score was 0.4031825 while the best leaderboard score was 0.3901120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Next Steps\n",
    "\n",
    "- Create a better VW model\n",
    "    - Shuffle the data before making the model as the VW algorithm is an online learner and might have given more preference to the latest data \n",
    "    - provide high weights for clicks as data is skewed. How Much?\n",
    "    - tune VW algorithm using vw-hypersearch. What should be tuned?\n",
    "    - Use categorical features like |C1 \"C1\"&\"1\"\n",
    "\n",
    "- Create a XGBoost Model.\n",
    "- Create a Sofia-ML Model and see how it works on this data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
