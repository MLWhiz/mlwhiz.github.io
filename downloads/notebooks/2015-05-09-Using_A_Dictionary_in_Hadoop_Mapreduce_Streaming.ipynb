{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Hadoop Mapreduce Streaming Tricks and Techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have been using Hadoop a lot now a days and thought about writing some of the novel techniques that a user could use to get the most out of the Hadoop Ecosystem.\n",
    "\n",
    "\n",
    "### Using Shell Scripts to run your Programs\n",
    "<div style=\"margin-top: -9px; margin-bottom: -30px;\">\n",
    "<img src=\"/images/I-love-bash-1024x220.png\" >\n",
    "</div>\n",
    "<br>\n",
    "I am not a fan of large bash commands. The ones where you have to specify the whole path of the jar files and the such. <em>You can effectively organize your workflow by using shell scripts.</em> Now Shell scripts are not as formidable as they sound. We wont be doing programming perse using these shell scripts(Though they are pretty good at that too), we will just use them to store commands that we need to use sequentially.\n",
    "\n",
    "Below is a sample of the shell script I use to run my Mapreduce Codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"/theme/highlight/styles/default.css\">\n",
    "<script src=\"/theme/highlight/highlight.pack.js\"></script>\n",
    "<script>hljs.initHighlightingOnLoad();</script>\n",
    "<pre style=\"font-size:80%; padding:7px; margin:0em; background-color:#000000;\">\n",
    "<code class=\"bash\" style=\"background-color:#000000; color:#FFFFFF\">#!/bin/bash\n",
    "#Defining program variables\n",
    "IP=\"/data/input\"\n",
    "OP=\"/data/output\"\n",
    "HADOOP_JAR_PATH=\"/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/contrib/streaming/hadoop-streaming-2.0.0-mr1-cdh4.5.0.jar\"\n",
    "MAPPER=\"test_m.py\"\n",
    "REDUCER=\"test_r.py\"\n",
    "\n",
    "hadoop fs -rmr -skipTrash&nbsp;$OP\n",
    "hadoop jar&nbsp;$HADOOP_JAR_PATH \\\n",
    "-file&nbsp;$MAPPER -mapper \"python test_m.py\" \\\n",
    "-file&nbsp;$REDUCER -reducer \"python test_r.py\" \\\n",
    "-input&nbsp;$IP -output&nbsp;$OP\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I generally save them as test_s.sh and whenever i need to run them i simply type <code>sh test_s.sh</code>. This helps in three ways. \n",
    "<ul><li> It helps me to store hadoop commands in a manageable way. </li>\n",
    "<li> It is easy to run the mapreduce code using the shell script. </li>\n",
    "<li> <em><strong>If the code fails, I do not have to manually delete the output directory</strong></em></li>\n",
    "</ul>\n",
    "\n",
    "<blockquote>\n",
    "<em>\n",
    "The simplification of anything is always sensational.\n",
    "<br></em>\n",
    "<small>Gilbert K. Chesterton</small>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Using Distributed Cache to provide mapper with a dictionary\n",
    "<div style=\"margin-top: -9px; margin-bottom: -30px;\">\n",
    "<img src=\"/images/Game-Of-Thrones-Wallpaper-House-Sigils-1.png\">\n",
    "</div>\n",
    "<br>\n",
    "Often times it happens that you want that your Hadoop Mapreduce program is able to access some static file. This static file could be a dictionary, could be parameters for the program or could be anything. What distributed cache does is that it provides this file to all the mapper nodes so that you can use that file in any way across all your mappers.\n",
    "Now this concept although simple would help you to think about Mapreduce in a whole new light.\n",
    "Lets start with an example. \n",
    "Supppose you have to create a sample Mapreduce program that reads a big file containing the information about all the characters in <a href=\"http://www.hbo.com/game-of-thrones\">Game of Thrones</a> stored as <strong><code>\"/data/characters/\"</code></strong>:\n",
    "<div style=\"width: 50%; margin: 0 auto;\">\n",
    "<table class=\"table\">\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Cust_ID</th>\n",
    "<th>User_Name</th>\n",
    "<th>House</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>Daenerys Targaryen</td>\n",
    "<td>Targaryen</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>2</td>\n",
    "<td>Tyrion Lannister</td>\n",
    "<td>Lannister</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>3</td>\n",
    "<td>Cersei Lannister</td>\n",
    "<td>Lannister</td>\n",
    "</tr>\n",
    "<tr class=\"warning\">\n",
    "<td>4</td>\n",
    "<td>Robert Baratheon</td>\n",
    "<td>Baratheon</td>\n",
    "</tr>\n",
    "<tr class=\"warning\">\n",
    "<td>5</td>\n",
    "<td>Robb Stark</td>\n",
    "<td>Stark</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "But you dont want to use the dead characters in the file for the analysis you want to do. <em>You want to count the number of living characters in Game of Thrones grouped by their House</em>. (I know its easy!!!!!)\n",
    "One thing you could do is include an if statement in your Mapper Code which checks if the persons ID is 4 then exclude it from the mapper and such.\n",
    "But the problem is that you would have to do it again and again for the same analysis as characters die like flies when it comes to George RR Martin.(Also where is the fun in that)\n",
    "So you create a file which contains the Ids of all the dead characters at <strong><code>\"/data/dead_characters.txt\"</code></strong>:\n",
    "\n",
    "<div style=\"width: 50%; margin: 0 auto;\">\n",
    "<table class=\"table\">\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Died</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>4</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>5</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "Whenever you have to run the analysis you can just add to this file and you wont have to change anything in the code.\n",
    "Also sometimes this file would be long and you would not want to clutter your code with IDs and such.\n",
    "\n",
    "So How Would we do it. \n",
    "Let's go in a step by step way around this.\n",
    "We will create a shell script, a mapper script and a reducer script for this task.\n",
    "\n",
    "#####1) Shell Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"/theme/highlight/styles/default.css\">\n",
    "<script src=\"/theme/highlight/highlight.pack.js\"></script>\n",
    "<script>hljs.initHighlightingOnLoad();</script>\n",
    "<pre style=\"font-size:80%; padding:7px; margin:0em; background-color:#000000;\">\n",
    "<code class=\"bash\" style=\"background-color:#000000; color:#FFFFFF\">#!/bin/bash\n",
    "#Defining program variables\n",
    "DC=\"/data/dead_characters.txt\"\n",
    "IP=\"/data/characters\"\n",
    "OP=\"/data/output\"\n",
    "HADOOP_JAR_PATH=\"/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/contrib/streaming/hadoop-streaming-2.0.0-mr1-cdh4.5.0.jar\"\n",
    "MAPPER=\"got_living_m.py\"\n",
    "REDUCER=\"got_living_r.py\"\n",
    "\n",
    "hadoop jar&nbsp;$HADOOP_JAR_PATH \\\n",
    "-file&nbsp;$MAPPER -mapper \"python got_living_m.py\" \\\n",
    "-file&nbsp;$REDUCER -reducer \"python got_living_r.py\" \\\n",
    "-cacheFile&nbsp;$DC#ref \\\n",
    "-input&nbsp;$IP -output&nbsp;$OP\n",
    "</code></pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we use the <code>\"-cacheFile\"</code> option here. We have specified that we will refer to the file that has been provided in the Distributed cache as <code>#ref</code>. \n",
    "\n",
    "Next is our Mapper Script.\n",
    "\n",
    "#####2) Mapper Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"/theme/highlight/styles/default.css\">\n",
    "<script src=\"/theme/highlight/highlight.pack.js\"></script>\n",
    "<script>hljs.initHighlightingOnLoad();</script>\n",
    "<pre style=\"font-size:80%; padding:7px; margin:0em; background-color:#000000;\">\n",
    "<code class=\"python\" style=\"background-color:#000000; color:#FFFFFF\">import sys\n",
    "dead_ids = set()\n",
    "\n",
    "def read_cache():\n",
    "\tfor line in open('ref'):\n",
    "\t\tid = line.strip()\n",
    "\t\tdead_ids.add(id)\n",
    "\n",
    "read_cache()\n",
    "\n",
    "for line in sys.stdin:\n",
    "\trec = line.strip().split(\"|\") # Split using Delimiter \"|\"\n",
    "\tid = rec[0]\n",
    "    house = rec[2]\n",
    "    if id not in dead_ids:\n",
    "    \tprint \"%s\\t%s\" % (house,1)\n",
    "</code></pre>\n",
    "And our Reducer Script.\n",
    "\n",
    "#####3) Reducer Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"/theme/highlight/styles/darkula.css\">\n",
    "<script src=\"/theme/highlight/highlight.pack.js\"></script>\n",
    "<script>hljs.initHighlightingOnLoad();</script>\n",
    "<pre style=\"font-size:80%; padding:7px; margin:0em; background-color:#000000;\">\n",
    "<code class=\"python\" style=\"background-color:#000000; color:#FFFFFF\">import sys\n",
    "current_key = None\n",
    "key = None\n",
    "count = 0\n",
    "\n",
    "for line in sys.stdin:\n",
    "\tline = line.strip()\n",
    "\trec = line.split('\\t')\n",
    "\tkey = rec[0]\t\n",
    "\tvalue = int(rec[1])\n",
    "\t\n",
    "\tif current_key == key:\n",
    "\t\tcount += value\n",
    "\telse:\n",
    "\t\tif current_key:\n",
    "\t\t\tprint \"%s:%s\" %(key,str(count))\t\t\n",
    "\t\tcurrent_key = key\n",
    "\t\tcount = value\n",
    "\n",
    "if current_key == key:\n",
    "    print \"%s:%s\" %(key,str(count))\t\n",
    "</code>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a simple program and the output will be just what you expected and not very exciting. <em><strong>But the Technique itself solves a variety of common problems. You can use it to pass any big dictionary to your Mapreduce Program</strong></em>. Atleast thats what I use this feature mostly for.\n",
    "Hope You liked it. Will try to expand this post with more tricks.\n",
    "\n",
    "The codes for this post are posted at github <a href=\"https://github.com/MLWhiz/Hadoop-Mapreduce-Tricks\">here</a>.\n",
    "\n",
    "Other Great Learning Resources For Hadoop:\n",
    "<ul>\n",
    "<li>\n",
    "<a href=\"http://www.google.co.in/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0CB0QFjAA&url=http%3A%2F%2Fwww.michael-noll.com%2Ftutorials%2Fwriting-an-hadoop-mapreduce-program-in-python%2F&ei=8RRVVdP2IMe0uQShsYDYBg&usg=AFQjCNH3DqrlSIG8D-K8jgQWTALic1no5A&sig2=BivwTW6mdJs5c9w9VaSK2Q&bvm=bv.93112503,d.c2E\">Michael Noll's Hadoop Mapreduce Tutorial</a>\n",
    "</li>\n",
    "<li>\n",
    "<a href=\"http://www.google.co.in/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0CCMQFjAB&url=http%3A%2F%2Fhadoop.apache.org%2Fdocs%2Fr1.2.1%2Fstreaming.html&ei=8RRVVdP2IMe0uQShsYDYBg&usg=AFQjCNEIB4jmqcBs-GepHdn7DRxqTI9zXA&sig2=nYkAnDjjjaum5YVlYuMUJQ&bvm=bv.93112503,d.c2E\">Apache's Hadoop Streaming Documentation</a>\n",
    "</li>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
